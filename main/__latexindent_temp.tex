%\documentclass[oneside,reqno,12pt]{amsart}





\documentclass[b5paper,draft,openbib,12pt]{memoir} 
%\documentclass[b5paper,openbib,12pt]{memoir} 


 
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{bbm}
\usepackage{graphicx}
\usepackage{epsfig, float}
\usepackage{pgf,tikz,pgfplots}
\usepackage{slashed}
\usepackage{eurosym}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathabx}
\usepackage{enumitem}
\usepackage{longtable}
\usepackage[mathscr]{eucal}
\usepackage{cancel}
\usepackage{lipsum}
\usepackage{bm}
\usepackage{scalerel}


%commutative diagram
\usepackage{amsmath,amscd}
%picture
\usepackage{wrapfig}

\usepackage[unicode=true, pdfusetitle, bookmarks=true,
  bookmarksnumbered=false, bookmarksopen=false, breaklinks=true, 
  pdfborder={0 0 0}, backref=false, colorlinks=true, linkcolor=blue,
  citecolor=blue, urlcolor=blue]{hyperref}
\hypersetup{final}
%needed to have hyperlinks in draft mode


% \numberwithin{equation}{section}
\allowdisplaybreaks[1]

\newtheorem{Def}{Definition}
\newtheorem{axiom}[Def]{Axiom}
\newtheorem{fact}[Def]{Fact}
\newtheorem{Conj}[Def]{Conjecture}
\newtheorem{Thm}[Def]{Theorem}
\newtheorem{Prp}[Def]{Proposition}
\newtheorem{Lemma}[Def]{Lemma}
\newtheorem{Remark}[Def]{Remark}
\newtheorem{Corollary}[Def]{Corollary}
\newtheorem{Example}[Def]{Example}
\newtheorem{Assumption}[Def]{Assumption}
\newenvironment{Remarks}[1][Remarks:]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newcommand{\D}{\dagger}
\newcommand{\tc}{\textcolor{red}}
\newcommand{\tb}{\textcolor{blue}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\M}{\mathbb{M}_0^+}
\newcommand{\id}{\mathbbm{1}}
\newcommand{\hastobe}{\stackrel{!}{=}}
\newcommand{\vx}{{\vec{x}}}
\newcommand{\vy}{\vec{y}}
\newcommand{\vz}{\vec{z}}
\newcommand{\vb}{\vec{b}}
\newcommand{\Banach}{\mathcal{B}}
\newcommand{\weightf}{\bm{w}}

\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\ret}{ret}
\DeclareMathOperator{\sym}{sym}
\DeclareMathOperator{\free}{{free}}
\DeclareMathOperator*{\supp}{supp}
\DeclareMathOperator*{\esssup}{ess \, sup}
\DeclareMathOperator{\past}{past}
\DeclareMathOperator{\future}{future}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\erf}{erf}
\DeclareMathOperator{\erfi}{erfi}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\ag}{ag}
\DeclareMathOperator{\AG}{AG}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\ev}{ev}
\DeclareMathOperator{\odd}{odd}
\DeclareMathOperator{\term}{Term}


% Annotations
\usepackage[colorinlistoftodos,shadow,textsize=scriptsize,textwidth=2.5cm]{todonotes}
\newcommand{\noch}[1]{ \todo[color=blue!20]{Todo: #1} }
\newcommand{\black}{ \color{black} }


\renewcommand\chapterheadstart{
\vspace *{\beforechapskip}
\hrulefill
\vskip 0pt
}

\renewcommand\afterchaptertitle{%
\vskip 0pt
\hrulefill
\par \nobreak  \vskip  \afterchapskip  } 


\setsecnumdepth{all}


%all divisions are numbered in the text body

\parindent 0cm

\begin{document}



\frontmatter

\title{On Relativistic Interaction of Electric Charges and External Fields in Quantum Electrodynamics}
%\subtitle{\footnotesize{Rigorous Control of the Scattering-Matrix Expansion}}
\author{M. Nöth}
\maketitle



\newpage 
{\large \textbf{Abstract}}\\
The main subject of this thesis is the problem 
of introducing interactions 
into relativistic quantum mechanics. 
This problem has many facets, two of which will be discussed.\\


The first one deals with a recent relativistically invariant 
integral equation for multi-time wavefunctions 
by Lienert~\cite{direct_interaction_quantum}. From a 
mathematical point of view this proposal is promising, since 
variants of it have been shown to be mathematically well-defined. 
In this thesis, firstly, previous 
results on existence and uniqueness of solutions of a variant of 
this equation for scalar particles  
are extended to include more realistic types of interaction. 

Secondly,
a proof of existence and uniqueness of solutions of another 
variant that allows to treat spin 1/2 particles is provided. \\

The second facet concerns interactions in the context of a 
variable number of particles.
Following famous works of Dirac\cite{dirac1934theorie},
Feynman\cite{feynman1949theory} and Schwinger\cite{schwinger1951gauge}, 
we
treat external electrodynamic fields in an otherwise free 
quantum field theory of electrons. In previous results, candidates for 
the time evolution operator have been constructed in this setting.
This construction is unique up to a phase, which may 
depend on the external field. This phase affects the current and 
should thus be identitied. In this work, this problem  
is addressed by a geometric 
construction assuming a certain causality condition.

Secondly, a compact formula for the  
scattering operator in terms of the corresponding one-particle 
scattering operator is provided and shown to be well-defined, 
assuming certain conditions on the external field.

Finally, the particular approach to quantum field theory employed
in this thesis is related to the one commonly used in 
the setting of quantum field theory on curved spacetimes based on 
Hadamrd states. The 
central objects of these two approaches and their canonical 
equivalence classes are juxtaposed and rigorous constructions of how 
the central object of one approach can be inferred from the other 
are provided. 

\newpage

{\large \textbf{Zusammenfassung}}\\
\textcolor{red}{erst neu schreiben wenn englische version passt}

Das Hauptthema dieser Arbeit sind die Schwierigkeiten die 
dabei \linebreak auftreten Wechselwirkungen in die relativistische 
Quantenmechanik einzuführen. Dieses Problem weist viele Facetten auf. 
Zwei dieser Facetten werden bearbeitet.

In der Ersten wird eine kürzlich von 
Lienert\cite{direct_interaction_quantum} vorgestellten 
relativistisch invariante Integralgleichung für Wellenfunktionen 
für mehrere Zeitkoordinaten thematisiert. Dies ist eine Gleichung für 
Fermionen welche direkt entlang lichtartiger Konfigurationen 
wechselwirken. In dieser Arbeit werden zunächst bestehende Resultate über 
Existenz und Eindeutigkeit von Lösungen einer Variante dieser 
Gleichung für skalare Teilchen auf realistische Wechselwirkungen
erweitert. 
Weiterhin wird ein erstes Resultat über Existenz und 
Eindeutigkeit von Lösungen für eine Variante der Gleichung 
für Dirac Teilchen bewiesen.

Die zweite Facette handelt von Wechselwirkung im Kontext 
veränderlicher Teilchenzahl.
Als ersten Schritt in 
Richtung einer wechselwirkenden Theorie führen wir ein externes 
elektromagnetisches Feld in eine ansonsten freie Quantenfeldtheorie (QFT)
ein. Frühere Resultate konstruierten 
Zeitentwicklungsoperatoren bis auf eine 
Phase eindeutig, welche vom externen Feld abhängen kann.
In dieser Arbeit wird diese Phase 
durch eine geometrische 
Konstruktion partiell bestimmt.
Kausalität spielt hierbei eine Rolle.

Anschließend wird eine Formel für den Streuoperator 
als Funktion des Einteilchenstreuoperators angegeben und
dessen Wohldefiniertheit gezeigt.

Schließlich wird die hier verwendete Formulierung der 
QFT mit der in der QFT auf 
gekrümmter Raumzeit üblichen algebraischen Formulierung 
verglichen. Dabei werden die zentralen Objekte
 und deren 
natürliche Äquivalenzklassen betrachtet.
Zusätzlich wird bewiesen wie das zentrale Objekt einer 
Formulierung aus dem der jeweils anderen hervorgeht. 


\newpage

%\vskip.5cm
%\thispagestyle{empty}

\begin{center}
  \textbf{Notes on Style}
\end{center}
I want to follow 
the example of the textbooks I enjoy reading 
which invite the reader to 
follow jointly the line of arguments
together with the text. So I will mostly be using 
the plural to refer to the reader as well as myself.


\vspace{0.5cm}
Furthermore, the right-hand side of equations will be referred to 
by the number of the equation or estimate in parenthesis. 
These referenes will also 
be used inside other equations and estimates.


\newpage 
\tableofcontents

\newpage



\mainmatter

\chapter{Introduction}



Interacting relativistic quantum physics in general and 
Quantum Field Theory (QFT) in particular has the curious
property that on the one hand it has been applied 
to predict the outcomes of experiments 
at particle accelerators such as the Large Hadron 
Collider with extraordinary success, on the other hand 
there is still no rigorous framework.  
%The free theory; however, is well understood see e.g. 
%\cite{derezinski2013mathematics} for an overview of the 
%rigorous mathematical results. 
Bearing this in mind, we 
might ask ourselves what kinds of interaction can be 
rigorously defined in a relativistic quantum mechanical 
setting at all. We are going to describe two possible 
answers in detail.

\begin{enumerate}
\item The first kind of interaction is introduced for  
a system of \(N\in\mathbb{N}\) persistent particles.
In order for the wavefunction of this system 
to transform covariantly with respect to Poincaré transforms 
we will consider it a
function of \(N\) spacetime points \(x_i\in\mathbb{R}^4\).
This \emph{multi-time} formulation 
goes back to Dirac \cite{dirac_32}. 
It heavily inspired works essential for the 
development of Quantum Electrodynamics such as 
that of Tomonaga \cite{tomonaga}
and has inspired research since then, see e.g.
\cite{marx_1974,2bdem} and \cite{dice_paper} for an overview. 
A natural way of introducing interaction in this setting 
would be to let the wavefunction 
solve \(N\) Dirac equations each minimally
coupled to a multiplication operator; however, recent no-go theorems 
\cite{nogo_potentials,deckert_nickel_2016} show that 
such systems are either not interacting or not Poincaré invariant.
The approach we will follow in chapter \ref{chap: direct interaction}
bypasses those no-go theorem in 
\cite{nogo_potentials,deckert_nickel_2016} 
by introducing only a single integral equation 
for the wavefunction of the particles. The equation under consideration 
will be of the type 
\begin{align}\label{eq:matt}
  \psi&(x_1,x_2) = \psi^{\free}(x_1,x_2)+i\, \frac{e_1e_2}{4\pi} \int d^4 x_1' \, d^4 x_2' \\\nonumber
  & \times \mathscr{S}^{\ret}_1(x_1-x_1') \mathscr{S}^{\ret}_2(x_2-x_2') \, \gamma_1^\mu \gamma_{2,\mu}\delta((x_1'-x_2')^2) \psi(x_1',x_2'),
\end{align}
of Lienert\cite{direct_interaction_quantum} for the wavefunction 
\(\psi\) of two spin 1/2 particles. 
Furthermore, subscripts \(1\) and \(2\) refer to quantities associated with 
the respective particle: \(e_k\) is the electric charge,
 \(\gamma_{k}^\alpha\) generate a representation of the Clifford algebra 
and \(\mathscr{S}^{\ret}_k\) is the 
retarded Greens function of the free Dirac equation.
Equations like 
\eqref{eq:matt} have, in fact, already been considered by 
Feynman \cite[eq. (4)]{feynman1949space} in a paper 
of fundamental importance 
to the development of quantum electrodynamics (QED).
The main difference between \eqref{eq:matt} and what 
appeared in \cite{feynman1949space}  
is that Feynman only uses positive Fourier
modes in time of the Dirac delta in the integral. 
Despite the fact that an equation close to \eqref{eq:matt} appeared 
very early in the development of QED and the similarity 
between \eqref{eq:matt}
and the Bethe-Salpeter equation, not much is known about the 
mathematical properties of equation \eqref{eq:matt}. 
Previous results about related equations are summarised in section 
\ref{sec: direct interation previous}.

There are two main results provided in  this thesis 
about equations of the 
same type as \eqref{eq:matt}. Theorem \ref{thm:KGexistence} extends 
previous results on the existence and uniqueness of the dynamics 
of a version of equation \eqref{eq:matt} for spin-less particles 
to singular interaction along the light-cone. The second main 
result on this topic is theorem \eqref{thm:minkhalfspace}, the 
first result on existence and uniqueness of an equation of 
the type of \eqref{eq:matt} for spin 1/2 particles. Section 
\ref{sec: multitime overview} provides perspective on 
the grounds of which these theorems should be judged. 
 


\item The second kind of interaction we are going 
to investigate is the interaction of an external 
electromagnetic field 
with an otherwise free 
quantum field representing spin 1/2 particles.
Even in this setting there are calssical theorems by 
Ruijsenaars\cite{ruijsenaars1977charged} and 
Shale and Stinespring\cite{shale1965spinor} that seem to 
prevent a dynamical mathematical description of the processes in 
question in the presence of magnetic fields. 
Recently, by the timescales of progress in this 
part of mathematical physics, this obstacle has been overcome 
by abandoning the restriction to work in a static Fock space
\cite{ivp0,ivp1,ivp2}.
These results form the basis upon which we will 
build our analysis in chapter \ref{chap:QFT}.

Chapter \ref{chap:QFT} contains three main results in 
four theorems.
The first, theorem \ref{thm: geometry} contains a 
construction which partially fixes the phase freedom of 
previous results. Theorem 
\ref{sleek_second_quantised_scattering_operator}
provides a well defined formula that gives the 
scattering operator of external field QED in terms of 
the one-particle scattering operator. Finally theorems 
\ref{thm:hadamard=>Pol} and \ref{thm:Pol=>hadamard} 
provide a first step to mutual intelligibility 
\todo{was ist das problem mit intelligibility?} 
between 
the approach to QFT based on Hadamard states commonly 
employed to study QFT in curved spacetimes and the formulation 
used in this thesis by providing a means to translate 
Hadamard states into \(I_2-\)almost projectors and vice 
versa.
\end{enumerate}








%\show\afterchaptertitle



\chapter[Direct Interaction in Relativistic Quantum Mechanics][Direct Interaction]{Direct Interaction in Relativistic Quantum Mechanics}\label{chap: direct interaction}
As discussed in the last chapter in the paragraph above equation 
\eqref{eq:matt}, having interaction mediated by multiplication operators 
in a set of Dirac equations is not a viable option, as was 
proven recently \cite{nogo_potentials,deckert_nickel_2016}.
As mentioned, one alternative approach to this problem 
is to reformulate Diracs equation as 
an integral equation of type \eqref{eq:matt} 
and explore the possibilities of 
interaction in that formulation. 
We will take a few steps in this direction in this chapter. 
It is based on the preprints \cite{selfDirac,selfKG} which 
are a result of the joint
work of Lienert and the author of this thesis. 
While these results fall short of establishing an 
empirically adequate  
relativistic quantum mechanical theory, they do provide
self-consistent relativistic interacting quantum mechanical 
toy models in three spacial and one temporal dimension.

Nevertheless, from a physical perspective 
these models may still be interesting, because they provide a tool 
by means of which circumvent the facet of the ulltraviolett problem due to 
self-interaction. to study to what extend the ultraviolet problem is 
due to self interaction. 
From a mathematical perspective, 
the equation is not in Hamiltonian form and involves 
temporal integrals, hence the well-developed theory of 
one-parameter unitary groups cannot be directly applied.
In fact, there are only few results about equations of this 
type.


We will first give
a heuristic derivation of this type of equation,  
briefly review some relevant
mathematical results that 
have been established in the past, 
and finally 
discuss the new results of the preprints \cite{selfDirac,selfKG}
which are the result of Lienert and the present auhtor.






\section{Overview}\label{sec: multitime overview}
\subsection{Heuristic Derivation} 
In order to motivate the subject of our study,
we will now closely follow the heuristic derivation
of equation \eqref{eq:matt} given in  
\cite{direct_interaction_quantum}.
This section is organised as follows: We start out 
reformulating Diracs equation
for a single particle 
as an integral equation. The reformulated version is then 
extended to two particles
in an Poincaré invariant manner. Extending the 
equation is conveniently done in 
the framework of multi-time wavefunctions.


Diracs equation for one particle subject to an 
external potential \(V\) takes the form
\begin{equation}
	i \partial_t \phi(t,\vx) = \big( H^{\free} + V(t,\vx) \big) \phi(t,\vx),
	\label{eq:singlepartschroed}
\end{equation}
here \(\phi\) denotes a potential \(\mathbb{C}^4\)-valued solution, 
\(\vx\in\mathbb{R}^3, t\in\mathbb{R}\)
and \(H^{\free}\) is the Hamiltonian associated with a free Dirac particle.
The latter acts on wavefunctions as 
\begin{equation}
  H^{\free} \phi=i \gamma^0 \vec{\gamma} \cdot \grad \phi + m \gamma^0 \phi,
\end{equation}
where \(\vec{\gamma}=(\gamma^1,\gamma^2,\gamma^3)\) and \(\grad \phi\) denotes 
the gradient of \(\phi\) with respect to the non-temporal coordinates.
The matrices \(\gamma^\alpha \in \mathbb{C}^{4\times 4}\) 
fulfil the anti-commutation relation
\begin{equation}
\forall \alpha, \beta \in \{0,1,2,3\}:\{\gamma^\alpha, \gamma^\beta\}:= \gamma^\alpha \gamma^\beta+ \gamma^\beta \gamma^\alpha= 2\bm{\eta}^{\alpha \beta},
\end{equation}
where \(\bm{\eta}\) is the Minkowski metric. We will work with 
the \(+---\) 
metric signature and the standard Dirac representation of this 
algebra. Squared four dimensional vectors always refer to 
the Minkowski square, meaning for all 
\(a\in \mathbb{C}^4\), \(a^2:= a^{\alpha} a_{\alpha}={a^0}^2-\vec{a}\cdot\vec{a}\).
Small arrows denote three dimensional vectors, for \(a\in\mathbb{C}^4\)
we denote by \(\vec{a}:=(a^1,a^2,a^3)^T\).
In the following a slashed four vector denotes 
\begin{equation}
  \slashed{a}:= a_\alpha \gamma^\alpha,
\end{equation}
where Einstein's summation convention is used. 
We will be working in units where \(\hbar=1=c\), i.e. 
Planck's constant and the speed of light are set to one.


We denote by \(\mathscr{S}^{\ret}\) the retarded Green's 
function of the non-interacting Dirac equation,
that is, the distribution \(\mathscr{S}^{\ret}\) satisfies
\begin{align}\label{eq:schroedgreensfn}
  \big( i \partial_t - H^{\free} \big) \mathscr{S}^{\ret} &= \delta^4,\\
  \supp \mathscr{S}^{\ret} &\subseteq \mathbb{R}^+_0\times\mathbb{R}^3,
\end{align}
in a suitable weak sense. Here \(\delta^4\)
denotes the Dirac measure in four dimensions concentrated on the origin.
This allows to recast \eqref{eq:singlepartschroed} in terms of the
following integral equation
\begin{equation}
	\phi(t,\vx) = \phi^{\free}(t,\vx) + \int_{t^0}^\infty d\tau \int d^3 \vec{y} \, \mathscr{S}^{\ret}(t-\tau,\vx-\vy) V(\tau,\vy) \phi(\tau,\vy),
	\label{eq:singlepartint}
\end{equation}
where $\phi^{\free}$ 
denotes the solution of the non-interacting equation
\begin{equation*}
  \big( i \partial_t - H^{\free} \big) \phi^{\free}=0,
\end{equation*}
subject to the 
initial condition \(\phi^{\free}(t_0)=\phi_0, t_0\in\mathbb{R}\) which for the 
present purpose we think of as a sufficiently regular square
integrable function. 
%Equations \eqref{eq:singlepartint} and \eqref{eq:singlepartschroed} subject to 
%\(\phi(t_0)=\phi_0\) yield equivalent 
%descriptions, as can be verified directly: An action of \(i\partial_t -H^{\free}\) on 
%\eqref{eq:singlepartint} shows that a solution thereof also solves \eqref{eq:singlepartschroed}.
%Also the initial condition is fulfilled, as the integral term vanishes for \(t=t_0\).
%Conversely equation \eqref{eq:singlepartschroed} can be considered a free Dirac equation 
%involving an inhomogeneous term of the form \(V \phi\), whose solutions are known to be
%of the form \eqref{eq:singlepartint}.
Analogously, we may recast the two particle Dirac equation 
including a \(\mathbb{C}^{4\times 4}\)-valued interaction potential
\(V\) to be specified later
\begin{equation}
	i \partial_t \phi(t,\vx_1,\vx_2) = \big(H_1^{\free} + H_2^{\free} + V(t,\vx_1,\vx_2)\big) \phi(t,\vx_1,\vx_2),
	\label{eq:twopartschroed}
\end{equation}
subject to the initial condition  
\(\phi(t_0)=\phi_0, t_0\in\mathbb{R}\) sufficiently regular and 
square integrable, 
into the integral equation
\begin{align}
	\phi(t,\vx_1,\vx_2) = \phi^{\free}&(t,\vx_1,\vx_2) + \int_{t_0}^\infty \! dt' \! \int d^3 \vx_1'\,  d^3 \vx_2'\, \mathscr{S}_1^{\ret}(t-t',\vx_1-\vx_1') \nonumber\\
	\times&\mathscr{S}_2^{\ret}(t-t',\vx_2-\vx_2') V(t',\vx_1',\vx_2') \phi(t',\vx_1',\vx_2'),
	\label{eq:twopartschroedint}
\end{align}
where again,
$\phi^{\free}(t)$ solves \(\eqref{eq:twopartschroed}\) for \(V=0\) 
with the boundary condition
\(\phi^{\free} (t_0)=\phi_0\) and \(\mathscr{S}_k^{\ret}\) is 
the retarded Green's function
of the free Dirac equation of particle number \(k\). 
That is the distribution \(\mathscr{S}_k^{\ret}\) satisfies 
\begin{align}
  \big( i \partial_t - H^{\free}_k \big) \mathscr{S}_k^{\ret} &= \delta^4,\\
  \supp \mathscr{S}^{\ret}(t,\vx_k) &\subset \mathbb{R}^+_0\times\mathbb{R}^3,
\end{align}
in a suitably weak sense, where 
\begin{equation}
  H_k^{\free}=i \gamma^0_k \vec{\gamma}_k \cdot \grad_k + m_k \gamma^0,
\end{equation}
with 
\begin{align}
  \gamma_1^\mu= \gamma^\mu \otimes 1\\
  \gamma_2^\mu= 1 \otimes \gamma^\mu
\end{align}
and \(1\in \mathbb{C}^{4\times 4}\) denotes the identity matrix
and \(\grad_k\) is the gradient with respect to the non-temporal 
coordinates of the \(k\)-th particle and \(m_k\in\mathbb{R}^+_0\).
Here, it is crucial to notice that
the Green's function of the free two particle Dirac equation 
factorises into a product 
of two Green's functions of the Dirac equation for one particle.

Since equation \eqref{eq:twopartschroedint} contains 
only one temporal variable but six spatial ones, there is unitary 
operator implementing Lorentz boots on such wavefunctions and 
hence 
it is not a relativistically covariant equation. 
In order to find a relativistically covariant equation, we will 
generalise the one-particle in the form 
\eqref{eq:singlepartint} to two particles in stead of finding a 
generalisation analogous to \eqref{eq:singlepartschroed}. 
Before we do so 
let us first rewrite equation \eqref{eq:singlepartint}
it in a more suggestive way:
\begin{equation}
	\psi(x) = \psi^{\free}(x) + \int d^4 x' \, \mathscr{S}^{\ret}(x-x') V(x') \psi(x'),
	\label{eq:singlepartintspacetime}
\end{equation}
where non-bold letters denote elements of Minkowski 
spacetime and we replaced \(\phi\)
by \(\psi\) in order to emphasise the change  to 
a relativistic notation. 
Furthermore, we replaced the lower bound in the 
temporal integral domain by \(-\infty\)
in order to render the total domain of integral Poincaré invariant,
which implies a change of the initial condition.

Equation \eqref{eq:singlepartintspacetime} 
suggests the
following generalisation for two particles
\begin{align}\label{eq:twopartintgeneral}
  \psi(x_1,x_2) &= \psi^{\free}(x_1,x_2) \\\nonumber
  &+ \int d^4 x_1'\, d^4 x_2' \, \mathscr{S}^{\ret}_1(x_1-x_1') \mathscr{S}^{\ret}_2(x_2-x_2') K(x_1',x_2') \psi(x_1',x_2'),
\end{align}
where we integrate over all of \(\mathbb{R}^8\) and 
\(\psi^{\free}\) is a solution of the free 
Dirac equation both in \(x_1\) and \(x_2\) and their 
respective spinor indices:
\begin{align}\label{eq:freemultitime1}
  D_1  \psi^{\free}(x_1,x_2)=\gamma_1^0(i \partial_{t_1} - H_1^{\free})  \psi^{\free}(x_1,x_2) = 0,\\
  D_2  \psi^{\free}(x_1,x_2) =\gamma_2^0(i \partial_{t_2} - H_2^{\free})  \psi^{\free}(x_1,x_2) = 0.
	\label{eq:freemultitime2}
\end{align}

\begin{Def}
  The class of equations \eqref{eq:twopartintgeneral} 
  with \(\mathbb{C}^{16}-\)valued wavefunctions \(\psi\) 
  obeyig the restriction 
  \eqref{eq:freemultitime1} and \eqref{eq:freemultitime2} 
  and tempered distributions 
  \(K\in (\mathcal{S}(\mathbb{R}^8)\otimes \mathbb{C}^{16\times 16})'\) 
  will be referred to as \emph{spin-1/2 delay-equation} with 
  \emph{interaction kernel} \(K\).

  The class of equations 
  \begin{align}\label{eq:KGtwopartint}
    \psi&(x_1,x_2) = \psi^{\free}(x_1,x_2)+\frac{\lambda}{4\pi} \int d^4 x_1' \, d^4 x_2' \\\nonumber
    & \times G^{\ret}_1(x_1-x_1') G^{\ret}_2(x_2-x_2') K(x_1',x_2') \psi(x_1',x_2'),
  \end{align}
  where \(\psi\) and \(\psi^{\free}\) are \(\mathbb{C}-\)valued
  and \(\psi^{\free}\) obeys
  \begin{align}
    (\Box_{x_1} + m_1^2)\psi(x_1,x_2)=0,\\
    (\Box_{x_2} + m_2^2)\psi(x_1,x_2)=0
  \end{align}
  will be called \emph{spin-0 delay-equation} with 
  \emph{interaction kernel} \(K\in (\mathcal{S}(\mathbb{R}^8))'\). 
\end{Def}

An optimal choice in the sense of empirical adequacy of 
the interaction kernel is not yet known.
However, a simple way of ensuring Poincaré invariance of spin 1/2 or 
spin 0 delay-equation
is to let \(K\) only depend directly 
the squared Minkowski distance \((x_1-x_2)^2\). A choice that 
incorporates interaction along light-like distances, i.e. 
\((x_1-x_2)^2=0\) and yields  is given by
\begin{equation}
	K(x_1,x_2) = i\, \frac{e_1e_2}{4\pi} \gamma_1^\mu \gamma_{2,\mu} \; \delta((x_1-x_2)^2),
	\label{eq:twopartkernel1/2}
\end{equation}
for the spin-1/2 case and \todo{mention non-rel limit.}
\begin{equation}
	K(x_1,x_2) = \frac{\lambda }{4\pi} \delta((x_1-x_2)^2),
	\label{eq:twopartkernel0}
\end{equation}
for the spin-0 case,
where \(\delta\) is the one-dimensional Dirac measure.
The model defined the spin-1/2 delay-equation with 
interaction kernel given by \eqref{eq:twopartkernel1/2} 
shows some resemblance of 
Wheeler-Feynman electrodynamics for the following reason: 
there are only particles 
but no electrodynamic field, 
the particles interact with each other
along light-like distances, and the particles do not interact 
with themselves.
The constant in front 
of \eqref{eq:twopartkernel1/2}
is fixed by a
non-relativistic limit, recovering an equation 
very much like the Breit equation,
see \cite[section 3.6]{direct_interaction_quantum}.

Summarising, we gave a heuristic line of argument motivating
the class of spin-1/2 and spin-0 delay-equations and a special 
choice of interaction kernel \eqref{eq:twopartkernel1/2} 
and \eqref{eq:twopartkernel0}, respectively. In this 
thesis we will study equations closely related to this.

As mentioned in the beginning of this section, there are only very few 
results on spin-1/2 and spin-0 delay-equations. 
The reason for this is that 
for these types of equations the theory of one-parameter 
unitary groups cannot be applied. Furthermore, the integrals 
on the right hand side of these equations involve the delayed 
wavefunction with arbitrarily large delay. As for the theory of 
delayed differential equations it is interesting to study existence
and uniqueness of solutions, as well as dependence on initial data.
We will review the, for our 
purposes, most relevant mathematical results
in the next subsection before we move on to the new results 
of this thesis. 

\subsection{Previous Mathematical Results on Directly Interacting Particles}\label{sec: direct interation previous}
In this section we summarise previous important mathematical 
existence results on spin-0 delay-equations. To the best 
of my knowledge there are no mathematical existence results
on spin-1/2 delay-equations prior to the one of Lienert and myself in \cite{selfDirac}.  
The results
we are going to cover are taken 
from \cite{direct_interaction_quantum} and 
\cite{lienertcurved}. The theorems are about the Klein-Gordon case, i.e.
slightly different versions of equations
of the type of \eqref{eq:KGtwopartint}. The 
necessary new notation is contained to within each
of the theorems. Mentioned below are only the theorems that are about a 
four dimensional spacetime; however,  
there are also results concerning lower dimensions, 
the interested reader 
is refered to \cite{direct_interaction_quantum,lienertcurved}. 
Since not much is known about the mathematical properties of 
spin-1/2 and spin-0 delay-equations the first results on 
equations of similar type will be subject to 
considerable modifications: 


\begin{enumerate}[label=(\Alph*)]
\item \label{matt simplifying assumption 1} 
The spacetime of equation \eqref{eq:KGtwopartint} 
is \(\mathbb{R}^4\), i.e. Minkowski spacetime.
All the rigorous results concerning vanishing curvature so far 
are about
\(\mathbb{R}^+\times\mathbb{R}^3=:\M\). 
That is, there is a beginning in time. This modification has 
technical reasons. However, it may be justified on physical 
grounds as current cosmological models also have a beginning in 
time. In order to give this reasoning additional weight 
the existence and uniqueness result was also proved on 
Friedmann-Lemaître-Robertson-Walker (FLRW) spacetime.
In sections \ref{sec:KG lightcones} and 
\ref{sec:direct dirac} we for the same reason provide results 
on this spacetime.
\item \label{matt simplifying assumption 2} 
The interaction kernel \(K\)
is replaced by various classes of less singular objects. 
These classes do not include the singular interaction kernel
proportional to \(\delta((x_1-x_2)^2)\) motivated in the 
last section. This modification is 
purely technical and we do not justify it. 
In section \ref{sec:direct dirac}, where we treat Dirac 
particles, 
we will also use a rather regular interaction kernel compared to 
\eqref{eq:twopartkernel1/2}. The new result 
about Klein-Gordon particles presented in 
section \ref{sec:KG lightcones} employs the fully 
singular \(\delta((x_1-x_2)^2)\) kernel. 
\end{enumerate}

%\begin{Thm}[Thm 3.1 of \cite{direct_interaction_quantum}]
%Let \(T>0\), \(M,N\in\mathbb{N}\), consider 
%the Banach space \(\mathcal{B}=L^\infty ([0,T]^N,L^2(\mathbb{R}^M))\).
%Let \(\mathcal{L}:[0,T]^{2N}\rightarrow L^2(\mathbb{R}^{2M})\) such that 
%\begin{equation*}
%\sup_{t,t'\in[0,T]^{N}}\|\mathcal{L}(t,t')\|^2<\infty,
%\end{equation*}
%then for any \(f_0\in\mathcal{B}\) the equation
%\begin{equation*}
%f(t,x)=f_0(t,x)+ \int_0^t dt' \int dx' L(t,t',x,x') f(t',x')
%\end{equation*}
%has a unique solution \(f\in\mathcal{B}\).
%\end{Thm}

%\begin{Thm}[Thm 3.2 \((d=1)\) of \cite{direct_interaction_quantum}]
%Let \(T>0, \lambda\in\mathbb{C}, m_1,m_2\ge 0\), every
%\begin{equation*}
%\psi^{\free} \in \mathcal{B}_1=L^\infty ([0,T]^2,L^2(\mathbb{R}^2)),
%\end{equation*}
%and every essentially bounded \(K:\mathbb{R}^4\rightarrow \mathbb{C}\), the integral equation 
%\begin{align*}
%\psi(t_1,z_1,t_2,z_2)=\psi^{\free}(t_1,z_1,t_2,z_2)+\frac{\lambda}{4}\int_0^{t_1}dt_1'\int_0^{t_2}dt_2'\int dz_1'dz_2'\\
% \times H(t_1-t_1'-|z_1-z_1'|) J_0(m_1\sqrt{(t_1-t_1')^2-|z_1-z_1'|^2})\\
% \times H(t_2-t_2'-|z_2-z_2'|) J_0(m_2\sqrt{(t_2-t_2')^2-|z_2-z_2'|^2})\\
%  \times K(t_1',z_1',t_2',z_2')\psi(t_1',z_1',t_2',z_2')
%\end{align*}
%has a unique solution \(\psi \in \mathcal{B}_1\).
%\end{Thm}

%\begin{Thm}[Thm 3.3 \((d=2)\) of \cite{direct_interaction_quantum}]
%Let \(T>0, \lambda\in\mathbb{C}, m_1,m_2\ge 0\), for every essentially bounded \(K:\mathbb{R}^6\rightarrow\mathbb{C}\)
%and every \(\psi^{\free} \in \mathcal{B}_2=L^\infty([0,T]^2,L^2(\mathbb{R}^4))\) the equation
%\begin{align*}
%&\psi(t_1,\vx_1,t_2,\vx_2)=\psi^{\free}(t_1,\vx_1,t_2,\vx_2)+\frac{\lambda}{(2\pi)^2}\int_0^{t_1}dt_1'\int_0^{t_2}dt_2'\\
%&\times\int d^2\vx_1'd^2\vx_2' H(t_1-t_1'-|\vx_1-\vx_1'|)\frac{\cos(m_1\sqrt{(t_1-t_1')^2-|\vx_1-\vx_1'|^2})}{\sqrt{(t_1-t_1')^2-|\vx_1-\vx_1'|^2}}\\
%&\quad \times H(t_2-t_2'-|\vx_2-\vx_2'|)\frac{\cos(m_2\sqrt{(t_2-t_2')^2-|\vx_2-\vx_2'|^2})}{\sqrt{(t_2-t_2')^2-|\vx_2-\vx_2'|^2}} \\
%&\quad \quad\quad \quad \times K(t_1',\vx_1',t_2',\vx_2')\psi(t_1',\vx_1',t_2',\vx_2')
%\end{align*}
%has a unique solution \(\psi \in \mathcal{B}_2\).
%\end{Thm}

The space \(\mathcal{B}\) to be defined 
below provides the solution 
sense for the following existence and uniqueness results.
\begin{Def}
  For \(T>0\), we define the Bochner space \(\mathcal{B}:=L^\infty([0,T]^2,L^2(\mathbb{R}^6))\)
  as the space of measureable functions from \([0,T]\) 
  to the space of measureable square integrabile functions from 
  \(\mathbb{R}^6\) to \(\mathbb{C}\) with essentially finite \(L^2\)
  norm, i.e. \(\forall f\in \mathcal{B}:\)
  \begin{equation}
    \esssup_{t_1,t_2\in[0,T]^2}\|f\|_2^2:=\inf_{\stackrel{\sigma \subset [0,T]^2}{ \lambda(\sigma)=0}} \sup_{(t_1,t_2)\in [0,T]^2\backslash \sigma} \int_{\mathbb{R}^6}dx |f(t_1,t_2,x)|^2<\infty,
  \end{equation}
  where \(\lambda\) is the Lebesgue measure.
\end{Def}

\begin{Thm}[Thm 3.4 \((d=3)\) of \cite{mtve}]
Let \(T>0, \lambda\in\mathbb{C}\), for every bounded \(K:\mathbb{R}^8\rightarrow\mathbb{C}\) and every
\(\psi^{\free} \in\mathcal{B}:=L^\infty([0,T]^2,L^2(\mathbb{R}^6))\)
the equation 

\begin{align*}
\psi(t_1,\vx_1,t_2,\vx_2)&=\psi^{\free}(t_1,\vx_1,t_2,\vx_2)+\frac{\lambda}{(4\pi)^2}\int d\vx_1' d\vx_2'\\
&\times \frac{H(t_1-|\vx_1-\vx_1'|)}{|\vx_1-\vx_1'|}\frac{H(t_2-|\vx_2-\vx_2'|)}{|\vx_2-\vx_2'|}\\
&\times K(t_1-|\vx_1-\vx_1'|,\vx_1',t_2-|\vx_2-\vx_2'|,\vx_2')\\
&\times \psi(t_1-|\vx_1-\vx_1'|,\vx_1',t_2-|\vx_2-\vx_2'|,\vx_2')
\end{align*}
has a unique solution \(\psi\in \mathcal{B}\), where \(H\) is the
Heaviside function.
\end{Thm}

\begin{Thm}[Thm 3.5 of \cite{mtve}]
  Let \(T>0, \lambda\in\mathbb{C}\), for every 
  bounded \(f:\mathbb{R}^8\rightarrow \mathbb{C}\) 
  and every \(\psi^{\free} \in \mathcal{B}:=L^\infty([0,T]^2,L^2(\mathbb{R}^6))\) the equation
\begin{align*}
\psi(t_1,\vx_1,t_2,\vx_2)&=\psi^{\free}(t_1,\vx_1,t_2,\vx_2) + \frac{\lambda}{(4\pi)^2}\int d^3\vx_1'd^3\vx_2'\\
& \times \frac{H(t_1-|\vx_1-\vx_1'|)}{|\vx_1-\vx_1'|} \frac{H(t_2-|\vx_2-\vx_2'|)}{|\vx_2-\vx_2'|}\\
&\times  \frac{f(t_1-|\vx_1-\vx_1'|,\vx_1',t_2-|\vx_2-\vx_2'|,\vx_2')}{|\vx_1'-\vx_1|}\\
& \times \psi(t_1-|\vx_1-\vx_1'|,\vx_1',t_2-|\vx_2-\vx_2'|,\vx_2'),
\end{align*}
has a unique solution \(\psi\in \mathcal{B}\).
\end{Thm}


The next results will be about the open FLRW spacetime.
There are also results about the closed
FLRW universe which we omit here. The reader is refered
to \cite[Thm 4.3]{lienertcurved}.
We have to introduce some notation before we can 
present the next results. In order to do so we follow 
\cite[sec 3.3]{selfKG}. 


We consider particles on a flat (FLRW) spacetime \(\mathcal{M}\) 
which admits a global coordinates 
chart \(x\mapsto (\eta, \vec{x})\in \mathbb{R}^+\times\mathbb{R}^3\). The metric \(g\)
in these coordinates at the point \(x\) is given by 
\begin{equation*}
  g_{x}(v_1,v_2)=a^2(\eta) (v_1^0 v_2^0 - \vec{v}_1\cdot \vec{v}_2)
\end{equation*}
for all \(v_1,v_2\in T_{x}\mathcal{M}\), 
i.e. the metric at every point is a multiple of the Minkowski metric.
%\begin{equation}
%	ds^2 = a^2(\eta) \left( d\eta^2 - dr^2 - r^2 d \Omega^2 \right),
%\end{equation}
The global time coordinate $\eta$ is called 
conformal time, and the scale function 
$a:\mathbb{R}^+\rightarrow \mathbb{R}$ is 
 continuous with $\lim_{\eta\rightarrow 0}a(\eta) = 0$ 
and $a(\eta) > 0$ for all $\eta$. 
In this spacetime the free wave equation takes the form 
\begin{equation}
	\left( \Box_g - R/6 \right) \chi(x) = 0,
	\label{eq:conformalbox}
\end{equation}
where $R$ denotes the Ricci scalar and \(\Box_g\) 
is the Laplace-Beltrami operator with respect to the metric \(g\)
and \(\chi\) is a \(\mathbb{C}-\)valued function on the 
manifold.The retarded and 
symmetric Green's functions of equation \eqref{eq:conformalbox}
are given by

\begin{align}\label{eq:KGcurvedGreen1}
	G_{\mathcal{M}}^{\ret}(x,x') ~&=~ \frac{1}{4\pi} \frac{1}{a(\eta) a(\eta')} \frac{\delta(\eta - \eta' -|\vx-{\vx}^{\,\prime}|)}{|\vx-{\vx}^{\,\prime}|}\\
G_{\mathcal{M}}^{\sym}(x,x') ~&=~ \frac{1}{4\pi} \frac{1}{a(\eta) a(\eta')} \delta((\eta-\eta')^2-|\vx-{\vx}^{\,\prime}|^2).\label{eq:KGcurvedGreen2}
\end{align}

This form may be derived exploiting the conformal equivalence of 
FLRW spacetime and Minkowski spacetime, see 
\cite{lienertcurved,john1987hadamard}
for details. 

The generalization of \eqref{eq:KGtwopartint} 
to FLRW spacetime is straightforward: $\psi$ becomes a scalar 
function on $\mathcal{M}\times\mathcal{M}$, one exchanges the 
Minkowski spacetime volume element with 
\begin{equation}\label{invariant volume}
	dV(x) = a^4(\eta) \, d\eta \, d^3 \vx,
\end{equation}
where 
the one-forms on the right hand side are the canonical ones 
in these coordinates and
the product of one-forms is to be understood as a wedge product.
Equation \eqref{invariant volume} gives the invariant 4-volume 
form on $\mathcal{M}$.
As in the Minkowski case, the interaction kernel is given by the 
symmetric Green's function. With this, the relevant integral 
equation turns into:
\begin{align}\notag
  \psi(x,y) = \psi^{\free}(x,y) +& \lambda \int_{\mathcal{M}\times \mathcal{M}} dV(x) \, dV(y)~G_{\mathcal{M}}^{\ret}(x,x')G_{\mathcal{M}}^{\ret}(y,y') \\
  & \times G_{\mathcal{M}}^{\sym}(x',y') \psi(x',y').\label{eq:KGinteqcurved}
\end{align}

For regular and only weakly singular interaction kernels $K(x',y')$ 
instead of $G^{\sym}(x',y')$, the problem of existence and uniqueness 
of solutions of this equation has been treated in 
\cite{lienertcurved}:


\begin{Thm}[Thm 4.1 of \cite{lienertcurved}]\label{thm 4.1 of curved}
Let \(T>0\),\(\lambda\in\mathbb{C}\).% and 
%\(\mathcal{B}:=L^\infty([0,T]^2,L^2(\mathbb{R}^6))\). 
Furthermore, let \(a:[0,\infty)\rightarrow [0,\infty)\)
be a continuous function with \(a(0)=0\) and 
\(a(\eta)>0\) for \(\eta>0\), and 
\(\tilde{K}:([0,\infty)\times \mathbb{R}^{3})^2\rightarrow \mathbb{C}\)
be bounded. Then for every \(\psi^{\free}\) with 
\(a(\eta_1)a(\eta_2)\psi^{\free}\in \mathcal{B} \),
the respective integral equation on the \(4-\)dimensional 
flat FLRW universe sith scale function \(a(\eta)\): 
\begin{align}\label{KG curved bounded}
  \psi(\eta_1, \vx_1,\eta_2,\vx_2)&=\psi^{{\free}}(\eta_1, \vx_1,\eta_2,\vx_2)
  +\frac{\lambda}{(4\pi)^2 a(\eta_1)a(\eta_2)}\\\notag
  &\quad \times \int d \vx_1' d \vx_2' 
  a^2(\eta_1-|\vx_1-\vx_1'|)a^2(\eta_2-|\vx_2-\vx_2'|)\\\notag
  &\quad \times \frac{H(\eta_1-|\vx_1-\vx_1'|)}{|\vx_1-\vx_1'|}
  \frac{H(\eta_2-|\vx_2-\vx_2'|)}{|\vx_2-\vx_2'|}\\\notag
  &\quad\times \tilde{K}(\eta_1-|\vx_1-\vx_1'|,\vx_1',\eta_2-|\vx_2-\vx_2'|,\vx_2')\\\notag
  &\quad\times \psi(\eta_1-|\vx_1-\vx_1'|,\vx_1',\eta_2-|\vx_2-\vx_2'|,\vx_2')
\end{align}
has a unique solution \(\psi\) for 
\(a(\eta_1)a(\eta_2)\psi\in \mathcal{B}\).
\end{Thm}

\begin{Thm}[Thm 4.2 of \cite{lienertcurved}]
  Let \(f:([0,\infty]\times \mathbb{R}^3)^2\rightarrow \mathbb{C}\) 
  be a bounded function. Then, under the same assumptions as in 
  theorem \ref{thm 4.1 of curved} but with 
  \begin{equation}
  \tilde{K}(\eta_1,\vx_1,\eta_2,\vx_2)=\frac{f(\eta_1,\vx_1,\eta_1,\vx_2)}{|\vx_1-\vx_2|},
  \end{equation}
the integral equation \eqref{KG curved bounded} has a unique solution
\(\psi\) for 
\(a(\eta_1)a(\eta_2)\psi\in \mathcal{B}\). 
\end{Thm}


\section{Singular light cone interactions of spin-less particles}\label{sec:KG lightcones}
In this section we prove existence and uniqueness
of an equation of type \eqref{eq:KGtwopartint},
subject to the simplifying assumption 
\ref{matt simplifying assumption 1}. In contrast to 
the previous results of section \ref{sec: direct interation previous} 
the equation will not be subject to the assumption
\ref{matt simplifying assumption 2}. Additionally, we will extend the 
result to an arbitrary number of particles. This extension 
is not the only possible one; however, we choose the 
extension called most promising in \cite{direct_interaction_quantum}.
In order to justify the cutoff in time, we extend the one-particle 
result to the FLRW spacetime, where the cutoff appears naturally.


%%%%%
\subsection{Overview}

This section is structured as follows. In subsec. \ref{sec:formulation} 
it is shown how to define the integral equation in a rigorous way 
(by using the delta distributions to eliminate certain integration 
variables). To this end, we again consider the equation on the 
Minkowski half-space (assuming a cutoff in time). Subsection 
\ref{sec:KG results} contains our main results: Thm. \ref{thm:boundsKG} 
contains explicit bounds for the integral operator in terms of a 
general weight function of a weighted $L^\infty$ space. Thm. 
\ref{thm:exponentialg} shows that in the case of massless particles 
already an exponential weight function leads to the existence and 
uniqueness of solutions of the integral equation. Our main result 
is Thm. \ref{thm:KGexistence}, an existence and uniqueness theorem 
for the full (massive) case. In that case, a different weight 
function growing like the exponential of a polynomial is used. 

Subsection \ref{sec:Npart} deals with generalizing this existence and 
uniqueness theorem to $N$ scalar particles; the corresponding 
theorem, Thm. \ref{thm:Npart}, is a direct consequence of Thm.
\ref{thm:KGexistence}. To the best of the knowledge of 
the Lienert and the author, this is the 
first rigorous result about a multi-time integral equation for 
$N$-particles. 

In Subsection \ref{sec:KGcurvedspacetime} we show by considering a 
specific example (an open FLRW spacetime) that the cutoff in time 
can be achieved naturally for a cosmological spacetime with a Big 
Bang singularity, without breaking any spacetime symmetries. That 
is, we show the equivalent result of \cite{lienertcurved} for 
singular light cone interactions. The respective existence and 
uniqueness theorem is Thm. \ref{thm:existencecurved}.

Subsection \ref{sec:KG proofs} contains the proofs.



%%%%%
\subsection{Precise formulation of the problem}
\label{sec:formulation}

In the following, we show how to precisely define the spin-0 
delay-equation \eqref{eq:KGtwopartint} with 
masses $m_1$ and $m_2$ on the Minkowski half space $\M = 
[0,\infty) \times \R^3$ and interaction kernel 
\eqref{eq:twopartkernel0}. 

It is necessary to take special care of the definition of the 
integral equation as it contains certain combinations (convolutions 
and products) of distributions (the Green's functions). Our strategy 
is to consider the integral operator acting on test functions first 
where its action can be defined straightforwardly. Later it will be 
shown that it is bounded on test functions with respect to a suitably 
chosen weighted norm. This will make it possible to linearly extend 
the integral operator to the completion of test functions with 
respect to that norm.

The retarded Green's function of the Klein-Gordon equation
with mass \(m\) is given 
by:
\begin{equation}
	G^{\ret}(x) ~=~ \frac{1}{4\pi|\vx|}\delta(x^0-|\vx|) - \frac{m}{4\pi \sqrt{x^2}} H(x^0-|\vx|) \frac{J_1(m\sqrt{x^2})}{\sqrt{x^2}} 
	\label{eq:gretkg}
\end{equation}
where $H$ denotes the Heaviside function and $J_1$ is a
Bessel function of the first kind.
Then, with $K(x,y) = \frac{\lambda}{4\pi} \delta((x-y)^2)$, our 
integral equation \eqref{eq:KGtwopartint} on $(\M)^2$ becomes:
\begin{equation}
	\psi ~=~ \psi^{\free} + A \psi
\label{eq:abstractinteq}
\end{equation}
where $A = A_0 + A_1 + A_2 + A_{12}$ and
\begin{align}
(A_0 \psi)(x,y) ~=& \frac{\lambda}{(4\pi)^3} \int_0^\infty d {x'}^0 \int_{\mathbb{R}^3} d^3 {\vx}^{\,\prime} \int_0^\infty d{y'}^0 \int_{\mathbb{R}^3} \nonumber\\ 
  &\times \frac{\delta(x^0-{x'}^0-|\vx-{\vx}^{\,\prime}|)}{|\vx-{\vx}^{\,\prime}|}\frac{\delta(y^0-{y'}^0-|\vy-{\vy}^{\,\prime}|)}{|\vy-{\vy}^{\,\prime}|}\notag\\
  &\times\delta((x'-y')^2) \psi(x',y'),\label{eq:a0informal}\\
(A_1 \psi)(x,y) ~=&  -\frac{\lambda \, m_1}{(4 \pi)^3} \int_0^\infty d{x'}^0 \int d^3 {\vx}^{\,\prime} \int_0^\infty d{y'}^0 \int d^3 {\vy}^{\,\prime}  \nonumber\\
  &\times H(x^0-{x'}^0-|\vx-{\vx}^{\,\prime}|)\frac{J_1(m_1\sqrt{(x-x')^2})}{\sqrt{(x-x')^2}} \notag \\
  &\times  \frac{\delta(y^0-{y'}^0-|\vy-{\vy}^{\,\prime}|)}{|\vy-{\vy}^{\,\prime}|}\delta((x'-y')^2) \psi(x',y')\label{eq:a1informal}\\
(A_2 \psi)(x,y) ~=& -\frac{\lambda \, m_2}{(4 \pi)^3} \int_0^\infty d{x'}^0 \int d^3 {\vx}^{\,\prime} \int_0^\infty d{y'}^0 \int d^3 {\vy}^{\,\prime} \nonumber\\
& \times \frac{\delta(x^0-{x'}^0-|\vx-{\vx}^{\,\prime}|)}{|\vx-{\vx}^{\,\prime}|}H(y^0-{y'}^0-|\vy-{\vy}^{\,\prime}|) \notag\\
& \times \frac{J_1(m_2\sqrt{(y-y')^2})}{\sqrt{(y-y')^2}} \delta((x'-y')^2) \psi(x',y') \label{eq:a2informal}\\
(A_{12} \psi)(x,y) ~=& \frac{\lambda \, m_1 m_2}{(4\pi)^3}  \int_0^\infty d{x'}^0 \int d^3 {\vx}^{\,\prime} \int_0^\infty d{y'}^0 \int d^3 {\vy}^{\,\prime}  \nonumber\\
&\times H(x^0-{x'}^0-|\vx-{\vx}^{\,\prime}|) \frac{J_1(m_1\sqrt{(x-x')^2})}{\sqrt{(x-x')^2}}  \nonumber\\
&\times H(y^0-{y'}^0-|\vy-{\vy}^{\,\prime}|) \frac{J_1(m_2\sqrt{(y-y')^2})}{\sqrt{(y-y')^2}}\notag\\
&\quad \times\delta((x'-y')^2) \psi(x',y')\label{eq:a12informal}.
\end{align}
We now formally manipulate these informal expressions in such a way 
that the end results can be given a precise meaning on test 
functions. Let $\mathcal{S} = \mathcal{S}((\M)^2)$ 
denote the space of Schwartz functions on $(\M)^2$, 
and let $\psi \in \mathcal{S}$. 

%%%
\subsubsection{Definition of \(A_0\).}
We consider the massless term $A_0$ first which is also the most 
singular term. Using the $\delta$-functions to eliminate the 
integration over ${x'}^0$ and ${y'}^0$ results in:
\begin{align}
	(A_0 \psi)(x,y) =& \frac{\lambda}{(4\pi)^3} \int_{B_{x^0}(\vx)} \hspace{-0.5cm}d^3{\vx}^{\,\prime} \int_{B_{y^0}(\vy)} \hspace{-0,5cm}d^3 {\vy}^{\,\prime} \,   \nonumber \\
  &\times \frac{\delta((x^0-y^0-|{\vx}^{\,\prime}|+|{\vy}^{\,\prime}|)^2-|\vx-\vy +{\vx}^{\,\prime}-{\vy}^{\,\prime}|^2)}{|{\vx}^{\,\prime}||{\vy}^{\,\prime}|}\notag\\
  &\times \psi(x+x',y+y')|_{{x'}^0 = -|{\vx}^{\,\prime}|, \, {y'}^0 = -|{\vy}^{\,\prime}|},
	\label{eq:a0informal2}
\end{align}
Note that the domain of integration has been reduced to a compact 
region whose size depends on $x^0$ and $y^0$. There is still one 
more $\delta$-distribution left. We choose to use it to eliminate 
$|{\vx}^{\,\prime}| =: r$. It is convenient to introduce the vector
\begin{equation}
	b = x-y-(-|{\vy}^{\,\prime}|, {\vy}^{\,\prime}).
\label{eq:b}
\end{equation}
Then the argument of the delta function can be written as:
\begin{equation}
	(b^0-|{\vx}^{\,\prime}|)^2 - |\vb + {\vx}^{\,\prime}|^2.
\end{equation}
This expression has a root in $r$ for
\begin{equation}
	r =  r^* := \frac{1}{2} \frac{b^2}{b^0 + |\vb| \cos \vartheta}
\label{eq:r}
\end{equation}
where $\vartheta$ is the angle between $\vb$ and ${\vx}^{\,\prime}$. Of course, 
$r^*$ inherits the restrictions of the range of $r$, thus is only a 
valid root for
\begin{equation}
	0 < r^* < x^0.
\end{equation}
The requirement $0 < r^*$ can be satisfied in two cases, either 
\(b^2>0\) and \(b^0>0\), or \(b^2<0\) and \(\cos\vartheta< - 
\frac{b^0}{|\vb|}\). Using these restrictions, the condition 
$r^*< x^0$ can be converted into a restriction of the domain of 
integration in \(\vartheta\):
\begin{align}
   & \frac{1}{2}\frac{b^2}{b^0+|\vb|\cos\vartheta}~ <~x^0\nonumber\\
   \iff~~~ &\sgn(b^2) b^2 ~< ~ 2x^0 \sgn(b^2) ( b^0+|\vb|\cos \vartheta)\nonumber\\
    \iff~~~ &\frac{|b^2|}{2x^0 |\vb|} -\frac{\sgn(b^2)b^0}{|\vb|} ~<~ \sgn(b^2) \cos \vartheta\nonumber\\
    \iff ~~~&\left\{\begin{matrix}\cos\vartheta > \frac{b^2}{2x^0|\vb|}- \frac{b^0}{|\vb|}, \quad \text{for} ~ b^2 >0 \\ \cos\vartheta < \frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}, \quad \,  \text{for} ~ b^2<0. \end{matrix} \right.
\end{align}
In case of $b^2<0$, the new restriction on \(\cos\vartheta\) is 
stricter than \(\cos\vartheta<-\frac{b^0}{|\vb|}\); we thus use it 
to replace the latter. We evaluate the $\delta$-function using 
spherical coordinates in ${\vy}^{\,\prime}$ and the usual rule
\begin{equation}\label{split delta}
    \delta(f(z))=\sum_{z^* : f(z^*)=0} \frac{\delta(z-z^*)}{|f'(z^*)|},
\end{equation}
where \(f(r)=(b^0-r)^2-(\vb+x')^2= -(r-r^*)2(b^0+|\vb|\cos\vartheta) \). 
The result is an expression for \(A_0\psi\) which does not contain 
distributions anymore:
\begin{align}\nonumber
    &(A_0\psi)(x,y)=\frac{\lambda}{(4\pi)^3}\int_{B_{y^0}(\vy)}d^3{\vy}^{\,\prime}  \int_0^{2\pi}d\varphi \int_{-1}^{1} d\!\cos\vartheta ~\frac{|b^2|}{4(b^0+|\vb|\cos\vartheta)^2 |{\vy}^{\,\prime}|} \\
    &\left(\!1_{b^2>0}1_{b^0>0} 1_{\cos\vartheta > \frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}}\!\!+1_{b^2<0}1_{\cos\vartheta<\frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}}\!\right)\!\psi(x+\!x',y+\!y'),
\label{eq:defa0}
\end{align}
still subject to \(x'^0=-r^*=-|{\vx}^{\,\prime}| , {y'}^0=-|{\vy}^{\,\prime}|\). The 
different cases for $b$ have been implemented through the various 
indicator functions. Eq.\@ \eqref{eq:defa0} will serve as our 
\textit{definition} of $A_0$ on test functions $\psi \in \mathcal{S}$.

%%%
\subsubsection{Definition of $A_1$.}
Next, we turn to the definition of $A_1$, starting from the informal 
expression \eqref{eq:a1informal}. We first split up the 
$\delta$-function of the interaction kernel according to 
\eqref{split delta}.
Then we use $\delta(y^0-{y'}^0-|\vy-{\vy}^{\,\prime}|)$ to eliminate 
${y'}^0~(=y^0-|\vy-{\vy}^{\,\prime}|)$. Note that the order of these two steps 
does not matter. This yields:
\begin{align}
	&(A_1 \psi)(x,y) =  -\frac{\lambda \, m_1}{2(4 \pi)^3} \int_0^\infty d{x'}^0 \int d^3 {\vx}^{\,\prime} \int d^3 {\vy}^{\,\prime}~H(x^0-{x'}^0-|\vx-{\vx}^{\,\prime}|)  \nonumber\\
& ~~~\times \frac{J_1(m_1\sqrt{(x-x')^2})}{\sqrt{(x-x')^2}} \frac{H(y^0-|\vy-{\vy}^{\,\prime}|)}{|\vy-{\vy}^{\,\prime}|} \frac{1}{|{\vx}^{\,\prime}-{\vy}^{\,\prime}|} \nonumber\\
&~~~\left[\delta({x'}^0 - y^0 \!+ \!|\vy-{\vy}^{\,\prime}| \!-\! |{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}|)+ \! \delta({x'}^0 \!- y^0\! +\!|\vy-{\vy}^{\,\prime}| \!+\! |{\vx}^{\,\prime}-{\vy}^{\,\prime}|) \right] \notag\\
&\hspace{1cm}\times\psi(x',y^0-|\vy-{\vy}^{\,\prime}|,{\vy}^{\,\prime}).\label{eq:a1informal2}
\end{align}
Finally, we use the remaining $\delta$-functions to eliminate 
${x'}^0$. We obtain:
\begin{align}
	(A_1 \psi)(x,y) &=  -\frac{\lambda \, m_1}{2(4 \pi)^3} \int d^3 {\vx}^{\,\prime} \int d^3 {\vy}^{\,\prime}~\frac{H(y^0-|\vy-{\vy}^{\,\prime}|)}{|\vy-{\vy}^{\,\prime}|} \frac{1}{|{\vx}^{\,\prime}-{\vy}^{\,\prime}|} \nonumber\\
&\Bigg[ H({x'}^0)H(x^0-{x'}^0-|\vx-{\vx}^{\,\prime}|)  \notag\\
& \quad \times\frac{J_1(m_1\sqrt{(x-x')^2})}{\sqrt{(x-x')^2}} \psi(x',y')\bigg|_{\substack{{y'}^0 = y^0-|\vy-{\vy}^{\,\prime}|,\\{x'}^0 = y^0\!\!- |\vy-{\vy}^{\,\prime}| \!+\! |{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}| }}\nonumber\\
&+ \, H({x'}^0)H(x^0-{x'}^0-|\vx-{\vx}^{\,\prime}|)  \notag\\
&\times \frac{J_1(m_1\sqrt{(x-x')^2})}{\sqrt{(x-x')^2}} \psi(x',y')\bigg|_{\substack{{y'}^0 = y^0-|\vy-{\vy}^{\,\prime}|,\\{x'}^0 = y^0\!\!- |\vy-{\vy}^{\,\prime}| \!-\! |{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}| }} \Bigg] .\label{eq:defa1}
\end{align}
This expression is free of distributions, so it will serve as our 
definition of $A_1$ on test functions $\psi \in \mathcal{S}$. Note 
that the domain of integration is effectively finite due to the 
Heaviside functions.

%%%
\subsubsection{Definition of $A_2$.} Starting from 
\eqref{eq:a2informal}, the analogous steps as for $A_1$ yield:
\begin{align}
	(A_2 \psi&)(x,y) \!=\!  -\frac{\lambda  m_2}{2(4 \pi)^3}\! \int \!d^3 {\vx}^{\,\prime} \!\!\int\! d^3 {\vy}^{\,\prime}\frac{H(x^0-|\vx-{\vx}^{\,\prime}|)}{|\vx-{\vx}^{\,\prime}|} \frac{1}{|{\vx}^{\,\prime}-{\vy}^{\,\prime}|} \nonumber\\
&\Bigg[ H({y'}^0)H(y^0-{y'}^0-|\vy-{\vy}^{\,\prime}|)  \notag\\
&\times \frac{J_1(m_2\sqrt{(y-y')^2})}{\sqrt{(y-y')^2}} \psi(x',y')\bigg|_{\substack{{x'}^0 = x^0-|\vx-{\vx}^{\,\prime}|,\\{y'}^0 = x^0 - |\vx-{\vx}^{\,\prime}| \!+\! |{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}| }}\nonumber\\
&+ \, H({y'}^0)H(y^0-{y'}^0-|\vy-{\vy}^{\,\prime}|)   \notag\\
&\times \frac{J_1(m_2\sqrt{(y-y')^2})}{\sqrt{(y-y')^2}} \psi(x',y')\bigg|_{\substack{{x'}^0 = x^0-|\vx-{\vx}^{\,\prime}|,\\{y'}^0 = x^0 - |\vx-{\vx}^{\,\prime}| \!-\! |{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}| }} \Bigg] .\label{eq:defa2}
\end{align}
This serves as our definition of $A_2$ on test functions $\psi \in \mathcal{S}$.

%%%
\subsubsection{Definition of $A_{12}$.} Here, we start with 
\eqref{eq:a12informal}. We change variables $({\vx}^{\,\prime},{\vy}^{\,\prime}) 
\rightarrow ({\vx}^{\,\prime},\vz = {\vx}^{\,\prime}-{\vy}^{\,\prime})$ (Jacobi determinant $=1$), with 
the goal of using the remaining $\delta$-function to eliminate 
$|\vz| = |{\vx}^{\,\prime}-{\vy}^{\,\prime}|$ in mind. We find:
\begin{align}
(A_{12} \psi)(x,y) =&\! \frac{\lambda  m_1 m_2}{(4\pi)^3}  \!\int_0^\infty \!\!d{x'}^0 \!\int \!d^3 {\vx}^{\,\prime}\! \int_0^\infty \!\!d{y'}^0 \!\int \!d^3 \vz H(x^0\!-\!{x'}^0\!\!-\!|\vx-{\vx}^{\,\prime}|)  \nonumber\\
&\times \frac{J_1(m_1\sqrt{(x-x')^2})}{\sqrt{(x-x')^2}} H(y^0-{y'}^0-|\vy-{\vx}^{\,\prime}+\vz|)\nonumber\\
&\times  \frac{J_1(m_2\sqrt{(y-y')^2})}{\sqrt{(y-y')^2}}\delta(({x'}^0\!-{y'}^0)^2 -|\vz|^2) \psi(x',y')\Big|_{{\vy}^{\,\prime} = {\vx}^{\,\prime}-\vz}\label{eq:a12informal2}.
\end{align}
Now we use spherical coordinates for $\vz$ and eliminate $|\vz|$ 
through the $\delta$-function, using
\begin{equation}
	 \delta(({x'}^0-{y'}^0)^2 -|\vz|^2) =  \frac{1}{2 |\vz|} \delta(|{x^0}'-{y^0}'|-|\vz|).
\end{equation}
This yields:
\begin{align}
&(A_{12} \psi)(x,y) = \frac{\lambda \, m_1 m_2}{2(4\pi)^3}  \int_0^\infty d{x'}^0 \int d^3 {\vx}^{\,\prime} \int_0^\infty d{y'}^0 \int_0^{2\pi} d\varphi \int_{0}^{\pi} d \vartheta  \nonumber\\
&\times \cos(\vartheta) |{x'}^0-{y'}^0| H(x^0-{x'}^0-|\vx-{\vx}^{\,\prime}|) \frac{J_1(m_1\sqrt{(x-x')^2})}{\sqrt{(x-x')^2}}\nonumber\\
&\times \!H(y^0\!\!-\!{y'}^0\!\!-|\vy\!-\!{\vx}^{\,\prime}\!+\!\vz|) \frac{J_1(m_2\sqrt{(y\!-\!y')^2})}{\sqrt{(y\!-\!y')^2}} \psi(x'\!,y')\Big|_{{\vy}^{\,\prime} = {\vx}^{\,\prime}-\vz, \, |\vz| = |{x^0}'-{y^0}'|}
\label{eq:defa12}.
\end{align}
The resulting expression does not contain distributions anymore and 
will serve as our definition of $A_{12}$ on test functions $\psi 
\in \mathcal{S}$. Note that the domain of integration is again 
effectively finite.

%%%
\subsubsection{Lifting of the integral operator from test 
functions to a suitable Banach space.}
In order to prove the existence and uniqueness of solutions 
of the integral equation $\psi = \psi^{\free} + A\psi$, we need 
to define the operator $A$ not only on test functions but on a 
suitable Banach space which includes (at least) sufficiently many 
solutions $\psi^{\free}$ of the free multi-time Klein-Gordon equations, 
$(\Box_k + m_k^2)\psi^{\free}(x_1,x_2) = 0,~k=1,2$. 
We shall define this Banach space as the completion of 
$\mathcal{S} =\mathcal{S}((\M)^2)$ with respect to a 
suitable norm. A good choice which works well for the upcoming 
existence and uniqueness proofs is the class of weighted 
$L^\infty$-norms
\begin{equation}
	 \| \psi \|_{\weightf} := \esssup_{x,y \in \M} \frac{|\psi(x,y)|}{\weightf(x^0)\weightf(y^0)},
\end{equation}
where $\weightf : \R^+_0 \rightarrow \R^+$ is assumed to be a monotonically 
increasing function such that $1/\weightf$ is bounded. Then our Banach space 
is given by the completion
\begin{equation}
	\Banach_{\weightf} = \overline{\mathcal{S}}^{\| \cdot \|_{\weightf}}.
\end{equation}
Our next goal is to find a weight function $\weightf$ such that the operator 
$A$ is not only bounded but even defines a contraction on $\Banach_{\weightf}$. 
By linear extension, it is sufficient to estimate $\| A \psi \|_{\weightf}$ 
on test functions $\psi \in \mathcal{S}$.

%%%%
\begin{Remarks}
	\begin{enumerate}
    \item We have attempted to use an $L^\infty_t L^2_\vx$-based norm 
    ($L^\infty$ in the times and $L^2$ in the space variables). 
    However, we did not succeed with obtaining suitable estimates 
  for that case. This might not be a problem in principle, but its 
  treatment would require further technical innovation.
More precisely, one would need to understand integral operators such 
as \eqref{eq:defa0} whose kernel is in $L^1$ but not in $L^2$.
		%
    \item Nevertheless, our definition of $\Banach_{\weightf}$ contains a 
    large class of free solutions of the Klein-Gordon equation. As 
    the Klein-Gordon equation preserves boundedness, all bounded 
    initial data for $\psi^{\free}$ lead to a free solution $\psi^{\free} 
    \in \Banach_{\weightf}$ which can be used as an input to our integral 
    equation.
	\end{enumerate}
\end{Remarks}


%%%%%
\subsection{Results}
\label{sec:KG results}

This section is structured as follows. Sec.\@ \ref{sec:2part} (which 
is about the two-particle case) contains the main results: the 
estimates of the integral operators as well as the theorems about 
existence and uniqueness of solutions. Sec.\@ \ref{sec:Npart} 
extends these results to the $N$-particle case and in Sec.\@ 
\ref{sec:KGcurvedspacetime} we show that a curved spacetime with a 
Big Bang singularity can provide a natural reason for a cutoff in 
time.


%%%%%%
\subsubsection{The two-particle case} \label{sec:2part}

For $t\geq0$, we define the functions:
\begin{align}
	\weightf_0(t) &= \weightf(t),\nonumber\\
\text{and for }n\in\N:~~~	\weightf_n(t) &= \int_0^t dt' \, \weightf_{n-1}(t').	
\end{align}
Note that due to the properties of $\weightf$, the functions $\weightf_n$ are 
monotonically increasing for all $n\in \N$; furthermore, by 
definition, they satisfy $\weightf_n(0)=0$.

Our first theorem gives explicit bounds for the operators 
\(A_0\), \(A_1\), \(A_2\), \(A_{12}\) in terms of the functions $\weightf_n$. 
The proof 
can be found in Sec.\@ \ref{sec:proofbounds}.

%%%%%
\begin{Thm}[Bounds of the integral operators on $\mathcal{S}$.]
	\label{thm:boundsKG}
	For all $\psi \in \mathcal{S}((\M)^2)$, the integral operators $A_0, A_1, A_2, A_{12}$ satisfy the following bounds:
	\begin{align}
		\sup_{\psi \in \mathcal{S}((\M)^2)} \frac{\| A_0 \psi \|_{\weightf}}{\| \psi \|_{\weightf}} ~\leq~& \frac{\lambda}{8\pi} \left(\sup_{t\geq 0} \frac{\weightf_1(t)}{\weightf(t)}\right)^2\label{eq:estimatea0},\\
%
  \sup_{\psi \in \mathcal{S}((\M)^2)} \frac{\| A_1 \psi \|_{\weightf}}{\| \psi \|_{\weightf}} ~\leq~& \frac{\lambda \, m_1^2}{16\pi} \bigg[ 3\left(\sup_{t\geq 0}\frac{t \weightf_1(t)}{\weightf(t)}\right)\left(\sup_{t\geq 0}\frac{\weightf_2(t)}{\weightf(t)}\right) \notag\\
  &\quad+ 3\left( \sup_{t\geq 0} \frac{\weightf_1(t)}{\weightf(t)} \right)\left( \sup_{t\geq 0} \frac{t\weightf_2(t)}{\weightf(t)} \right) \nonumber\\
	&\quad\left. +\, 2 \left( \sup_{t\geq 0} \frac{\weightf_1(t)}{\weightf(t)} \right)\left( \sup_{t\geq 0} \frac{\weightf_3(t)}{\weightf(t)} \right) \right], \label{eq:estimatea1}\\
%
  \sup_{\psi \in \mathcal{S}((\M)^2)} \frac{\| A_2 \psi \|_{\weightf}}{\| \psi \|_{\weightf}} ~\leq~& \frac{\lambda \, m_2^2}{16\pi} \bigg[ 3\left(\sup_{t\geq 0}\frac{t \weightf_1(t)}{\weightf(t)}\right)\left(\sup_{t\geq 0}\frac{\weightf_2(t)}{\weightf(t)}\right) \notag\\
  &\quad+ 3\left( \sup_{t\geq 0} \frac{\weightf_1(t)}{\weightf(t)} \right)\left( \sup_{t\geq 0} \frac{t\weightf_2(t)}{\weightf(t)} \right) \nonumber\\
	&\quad\left. + \, 2 \left( \sup_{t\geq 0} \frac{\weightf_1(t)}{\weightf(t)} \right)\left( \sup_{t\geq 0} \frac{\weightf_3(t)}{\weightf(t)} \right) \right], \label{eq:estimatea2}\\
	\sup_{\psi \in \mathcal{S}((\M)^2)} \frac{\| A_{12} \psi \|_{\weightf}}{\| \psi \|_{\weightf}} ~\leq~& \frac{\lambda \, m_1^2 m_2^2}{96\pi} \left[ \left( \sup_{t\geq 0} \frac{t^2 \weightf_2(t)}{\weightf(t)}\right)\left( \sup_{t\geq 0} \frac{t \weightf_1(t)}{\weightf(t)}\right) \right.\nonumber\\
&~~~~~\left.+ \, \frac{1}{2}  \left( \sup_{t\geq 0} \frac{t^2 \weightf_3(t)}{\weightf(t)}\right)\left( \sup_{t\geq 0} \frac{\weightf_1(t)}{\weightf(t)}\right) \right].\label{eq:estimatea12}
	\end{align}
\end{Thm}
In case these expressions are finite, $A_0, A_1, A_2, A_{12}$ 
extend to linear operators on $\Banach_{\weightf}$ with the same norms. Our 
next task is to find suitable weight functions $g$ such that this 
is actually the case. We begin with the massless case where already 
an exponential weight function leads to an estimate which remains 
finite after taking the supremum. The massive case is treated 
subsequently; it is a little more difficult since all the estimates 
for the operators $A_0, A_1, A_2, A_{12}$ have to be finite at 
the same time. This  requires a different choice of weight 
function (see Thm.\@ \ref{thm:KGexistence}).


%%%%%
\begin{Thm}[Bounds for $A_0$ and $\weightf(t) = e^{\gamma t}$; existence 
  of massless dynamics.]
	\label{thm:exponentialg}
~\\ For any $\gamma> 0$, let $\weightf(t) = e^{\gamma t}$. Then $A_0$ 
can be linearly extended to a bounded operator on $\Banach_{\weightf}$ 
with norm
	\begin{equation}
		\| A_0 \| ~\leq~ \frac{\lambda}{8\pi \gamma^2}.
	\label{eq:norma0exponential}
	\end{equation}
Consequently, for all $\gamma > \sqrt{\frac{\lambda}{8\pi}}$, the 
integral equation $\psi = \psi^{\free} + A_0\psi$ has a unique 
solution $\psi \in \Banach_{\weightf}$ for every $\psi^{\free} \in \Banach_{\weightf}$.
\end{Thm}

Now we come to our main result.

%%%%%
\begin{Thm}[Existence of dynamics in the massive case.]
	\label{thm:KGexistence}~\\
	For any $\alpha > 0$, let
	\begin{equation}
		\weightf(t) = (1+\alpha t^2)e^{\alpha t^2/2}.
	\label{eq:weightfactor}
	\end{equation}
	 Then $A_0, A_1, A_2$ and $A_{12}$ can be linearly extended to bounded operators on $\Banach_{\weightf}$ with norms
	\begin{align}
		\| A_0 \| ~&\leq~ \frac{\lambda}{32 \pi} \frac{1}{\alpha}, \label{eq:estimatea0final}\\
		\| A_1 \| ~&\leq~ \frac{5\lambda \, m_1^2}{16\pi} \frac{1}{\alpha^2},\label{eq:estimatea1final}\\
		\| A_2 \| ~&\leq~ \frac{5\lambda \, m_2^2}{16\pi} \frac{1}{\alpha^2}, \label{eq:estimatea2final}\\
		\| A_{12} \| ~&\leq~ \frac{\lambda \, m_1^2 m_2^2}{80\pi} \frac{1}{\alpha^3}. \label{eq:estimatea12final}
	\end{align}
	Consequently, for all $\alpha > 0$ with
\begin{equation}
	\frac{\lambda}{8\pi \alpha} \left( \frac{1}{4} + \frac{5(m_1^2 + m_2^2)}{2} \frac{1}{\alpha} + \frac{m_1^2 \, m_2^2}{10} \frac{1}{\alpha^2} \right) ~<~ 1,
\label{eq:condexistencemassive}
\end{equation}
	the integral equation $\psi = \psi^{\free} + A\psi$ has a unique solution $\psi \in \Banach_{\weightf}$ for every $\psi^{\free} \in \Banach_{\weightf}$.
\end{Thm}

The proof can be found in Sec.\@ \ref{sec:proofexistence}.

%%%
\begin{Remarks}
	\begin{enumerate}
    \item \textit{Comparison of Thms. 
    \ref{thm:exponentialg} and \ref{thm:KGexistence} in 
    the massless case.} On the first glance, the result 
    of Thm.\@ \ref{thm:exponentialg} looks stronger in 
    the sense that for $\weightf(t)=e^{\gamma t}$, the estimate 
    of $\|A_0\|$ goes with $\gamma^{-2}$ while for 
    $\weightf(t)=(1+\alpha t^2 )e^{\alpha t^2/2}$, the 
    estimate of $\|A_0\|$ goes with $\alpha^{-1}$. 
    However, one should note that $\gamma$ is the 
    constant in front of $t$ while $\alpha$ occurs in 
    combination with $t^2$. Thus, if one wants to draw 
    a comparison between these different cases at all, 
    then it should be between $\gamma$ and 
    $\sqrt{\alpha}$. Of course, the main difference 
    between the two theorems is the admitted growth 
    rate of the solutions. In this regard, Thm.\@ 
    \ref{thm:exponentialg} contains the stronger 
    statement.
	%
    \item A \textit{physically realistic value of 
    $\lambda$} is $\frac{1}{137}$, the value of the 
    fine structure constant. In that case, $\alpha$ 
    need not even be particularly large in order for 
    condition \eqref{eq:condexistencemassive} to be 
    satisfied.
	%
    \item \textit{Initial value problem.} By the 
    integral equation \eqref{eq:KGtwopartint}, we obtain that 
    the solution $\psi$ satisfies $\psi(0,\vx,0,\vy) = 
    \psi^{\free}(0,\vx,0,\vy)$. If $\psi^{\free}$ is a 
    solution of the free multi-time Klein-Gordon 
    equations, then it is itself determined by initial 
    data at $x_1^0,x_2^0=0$. (As the Klein-Gordon 
    equation is of second order in time, these initial 
    data include data for $\partial_{x^0}\psi$, 
    $\partial_{y^0}\psi$ and $\partial_{x^0} 
    \partial_{y^0} \psi$, see 
    \cite[chap. 5]{phd_nickel}.) Thus, we find that 
    $\psi$ is determined by these data at 
    $x_1^0,x_2^0=0$ as well. Note that for later 
    times, $\psi$ and $\psi^{\free}$ do not, in general, 
    coincide and consequently a similar statement does 
    not hold.
	%
  \item \textit{Finite propagation speed.} The theorem 
  implies that \linebreak 
  $\psi = \sum_{k=0}^\infty A^k\psi^{\free}$. 
  As $(A \psi^{\free})(x,y)$ involves only values of 
  $\psi^{\free}$ in $\past(x) \times \past(y)$ where 
  $\past(x)$ denotes the causal past of $x \in 
  \M$ (see Eqs.\@ \eqref{eq:defa0}, 
  \eqref{eq:defa1}, \eqref{eq:defa2}, 
  \eqref{eq:defa12}), so do $A^k \psi^{\free}$ for 
  all $k \in \N$ and $\psi$. Therefore, we obtain: 
  if the initial data for $\psi^{\free}$ at $x^0 = 0 
  = y^0$ are compactly supported in a region 
  $R \subset \left( \{ 0\} \times \R^3\right)^2$, 
  then for all Cauchy surfaces $\Sigma \subset 
  \M$, $\psi|_{\Sigma \times \Sigma}$ is 
  supported in the causally grown set \linebreak 
  $\text{Gr}(R,\Sigma) = \left(\bigcup_{(x,y)\in R} 
  \future(x) \times \future(y) \right) \cap 
  (\Sigma \times \Sigma)$ where $\future(x)$ stands 
  for the causal future of $x \in \M$.
%
  \item \textit{Square integrable solutions.} As a 
  consequence of the previous item, compactly supported 
  and bounded initial data for $\psi^{\free}$ lead to a 
  compactly supported and bounded solution $\psi$. In 
  particular, this implies that $\psi(x^0,\cdot,y^0)$ 
  lies in $L^2(\R^6)$ for all times $x^0,y^0\geq 0$.
	\end{enumerate}
\end{Remarks}


%%%%%
\subsubsection{The $N$-particle case} \label{sec:Npart}

Here we extend Thm.\@ \ref{thm:KGexistence} from two to 
$N\geq 3$ scalar particles. While there are different 
possibilities to generalize the two-particle integral 
equation \eqref{eq:KGtwopartint}, we focus on the one 
advocated in \cite{direct_interaction_quantum} as the 
most promising. For
\begin{equation}
	\psi : \big(\M\big)^N \rightarrow \CC,~~~~~(x_1,...,x_N) \mapsto \psi(x_1,...,x_N)
\end{equation}
we consider the integral equation
\begin{align}\label{eq:npartint}
  \psi(x_1,...,x_N) &~=~ \psi^{\free}(x_1,...,x_N) +\frac{ \lambda}{4\pi} \sum_{i,j =1,...,N; \, i<j}\\
&\times \int_{\M} d^4 x_i \int_{\M} d^4 x_j~G^{\ret}(x_i-x_i')G^{\ret}(x_j-x_j') \nonumber\\
&\times \delta((x_i'-x_j')^2) \psi(x_1,...,x_i, ...,x_j,..., x_N).\notag
\end{align}
Here, $\psi^{\free}$ is again a solution of the free 
Klein-Gordon equations $(\Box_k + m_k^2)\phi(x_k)$ in 
each spacetime variable.

Eq.\@ \eqref{eq:npartint} is written down in an 
informal way. To define a rigorous version, let 
$\psi \in \mathcal{S}\big( (\M)^N\big)$ 
be a test function. Moreover, let $A^{(ij)}$ be the 
integral operator of the two-particle problem acting 
on the variables $x_i$ and $x_j$ instead of $x = x_1$ 
and $y=x_2$. We define
\begin{equation}
	\,^{(N)}\! A ~=~ \sum_{i,j =1,...,N; \, i<j} A^{(ij)}.
\end{equation}
As will be shown below, $\! \,^{(N)}\! A$ can be 
linearly extended to a bounded operator on the Banach 
space $\! \,^{(N)}\Banach_{\weightf}$. That space is defined 
as the completion of $\mathcal{S}\big( 
  (\M)^N\big)$ with respect to the norm
\begin{equation}
	\|\psi \|_{\weightf} ~=~ \esssup_{x_1,...,x_N \in \M} \frac{|\psi|(x_1,...,x_N)}{\weightf(x_1^0)\cdots \weightf(x_N^0)},
\end{equation}
where the function $g$ is defined as before.

Then we take the equation
\begin{equation}
	\,^{(N)}\! A ~=~\psi^{\free} + \! \,^{(N)}\! A \psi,
\label{eq:npartintabstract}
\end{equation}
to be the rigorous version of \eqref{eq:npartint} on 
$\! \,^{(N)}\!\Banach_{\weightf}$.

With these preparations, we are ready to formulate 
the $N$-particle existence and uniqueness theorem.

%%%%%
\begin{Thm}[Existence of dynamics for $N$ particles.]
	\label{thm:Npart}~\\
    For any $\alpha > 0$, let $\weightf(t) = (1+\alpha t^2)
    e^{\alpha t^2/2}$. Then the operator $\! \,^{(N)}\! A$ 
    can be linearly extended to a bounded operator on 
    $\! \,^{(N)} \Banach_{\weightf}$ with norm
	\begin{equation}
    \|\! \,^{(N)}\! A\| \leq\frac{\lambda}{8\pi \alpha}\! \sum_{i,j =1,...,N; \, i<j} \! 
    \left( \frac{1}{4} \!+\! \frac{5(m_i^2 + m_j^2)}{2} \frac{1}{\alpha} 
    \!+ \!\frac{m_i^2 \, m_j^2}{10} \frac{1}{\alpha^2} \right).
	\end{equation}
  If $\alpha$ is such that this expression is 
  strictly smaller than one, the integral equation 
  \eqref{eq:npartintabstract} has a unique solution 
  $\psi \in \!\!\! \,^{(N)}\Banach_{\weightf}$ for every 
  $\psi^{\free} \in \!\!\! \,^{(N)}\Banach_{\weightf}$.
\end{Thm}

The proof follows straightforwardly from that of 
Thm.\@ \ref{thm:KGexistence} using
\begin{equation}
	\|\! \,^{(N)}\! A\| \leq \sum_{i,j =1,...,N; \, i<j} \| A^{(ij)}\|_{\weightf}.
\end{equation}
For the norms of the operators $A^{(ij)}$, one can 
use the previous expressions as these operators act 
only as the identity on variables $x_k$ with 
$k \notin \{i,j\}$.

%%%
\begin{Remark}
  To the best of my knowledge, Thm.\@ \ref{thm:Npart} 
  is the first result about the existence and 
  uniqueness of solutions of multi-time integral 
  equations for $N$ particles. While for the present 
  contraction argument the generalization to $N$ 
  particles has been straightforward, this is not 
  the case for other works. For example, the Volterra 
  iterations used in \cite{mtve} become increasingly 
  complicated with increasing particle number. For 
  Dirac particles,  a similar technique is 
  used section \ref{sec:direct dirac}. However, as the Dirac 
  Green's functions contain distributional derivatives, 
  one has to control weak derivatives of the solutions, 
  and the number of such derivatives depends on $N$. 
  That situation also does not allow for such a 
  straightforward generalization to $N$ particles as 
  has been possible here.
\end{Remark}


%%%%%
\subsubsection{Result on FLRW Spacetime}
\label{sec:KGcurvedspacetime}


%So far, we have assumed a cutoff in time. In the way 
%this has been treated so far, this cutoff breaks the 
%manifest Poincar\'e invariance of our integral 
%equation. In this section, we demonstrate at a 
%particular (simple and tractable) example that such a 
%cutoff can arise naturally if the considered spacetime 
%has a Big Bang singularity. Then the Big Bang defines 
%the initial time. To consider a simple example is 
%necessary as otherwise the Green's functions may not 
%be known in detail, and in that case it would not be 
%possible to explicitly define the integral operator, 
%let alone to carry out an analysis of that operator 
%comparable to the one before.

%Our example consists of two massless scalar particles 
%which, in absence of interactions, obey the conformally 
%invariant wave equation on a curved spacetime 
%$\mathcal{M}$ with metric g,
%\begin{equation}
%	\left( \Box_g - R/6 \right) \chi = 0,
%	\label{eq:conformalwaveeq}
%\end{equation}
%where $R$ denotes the Ricci scalar.

%We consider these particles on a flat 
%Friedman-Lema\^itre-Robertson-Walker (FLRW) spacetime 
%which is described by the metric
%\begin{equation}
%	ds^2 = a^2(\eta) \left( d\eta^2 - dr^2 - r^2 d \Omega^2 \right),
%\end{equation}
%where $\eta$ denotes conformal time, $d \Omega$ 
%denotes the surface measure on $\mathbb{S}^2$ and 
%$a(\eta)$ is the so-called \textit{scale function}, a 
%continuous function with $a(0) = 0$ and $a(\eta) > 0$ 
%for $\eta >0$. This form makes it obvious that the 
%spacetime is conformally equivalent to a Minkowski 
%half space $\M$, with conformal factor 
%$a(\eta)$.

%In this case, it is well-known that the Green's 
%functions of \eqref{eq:conformalwaveeq} on the flat 
%FLRW spacetime $\mathcal{M}$ can be obtained from 
%those of the usual wave equation on $\M$ 
%as follows (using coordinates $x=(\eta,\vx)$ and 
%$x'=(\eta',{\vx}^{\,\prime})$ with $\eta,\eta' \in [0,\infty)$ 
%and $\vx,{\vx}^{\,\prime} \in \R^3$):
%\begin{equation}\label{eq: greens function singular interaction curved}
%	G_{\mathcal{M}}(x,x') ~=~ \frac{1}{a(\eta)} \frac{1}{a(\eta')} G_{\M}(x,x'),
%\end{equation}
%which can be derived from the transformation behavior of 
%the Ricci scalar 
%\begin{equation}
%  R_{\mathcal{M}_2}=a^{-2}R_{\mathcal{M}_1}-6a^{-3}\Box_{\mathcal{M}_1} a
%\end{equation}
%for general spacetimes \(\mathcal{M}_2\) and \(\mathcal{M}_1\) connected by a 
%conformal transformation; 
%see \cite{lienertcurved,john1987hadamard} for 
%more detailed explanations.
%Inserting the well-known expression for the retarded 
%and symmetric Green's functions on $\M$ 
%(see \eqref{eq:gretkg}) yields:
%\begin{align}
%	G_{\mathcal{M}}^{\ret}(x,x') ~&=~ \frac{1}{4\pi} \frac{1}{a(\eta) a(\eta')} \frac{\delta(\eta - \eta' -|\vx-{\vx}^{\,\prime}|)}{|\vx-{\vx}^{\,\prime}|}\nonumber\\
%G_{\mathcal{M}}^{\sym}(x,x') ~&=~ \frac{1}{4\pi} \frac{1}{a(\eta) a(\eta')} \delta((\eta-\eta')^2-|\vx-{\vx}^{\,\prime}|^2).
%\end{align}

%With this information, we are ready to write down 
%the integral equation on $\mathcal{M}$. The 
%generalization of \eqref{eq:KGtwopartint} to curved 
%spacetimes is straightforward: $\psi$ becomes a 
%scalar function on $\mathcal{M}\times\mathcal{M}$, 
%one exchanges the Minkowski spacetime volume elements 
%with the invariant 4-volume elements on $\mathcal{M}$, 
%and the Green's functions on $\M$ get 
%replaced with those on $\mathcal{M}$ as well. As in 
%the Minkowski case, the interaction kernel is given 
%by the symmetric Green's function. With this, the 
%relevant integral equation becomes:
%\begin{align}\notag
%\psi(x,y) = \psi^{\free}(x,y) 
%+ \lambda \int_{\mathcal{M}\times \mathcal{M}} \!\!
%&dV(x) dV(y)~G^{\ret}(x,x')G^{\ret}(y,y')\\
%&\times  G^{\sym}(x',y') \psi(x',y'),
%\label{eq:KGinteqcurved}
%\end{align}
%For flat FLRW 
%universes and scalar particles, we here extend 
%\cite{lienertcurved} to the physically most interesting 
%and mathematically challenging case 
%$K(x,y)=G^{\sym}(x,y)$.

%We now formulate \eqref{eq:KGinteqcurved} explicitly. 
%The spacetime volume element is given by:
%\begin{equation}
%	dV(x) = a^4(\eta) \, d\eta \, d^3 \vx.
%\end{equation}

Recall the formulation of the spin-0 delay-equation \eqref{eq:KGtwopartint} 
on FLRW spacetime, equation \eqref{eq:KGinteqcurved} which 
upon plugging in the expressions \eqref{eq:KGcurvedGreen1}
and \eqref{eq:KGcurvedGreen2} for the Green's functions 
becomes
\begin{align}
  \psi(\eta_1,&\vx_1,\eta_2,\vx_2) = \psi^{\free}(\eta_1,\vx_1,\eta_2,\vx_2) + \frac{\lambda}{(4\pi)^3} \frac{1}{a(\eta_1) a(\eta_2)} \notag\\
&\int_0^{\eta_1} d \eta_1' \int d^3 \vx_1' \int_0^{\eta_2} d \eta_2' \int d^3  \vx_2' a^2(\eta_1') a^2(\eta_2')\nonumber\\
&\times ~\frac{\delta(\eta_1-\eta_1' - |\vx_1-\vx_1'|)}{|\vx_1-\vx_1'|}\frac{\delta(\eta_2-\eta_2' - |\vx_2-\vx_2'|)}{|\vx_2-\vx_2'|}\nonumber\\
&\times ~\delta((\eta_1'-\eta_2')^2-|\vx_1'-\vx_2'|^2) \psi(\eta_1',\vx_1',\eta_2',\vx_2').
\label{eq:KGinteqcurvedexplicit}
\end{align}
Now let
\begin{equation}
	\chi(\eta_1,\vx_1,\eta_2) = a(\eta_1) a(\eta_2) \psi(\eta_1,\vx_1,\eta_2).
\end{equation}
and $\chi^{\free}(\eta_1,\vx_1,\eta_2) = a(\eta_1) a(\eta_2) \psi^{\free}(\eta_1,\vx_1,\eta_2)$.
Then \eqref{eq:KGinteqcurvedexplicit} is equivalent to:
\begin{align}\label{eq:KGinteqcurvedexplicitchi}
	\chi(\eta_1,\vx_1&,\eta_2,\vx_2)\! =\! \chi^{\free}(\eta_1,\vx_1,\eta_2,\vx_2) + \frac{\lambda}{(4\pi)^3} \int_0^{\eta_1} d \eta_1' \int d^3 \vx_1' \\
&\times \int_0^{\eta_2} \!\!d \eta_2' \int d^3\!  \vx_2' \frac{\delta(\eta_1\!-\!\eta_1'\! -\! |\vx_1\!-\!\vx_1'|)}{|\vx_1\!-\!\vx_1'|}\frac{\delta(\eta_2\!-\!\eta_2' \!-\! |\vx_2\!-\!\vx_2'|)}{|\vx_2\!-\!\vx_2'|}\nonumber\\
&\times  a(\eta_1') a(\eta_2') \delta((\eta_1'\!-\!\eta_2')^2-|\vx_1'-\vx_2'|^2) \chi(\eta_1',\vx_1',\eta_2',\vx_2').\notag
\end{align}
We can see that this equation has almost exactly the 
same form as the massless version of \eqref{eq:KGtwopartint} 
on $\M$ (see \eqref{eq:a0informal}). The 
only difference is the additional appearance of the 
factor $a(\eta_1') a(\eta_2')$ inside the integrals.

Going through the same steps as for \eqref{eq:defa0} 
before, \eqref{eq:KGinteqcurvedexplicitchi} can be 
defined on test functions $\chi \in \mathcal{S}$ by
\begin{equation}
	\chi ~=~ \chi^{\free} + \widetilde{A}_0 \chi,
\label{eq:inteqcurvedabstract}
\end{equation}
where $\widetilde{A}_0$ is defined by (using 
coordinates $x=(\eta_1,\vx)$, $y=(\eta_2,\vy)$):
\begin{align}\nonumber
    &(\widetilde{A}_0\psi)(x,y)\!=\!\frac{\lambda}{(4\pi)^3}\int_{B_{y^0}(\vy)}\!\!\!d^3{\vy}^{\,\prime}  \!\int_0^{2\pi}\!\!d\varphi \int_{-1}^{1} \!\!d\!\cos\vartheta ~\frac{|b^2|}{4(b^0+|\vb|\cos\vartheta)^2 |{\vy}^{\,\prime}|}  \\
    &\times a(\eta_1+\eta_1') a(\eta_2+\eta_2') \psi(x+x',y+y')\notag\\ 
    &\times \left(1_{b^2>0}1_{b^0>0} 1_{\cos\vartheta > \frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}}+1_{b^2<0}1_{\cos\vartheta<\frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}}\right),
\label{eq:defa0tilde}
\end{align}
with \(\eta_1'=-r^*=-|{\vx}^{\,\prime}| , \eta_2'=-|{\vy}^{\,\prime}|\). 
(Here, $b$ and $r^*$ are defined as in \eqref{eq:b} 
and \eqref{eq:r}, respectively).

Knowing precisely how our integral equation on the 
flat FLRW spacetime is to be understood, we can 
formulate the respective existence and uniqueness 
theorem:

%%%%%
\begin{Thm}[Existence of dynamics for an open FLRW 
  universe]
	\label{thm:existencecurved}~\\
  Let $a: [0,\infty) \rightarrow [0,\infty)$ be a 
  continuous function with $a(0)=0$ and $a(\eta)>0$ 
  for $\eta>0$. Moreover, let
	\begin{equation}
		\weightf(t) = \exp \left( \gamma \int_0^t d\tau \, a(\tau) \right).
	\end{equation}
  Then, the operator $\widetilde{A}_0$ satisfies the 
  following estimate:
	\begin{equation}
		\sup_{\chi \in \mathcal{S}\big( ([0,\infty)\times \R^3)^2\big)} \frac{\| \widetilde{A}_0 \chi \|_{\weightf}}{\| \chi \|_{\weightf}} ~\leq~ \frac{\lambda}{8\pi \gamma^2}.
	\label{eq:a0tildebound}
	\end{equation}
  $\widetilde{A}_0$ can be extended to a linear 
  operator on $\Banach_{\weightf}$ which satisfies the same 
  bound. Moreover, for $\gamma < 
  \sqrt{\frac{\lambda}{8\pi}}$, the equation 
  $\chi = \chi^{\free} + \widetilde{A}_0\chi$ has a 
  unique solution $\chi \in \Banach_{\weightf}$ for every 
  $\psi^{\free} \in \Banach_{\weightf}$.
\end{Thm}

The proof can be found in Sec.\@ 
\ref{sec:proofexistencecurved}.

\begin{Remarks}
	\begin{enumerate}
    \item \textit{Manifest covariance.} The theorem 
    shows the existence and uniqueness of solutions 
    of the manifestly covariant integral equation 
    \eqref{eq:KGinteqcurved}. Our example of a particular 
    FLRW spacetime thus achieves its goal of 
    demonstrating that a cutoff in time can arise 
    naturally in a cosmological context.
		%
    \item \textit{Initial value problem.} As in the 
    case of $\M$, the solution $\chi$ 
    satisfies $\chi(0,\vx,0,\vy) = 
    \chi^{\free}(0,\vx,0,\vy)$ where $\chi^{\free}$ is 
    determined by the solution $\psi^{\free}$ of the 
    free conformal wave equation 
    \eqref{eq:conformalwaveeq} in both spacetime 
    variables. Since $\psi^{\free}$ is determined by 
    initial data at $\eta_1 = 0 =\eta_2$, so are 
    $\chi^{\free}$ and $\chi$.
		%
    \item \textit{Behavior of $\psi$ towards the Big 
    Bang singularity}. While the transformed wave 
    function $\chi$ remains bounded for $\eta_1, 
    \eta_2 \rightarrow 0$, the physical wave function 
    $\psi(\eta_1,\vx,\eta_2,\vy) = 
    \frac{1}{a(\eta_1)a(\eta_2)} 
    \chi(\eta_1,\vx,\eta_2,\vy)$ diverges like 
    $\frac{1}{a(\eta_1)a(\eta_2)}$. This is to be 
    expected, as the Klein-Gordon equation has a 
    preserved "energy" (given by a certain spatial 
    integral) and as the volume in $\vx, \vy$ 
    contracts to zero towards the Big Bang.
		%
    \item \textit{$N$-particle generalization.} As 
    shown in Sec.\@ \ref{sec:Npart} for the \linebreak 
    Minkowski 
    half-space, it would also be possible to directly extend 
    Thm.\@ \ref{thm:existencecurved} to $N$ particles. 
    To avoid duplication, we do not carry this out 
    explicitly for the curved spacetime example here.
	\end{enumerate}
\end{Remarks}


%%%%%
\subsection{Proofs}
\label{sec:KG proofs}

%%%%%
\subsubsection{Proof of Theorem \ref{thm:boundsKG}} 
\label{sec:proofbounds}
The proof is divided into the proofs of the estimates 
\eqref{eq:estimatea0}, \eqref{eq:estimatea1}, 
\eqref{eq:estimatea2} and \eqref{eq:estimatea12}, 
respectively. Here, \eqref{eq:estimatea0} is the most 
singular and difficult term which deserves the greatest 
attention.

Throughout this subsection, let $\psi \in 
\mathcal{S}((\M)^2)$.

%%%
\paragraph{Estimate of the massless term 
\eqref{eq:estimatea0}.} \label{sec:estimatemassless}

We start with Eq.\@ \eqref{eq:defa0} and take the 
absolute value. Using, in addition, that
\begin{equation}
	|\psi(x,y)| ~\leq~ \| \psi \|_{\weightf} \, \weightf(x^0) \weightf(y^0)
\end{equation}
leads us to:
\begin{align}
    &|A_0\psi|(x,y) \!\le\! \frac{\lambda \|\psi\|_{\weightf}}{4(4\pi)^3} \!\int_{B_{y^0}(\vy)}\!\!\!d^3 {\vy}^{\,\prime} \int_0^{2\pi} \!\!d\varphi \int_{-1}^1 \!\!\!d\cos\vartheta \, \frac{|b^2|}{(b^0\!+\!|\vb|\cos\vartheta)^2 |{\vy}^{\,\prime}|} \nonumber\\
    &\times \weightf(y^0\!-\!|{\vy}^{\,\prime}|) g\!\left(x^0-\frac{1}{2}\frac{b^2}{b^2+|\vb|\cos\vartheta}\right)\notag\\
    &\times \left(1_{b^2>0}1_{b^0>0} 1_{\cos\vartheta > \frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}}+1_{b^2<0}1_{\cos\vartheta<\frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}}\right).
\label{eq:a0calc01}
\end{align}
Next, we observe that the fraction 
$\frac{|b^2|}{(b^0+|\vb|\cos\vartheta)^2}$ is 
the derivative of the fraction which occurs in the 
argument of the second $g$-function. Introducing 
$u = \cos \vartheta$ allows us to rewrite 
\eqref{eq:a0calc01} as
\begin{align}
     &\eqref{eq:a0calc01} =\frac{\lambda \|\psi\|_{\weightf}}{8(4\pi)^2} \int_{B_{y^0}(\vy)}\!\!\!d^3{\vy}^{\,\prime} \int_{-1}^1\!du  2 \sgn(b^2)\,  \notag\\
    &\quad \times \partial_u \weightf_1\!\left(x^0-\frac{1}{2}\frac{b^2}{b^0+|\vb|u}\right) \weightf(y^0-|{\vy}^{\,\prime}|) \frac{1}{|\vb||{\vy}^{\,\prime}|}\\\nonumber
    &\quad \times \left(1_{b^2>0}1_{b^0>0} 1_{u > \frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}}+1_{b^2<0}1_{u<\frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}}\right) \\
    &=\frac{\lambda \|\psi\|_{\weightf}}{4(4\pi)^2} \int_{B_{y^0}(\vy)}d^3{\vy}^{\,\prime} \int_{-1}^1 du  ~ \partial_u \weightf_1\left(x^0-\frac{1}{2}\frac{b^2}{b^0+|\vb|u}\right) \weightf(y^0-|{\vy}^{\,\prime}|)\nonumber\\
    &\quad \times   \left(1_{b^2>0}1_{b^0>0} 1_{u > \frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}}-1_{b^2<0}1_{u<\frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}}\right) \frac{1}{|\vb||{\vy}^{\,\prime}|}.
\label{eq:a0calc02}
\end{align}
This form allows for a direct integration with respect 
to $u$.
Before we integrate, we check whether the conditions 
implicit in the characteristic functions can always be 
satisfied. (Otherwise, the respective term would not 
contribute any further and we could drop it.) Recall 
that $	b = x-y-(-|{\vy}^{\,\prime}|, {\vy}^{\,\prime})$. First we check 
whether in the case \(b^2>0, b^0>0\) it is true that 
\( 1> \frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}\) 
holds. (The comparison with 1 is due to the upper 
range for $u$.) We compute
\begin{align}
    1> \frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|} &\iff  2 x^0 |\vb|+2 x^0 b^0 > b^2 \nonumber\\
    &\iff 2 x^0(b^0 + |\vb|) > (b^0+|\vb|)(b^0-|\vb|)\nonumber\\
   &\!\!\!\! \overset{b^2>0,b^0>0}{\iff} 2x^0>b^0-|\vb| \nonumber \\
   &\iff  x^0+y^0\!\!- |{\vy}^{\,\prime}| > -|\vb|.
\end{align}
Now because of \(|{\vy}^{\,\prime}|<y^0\) we see that this 
inequality always holds true. Hence the respective 
term in \eqref{eq:a0calc02} contributes without 
further restrictions.

Next, we turn to the case \(b^2<0\). Here we check 
whether (or when) $-1<\frac{b^2}{2x^0|\vb|} - 
\frac{b^0}{|\vb|}$ holds. (The comparison with $-1$ 
is due to the lower bound for $u$.) A similar 
calculation yields 
\begin{align}
    -1<\frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|} &\iff -2x^0|\vb| + 2x^0 |\vb| < b^2\\
    &\iff 2x^0 (b^0-|\vb|) < (b^0-|\vb|)(b^0+|\vb|) \\
   & \overset{b^2<0}{\iff} 2x^0 > b^0 + |\vb|.
\end{align}
This inequality need not always hold, as we can 
increase \(|\vb|\) with respect to \(b^0\) as much as 
we like, e.g., by picking \(|\vx-\vy|\) large. 
Therefore, in this case, the respective term is only 
sometimes nonzero. We make this clear by including 
the characteristic function $1_{2x^0>b^0+|\vb|}$.

Taking these considerations into account, we now carry 
out the $u$-integration in \eqref{eq:a0calc02}:
\begin{align}
    &|A_0\psi|(x,y) ~\le~ \frac{\lambda \|\psi\|_{\weightf}}{4(4\pi)^2} \int_{B_{y^0}(\vy)}d^3{\vy}^{\,\prime}~ \frac{\weightf(y^0-|{\vy}^{\,\prime}|)}{|\vb||{\vy}^{\,\prime}|} \notag\\
    &\times \Bigg(1_{b^2>0,b^0>0} \Bigg[\weightf_1\left(x^0-\frac{1}{2} \frac{b^2}{b^0+|\vb|}\right) \notag\\
    &\quad \quad - \weightf_1\left( x^0 - \frac{1}{2}\frac{b^2}{b^0+|\vb| \max (-1, \frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|})}\right)\Bigg]\notag\\
    & -1_{b^2<0}1_{2x^0>b^0+|\vb|}\Bigg[
    \weightf_1\left(x^0-\frac{1}{2} \frac{b^2}{b^0+|\vb| \min(1, \frac{b^2}{2x^0|\vb|}-\frac{b^0}{|\vb|})}\right)\notag\\
    &\quad \quad - \weightf_1\left(x^0-\frac{1}{2} \frac{b^2}{b^0-|\vb|} \right)\Bigg]\Bigg).
\label{eq:a0calc03}
\end{align}
The minima and maxima in this expression result from 
the indicator functions $1_{u > \frac{b^2}{2x^0|\vb|} 
- \frac{b^0}{|\vb|}}$ and $1_{u<\frac{b^2}{2x^0|\vb|} 
- \frac{b^0}{|\vb|}}$, respectively.

Our next step is to simplify the complicated fractions 
in \eqref{eq:a0calc03} involving $\min$ and $\max$. 
For the first one we use that 
\(1/\max(a,b)=\min(1/a,1/b)\) whenever \(a,b>0\) or 
\(a,b<0\) holds. Therefore, we have:
\begin{align}
    &\frac{1}{2}\frac{b^2}{b^0+|\vb|\max\left( -1,\frac{b^2}{2x^0|\vb|} - \frac{b^0}{|\vb|}\right)}
	= \frac{1}{2} \frac{b^2}{\max\left(b^0-|\vb|,\frac{b^2}{2x^0}\right)}\nonumber\\
    &= \frac{1}{2} \min \left(\frac{b^2}{b^0-|\vb|}, 2x^0 \right)\nonumber
    = \min \left( \frac{b^0+|\vb|}{2}, x^0 \right).
\end{align}
The fraction in \eqref{eq:a0calc03} which contains a 
minimum can be simplified by observing that
\begin{align}
    b^0+|\vb|\min\left(1,\frac{b^2}{2x^0|\vb|}-\frac{b^0}{|\vb|}\right) = \min \left( b^0+|\vb|, \frac{b^2}{2x^0} \right)= \frac{b^2}{2x^0}
\end{align}
as the term contributes only for \(b^2<0\) hence \(b^0+|\vb|>0>b^2/(2x^0)\). Thus,
\begin{equation}
	\frac{1}{2} \frac{b^2}{b^0+|\vb| \min(1, \frac{b^2}{2x^0|\vb|}-\frac{b^0}{|\vb|})} = x^0.
\end{equation}
With these simplifications, we obtain (using 
$\weightf_1(0)=0$):
\begin{align}
    &|A_0\psi|(x,y) \le  \frac{\lambda \|\psi\|_{\weightf}}{4(4\pi)^2} \int_{B_{y^0}(\vy)}d^3{\vy}^{\,\prime}~ \frac{\weightf(y^0-|{\vy}^{\,\prime}|)}{|\vb||{\vy}^{\,\prime}|} \nonumber\\
    &\times \!\left(\!1_{b^2>0,b^0>0} \left[\weightf_1\!\left(\!x^0\!-\frac{b^0-|\vb|}{2} \!\right)\! -\! \weightf_1\!\left(\! x^0 \!- \!\min\!\left(\frac{b^0+|\vb|}{2},x^0\!\right)\!\right)\!\right]\right.\nonumber\\
    &\left. -1_{b^2<0}~1_{2x^0>b^0+|\vb|}\left[
    \weightf_1\left(x^0-x^0\right)- \weightf_1\left(x^0-\frac{b^0+|\vb|}{2} \right)\right]\right)\nonumber\\\label{y'Integral1}
    &=\!\frac{\lambda \|\psi\|_{\weightf}}{4(4\pi)^2} \!\int_{B_{y^0}(\vy)}\!\!\!d^3{\vy}^{\,\prime} \frac{\weightf(y^0\!-\!|{\vy}^{\,\prime}|)}{|\vb||{\vy}^{\,\prime}|}
    1_{b^2>0,b^0>0} \notag\\
    &\hspace{3cm} \times \weightf_1\!\left(\!\frac{x^0+y^0-|{\vy}^{\,\prime}|+|\vb|}{2} \right) \\\label{y'Integral2}
    &-\frac{\lambda \|\psi\|_{\weightf}}{4(4\pi)^2}\! \int_{B_{y^0}(\vy)}\!\!\!d^3{\vy}^{\,\prime} \, \frac{\weightf(y^0-|{\vy}^{\,\prime}|)}{|\vb||{\vy}^{\,\prime}|}
    1_{b^2>0,b^0>0}\notag\\
    &\hspace{3cm} \times   \weightf_1\left( \max\left(\frac{x^0+y^0-|{\vy}^{\,\prime}|-|\vb|}{2},0\right)\right)\\\label{y'Integral3}
    & +\frac{\lambda \|\psi\|_{\weightf}}{4(4\pi)^2} \int_{B_{y^0}(\vy)}d^3{\vy}^{\,\prime} \, \frac{\weightf(y^0-|{\vy}^{\,\prime}|)}{|\vb||{\vy}^{\,\prime}|} 1_{b^2<0}~1_{x^0+y^0-|{\vy}^{\,\prime}|>|\vb|}\notag\\
    &\hspace{3cm} \times \weightf_1\left(\frac{x^0+y^0-|{\vy}^{\,\prime}|-|\vb|}{2} \right).
\end{align}

We now want to carry out as many of the remaining 
${\vy}^{\,\prime}$-integrations as possible. In order to do so, 
we orient the coordinates such that \(\vx-\vy\) is 
parallel to the \(({\vy}^{\,\prime})_3\) axis. Then the integrands 
in \eqref{y'Integral1}-\eqref{y'Integral3} are 
independent of the azimuthal angle $\varphi$ of the 
respective spherical coordinate system 
$(\rho,\theta,\varphi)$ with standard conventions.

In order to perform the remaining angular and then the 
radial integral, we need to find out which boundaries 
for $\theta$ and $r$ result from the characteristic 
functions. First we analyze for which arguments the 
maximum in \eqref{y'Integral2} is greater than zero 
and therefore contributes to the integral (as 
$\weightf_1(0) = 0$). We have:
\begin{align}\notag
  &\frac{x^0+y^0-|{\vy}^{\,\prime}|-|\vb|}{2}~>~0 \\
  &\iff  (x^0\!+\!y^0\!-\!|{\vy}^{\,\prime}|)^2>|\vx-\vy|^2\!+\!|{\vy}^{\,\prime}|^2\!+\!2|{\vy}^{\,\prime}||\vx\!-\!\vy|\!\cos\theta\nonumber\\
  &\iff \cos\theta\!<\!\frac{(x^0\!+\!y^0)^2}{2|{\vy}^{\,\prime}||\vx\!-\!\vy|} \!-\!\frac{|\vx\!-\!\vy|}{2|{\vy}^{\,\prime}|} \!-\! \frac{x^0\!+\!y^0}{|\vx\!-\!\vy|}\!=:P_{x,y}(|{\vy}^{\,\prime}|).
\label{eq:costhetapxy}
\end{align}
This calculation also helps to reformulate the second 
indicator function $1_{b^2<0}~1_{x^0+y^0-|{\vy}^{\,\prime}|>
|\vb|}$ in \eqref{y'Integral3} (for which we have 
\(b^2<0\)).
The condition \(b^0>0\) in \eqref{y'Integral1} and 
\eqref{y'Integral2} is readily seen to be equivalent 
to
\begin{equation}
	|{\vy}^{\,\prime}|>y^0-x^0.
	\label{eq:b0cond}
\end{equation}
In order to perform the \(\theta\)-integral we have 
to translate \(b^2\gtrless 0\) into conditions on 
\(\theta\). We have:
\begin{align}
    b^2>0 &\iff (x^0-y^0+|{\vy}^{\,\prime}|)^2~>~ |\vx-\vy|^2+|{\vy}^{\,\prime}|^2+2|{\vy}^{\,\prime}||\vx-\vy|\cos\theta \nonumber\\
    &\iff \cos\theta~<~ \frac{(x-y)^2}{2|{\vy}^{\,\prime}||\vx-\vy|} + \frac{x^0-y^0}{|\vx-\vy|}:=K_{x-y}(|{\vy}^{\,\prime}|).
\label{eq:costhetakxy}
\end{align}
With these considerations, we have extracted 
relatively simple conditions on the boundaries of the 
integrals in spherical coordinates. However, if 
different restrictions of the boundaries conflict 
with each other, it may happen that for some 
parameter values the domain of integration is the 
empty set. 
We check whether this is so term by term, focusing 
on the \(\theta\)-integration first. For term 
\eqref{y'Integral1}, \(\theta\) needs to satisfy 
\(-1<\cos\theta<\min(1,K_{x-y}(|{\vy}^{\,\prime}|))\), so we 
need to check whether \(-1<K_{x-y}(|{\vy}^{\,\prime}|)\) holds. 
We have:
\begin{align}\notag
    &-1 < K_{x-y}(|{\vy}^{\,\prime}|) \\
    &\iff -2|{\vy}^{\,\prime}||\vx-\vy|<(x-y)^2+2|{\vy}^{\,\prime}|(x^0-y^0)\nonumber\\
    &\iff 0~<~(x-y)^2+2|{\vy}^{\,\prime}|(x^0-y^0+|\vx-\vy|)\nonumber\\
    &\iff \left\{\begin{matrix}
    \frac{y^0-x^0+|\vx-\vy|}{2}<|{\vy}^{\,\prime}|  \quad \text{for } |\vx-\vy|>y^0-x^0\\
    \frac{y^0-x^0+|\vx-\vy|}{2}>|{\vy}^{\,\prime}| \quad \, \text{for } |\vx-\vy|<y^0-x^0.
    \end{matrix}\right.
\end{align}
Together with \eqref{eq:b0cond}, we obtain the 
condition \(y^0-x^0<|{\vy}^{\,\prime}|<
\frac{y^0-x^0+|\vx-\vy|}{2}<y^0-x^0\) in the second 
case which means that there is no contribution to 
the integral. For \(y^0-x^0=|\vx-\vy|\) we have 
\(K_{x-y}(|{\vy}^{\,\prime}|)=-1\) so this case is also ruled out. 
So we focus on the first case,
\begin{equation}
	\frac{y^0-x^0+|\vx-\vy|}{2}<|{\vy}^{\,\prime}|  \quad \text{and } |\vx-\vy|>y^0-x^0,
\label{eq:xycond1}
\end{equation}
by including the characteristic function 
$1_{|\vx-\vy|>y^0-x^0}$ in the integral. Next, we turn 
to the radial integral. By comparing its upper 
limit $|{\vy}^{\,\prime}|<y^0$ and lower limit $(y^0-x^0+
|\vx-\vy|)/2$, we find that the integral can only be 
nonzero for
\begin{equation}
	y^0+x^0>|\vx-\vy|.
	\label{eq:xycond2}
\end{equation}
For equality the integral vanishes, because the inegral domain,
while not empty, 
is of measure zero. We make this clear by including the respective 
characteristic function.

%%%
\subparagraph{Simplification of term 
\eqref{y'Integral1}.}
These considerations allow us to continue computing 
\eqref{y'Integral1}:
\begin{align}\label{casesFirstTermBeginning}
    &\eqref{y'Integral1}
    =\frac{\lambda \|\psi\|_{\weightf}}{4(4\pi)^2}1_{y^0+x^0>|\vx-\vy|}  \int_{\max(0,y^0-x^0)}^{y^0} d\rho \int_{0}^{2\pi}d\varphi~ 
    1_{\frac{y^0-x^0+|\vx-\vy|}{2}<\rho}\nonumber\\ 
  &\times 1_{|\vx-\vy|>y^0-x^0} \int_{-1}^{\min(1,K_{x-y}(\rho))} d\cos\theta  ~\frac{\rho \, \weightf(y^0-\rho)}{\sqrt{|\vx-\vy|^2+\rho^2 + 2 |\vx-\vy|\rho \cos\theta}}\nonumber\\ 
	&\times \weightf_1\left(\frac{x^0+y^0-\rho + \sqrt{|\vx-\vy|^2+\rho^2+2\rho|\vx-\vy|\cos\theta}}{2}\right).
    \end{align}
Now we carry out the $\varphi$-integration and use the 
same trick for the $\theta$-integral as for the 
$\vartheta$-integral in the \({\vx}^{\,\prime}\)-integration 
earlier.  Moreover, we absorb some of the restrictions 
of \(\rho\) into the limits of the integrals. This 
yields:
    \begin{align}
    \eqref{y'Integral1} &=\frac{\lambda \|\psi\|_{\weightf}}{8(4\pi)}  1_{y^0+x^0>|\vx-\vy|>y^0-x^0} \int_{\max\left(0,y^0-x^0,\frac{y^0-x^0+|\vx-\vy|}{2}\right)}^{y^0} d\rho \notag\\
    &\int_{-1}^{\min(1,K_{x-y}(\rho))} \!\!\! dw \, \frac{2 \weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\
 &\times \partial_w \weightf_2\left(\frac{x^0+y^0-\rho + \sqrt{|\vx-\vy|^2+\rho^2+2\rho|\vx-\vy|w}}{2}\right)\nonumber\\
    &= \frac{\lambda \|\psi\|_{\weightf}}{4(4\pi)} 1_{x^0+y^0>|\vx-\vy|>y^0-x^0} \int_{\max\left(0,y^0-x^0,\frac{y^0-x^0+|\vx-\vy|}{2}\right)}^{y^0} \!\!\!\!d\rho~   \frac{ \weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\ 
    &\hspace{-1cm}\times \left[ \weightf_2\!\left(\!\frac{x^0\!+\!y^0\!-\!\rho \!+\! \sqrt{|\vx\!-\!\vy|^2\!+\!\rho^2\!+\!2\rho|\vx\!-\!\vy|\min(1,K_{x-y}(\rho))}}{2}\right)\right.\nonumber\\
    &\left.-\weightf_2\left(\frac{x^0+y^0-\rho + ||\vx-\vy|-\rho|}{2}\right)\right]
\end{align}
The square root can be simplified using the following 
identity:
\begin{align}\notag
   &\sqrt{|\vx-\vy|^2+\rho^2+2\rho|\vx-\vy|K_{x-y}(\rho)}\\\label{PlugKIn}
   &=\sqrt{\rho^2 +(x^0-y^0)^2+2\rho (x^0-y^0)}
   =|x^0-y^0+\rho|.
\end{align}
Using this, we can effectively pull the minimum out of 
the square root. We obtain:
\begin{align}\nonumber
    &\eqref{y'Integral1} \!=\!\frac{\lambda \|\psi\|_{\weightf}}{16\pi} 1_{x^0+y^0>|\vx-\vy|>y^0-x^0}\! \int_{\max\left(0,y^0-x^0,\frac{y^0-x^0+|\vx-\vy|}{2}\right)}^{y^0} \!\!\!d\rho ~ \frac{ \weightf(y^0-\rho)}{|\vx-\vy|}\\ 
    &\times\Bigg[ \weightf_2\!\left(\frac{x^0+y^0-\rho + \min(|\vx-\vy|+\rho,|x^0-y^0+\rho|)}{2}\right)\notag\\
    &\hspace{3cm}-\weightf_2\!\left(\frac{x^0+y^0-\rho + ||\vx-\vy|-\rho|}{2}\right)\Bigg].
\label{CasesFirstTermEnd}
\end{align}
Next, we subdivide the conditions in the first 
indicator function into two cases, (a) $(x-y)^2\ge0$ and 
(b) $(x-y)^2<0$. In case (a), the condition 
$|\vx-\vy|>y^0-x^0$ implies $x^0>y^0$. This, in turn, 
yields $\max\left(0,y^0-x^0,\frac{y^0-x^0+|\vx-\vy|}{2}
\right) = 0$.  Moreover, the condition 
$x^0+y^0>|\vx-\vy|$ is automatically satisfied (note 
that $x^0,y^0>0$). In case (b), the condition 
$|\vx-\vy|>0$ is automatically satisfied. We find:
\begin{align}
 \nonumber
     &\eqref{y'Integral1} = \frac{\lambda \|\psi\|_{\weightf}}{16\pi} 1_{(x-y)^2\ge 0, x^0>y^0} \int_{0}^{y^0} d\rho  \, \frac{ \weightf(y^0-\rho)}{|\vx-\vy|}\\\nonumber
    &\times\left[ \weightf_2\left(\frac{x^0+y^0 + |\vx-\vy|}{2}\right)
    -\weightf_2\left(\frac{x^0+y^0-\rho + ||\vx-\vy|-\rho|}{2}\right)\right]\\\nonumber
    &+ \frac{\lambda \|\psi\|_{\weightf}}{16\pi} 1_{(x-y)^2<0}~1_{ x^0+y^0>|\vx-\vy|} \int_{\frac{y^0-x^0+|\vx-\vy|}{2}}^{y^0} d\rho \, \frac{ \weightf(y^0-\rho)}{|\vx-\vy|}\\\nonumber
    &\times \Bigg[ \weightf_2\left(\frac{x^0+y^0-\rho + |x^0-y^0+\rho|}{2}\right)\\\notag
    &\quad \quad -\weightf_2\left(\frac{x^0+y^0-\rho + ||\vx-\vy|-\rho|}{2}\right)\Bigg]\\\nonumber
    &= \frac{\lambda \|\psi\|_{\weightf}}{16\pi} 1_{(x-y)^2\ge0, x^0>y^0} \int_{0}^{y^0} d\rho \, \frac{ \weightf(y^0-\rho)}{|\vx-\vy|}\\\nonumber
    &\times \Bigg[ \weightf_2\left(\frac{x^0+y^0 + |\vx-\vy|}{2}\right)\\\notag
    &\quad \quad -\weightf_2\!\max\left(\frac{x^0+y^0- |\vx-\vy|}{2},\frac{x^0+y^0+ |\vx-\vy|}{2}-\rho\right)\Bigg]\\\nonumber
    &+ \frac{\lambda \|\psi\|_{\weightf}}{16\pi} 1_{(x-y)^2<0}~1_{ x^0+y^0>|\vx-\vy|} \int_{\frac{y^0-x^0+|\vx-\vy|}{2}}^{y^0} d\rho \, \frac{ \weightf(y^0-\rho)}{|\vx-\vy|}\\
    &\times\Bigg[ \weightf_2\!\max\left(x^0,y^0-\rho\right)\notag\\
    &\quad \quad -\weightf_2\!\max\left(\frac{x^0+y^0-|\vx-\vy|}{2},\frac{x^0+y^0+|\vx-\vy|}{2}-\rho\right)\Bigg].
\label{eq:resulty'Integral1}
\end{align}
Here and in the following we abbreviate 
$\weightf_2(\max(\cdots))$ as $\weightf_2 \max (\cdots)$, and 
similarly for the minimum. This ends the calculation 
of \eqref{y'Integral1}: we have arrived at an 
expression where no more exact calculations can be 
done and further estimates are needed.

%%%
\subparagraph{Simplification of term \eqref{y'Integral2}.}
Next, we proceed with \eqref{y'Integral2} in a similar fashion. In case the reader is not interested in the details of the calculation, the result can be found in \eqref{eq:resulty'Integral2}.

The restrictions of the integration variables for 
\eqref{y'Integral2} are the same as for 
\eqref{y'Integral1}, namely:
\begin{align}
\cos\theta<K_{x-y}(|{\vy}^{\,\prime}|)\quad\quad   &\text{from } \eqref{eq:costhetakxy},\\
\frac{y^0-x^0+|\vx-\vy|}{2} < |{\vy}^{\,\prime}| \quad\quad  &\text{from } \eqref{eq:xycond1}\label{eq:condfromkxy}\\
y^0-x^0<|\vx-\vy|<y^0+x^0 \quad\quad  &\text{from \eqref{eq:xycond1} and } \eqref{eq:xycond2}.
\end{align}
The only difference is that from the maximum in 
\eqref{y'Integral2}, we obtain the additional 
restriction \eqref{eq:costhetapxy}, i.e.
\begin{equation}
	\cos\theta< P_{x,y}(|{\vy}^{\,\prime}|).
\end{equation}
We need to check if there are new restrictions imposed 
by \(P_{x,y}(|{\vy}^{\,\prime}|)>-1\). We compute
\begin{align}
    P_{x,y}(|{\vy}^{\,\prime}|) ~&>~ -1~~ \iff\nonumber\\
     \frac{(x^0+y^0)^2}{2|{\vy}^{\,\prime}||\vx-\vy|} - \frac{|\vx-\vy|}{2|{\vy}^{\,\prime}|} - \frac{x^0+y^0}{|\vx-\vy|}~&>~-1    ~~\iff\nonumber \\
   |{\vy}^{\,\prime}| ~&<~ \frac{x^0+y^0+|\vx-\vy|}{2};
\end{align}
however, the last inequality is already ensured by 
\eqref{eq:condfromkxy} and $x^0>0$. 
In order to be able to evaluate \eqref{y'Integral2} 
further, we next plug the condition 
$\cos \theta < P_{x,y}(|{\vy}^{\,\prime}|)$ into the expression 
for $|\vb|$. This yields (recall that we use spherical 
variables for $|{\vy}^{\,\prime}|$):
\begin{align}\label{PlugPIn}
   |\vb| &= \sqrt{|\vx-\vy|^2+\rho^2 + 2 \rho |\vx-\vy| \cos \theta} \notag\\
   &< \sqrt{|\vx-\vy|^2+\rho^2 + 2 \rho |\vx-\vy| P_{x,y}(\rho)}\nonumber\\
    &= \sqrt{\rho^2 - 2\rho(x^0+y^0) +(x^0+y^0)^2}=x^0+y^0-\rho.
\end{align}
With this, we perform for \eqref{y'Integral2} the 
analogous calculation to 
\eqref{casesFirstTermBeginning}--
\eqref{CasesFirstTermEnd}. This yields:
\begin{align}
    &\eqref{y'Integral2}=\frac{\lambda\|\psi\|_{\weightf}}{16\pi} 1_{y^0-x^0<|\vx-\vy|<x^0+y^0} \int_{\max \left(0,y^0-x^0, \frac{y^0-x^0+|\vx-\vy|}{2} \right)}^{y^0} \!\!\!d\rho \frac{\weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\
    &\times \left[\weightf_2\!\left(\frac{x^0\!+\!y^0\!-\!\rho\!-\!\min(|\vx\!-\!\vy|\!+\!\rho,|x^0\!-\!y^0\!+\!\rho|,x^0\!+\!y^0\!-\!\rho)}{2} \right)\right.\nonumber\\
    &\left.\quad\quad  -\weightf_2\!\left( \frac{x^0+y^0-\rho-||\vx-\vy|-\rho|}{2} \right) \right] \nonumber\\
    &= \frac{\lambda \|\psi\|_{\weightf}}{16\pi} 1_{(x-y)^2\ge0, x^0>y^0} \int_{0}^{y^0} d\rho  ~\frac{ \weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\
    &\times\left[ \weightf_2\!\left(\frac{x^0\!+\!y^0 \!-\! |\vx\!-\!\vy|}{2}\!-\!\rho\right)
    \!-\!\weightf_2\!\left(\!\frac{x^0\!+\!y^0\!-\!\rho \!-\! ||\vx\!-\!\vy|\!-\!\rho|}{2}\right)\right]\nonumber\\
    &+ \frac{\lambda \|\psi\|_{\weightf}}{16\pi} 1_{(x-y)^2<0}~1_{ x^0+y^0>|\vx-\vy|} \int_{\frac{y^0-x^0+|\vx-\vy|}{2}}^{y^0} d\rho  ~\frac{ \weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\
    &\times \left[ \weightf_2\!\left(\!\frac{x^0\!+\!y^0\!-\!\rho \!-\! |x^0\!-\!y^0\!+\!\rho|}{2}\right)
    \!-\!\weightf_2\!\left(\!\frac{x^0\!+\!y^0\!-\!\rho \!-\! ||\vx\!-\!\vy|\!-\!\rho|}{2}\right)\right]\nonumber\\
    &= \frac{\lambda \|\psi\|_{\weightf}}{16\pi} 1_{(x-y)^2\ge0, x^0>y^0} \int_{0}^{y^0} d\rho  ~\frac{ \weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\
    &\times \Bigg[ \weightf_2\!\left(\!\frac{x^0\!+\!y^0 \!-\! |\vx\!-\!\vy|}{2}\!-\!\rho\right)\\
    &\quad \quad \!-\!\weightf_2\!\min\!\left(\!\frac{x^0\!+\!y^0 \!-\! |\vx\!-\!\vy|}{2},\frac{x^0\!+\!y^0 \!+\! |\vx\!-\!\vy|}{2}\!-\!\rho\!\right)\Bigg]\nonumber\\
    &+ \frac{\lambda \|\psi\|_{\weightf}}{16\pi} 1_{(x-y)^2<0}~1_{ x^0+y^0>|\vx-\vy|} \int_{\frac{y^0-x^0+|\vx-\vy|}{2}}^{y^0} d\rho ~ \frac{ \weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\
    &\times \Bigg[ \weightf_2\!\min\left(x^0,y^0-\rho\right)\notag\\
    &\quad \quad -\weightf_2\!\min\left(\!\frac{x^0\!+\!y^0\!-\! |\vx\!-\!\vy|}{2},\frac{x^0\!+\!y^0\!+\! |\vx\!-\!\vy|}{2}\!-\!\rho\right)\Bigg].
\label{eq:resulty'Integral2}
\end{align}
This ends the calculation of \eqref{y'Integral2}. 

%%%
\subparagraph{Simplification of term 
\eqref{y'Integral3}.}
We next turn to \eqref{y'Integral3}. In case the reader 
is not interested in the details of the computation, 
the result can be found in \eqref{eq:resulty'Integral3}.
First we note that the restriction imposed by the first 
indicator function here is \(\cos\theta>K_{x-y}(|{\vy}^{\,\prime}|)\) 
and the condition of the second indicator function is 
\(\cos\theta<P_{x,y}(|{\vy}^{\,\prime}|)\). In order to to satisfy 
these conditions (and the restrictions of the regular 
range of integration) it is required that
\begin{equation}
    \max(-1,K_{x-y}(|{\vy}^{\,\prime}|)<\cos\theta<\min(1,P_{x,y}(|{\vy}^{\,\prime}|)).
\end{equation}
This leads us to ask which restrictions on \(|{\vy}^{\,\prime}|\) 
are imposed by the conditions
\begin{align}
    K_{x-y}(|{\vy}^{\,\prime}|) ~&<~1,\\
    P_{x,y}(|{\vy}^{\,\prime}|) ~&>~-1,\\
    K_{x-y}(|{\vy}^{\,\prime}|) ~&<~ P_{x,y}(|{\vy}^{\,\prime}|).
\end{align}
These restrictions shall be computed next. With 
\(|{\vy}^{\,\prime}|=\rho\), we find:
\begin{align}\notag
     &K_{x-y}(|{\vy}^{\,\prime}|)<1\\
    &\iff \frac{(x-y)^2}{2\rho|\vx-\vy|}+\frac{x^0-y^0}{|\vx-\vy|}~<~1\nonumber\\
 &\iff    (x-y)^2~<~2\rho(y^0-x^0+|\vx-\vy|)\nonumber\\
   &\iff  \left\{\begin{matrix}\rho>\frac{y^0-x^0-|\vx-\vy|}{2}\quad \text{for } |\vx-\vy|>x^0-y^0,\\
\rho<\frac{y^0-x^0-|\vx-\vy|}{2}\quad \, \text{for } |\vx-\vy|<x^0-y^0.
     \end{matrix} \right.
\end{align}
The second case in the last line is in conflict with 
\(\rho>0\), so we have to impose the first condition on 
\eqref{y'Integral3}. We continue with 
\(P_{x,y}(\rho)>-1\).
\begin{align}\notag
    &P_{x,y}(\rho)>-1\\
    &\iff~ \frac{(x^0+y^0)^2}{2\rho|\vx-\vy|} - \frac{|\vx-\vy|}{2\rho}-\frac{x^0+y^0}{|\vx-\vy|} ~>~-1 \nonumber \\
   &\iff~ (x^0+y^0)^2-|\vx-\vy|^2~>~2\rho(x^0+y^0-|\vx-\vy|)\nonumber \\
    &\iff~\left\{\begin{matrix}\rho< \frac{x^0+y^0+|\vx-\vy|}{2} \quad \text{for } x^0+y^0>|\vx-\vy|,\\
    \rho> \frac{x^0+y^0+|\vx-\vy|}{2} \quad \text{for } x^0+y^0<|\vx-\vy|.
    \end{matrix} \right.
\end{align}
The second case is in conflict with \(\rho<y^0\), so 
we implement indicator functions corresponding only to 
the first case in \eqref{y'Integral3}. The third 
condition \(K_{x-y}(\rho)<P_{x,y}(\rho)\) in fact does 
not impose any additional conditions. This can be seen 
as follows:
\begin{align}\notag
  &K_{x-y}(\rho)~<~P_{x,y}(\rho)\\
  &\iff~~~ \frac{(x-y)^2}{2\rho|\vx-\vy|}+\frac{x^0-y^0}{|\vx-\vy|}~<~\frac{(x^0+y^0)^2}{2\rho|\vx-\vy|} - \frac{|\vx-\vy|}{2\rho}-\frac{x^0+y^0}{|\vx-\vy|}\nonumber\\
  &\iff~~~ -2x^0y^0 + 4\rho x^0~<~2x^0y^0\nonumber\\
  &\iff~~~   \rho<y^0,
\end{align}
which always holds true.

Taking into account the computed restrictions, we 
arrive at:
\begin{align}
    &\eqref{y'Integral3} \stackrel{\cos\theta=w}{=}\frac{\lambda \|\psi\|_{\weightf}}{4(4\pi)^2} \int_0^{2\pi} d\varphi \int_0^{y^0} d\rho \int_{-1}^1 dw \,1_{K_{x-y}(\rho)<w<P_{x,y}(\rho)}  \nonumber\\
     &\quad \times 1_{\frac{y^0-x^0-|\vx-\vy|}{2}<\rho<\frac{x^0+y^0+|\vx-\vy|}{2}}\frac{\weightf(y^0-\rho)\rho}{\sqrt{\rho^2+|\vx-\vy|^2+2\rho|\vx-\vy|w}} \nonumber\\
     &\quad \times 1_{x^0-y^0<|\vx-\vy|<x^0+y^0} \weightf_1\!\!\left( \!\frac{x^0\!\!+\!y^0\!\!-\!\sqrt{\rho^2\!\!+\!|\vx\!-\!\vy|^2\!\!+\!2\rho|\vx\!-\!\vy|w}}{2}\right)\nonumber\\
     &= \frac{\lambda \|\psi\|_{\weightf} 2\pi}{4(4\pi)^2}1_{x^0-y^0<|\vx-\vy|<x^0+y^0} \int_{\max\big(0,\frac{y^0-x^0-|\vx-\vy|}{2}\big)}^{\min\big(y^0,\frac{x^0+y^0+|\vx-\vy|}{2} \big)}d\rho\notag\\
     &\quad \times \int_{\max(-1,K_{x-y}(\rho))}^{\min(1,P_{x,y}(\rho))}dw \, \frac{-2 \weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\
     &\times \partial_w 
     \weightf_2\!\left(\frac{x^0+y^0-\sqrt{\rho^2+|\vx-\vy|^2 +2\rho|\vx-\vy|w}}{2} \right)\nonumber\\
     &=\frac{\lambda \|\psi\|_{\weightf}}{16\pi} 1_{x^0-y^0<|\vx-\vy|<x^0+y^0} 
     \int_{\max\big(0,\frac{y^0-x^0-|\vx-\vy|}{2}\big)}^{\min\big(y^0,\frac{x^0+y^0+|\vx-\vy|}{2} \big)}d\rho \, \frac{\weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\ 
     &\times \left[\weightf_2\!\!\left(\!\frac{x^0\!+\!y^0\!-\!\rho\!-\!\sqrt{\rho^2\!+\!|\vx\!-\!\vy|^2\!+\!2\rho|\vx\!-\!\vy|\max(-1,K_{x-y}(\rho))}}{2}\right)\right.\nonumber\\
     &\left.-\weightf_2\!\!\left(\!\frac{x^0\!\!+\!y^0\!\!-\!\rho\!-\!\sqrt{\rho^2\!+\!|\vx\!-\!\vy|^2\!+\!2\rho|\vx\!-\!\vy|\min(1,P_{x,y}(\rho))}}{2}\right)
     \!\right]\!.
\end{align}
At this point, the expressions look quite formidable. 
We can, however, achieve significant simplifications 
by inserting the functional form of $K_{x,y}(\rho)$ 
and $P_{x,y}(\rho)$ as in \eqref{PlugPIn} and 
\eqref{PlugKIn}. This yields:
\begin{align}
  &\eqref{y'Integral3} =\notag\\
  &\frac{\lambda\|\psi\|_{\weightf}}{16\pi} 1_{x^0-y^0<|\vx-\vy|<x^0+y^0}
  \int_{\max\left(0,\frac{y^0-x^0-|\vx-\vy|}{2}\right)}^{\min\left(y^0,\frac{x^0+y^0+|\vx-\vy|}{2} \right)}d\rho \, \frac{\weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\ 
  &~~~\times\left[ \weightf_2\left( \frac{x^0+y^0-\rho-\max(||\vx-\vy|-\rho|,|x^0-y^0+\rho|)}{2} \right)\right.\nonumber\\
  &~~~\left.-\weightf_2\left( \frac{x^0+y^0-\rho-\min(|\vx-\vy|+\rho,x^0+y^0-\rho)}{2} \right)\right]
	\label{eq:y'Integral3calc}
\end{align}
Now we simplify the arguments of the $\weightf_2$-functions. 
For the first one, we have:
\begin{align}
&x^0\!\!+\!y^0\!\!-\!\rho\!-\!\max(||\vx\!-\!\vy|\!-\!\rho|,|x^0\!\!-\!y^0\!\!+\!\rho|)\nonumber\\
&= x^0\!\!+\!y^0\!\!-\!\rho\! -\!\max ( |\vx\!-\!\vy|\!-\!\rho,\rho\!-\!|\vx\!-\!\vy|,x^0\!\!-\!y^0\!\!+\!\rho,y^0\!\!-\!\rho\!-\!x^0)\nonumber\\
&= \min\!\left(x^0\!\!+\!y^0\!\!-\!|\vx\!-\!\vy|,x^0\!\!+\!y^0\!\!+\!|\vx\!-\!\vy|\!-\!2\rho,2(y^0\!\!-\!\rho),2x^0 \right).
\end{align}
For the second one we get
\begin{equation}
	x^0\!\!+\!y^0\!\!-\rho-\!\min(|\vx\!-\!\vy|\!+\!\rho,x^0\!\!+\!y^0\!\!-\!\rho) = \max(x^0\!\!+\!y^0\!\!-\!|\vx\!-\!\vy|\!-\!2\rho,0).
\end{equation}
Using this in \eqref{eq:y'Integral3calc}, we find:
\begin{align}
    &\eqref{y'Integral3} =\frac{\lambda\|\psi\|_{\weightf}}{16\pi} 
    1_{x^0-y^0<|\vx-\vy|<x^0+y^0}
    \int_{\max\big(0,\frac{y^0-x^0-|\vx-\vy|}{2}\big)}^{\min\big(y^0,\frac{x^0+y^0+|\vx-\vy|}{2} \big)}\!d\rho \, \frac{\weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\
    &\quad\times \left[\weightf_2 \min\!\left(\frac{x^0\!\!+\!y^0\!\!-\!|\vx\!-\!\vy|}{2},\frac{x^0\!\!+\!y^0\!\!+\!|\vx\!-\!\vy|}{2}\!-\!\rho,y^0\!\!-\!\rho,x^0 \!\right) \right.\nonumber\\
    &\quad \quad \left. -\weightf_2 \max\!\left( \frac{x^0\!\!+\!y^0\!\!-\!|\vx\!-\!\vy|}{2}\!-\!\rho,0\!\right) \right].
\end{align}
As in the consideration below 
\eqref{CasesFirstTermEnd}, we split the expression 
into separate terms with \((x-y)^2 \gtrless 0\). 
Using \(y^0\gtrless x^0+|\vx-\vy|\), we can simplify 
the expressions involving the minimum. This results 
in:
\begin{align}
    &\eqref{y'Integral3} =
    \frac{\lambda\|\psi\|_{\weightf}}{16\pi} 1_{(x-y)^2\ge0,y^0>x^0}
    \int_{\frac{y^0-x^0-|\vx-\vy|}{2}}^{\frac{x^0+y^0+|\vx-\vy|}{2}}d\rho \, \frac{\weightf(y^0-\rho)}{|\vx-\vy|}\nonumber\\
    &\times \left[\weightf_2 \min\!\left(\!\frac{x^0\!\!+\!y^0\!\!+\!|\vx\!-\!\vy|}{2}\!-\!\rho,x^0\!\right) \!-\!\weightf_2\!\max\!\left(\! \frac{x^0\!\!+\!y^0\!\!-\!|\vx\!-\!\vy|}{2}\!-\!\rho,0\!\right) \right]\nonumber\\
    &+\frac{\lambda\|\psi\|_{\weightf}}{16\pi} 
    1_{(x-y)^2<0,|\vx-\vy|<x^0+y^0}
    \int_{0}^{y^0}d\rho \, \frac{\weightf(y^0-\rho)}{|\vx-\vy|}\label{eq:resulty'Integral3}\\
    &\times \left[\weightf_2\!\min\!\left(\!\frac{x^0\!\!+\!y^0\!\!-\!|\vx\!-\!\vy|}{2},y^0\!\!-\!\rho\!\right) \!-\!\weightf_2\!\max\!\left( \!\frac{x^0\!\!+\!y^0\!\!-\!|\vx\!-\!\vy|}{2}\!-\!\rho,0\!\right) \right].\notag
\end{align}
This concludes the calculation of \eqref{y'Integral3}.

%%%
\subparagraph{Summary of the first estimate.} We have 
obtained the following bound for $| A_0 \psi |(x,y)$:
\begin{align}
    &\frac{16\pi}{\lambda\|\psi\|_{\weightf}}|A_0\psi|(x,y) \le 
    1_{(x-y)^2\ge0, x^0>y^0} \int_{0}^{y^0} d\rho \, \frac{ \weightf(y^0-\rho)}{|\vx\!-\!\vy|}\nonumber\\
    &\times \Bigg[ \weightf_2\!\left(\!\frac{x^0\!\!+\!y^0\!\! +\! |\vx\!-\!\vy|}{2}\right)\notag\\
    &\quad\quad \!-\!\weightf_2\!\max\!\left(\!\frac{x^0\!\!+\!y^0\!\!-\! |\vx\!-\!\vy|}{2},\frac{x^0\!\!+\!y^0\!\!+ \!|\vx\!-\!\vy|}{2}\!-\!\rho\right)\Bigg]\nonumber\\
    &+ 1_{(x-y)^2<0}~1_{ x^0+y^0>|\vx\!-\!\vy|} \int_{\frac{y^0-x^0+|\vx\!-\!\vy|}{2}}^{y^0} d\rho \, \frac{ \weightf(y^0-\rho)}{|\vx\!-\!\vy|}\nonumber\\
    &\times \Big[ \weightf_2\!\max\!\left(x^0,y^0-\rho\right)\notag\\
    &\quad\quad -\weightf_2\!\max\!\left(\frac{x^0\!\!+\!y^0\!\!-\!|\vx\!-\!\vy|}{2},\frac{x^0\!\!+\!y^0\!\!+|\vx\!-\!\vy|}{2}-\rho\right)\Bigg]\nonumber\\
    &+ 1_{(x-y)^2\ge0, x^0>y^0} \int_{0}^{y^0} d\rho \, \frac{ \weightf(y^0-\rho)}{|\vx\!-\!\vy|}\nonumber\\
    &\times \Bigg[ \weightf_2\left(\frac{x^0+y^0 - |\vx\!-\!\vy|}{2}-\rho\right)\notag\\
    &\quad\quad -\weightf_2\min\!\left(\frac{x^0+y^0 - |\vx\!-\!\vy|}{2},\frac{x^0+y^0 + |\vx\!-\!\vy|}{2}\!-\!\rho\right)\Bigg]\nonumber\\\nonumber
    &+ 1_{(x-y)^2<0}~1_{ x^0+y^0>|\vx\!-\!\vy|} \int_{\frac{y^0-x^0+|\vx\!-\!\vy|}{2}}^{y^0} d\rho \, \frac{ \weightf(y^0\!\!-\!\rho)}{|\vx\!-\!\vy|}\nonumber\\
    &\times \Bigg[ \weightf_2\min\!\left(x^0,y^0-\rho\right)\notag\\
    &\quad\quad -\weightf_2\min\!\left(\frac{x^0+y^0- |\vx\!-\!\vy|}{2},\frac{x^0\!\!+\!y^0\!\!+ |\vx\!-\!\vy|}{2}-\rho\right)\Bigg]\nonumber\\
    &+1_{(x-y)^2\ge0,y^0>x^0} \int_{\frac{y^0-x^0-|\vx\!-\!\vy|}{2}}^{\frac{x^0\!\!+\!y^0\!\!+|\vx\!-\!\vy|}{2}}d\rho \, \frac{\weightf(y^0\!\!-\!\rho)}{|\vx\!-\!\vy|}\nonumber\\
    &\times \Bigg[\weightf_2 \min\!\left(\frac{x^0\!\!+\!y^0\!\!+|\vx\!-\!\vy|}{2}\!-\!\rho,x^0\right)\notag\\
    &\quad\quad \!-\!\weightf_2\!\max\!\left( \frac{x^0\!\!+\!y^0\!\!-\!|\vx\!-\!\vy|}{2}\!-\!\rho,0 \right) \Bigg]\nonumber\\
    &+1_{(x-y)^2<0,|\vx\!-\!\vy|<x^0+y^0}
    \int_{0}^{y^0}d\rho \,\frac{\weightf(y^0-\rho)}{|\vx\!-\!\vy|}\nonumber\\
    &\times \Bigg[\weightf_2 \min\!\left(\!\frac{x^0\!\!+\!y^0\!\!-\!|\vx\!-\!\vy|}{2},y^0\!\!-\!\rho\right)\notag\\
    &\quad\quad \!-\!\weightf_2\!\max\!\left( \!\frac{x^0\!\!+\!y^0\!\!-\!|\vx\!-\!\vy|}{2}\!-\!\rho,0\!\right)  \Bigg].
\end{align}
In order to simplify the notation, we introduce the 
variables
\begin{align}
    \xi^+:=\frac{x^0+y^0+|\vx-\vy|}{2},\\
    \xi^-:=\frac{x^0+y^0-|\vx-\vy|}{2}.
\end{align}
Moreover, we collect terms with the same indicator 
functions. This results in:
\begin{align}
    &\frac{16\pi}{\lambda\|\psi\|_{\weightf}}|A_0\psi|(x,y)\le\notag\\
    &1_{(x-y)^2<0,\xi^->0} \!\!\int_0^{y^0}\!\!\!d\rho  \frac{\weightf(y^0\!\!-\!\rho)}{|\vx\!-\!\vy|}
    \Big[\weightf_2\min(\xi^-,y^0\!\!-\!\rho)\!-\!\weightf_2\!\max(\xi^-\!\!-\!\rho,0)
    \notag\\\label{A psi estimate 1}
    &\quad + 1_{\frac{y^0\!\!-\!x^0+|\vx\!-\!\vy|}{2}<\rho} \big(\weightf_2(x^0)+\weightf_2(y^0\!\!-\!\rho)
    \!-\!\weightf_2(\xi^-)\!-\!\weightf_2(\xi^+\!\!-\!\rho)\big)
    \Big]\\\label{A psi estimate 2}
    &+1_{(x-y)^2\ge0,x^0>y^0}\int_0^{y^0} d\rho \, \frac{\weightf(y^0\!\!-\!\rho)}{|\vx\!-\!\vy|} \big[\weightf_2(\xi^+)+\weightf_2(\xi^-\!\!-\!\rho)\notag\\
    &\hspace{6cm} \!-\! \weightf_2(\xi^-)\!-\!\weightf_2(\xi^+\!\!-\!\rho)\big]\\\label{A psi estimate 3}
    &+1_{(x-y)^2\ge0,y^0>x^0}\int_{(y^0\!\!-\!x^0\!\!-\!|\vx\!-\!\vy|)/2}^{\xi^+}d\rho \, \frac{\weightf(y^0\!\!-\!\rho)}{|\vx\!-\!\vy|}\notag\\
    &\hspace{3cm}\times \big[\weightf_2\min(\xi^+\!\!-\!\rho,x^0) \!-\! \weightf_2\!\max(\xi^-\!\!-\!\rho,0)\big].
\end{align}
This estimate is an important stepping stone in the proof. Except for special weight functions, the resulting expressions are too complicated to be computed explicitly. We therefore continue with further estimates. The main difficulty in these estimates is that the $1/|\vx-\vy|$ singularity in the expressions needs to be compensated by the integrand and that this cancellation needs to be preserved by the respective estimate. Fortunately, the mean value theorem turns out suitable to provide such estimates.


%%%
\subparagraph{Simplification of 
\eqref{A psi estimate 1}-\eqref{A psi estimate 3}.}
First, we note that since $g, \weightf_1$ and $\weightf_2$ are monotonously increasing and 
since $\xi^- \leq \xi^+$, we have in \eqref{A psi estimate 2}:
\begin{equation}
	\weightf_2(\xi^- - \rho) - \weightf_2(\xi^+ - \rho) \leq 0.
\end{equation}
As the remaining terms in \eqref{A psi estimate 2} still vanish in the limit 
$|\vx-\vy| \rightarrow 0$, we may replace this difference by zero to obtain a 
suitable estimate.

Similarly, a brief calculations shows that we have 
$\xi^+ > y^0$ for $(x-y)^2<0$. It follows that:
\begin{equation}
	\weightf_2(y^0-\rho) - \weightf_2(\xi^+ - \rho) < 0.
\end{equation}
We shall use this in \eqref{A psi estimate 1}.

Further simplifications can be obtained using the mean 
value theorem. We begin with the expression in the 
square brackets in \eqref{A psi estimate 3}. The mean 
value theorem then implies that there is a 
\(\chi\in[\max(\xi^-\!\!-\!\rho,0),\min(\xi^+\!\!-\!\rho,x^0)]\) 
such that
\begin{align}\notag
    \weightf_2\!\min(&\xi^+\!\!-\!\rho,x^0)-\weightf_2\!\max(\xi^-\!\!-\!\rho,0)\\
    &= \big[\min(\xi^+\!\!-\!\rho,x^0)-\max(\xi^-\!\!-\!\rho,0)\big]\weightf_1(\chi).
\end{align}
Therefore, we have:
\begin{align}
   & \weightf_2\!\min(\xi^+\!\!-\!\rho,x^0)-\weightf_2\!\max(\xi^-\!\!-\!\rho,0)\nonumber\\
   &~~~\le~ \min(\xi^+\!\!-\xi^-,\xi^+\!\!-\!\rho,x^0-\xi^-+\rho,x^0)\, \weightf_1\!\min(\xi^+\!\!-\!\rho,x^0)\nonumber\\
   & ~~~\le~ |\vx-\vy|\, \weightf_1\!\min(\xi^+\!\!-\!\rho,x^0) ~\le~ |\vx-\vy| \,\weightf_1(x^0).
\end{align}
Note that the factor $|\vx-\vy|$ exactly compensates the $1/|\vx-\vy|$ 
singularity. 
This is the main reason the mean value theorem is so useful here.

Analogously we find for the expression in the square bracket in the first 
line of \eqref{A psi estimate 1}:
\begin{align}
    &\weightf_2\!\min(\xi^-,y^0-\!\rho)-\weightf_2\!\max(\xi^-\!\!-\!\rho,0)\nonumber\\
&~~~\leq ~ \big[\min(\xi^-,y^0-\!\rho)-\max(\xi^-\!\!-\!\rho,0)\big] \weightf_1\!\min(\xi^-,y^0-\!\rho)\nonumber\\
    &~~~=~\min(\rho,\xi^-,y^0-\xi^-,y^0-\!\rho) \, \weightf_1\!\min(\xi^-,y^0-\!\rho)\nonumber\\
    &~~~\le~ (y^0-\xi^-) \,\weightf_1\!\min(\xi^-,y^0-\!\rho)\nonumber\\
    &~~~\le~ |\vx-\vy| \,\weightf_1\!\min(\xi^-,y^0-\!\rho),
\end{align}
where we have used that the further restriction of that term, $(x-y)^2<0$, 
implies $|\vx-\vy|>|x^0-y^0|\geq y^0-x^0$.

With these considerations, we obtain a rougher but simpler estimate than 
\eqref{A psi estimate 1}-\eqref{A psi estimate 3}:
\begin{align}\notag
    &\frac{16\pi}{\lambda\|\psi\|_{\weightf}}|A_0\psi|(x,y) \\
    &\le~ \label{massless_after estimate1}
    1_{(x-y)^2<0,\xi^->0} \int_0^{y^0}d\rho~ \weightf(y^0-\!\rho)\Big[ \weightf_1\!\min(\xi^-,y^0-\!\rho) \\\label{massless_after estimate2}
    &~~~+ 1_{\frac{y^0-x^0+|\vx-\vy|}{2}<\rho}\frac{\weightf_2(x^0)-\weightf_2(\xi^-)}{|\vx-\vy|}\Big]\\\label{massless_after estimate3}
    &~~~+1_{(x-y)^2\ge0,x^0>y^0}\frac{\weightf_2(\xi^+)-\weightf_2(\xi^-)}{|\vx-\vy|} \int_{0}^{y^0}d\rho~ \weightf(y^0-\!\rho)\\\label{massless_after estimate4}
    &~~~+1_{(x-y)^2\ge0,y^0>x^0}\, \weightf_1(x^0)\int_{\frac{y^0-x^0-|\vx-\vy|}{2}}^{\xi^+}d\rho~ \weightf(y^0-\!\rho).
\end{align}
Next, we continue estimating these terms separately so that only expressions 
without integrals remain.

%%%
\subparagraph{Further estimate of \eqref{massless_after estimate1}.}
Using the monotonicity of $\weightf_1$ as well as $\min(\xi^-,y^0-\rho) \leq \xi^-$, 
we find:
\begin{align}
  \eqref{massless_after estimate1} ~&\leq~  1_{(x-y)^2<0,\xi^->0}\, \weightf_1(\xi^-) \int_0^{y^0} ds~ \weightf(s) \notag\\
  &~=~  1_{(x-y)^2<0,\xi^->0} \, \weightf_1(\xi^-) \weightf_1(y^0).
\end{align}
For the constraints given by the indicator function, we have $\xi^- < x^0$. 
Thus:
\begin{equation}
	\eqref{massless_after estimate1} \leq 1_{(x-y)^2<0,\xi^->0} \, \weightf_1(x^0) \weightf_1(y^0).
\label{eq:resultmasslessafterestimate1}
\end{equation}


%%%
\subparagraph{Further estimate of \eqref{massless_after estimate2}.}
We have:
\begin{align}
	 \eqref{massless_after estimate2} ~&=~ 1_{(x-y)^2 < 0, \xi^- >0} \, \frac{ \weightf_2(x^0) - \weightf_2(\xi^-) }{|\vx-\vy|} \int_{\frac{y^0-x^0+|\vx-\vy|}{2}}^{y_0} d \rho \, \weightf(y^0-\rho) \nonumber\\
&= 1_{(x-y)^2 < 0, \xi^- >0} \, \frac{\weightf_2(x^0) - \weightf_2(\xi^-)}{|\vx-\vy|} \int_{0}^{\xi^-} d s \, \weightf(s)\nonumber\\
&= 1_{(x-y)^2 < 0, \xi^- >0} \, \frac{\weightf_2(x^0) - \weightf_2(\xi^-)}{|\vx-\vy|} \big[ \weightf_1(\xi^-) - \underbrace{\weightf_1(0)}_{=0} \big].
\label{eq:secondline159b}
\end{align}
Applying the mean value theorem to $\weightf_2$ in the interval $[\xi^-,x^0]$ 
(note that here $\xi^-<x^0$), we obtain that:
\begin{equation}
	\eqref{massless_after estimate2} \leq 1_{(x-y)^2 < 0, \xi^- >0} \, \frac{x^0-\xi^-}{|\vx-\vy|}\, \weightf_1(x^0) \weightf_1(\xi^-).
\end{equation}
Next, we use that $\frac{x^0-\xi^-}{|\vx-\vy|}  = \frac{x^0-y^0+|\vx-\vy|}{2|\vx-\vy|} \leq 1$ as $|x^0-y^0| < |\vx-\vy|$. Thus:
\begin{equation}
	\eqref{massless_after estimate2} \leq 1_{(x-y)^2 < 0, \xi^- >0} \, \weightf_1(x^0) \weightf_1(\xi^-).
\end{equation}
Using also that for the given constrains $\xi^- < y^0$, we finally obtain:
\begin{equation}
	\eqref{massless_after estimate2} \leq 1_{(x-y)^2 < 0, \xi^- >0} \, \weightf_1(x^0) \weightf_1(y^0).
\label{eq:resultmasslessafterestimate2}
\end{equation}


%%%
\subparagraph{Further estimate of \eqref{massless_after estimate3}.}
Here, we can directly carry out the remaining integral using the definition 
of $\weightf_1$ as the integral of $g$:
\begin{equation}
	\eqref{massless_after estimate3} = 1_{(x-y)^2\ge0,x^0>y^0}\, \frac{\weightf_2(\xi^+)-\weightf_2(\xi^-)}{|\vx-\vy|} \weightf_1(y^0).
\end{equation}
Next, we apply the mean value theorem to $\weightf_2$ in the interval 
$[\xi^-,\xi^+]$ noting that $\xi^+\!\!-\xi^- = |\vx-\vy|$. This implies:
\begin{equation}
	\eqref{massless_after estimate3} \leq 1_{(x-y)^2>0,x^0>y^0} \,\weightf_1(\xi^+) \weightf_1(y^0).
\end{equation}
Next, we note that $(x-y)^2 \ge 0 \Leftrightarrow |x^0-y^0| \ge |\vx-\vy|$. 
Together with $x^0>y^0$, we obtain $x^0\ge y^0 +|\vx-\vy|$ and therefore:
\begin{equation}
	\xi^+ = \frac{x^0+y^0 +|\vx-\vy|}{2} \leq x^0.
\end{equation}
Thus, we obtain:
\begin{equation}
	\eqref{massless_after estimate3} \leq 1_{(x-y)^2\ge0,x^0>y^0} \, \weightf_1(x^0) \weightf_1(y^0).
	\label{eq:resultmasslessafterestimate3}
\end{equation}

%%%
\subparagraph{Further estimate of \eqref{massless_after estimate4}.}
Here, we carry out the remaining integral as well.
\begin{align}
	\eqref{massless_after estimate4} &\leq 1_{(x-y)^2>0,y^0>x^0}\, \weightf_1(x^0) [ \weightf_1(\xi^+)\!-\!\weightf_1( (y^0\!\!-\!x^0\!\!-\!|\vx\!-\!\vy|)/2)]\nonumber\\
&\leq 1_{(x-y)^2>0,y^0>x^0}\, \weightf_1(x^0)\weightf_1(y^0).
\label{eq:resultmasslessafterestimate4}
\end{align}
as $\xi^+\leq y^0$.


%%%
\subparagraph{Summary of the result.} Gathering the terms 
\eqref{eq:resultmasslessafterestimate1}, 
\eqref{eq:resultmasslessafterestimate2}, 
\eqref{eq:resultmasslessafterestimate3} and 
\eqref{eq:resultmasslessafterestimate4} yields:
\begin{align}
    &\frac{16\pi}{\lambda\|\psi\|_{\weightf}}\, |A_0 \psi |(x,y) \\
    &\leq \weightf_1(x^0) \weightf_1(y^0) \left( 2 \!\times\! 1_{(x-y)^2 < 0, \xi^- >0} \!+\! 1_{(x-y)^2\ge0,x^0>y^0} \!+\! 1_{(x-y)^2\ge0,y^0>x^0}\right).\notag
\end{align}
Considering that the conditions in different indicator functions are mutually 
exclusive, we finally obtain:
\begin{equation}
	  \frac{16\pi}{\lambda\|\psi\|_{\weightf}}\, |A_0 \psi |(x,y) \leq 2 \weightf_1(x^0) \weightf_1(y^0).
	\label{eq:resultmasslessestimate}
\end{equation}
Dividing by $\weightf(x^0)\weightf(y^0)$, taking the supremum over 
$x,y \in \M$ and factorizing into one-dimensional suprema 
finally yields the claim \eqref{eq:estimatea0}.


%%%
\paragraph{Estimate of the mixed terms \eqref{eq:estimatea1} and 
\eqref{eq:estimatea2}.} \label{sec:estimatemixed}

We focus on $A_2$ first, starting from its definition \eqref{eq:defa2}. 
We take the absolute value and make use of 
$|\psi(x,y)| \leq \weightf(x^0) \weightf(y^0)\, \| \psi \|_{\weightf}$. Moreover, we use:
\begin{equation}
	\left| J_1(t)/t \right| \leq \frac{1}{2}.
\end{equation}
This yields:
\begin{align}
	&|A_2 \psi|(x,y) \leq  \frac{\lambda \, m_2^2 \, \|\psi\|_{\weightf}}{4(4 \pi)^3} \int d^3 {\vx}^{\,\prime} \int d^3 {\vy}^{\,\prime}~\frac{H(x^0\!\!-\!|\vx\!-\!{\vx}^{\,\prime}|)}{|\vx\!-\!{\vx}^{\,\prime}|} \frac{\weightf( x^0\!\!-\!|\vx\!-\!{\vx}^{\,\prime}|)}{|{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}|} \nonumber\\
&\times \left[\weightf(x^0\!\!-\! |\vx\!-\!{\vx}^{\,\prime}| \!+\! |{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}| ) H(x^0\!\!-\! |\vx\!-\!{\vx}^{\,\prime}| \!+\! |{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}|) \right. \nonumber\\
&\quad \quad \times H(y^0\!\!-x^0\!\! +\! |\vx\!-\!{\vx}^{\,\prime}| \!-\! |{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}| \!-\!|\vy\!-\!{\vy}^{\,\prime}|)\notag\\
&\quad + \weightf(x^0\!\!-\! |\vx\!-\!{\vx}^{\,\prime}| \!-\! |{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}|) H(x^0\!\!-\! |\vx\!-\!{\vx}^{\,\prime}| \!-\! |{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}|) \nonumber\\
&\quad \quad \left. \times H(y^0\!\!-x^0\!\! +\! |\vx\!-\!{\vx}^{\,\prime}| \!+\! |{\vx}^{\,\prime}\!-\!{\vy}^{\,\prime}|\!-\!|\vy\!-\!{\vy}^{\,\prime}|) \right].
\end{align}
As the remaining singularities are independent of each other for a suitable 
choice of integration variables (see below), we are left with an integrable 
function on a finite domain.

The next task is to bring the expressions into a simpler form. One 
possibility to do this is to use
\begin{align}\notag
  H(y^0-x^0+|\vx-{\vx}^{\,\prime}|+|{\vx}^{\,\prime}-{\vy}^{\,\prime}| - |\vy-{\vy}^{\,\prime}|) \\
  \leq H(y^0-x^0+|\vx-{\vx}^{\,\prime}|+|{\vx}^{\,\prime}-{\vy}^{\,\prime}|)
\end{align}
for the second Heaviside function in the second summand.
The first Heaviside function in the first summand equals 1 anyway, as 
$|\vx-{\vx}^{\,\prime}| < x^0$. We furthermore use
\begin{align}\notag
  H(y^0-x^0+|\vx-{\vx}^{\,\prime}|-|{\vx}^{\,\prime}-{\vy}^{\,\prime}| - |\vy-{\vy}^{\,\prime}|) \\
  \leq H(y^0-x^0+|\vx-{\vx}^{\,\prime}|-|{\vx}^{\,\prime}-{\vy}^{\,\prime}|),
\end{align}
as it simplifies the domain of integration. Overall, the domain of 
integration remains bounded. 
Introducing $\vz_1 = \vx-{\vx}^{\,\prime}$, $\vz_2 = {\vx}^{\,\prime}-{\vy}^{\,\prime}$ (with Jacobi determinant 
of modulus 1) and using spherical coordinates for $\vz_2$, this leads to:
\begin{align}
	&|A_2 \psi|(x,y) \frac{4(4\pi)^3}{\lambda \, m_2^2 \, \| \psi \|_{\weightf}}\nonumber\\
& \leq \int_{B_{x^0}(0)} \!\!\!d^3 \vz_1 4\pi \!\int_0^{\max(0,y^0-x^0+|\vz_1|)}\!\!\!\!\!\! d^3 \vz_2  \frac{\weightf(x^0\!\!-\!|\vz_1|) \weightf(x^0\!\!-\!|\vz_1|\!+\!|\vz_2|)}{|\vz_1||\vz_2|} |\vz_2|^2  \nonumber\\
&+\!\int_{B_{x^0}(0)} \!\!\!d^3 \vz_1 4\pi\! \int_{\max( 0, x^0-y^0-|\vz_1|)}^{x^0-|\vz_1|} \!\!\!\!\!\! d|\vz_2| \frac{\weightf(x^0-|\vz_1|) \weightf(x^0-|\vz_1|-|\vz_2|)}{|\vz_1||\vz_2|}  |\vz_2|^2.
\end{align}

Using spherical coordinates also for $\vz_1$, this can be further simplified 
to:
\begin{align}
  &|A_2 \psi|(x,y)  \frac{16\pi}{\lambda  m_2^2 \, \| \psi \|_{\weightf}} \notag\\
  &\leq  \int_0^{x^0} d r_1 \int_0^{\max(0,y^0-x^0+r_1)} \!\!\! dr_2~r_1 r_2\,\weightf(x^0\!\!-\!r_1) \weightf(x^0\!\!-\!r_1\!+\!r_2)\label{eq:A2firstestimate}\\
&+~\int_0^{x^0} d r_1 \int_{\max( 0,x^0-r_1-y^0)}^{x^0-r_1} \!\!\! dr_2~r_1 r_2 ~ \weightf(x^0\!\!-\!r_1) \weightf(x^0\!\!-\!r_1\!-\!r_2) \label{eq:A2secondestimate}.
\end{align}

Our next task is to simplify the remaining integrals. We begin with making 
the change of variables $\rho = x^0-r_1$:
\begin{align}
  &|A_2 \psi|(x,y)  \frac{16\pi}{\lambda  m_2^2 \, \| \psi \|_{\weightf}} \notag\\
&\leq  \int_0^{x^0} d \rho~(x^0-\rho) \weightf(\rho) \int_0^{\max(0,y^0-\rho)} \!\!\! dr_2~r_2\, \weightf(\rho+r_2)\nonumber\\
&+\int_0^{x^0} d \rho~(x^0-\rho)\weightf(\rho) \int_{\max( 0,\rho-y^0)}^{\rho} \!\!\! dr_2~r_2 \, \weightf(\rho-r_2).
\label{eq:a2estimate1}
\end{align}
Now we consider the $r_2$-integral in both terms and integrate by parts. 
This yields:
\begin{align}
   \int_0^{\max(0,y^0\!\!-\!\rho)} \!\!\! dr_2~r_2\, \weightf(\rho\!+\!r_2)
   &=\max(0,y^0\!\!-\!\rho) \weightf_1(y^0) \notag\\
   &\quad \quad \quad \!-\! \weightf_2(\max(\rho,y^0)) \!+\! \weightf_2(\rho),\\
\int_{\max( 0,\rho\!-\!y^0)}^{\rho} \!\!\! dr_2~r_2 \, \weightf(\rho\!-\!r_2) \notag
&= \max( 0,\rho\!-\!y^0) \weightf_1(y^0) \\
&\quad\quad  \quad \!+\! \weightf_2(\min(\rho,y^0)).
\end{align}
We now use $- \weightf_2(\max(\rho,y^0)) + \weightf_2(\rho) \leq 0$ in the first term and 
then re-insert the resulting estimate into \eqref{eq:a2estimate1}. 
Considering also $\max(0,y^0-\rho) + \max( 0,\rho-y^0) = |y^0-\rho|$, this 
yields:
\begin{align}
  &|A_2 \psi|(x,y) \, \frac{16\pi}{\lambda \, m_2^2 \, \| \psi \|_{\weightf}}\notag\\
  &\quad \leq  \int_0^{x^0} d \rho~(x^0-\rho) \weightf(\rho) \left[|y^0-\rho| \weightf_1(y^0) + \weightf_2(\min(\rho,y^0)) \right]
\label{eq:a2estimate2}
\end{align}
The first summand of \eqref{eq:a2estimate2} can be treated as follows. First 
we focus on whether $x^0>y^0$ or $x^0\leq y^0$. In the first case, we then 
differentiate between the cases $\rho < y^0$ and $\rho \geq y^0$ and split 
up the integrals accordingly. This yields:
\begin{align}
	 &\int_0^{x^0} d \rho~(x^0-\rho) \weightf(\rho) |y^0-\rho| \weightf_1(y^0)\nonumber\\
&=~ \weightf_1(y^0)\, 1_{x^0>y^0} \int_0^{y^0} d \rho~(x^0-\rho)(y^0-\rho) \weightf(\rho)\label{eq:a2estimate2a}\\
&~~~ - \weightf_1(y^0)\, 1_{x^0>y^0} \int_{y^0}^{x^0} d \rho~(x^0-\rho)(y^0-\rho) \weightf(\rho)\label{eq:a2estimate2b}\\
& ~~~+ \weightf_1(y^0)\, 1_{x^0\le y^0} \int_0^{x^0} d \rho~(x^0-\rho)(y^0-\rho) \weightf(\rho).
\label{eq:a2estimate2c}
\end{align}
We now calculate these terms separately using integration by parts. The first 
term yields:
\begin{align}
	\eqref{eq:a2estimate2a} ~&=~ \weightf_1(y^0) 1_{x^0>y^0} \left[ (x^0-y^0) \weightf_2(y^0)+ 2\weightf_3(y^0)\right].
\label{eq:a2estimate2a2}
\end{align}
We turn to \eqref{eq:a2estimate2b}:
\begin{align}\notag
  \eqref{eq:a2estimate2b} = -\weightf_1(y^0) 1_{x^0>y^0}\!&\big[ (y^0\!\!-\!x^0)(\weightf_2(x^0)\\
  &\quad \!+\!\weightf_2(y^0))\!+\!2\weightf_3(x^0) \!-\! 2\weightf_3(y^0)\big].
\label{eq:a2estimate2b2}
\end{align}
The result of \eqref{eq:a2estimate2c} is:
\begin{align}
	\eqref{eq:a2estimate2c} ~&=~ \weightf_1(y^0) 1_{x^0\le y^0} \left[ (y^0-x^0) \weightf_2(x^0)+ 2\weightf_3(x^0)\right].
	\label{eq:a2estimate2c2}
\end{align}
Gathering the terms \eqref{eq:a2estimate2a2}, \eqref{eq:a2estimate2b2} and 
\eqref{eq:a2estimate2c2} yields:

\begin{align}
  |A_2 \psi|(x,y)& \frac{16\pi}{\lambda \, m_2^2 \, \| \psi \|_{\weightf}} \notag\\
  &\leq \weightf_1(y^0) 1_{x^0>y^0} \left[ 2(x^0\!\!-\!y^0)\weightf_2(y^0) \!+\! 4 \weightf_3(y^0)\!-\!2\weightf_3(x^0) \right]\nonumber\\
&~~~+\weightf_1(y^0) |x^0\!\!-\!y^0| \weightf_2(x^0) + 2 \weightf_1(y^0) 1_{x^0\le y^0} \weightf_3(x^0)\nonumber\\
&\leq 2\weightf_1(y^0)|x^0\!\!-\!y^0| \weightf_2(x^0) + 2 \weightf_1(y^0)\weightf_3(x^0) 1_{x^0<y^0}\nonumber\\
&~~~+\weightf_1(y^0)|x^0\!\!-\!y^0|\weightf_2(x^0) + 2 \weightf_1(y^0) \weightf_3(x^0) 1_{x^0\le y^0}\nonumber\\
&= 3\weightf_1(y^0)|x^0\!\!-\!y^0| \weightf_2(x^0) + 2 \weightf_1(y^0)\weightf_3(x^0)\nonumber\\
&\leq 3(x^0+y^0)\weightf_1(y^0) \weightf_2(x^0) + 2 \weightf_1(y^0)\weightf_3(x^0).
\end{align}
In order to obtain $\| A_2 \psi \|_{\weightf}$, we divide by 
$\weightf(x^0)\weightf(y^0)$ and take 
the supremum over $x,y \in \M$. This results in:
\begin{align}
  &\sup_{\psi \in \mathcal{S}((\M)^2)} \frac{\| A_2 \psi \|_{\weightf}}{\| \psi \|_{\weightf}} \\
  &\leq~ \frac{\lambda \, m_2^2}{16\pi} \left( \!3\!\!\!\sup_{x^0,y^0 \geq 0}\!\!\! \frac{(x^0\!\!+\!y^0)\weightf_2(x^0)\, \weightf_1(y^0)}{\weightf(x^0)\weightf(y^0)}  \!+\! 2\!\!\! \sup_{x^0,y^0\geq 0}\!\! \frac{\weightf_3(x^0)\weightf_1(y^0)}{\weightf(x^0)\weightf(y^0)}\!\right).\notag
\end{align}
After factorizing the two-dimensional suprema 
into one-dimensional ones, 
this exactly yields the claim, \eqref{eq:estimatea2}.

For the operator $A_1$, we find analogously:
\begin{align}
  &\sup_{\psi \in \mathcal{S}((\M)^2)} \frac{\| A_1 \psi \|_{\weightf}}{\| \psi \|_{\weightf}} \notag\\
  &\leq\! \frac{\lambda m_1^2}{16\pi} \left(\!\! 3\!\!\sup_{x^0,y^0 \geq 0}\!\!\!\! \frac{(x^0\!\!+\!y^0)\weightf_1(x^0) \weightf_2(y^0)}{\weightf(x^0)\weightf(y^0)}  
  \!+\! 2\!\!\! \sup_{x^0,y^0\geq 0}\!\! \frac{\weightf_1(x^0)\weightf_3(y^0)}{\weightf(x^0)\weightf(y^0)}\right).
\end{align}
which, after factorization into one-dimensional suprema, yields 
the claim 
\eqref{eq:estimatea1}.


%%%
\paragraph{Estimate of the mass-mass term \eqref{eq:estimatea12}.} 
\label{sec:estimatemassmass}
We begin with \eqref{eq:defa12}. Taking the absolute value and using 
$|\psi(x,y)| \leq \| \psi \|_{\weightf} \, \weightf(x^0) \weightf(y^0)$ as well as 
$|J_1(t)/t|\leq \frac{1}{2}$ yields:
\begin{align}
&|A_{12} \psi|(x,y) \notag\\
&\leq \frac{\lambda \, m_1 m_2 \, \| \psi \|_{\weightf}}{8(4\pi)^3}\!  \int_0^\infty\!\!\! d{x'}^0\!\! \int d^3 \!{\vx}^{\,\prime} \!\int_0^\infty \!\!\!d{y'}^0 \!\int_0^{2\pi}\!\!\! d\varphi \!\int_{0}^{\pi} \!\!\!d \vartheta \, \cos(\vartheta) |{x'}^0\!\!-\!{y'}^0| \,  \nonumber\\
&\hspace{1cm}\times\! H(x^0\!\!-{x'}^0\!\!-\!|\vx-{\vx}^{\,\prime}|)H(y^0\!\!-{y'}^0\!\!-\!|\vy\!-\!{\vx}^{\,\prime}\!+\!\vz|)\notag\\
&\hspace{3cm} \times \weightf({x'}^0)\weightf({y'}^0)\Big|_{|\vz| = |{x^0}'-{y^0}'|},
\end{align}
where, we recall, $\vz$ is the variable for which the spherical 
coordinates are used.

Next, we consider the ranges of integration which the Heaviside 
functions imply. $H(x^0-{x'}^0-|\vx-{\vx}^{\,\prime}|)$ restricts the range 
of integration of ${\vx}^{\,\prime}$ to the ball $B_{x^0-{x'}^0}(\vx)$ and the 
range of the ${x'}^0$-integration to $(0,x^0)$. The range implied 
by the second Heaviside function is more complicated. We therefore 
use the estimate
\begin{equation}
	H(y^0-{y'}^0-|\vy-{\vx}^{\,\prime}+\vz|) \leq H(y^0-{y'}^0).
\end{equation}
Then ${y'}^0 \in (0,y^0)$ and there is no further restriction for 
the angular variables. We obtain:
\begin{align}
|A_{12} \psi|(x,y) &\leq \frac{\lambda \, m_1 m_2 \, \| \psi \|_{\weightf}}{8(4\pi)^3}  \int_0^{x^0} d{x'}^0 \int_{B_{x^0-{x'}^0}(\vx)} \!\!\!\!\!\!\!\!\!\! d^3 {\vx}^{\,\prime} \int_0^{y^0} d{y'}^0 \int_0^{2\pi} d\varphi \int_{0}^{\pi} d \vartheta \nonumber\\
&~~~\times \cos(\vartheta) |{x'}^0-{y'}^0| \, \weightf({x'}^0)\weightf({y'}^0).
\end{align}
Performing the ${\vx}^{\,\prime}$-integration, as well as the angular integrals 
yields:
\begin{align}
  &|A_{12} \psi|(x,y) \notag\\
  &\leq \frac{\lambda \, m_1 m_2 \, \| \psi \|_{\weightf}}{96\pi}\!  \int_0^{x^0}\!\! d{x'}^0 |x^0\!\!-\!{x'}^0|^3 \weightf({x'}^0)\! \int_0^{y^0}\!\! d{y'}^0 |{x'}^0\!\!-\!{y'}^0| \, \weightf({y'}^0).
\end{align}
Our next task is to estimate the term explicitly in terms of the 
functions $\weightf_n$ only. To do so, we use
\begin{equation}
	|{x'}^0-{y'}^0| \leq {x'}^0 + {y'}^0.
\end{equation}
This yields:
\begin{align}
  &|A_{12} \psi|(x,y) \notag\\
  &\leq \!\frac{\lambda  m_1 m_2  \| \psi \|_{\weightf}}{96\pi}\!  \int_0^{x^0} \!\!\!d{x'}^0 |x^0\!\!-\!{x'}^0|^3 \weightf({x'}^0) \!\!\int_0^{y^0} \!\!\!d{y'}^0 ({x'}^0 \!\!+\! {y'}^0) \weightf({y'}^0).
\label{eq:a12estimatecalc}
\end{align}
Let
\begin{equation}
	I(x^0,y^0) = \int_0^{x^0} d{x'}^0 |x^0-{x'}^0|^3 \weightf({x'}^0) \int_0^{y^0} d{y'}^0~ ({x'}^0 + {y'}^0) \weightf({y'}^0)
\end{equation}
and
\begin{equation}
	L({x'}^0,y^0) = \int_0^{y^0} d{y'}^0~ ({x'}^0 + {y'}^0) \weightf({y'}^0).
\end{equation}
Integration by parts yields:
\begin{align}
  L({x'}^0,y^0) =& {x'}^0 \weightf_1(y^0) \!+\! y^0 \weightf_1(y^0) \!-\! \weightf_2(y^0) \notag\\
  \leq& {x'}^0 \weightf_1(y^0) \!+\! y^0 \weightf_1(y^0).
\end{align}
Next, let
\begin{align}
	I_a(x^0) &= \int_0^{x^0} d {x'}^0~|x^0-{x'}^0|^3 \weightf({x'}^0),\nonumber\\
	I_b(x^0) &=  \int_0^{x^0} d {x'}^0~{x'}^0 |x^0-{x'}^0|^3 \weightf({x'}^0).
\end{align}
Then:
\begin{equation}
	I(x^0,y^0) \leq I_a(x^0) \, y^0 \weightf_1(y^0) + I_b(x^0) \, \weightf_1(y^0).
\label{eq:massmassintparts}
\end{equation}
We consider $I_a$ first, using $(x^0-{x'}^0)^2 \leq (x^0)^2$ and 
integrating by parts:
\begin{align}
	I_a(x^0) &\leq (x^0)^2 \int_0^{x^0} d {x'}^0~(x^0-{x'}^0)\weightf({x'}^0)\\
&= (x^0)^2 \left( \underbrace{(x^0-{x'}^0)\weightf_1({x'}^0)|_{{x'}^0 = 0}^{x^0}}_{=0} + \weightf_2(x^0)\right) = (x^0)^2 \weightf_2(x^0).\nonumber
\end{align}
We turn to $I_b$, using ${x'}^0(x^0-{x'}^0)\leq \frac{1}{4}(x^0)^2$ 
and integrating by parts twice. This results in:
\begin{align}
	I_b(x^0) ~\leq~ \frac{(x^0)^2}{4} \int_0^{x^0} d{x'}^0~ (x^0-{x'}^0)^2 \weightf({x'}^0) ~=~ \frac{(x^0)^2}{2}\, \weightf_3(x^0).
\end{align}
Considering \eqref{eq:massmassintparts}, we therefore obtain:
\begin{equation}
	I(x^0,y^0) ~\leq~ (x^0)^2 \weightf_2(x^0)\, y^0 \weightf_1(y^0) + \frac{(x^0)^2}{2}\, \weightf_3(x^0)\, \weightf_1(y^0).
\label{eq:resultmassmasstermgeneralg}
\end{equation}
Returning to \eqref{eq:a12estimatecalc}, we divide by $\weightf(x^0)\weightf(y^0)$ 
and take the supremum, with the result:
\begin{align}
	\sup_{\psi \in \mathcal{S}((\M)^2)} \frac{\| A_{12} \psi \|_{\weightf}}{\| \psi \|_{\weightf}} ~&\leq~\frac{\lambda \, m_1 m_2 \, \| \psi \|_{\weightf}}{96\pi} \left[ \sup_{x^0,y^0\geq 0} \frac{(x^0)^2 \weightf_2(x^0)\, y^0 \weightf_1(y^0)}{\weightf(x^0)\weightf(y^0)} \right.\nonumber\\
&~~~\left.+ \frac{1}{2} \sup_{x^0,y^0\geq 0} \frac{(x^0)^2 \weightf_3(x^0)\, \weightf_1(y^0)}{\weightf(x^0)\weightf(y^0)} \right].
\end{align}
Factorizing the two-dimensional suprema into one-dimensional ones 
yields the claim, \eqref{eq:estimatea12}.

%%%%%
\subsubsection{Proof of Theorem \ref{thm:exponentialg}} 
\label{sec:proofexponentialg}

Let $\psi \in \mathcal{S}$. It only remains to calculate the 
supremum in \eqref{eq:estimatea0} for $\weightf(t)=e^{\gamma t}$. We have:
\begin{equation}
	\weightf_1(t) = \frac{1}{\gamma} \left( e^{\gamma t} - 1\right)
\end{equation}
and hence
\begin{align}
  \sup_{\psi \in \mathcal{S}((\M)^2)} &\frac{\| A_0 \psi \|_{\weightf}}{\| \psi \|_{\weightf}} \leq \frac{\lambda}{8\pi} \left( \sup_{t \geq 0} \frac{\weightf_1(t)}{\weightf(t)} \right)^2 \notag\\
  &= \frac{\lambda}{4\pi} \left( \sup_{t \geq 0} \frac{1}{\gamma} (1 - e^{-\gamma t}) \right)^2 = \frac{\lambda}{8\pi \gamma^2}. 
\end{align}
This shows that $A_0$ can be linearly extended to a bounded operator 
on $\Banach_{\weightf}$ which satisfies the same estimate, 
\eqref{eq:norma0exponential}. Moreover, for $\gamma > 
\sqrt{\frac{\lambda}{4\pi}}$, $A_0$ is a contraction and Banach's 
fixed point theorem implies the existence of a unique solution 
$\psi \in \Banach_{\weightf}$ of the equation $\psi = \psi^{\free} + A_0 \psi$ 
for every $\psi^{\free} \in \Banach_{\weightf}$.


%%%%%
\subsubsection{Proof of Theorem \ref{thm:KGexistence}} \label{sec:proofexistence}

Let again $\psi \in \mathcal{S}$. We need to calculate the suprema 
in \eqref{eq:estimatea0} to \eqref{eq:estimatea12} for 
$\weightf(t)=(1+\alpha t^2)e^{\alpha t^2/2}$. We first note:
\begin{align}
	\weightf_1(t) ~&=~ t e^{\alpha t^2/2},\nonumber\\
	\weightf_2(t) ~&=~\frac{1}{\alpha} \left( e^{\alpha t^2/2}-1 \right),\nonumber\\
	\weightf_3(t) ~&=~\frac{1}{\alpha} \left[ \sqrt{\frac{\pi}{2\alpha}} \erfi(\sqrt{\alpha/2} t)-t \right].
\end{align}
We can see that with each successive integration, the functions 
$\weightf_n$ grow slower as $t\rightarrow \infty$. Furthermore, the leading 
terms in $\weightf_n$ are inversely proportional to increasing powers of 
$\alpha$. These two properties (and of course the fact that $\weightf_1, 
\weightf_2,\weightf_3$ can be written down in terms of elementary functions) make 
this particular function $\weightf(t)$ a suitable choice for the proof.

As we need to estimate the behavior of quotients like $\weightf_3(t)/\weightf(t)$ 
for $t\rightarrow \infty$, we look for a simpler estimate of $\weightf_3$ 
in terms of exponential functions. We note:
\begin{align}
	\weightf_3(t) ~&=~ \int_0^t dt'\,  \frac{1}{\alpha} \left( e^{\alpha {t'}^2/2} -1\right)\nonumber\\
	&\le~ \frac{e^{\alpha t^2/2}}{\alpha} e^{-\alpha t^2/2} \sqrt{2/\alpha} \int_0^{\sqrt{\alpha/2} t}  d\tau  \,e^{\tau^2}\nonumber\\
	&=~\frac{\sqrt{2}}{\alpha^{3/2}} \, e^{\alpha t^2/2} \, D(\sqrt{\alpha/2}\,t),
\end{align}
where $D(t) = e^{-t^2}\int_0^{t}  d\tau \, e^{\tau^2}$ denotes the 
Dawson function.
Using the property \(|tD(t)|<\frac{2}{3}\), we obtain:
\begin{equation}
	t \weightf_3(t)~\leq~\frac{4}{3} \frac{e^{\alpha t^2/2}}{\alpha^{2}}.
\label{eq:g3estimate}
\end{equation}
We are now well-equipped to calculate the suprema occurring in 
\eqref{eq:estimatea0} to \eqref{eq:estimatea12}. Using
\begin{equation}
 \sup_{t\geq 0}\frac{t^\beta}{1+t^2} ~=~ \left\{ \begin{matrix} 1\quad \text{ for } \beta=0\\ \frac{1}{2} \quad \text{ for } \beta=1 \\ 1\quad \text{ for } \beta=2 \end{matrix}\right. 
\end{equation}
we obtain:
\begin{align}
	\sup_{t\geq 0} \frac{\weightf_1(t)}{\weightf(t)} ~&=~ \sup_{t\geq 0} \frac{t}{1+\alpha t^2} ~=~ \frac{1}{2}\frac{1}{\sqrt{\alpha}},\label{eq:sup1}\\
	\sup_{t\geq 0} \frac{t \weightf_1(t)}{\weightf(t)} ~&=~ \sup_{t\geq 0} \frac{t^2}{1+\alpha t^2} ~=~ \frac{1}{\alpha},\label{eq:sup2}\\
	\sup_{t\geq 0} \frac{\weightf_2(t)}{\weightf(t)} ~&\leq~ \sup_{t\geq 0} \frac{1}{\alpha} \frac{1}{1+\alpha t^2} ~=~ \frac{1}{\alpha},\label{eq:sup3}\\
\sup_{t\geq 0} \frac{t\weightf_2(t)}{\weightf(t)} ~&\leq~ \sup_{t\geq 0} \frac{1}{\alpha} \frac{t}{1+\alpha t^2} ~=~ \frac{1}{2}\frac{1}{\alpha^{3/2}},\label{eq:sup4}\\
\sup_{t\geq 0} \frac{t^2\weightf_2(t)}{\weightf(t)} ~&\leq~ \sup_{t\geq 0} \frac{1}{\alpha} \frac{t^2}{1+\alpha t^2} ~=~ \frac{1}{\alpha^2}\label{eq:sup5}.
\end{align}
Using, in addition, the property $|D(t)| < \frac{3}{5}$, we find:
\begin{align}
	\sup_{t\geq 0} \frac{\weightf_3(t)}{\weightf(t)} ~&\leq~ \sup_{t\geq 0} \frac{\sqrt{2}}{\alpha^{3/2}} \frac{D(\sqrt{\alpha/2}t)}{1+\alpha t^2} ~=~ \frac{3\sqrt{2}}{5}\frac{1}{\alpha^{3/2}} ~<~ \frac{1}{\alpha^{3/2}},\label{eq:sup6}\\
\sup_{t\geq 0} \frac{t^2 \weightf_3(t)}{\weightf(t)} ~&\leq~ \sup_{t\geq 0} \frac{4}{3}\frac{1}{\alpha^2} \frac{t}{1+\alpha t^2} ~=~\frac{2}{3}\frac{1}{\alpha^{5/2}}. \label{eq:sup7}
\end{align}
In the last line, we have made use of \eqref{eq:g3estimate}.

With these results, we find for $A_0$:
\begin{equation}
	\eqref{eq:estimatea0} ~\leq~ \frac{\lambda}{8\pi} \left(\frac{1}{2} \frac{1}{\sqrt{\alpha}}\right)^2 ~=~  \frac{\lambda}{32\pi} \frac{1}{\alpha}.
\end{equation}
This yields \eqref{eq:estimatea0final}.

We continue with $A_1$.
\begin{align}\notag
  \eqref{eq:estimatea1} \leq \frac{\lambda  m_1^2}{16\pi} \left[  3  \frac{1}{\alpha}  \frac{1}{\alpha} + 3  \frac{1}{2} \frac{1}{\sqrt{\alpha}}  \frac{1}{2} \frac{1}{\alpha^{3/2}} +2  \frac{1}{2} \frac{1}{\sqrt{\alpha}}  \frac{1}{\alpha^{3/2}} \right] \\
  = \frac{\lambda  m_1^2}{16\pi} \frac{19}{4} \frac{1}{\alpha^2} ~<~\frac{\lambda  m_1^2}{16\pi} \frac{5}{\alpha^2}.
\end{align}
This yields \eqref{eq:estimatea1final}. Analogously, we obtain the 
estimate \eqref{eq:estimatea2final} for $A_2$.

Finally, for $A_{12}$, we have
\begin{align}
  \eqref{eq:estimatea12} \leq \frac{\lambda  m_1^2 m_2^2}{96 \pi} \left[ \frac{1}{\alpha^2}  \frac{1}{\alpha} + \frac{1}{2}  \frac{2}{3} \frac{1}{\alpha^{5/2}}  \frac{1}{2} \frac{1}{\sqrt{\alpha}} \right] \notag\\
  = \frac{\lambda  m_1^2 m_2^2}{96\pi}  \frac{7}{6} \frac{1}{\alpha^3} < \frac{\lambda  m_1^2 m_2^2}{80 \pi}  \frac{1}{\alpha^3},
\end{align}
which yields \eqref{eq:estimatea12final}.

Now, the estimates \eqref{eq:estimatea0final} to
\eqref{eq:estimatea12final} show that the operators 
$A_0$, $A_1$, $A_2$ and $A_{12}$ are bounded on test functions. 
Thus, they can be linearly extended to bounded operators on 
$\Banach_{\weightf}$ with the same bounds.

The operator $A = A_0 + A_1 + A_2 + A_{12}$ then also defines a 
bounded linear operator on $\Banach_{\weightf}$ with norm
\begin{equation}
	\| A \| ~\leq~ \| A_0 \| + \| A_1 \| + \| A_2 \| + \| A_{12} \|.
\end{equation}
Using the previous results \eqref{eq:estimatea0final}-
\eqref{eq:estimatea12final}, we obtain:
\begin{equation}
	\|A \| ~\leq~ \frac{\lambda}{8\pi \alpha} \left( \frac{1}{4} + \frac{5(m_1^2 + m_2^2)}{2} \frac{1}{\alpha} + \frac{m_1^2 \, m_2^2}{10} \frac{1}{\alpha^2} \right).
\end{equation}
If $\alpha$ is chosen such that this expression is strictly smaller 
than unity, $A$ becomes a contraction and the existence and 
uniqueness of solutions of the equation $\psi = \psi^{\free} + A\psi$ 
follows. This yields condition \eqref{eq:condexistencemassive} and 
ends the proof.

%%%%%
\subsubsection{Proof of Theorem \ref{thm:existencecurved}} 
\label{sec:proofexistencecurved}

The proof can be reduced to the one for $\M$. To do so, 
we take the absolute value of \eqref{eq:defa0tilde} and use 
$|\psi|(\eta_1,\vx,\eta_2,\vy) \leq \weightf(\eta_1) \weightf(\eta_2) \|\psi\|_{\weightf}$. 
With
\begin{align}
	G(\eta) ~&=~ a(\eta) \exp \left(\gamma \int_0^\eta d\eta'~a(\eta') \right)	\label{eq:defG}\\
	G_1(\eta)~&=~ \int_0^\eta d\eta'~G(\eta)
\end{align}
we obtain the estimate
\begin{align}\notag
    &|\widetilde{A}_0\psi|(x,y) \\
    &\le \frac{\lambda \|\psi\|_{\weightf}}{4(4\pi)^3}\!\! \int_{B_{\eta_2}(\vy)}\!\!\!\!\!d^3 {\vy}^{\,\prime} \!\!\int_0^{2\pi} \!\!\!d\varphi \int_{-1}^1 \!\!\!d\cos\vartheta \, \frac{|b^2|}{(b^0\!\!+\!|\vb|\cos\vartheta)^2 |{\vy}^{\,\prime}|} G(\eta_2\!-\!|{\vy}^{\,\prime}|)\nonumber\\
    &\times G\left(\eta_1-\frac{1}{2}\frac{b^2}{b^2+|\vb|\cos\vartheta}\right)\notag\\
    &\times \left(1_{b^2>0}1_{b^0>0} 1_{\cos\vartheta > \frac{b^2}{2\eta_1^0|\vb|} - \frac{b^0}{|\vb|}}+1_{b^2<0}1_{\cos\vartheta<\frac{b^2}{2\eta_1|\vb|} - \frac{b^0}{|\vb|}}\right).
\label{eq:a0tildecalc01}
\end{align}
This estimate is identical to \eqref{eq:a0calc01} with the only 
difference that the function $g$ is exchanged with $G$ in the 
integral (but not in $\| \cdot\|_{\weightf}$). Thus, going through the same 
steps as in Secs. \ref{sec:proofbounds}, \ref{sec:proofexistence}, 
we obtain:
\begin{equation}
	\sup_{\psi \in \mathcal{S}\left(([0,\infty)\times \R^3)^2\right)} \frac{\| \widetilde{A}_0 \psi \|_{\weightf}}{\| \psi \|_{\weightf}} ~\leq~ \frac{\lambda}{8\pi} \left(\sup_{t\geq 0} \frac{G_1(t)}{\weightf(t)}\right)^2.\label{eq:estimatea0tilde}
\end{equation}
Now, recalling $\weightf(t) = \exp\left(\gamma \int_0^t d\tau \, 
a(\tau)\right)$ we have
\begin{equation}
	G_1(t) = \frac{1}{\gamma} \weightf(t)
\end{equation}
and it follows that
\begin{equation}
	\sup_{\psi \in \mathcal{S}\left(([0,\infty)\times \R^3)^2\right)} \frac{\| \widetilde{A}_0 \psi \|_{\weightf}}{\| \psi \|_{\weightf}} ~\leq~ \frac{\lambda}{8\pi \gamma^2},
\end{equation}
which yields \eqref{eq:a0tildebound}. The rest of the claim follows 
as before.




\section{Directly Interacting Dirac Particles}\label{sec:direct dirac}

In this section we prove the existence and uniqueness 
of solutions of the spin-1/2 delay-equation \eqref{eq:twopartintgeneral}
for a class of kernels \(K\)
subject to similar modifications \ref{matt simplifying assumption 1}
and \ref{matt simplifying assumption 2}.
Similar to the results of the last chapter an analogous 
result is proven on FLRW spacetime.
Furthermore, we show that the solutions 
are determined by Cauchy data at the initial time; however, 
no Cauchy problem is admissible at other times. 

\subsection{Introduction}

In order to take a closer look at equation \eqref{eq:twopartintgeneral},
we start with its constituents.

The Greens function of Diracs equation is given by 
\begin{equation}
	\mathscr{S}(x)= \overline{D}G(x),
\end{equation}
where \(\overline{D} = (-i \gamma^\mu \partial_\mu - m)\).
This can be verified directly by computing 
\(D\overline{D}=\Box +m^2\).
The operator \(\overline{D}\)
will be refered to as the adjoint Dirac operator.
Consequently, one has to define the integral operator in 
\eqref{eq:twopartintgeneral} on a function space where one can take 
certain weak derivatives. In contrast to most of non-relativistic 
physics, this also concerns the time derivatives here. The choice 
of function space can be a tricky issue, as the fixed point
scheme
requires the integral operator to preserve the regularity, so 
that the regularity needs to be in harmony with the structure 
of the integral equation (see Sec. \ref{sec:choiceofB}).


This section is structured as follows. 
In subsec. \ref{sec:setting}, we specify the integral equation 
\eqref{eq:twopartintgeneral} in detail. The difficulties 
with understanding 
the distributional derivatives are discussed and a suitable 
function space is identified. Subsec. \ref{sec:results} contains 
the main results of this section. 
In subsec. \ref{sec:minkhalfspace}, we formulate 
an existence and uniqueness theorem (Thm. \ref{thm:minkhalfspace}) 
for eq. \eqref{eq:twopartintgeneral} on $\M$. 
It is shown that 
the relevant initial data are equivalent to Cauchy data at $t=0$. 
In subsec. \ref{sec:flrw}, we provide a physical justification for 
the cutoff at $t=0$ by extending the results to a FLRW spacetime. 
In the massless case, we show that an existence and uniqueness 
theorem can be obtained from the one for $\M$ via 
conformal invariance. The result, thm. \ref{thm:flrw}, covers a 
fully relativistic interacting dynamics in 1+3 spacetime 
dimensions. The proofs are carried out in subsec. \ref{sec:proofs}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Setting of the problem} \label{sec:setting}

%%%
\subsubsection{Definition of the integral operator on test functions} \label{sec:aontestfunctions}

In this section, we show how the integral operator in 
\eqref{eq:twopartintgeneral} can be defined rigorously on 
test functions.
We consider the integral equation \eqref{eq:twopartintgeneral} 
on the Minkowski half space $\M$ as we did in the last section.
We focus on retarded Green's functions of the Dirac equation, 
$\mathscr{S}^{\ret}(x) = \overline{D} G^{\ret}(x)$ where 
$G^{\ret}(x)$ is the retarded Green's function of the KG equation defined 
in equation \eqref{eq:gretkg}.
In order to define the meaning of the Green's functions as distributions, we introduce a suitable space of test functions:
\begin{equation}
	\mathscr{D} = \mathcal{S}\big( (\M)^2,\CC^{16} \big),
\end{equation}
the space of 16-component Schwarz functions on $(\M)^2$.
For a smooth interaction kernel $K$ and a test function $\psi \in \mathscr{D}$, we then understand \eqref{eq:twopartintgeneral} by formally integrating by parts so that all partial derivatives act on $K \psi$:
\begin{align}
  \psi(x_1,x_2) =\, &\psi^{\free}(x_1,x_2) +\int_{\M} d^4 x_1' \int_{\M} d^4 x_2' \, G_1^{\ret}(x_1-x_1')\\
  & \times G_2^{\ret}(x_2-x_2') [D_1 D_2(K \psi)](x_1',x_2')\nonumber\\
&+\text{boundary terms},
\label{eq:inteqpi}
\end{align}
where $D_k = (i \gamma_k^\mu \partial_{x_k^\mu} - m_k)$, $k=1,2$. The boundary terms result from the fact that $\psi(x_1,x_2) \neq 0$ for $x_1^0 = 0$ or $x_2^0 =0$ and are given by:
\begin{align}
  &\int_{\R^3} d^3 \vx_1' \int_{\R^3} d^3 \vx_2'  i \gamma_1^0 G_1^{\ret}(x_1-x_1') i \gamma_2^0 G_2^{\ret}(x_2-x_2')\\
  &\hspace{3cm}\times  \left.(K \psi)(x_1',x_2') \right|_{{x_1^0}' = 0,\, {x_2^0}' = 0}\nonumber\\
+ &\int_{\R^3} d^3 \vx_1' \int_{\frac{1}{2} \M} d^4 x_2'  i \gamma_1^0 G_1^{\ret}(x_1-x_1') G_2^{\ret}(x_2-x_2')  \\
&\hspace{3cm}\times \left.D_2(K \psi)(x_1',x_2') \right|_{{x_1^0}' = 0}\nonumber\\
 +&\int_{\frac{1}{2} \M} d^4 x_1' \int_{\R^3} d^3 \vx_2'  G_1^{\ret}(x_1-x_1')  i \gamma_2^0 G_2^{\ret}(x_2-x_2') \\
&\hspace{3cm}\times \left.D_1 (K \psi)(x_1',x_2') \right|_{{x_2^0}' = 0}.
\label{eq:boundaryterms}
\end{align}
Now, $G_k^{\ret}$ still contains the $\delta$-distribution. We use the latter to cancel the integrals over ${x_k^0}'$, $k=1,2$ in \eqref{eq:inteqpi} in the following manner.
\begin{align}
	&\frac{1}{4\pi} \int_{\M} d^4 x' \, \frac{\delta(x^0-{x^0}'-|\vx-{\vx}^{\,\prime}|)}{|\vx-{\vx}^{\,\prime}|} f(x')\\
= ~&\frac{1}{4\pi} \int_{B_{x^0}(\vx)} d^3 {\vx}^{\,\prime} \, \frac{1}{|\vx-{\vx}^{\,\prime}|} f(x')|_{{x^0}'=x^0-|\vx-{\vx}^{\,\prime}|}\nonumber\\
= ~&\frac{1}{4\pi} \int_{B_{x^0}(0)} d^3 \vy\, \frac{1}{|\vy|} f(x +y)|_{y^0=-|\vy|}.
\end{align}
Moreover,
\begin{align}
	&\frac{m}{4\pi} \int_{\M} \!\! d^4 x' ~ H(x^0 - {x^0}' - |\vx-{\vx}^{\,\prime}|) \frac{J_1(m\sqrt{(x-x')^2})}{\sqrt{(x-x')^2}} f(x')\nonumber\\
= ~& \frac{m}{4\pi} \int_{[-x^0,\infty) \times \R^3} \!\!\!\! d^4 y ~ H(-y^0- |\vy|) \frac{J_1(m\sqrt{y^2})}{\sqrt{y^2}} f(x +y)\nonumber\\
= ~& \frac{m}{4\pi} \int_{-x^0}^0 dy^0 \int_{B_{|y^0|}(0)} d^3 \vy_k \, \frac{J_1(m\sqrt{y^2})}{\sqrt{y^2}} f(x+y).
\end{align}
For the boundary terms, we similarly use
\begin{align}
   \frac{i \gamma^0}{4\pi} \int_{\R^3}d^3 {\vx}^{\,\prime}& ~ \frac{\delta(x^0-|\vx-{\vx}^{\,\prime}|)}{|\vx-{\vx}^{\,\prime}|}f(0,{\vx}^{\,\prime}) \\
   &~=~ \frac{i \gamma^0}{4\pi} \int_{\partial B_{x^0}(0)}d\sigma(\vy) ~ \frac{f(0,\vx+\vy)}{x^0}
  \end{align}
as well as
\begin{align}
	&i \gamma^0\frac{m}{4\pi} \int_{\R^3}d^3 {\vx}^{\,\prime} ~ H(x^0 - {x^0}' - |\vx-{\vx}^{\,\prime}|) \frac{J_1(m\sqrt{(x-x')^2})}{\sqrt{(x-x')^2}} f(x')|_{{x^0}' = 0}\nonumber\\
&= i \gamma^0\frac{m}{4\pi} \int_{B_{x^0}(0)}d^3 \vy ~ \frac{J_1(m\sqrt{(x^0)^2 - \vy^2})}{\sqrt{(x^0)^2 - \vy^2}} f(0,\vx+\vy).
\end{align}
This yields the form of the integral equation which shall be the basis of our investigation:
\begin{equation}
	\psi(x_1,x_2) = \psi^{\free}(x_1,x_2) + (A \psi)(x_1,x_2).
\label{eq:inteqschematic}
\end{equation}
The operator $A$ is first defined on test functions $\psi \in \mathscr{D}$ as
\begin{equation}
	A\psi ~=~ \prod_{j=1,2} \left(A_j^{(1)}(m) + A_j^{(2)}(m) + A_j^{(3)}(m) + A_j^{(4)}(m)\right)
 \label{eq:defa}   
\end{equation}
where for $j=1,2$, $k=1,2,3,4$ the operator \\
\(A_j^{(k)}(m) : \mathscr{D} \rightarrow C^\infty\big((\M)^2,\CC^{16}\big)\)  
is defined by letting the respective operator $A^{(k)}(m)$, given 
below, act on the $j$-th spacetime-variable and spin index of 
$\psi(x_1,x_2),~ \psi \in \mathscr{D}$.
\footnote{We deliberately avoid using tensor products here, as 
the completion of an algebraic tensor product of Banach spaces depends sensitively 
on which completion is taken.}
\begin{align}
	\left(A^{(1)}(m) \,\phi \right)(x) ~&=~ \frac{1}{4\pi} \int_{B_{x^0}(0)} \! \!d^3 \vy ~ \frac{1}{|\vy|} \phi(x+y)|_{y^0 = -|\vy|}, \label{eq:a1}\\
	\left(A^{(2)}(m) \,\phi\right)(x) ~&=~ -\frac{m}{4\pi} \int_{-x^0}^0 dy^0 \int_{B_{|y^0|}(0)} d^3 \vy ~ \frac{J_1(m\sqrt{y^2})}{\sqrt{y^2}} \phi(x+y),\label{eq:a2}\\
	\left(A^{(3)}(m)\, \phi\right)(x) ~&=~ \frac{i \gamma^0}{4\pi} \int_{\partial B_{x^0}(0)}d\sigma(\vy) ~ \frac{\phi(0,\vx+\vy)}{x^0}, \label{eq:a3}\\\nonumber
  \left(A^{(4)}(m) \, \phi\right)(x) ~&=~ - i \gamma^0 \frac{m}{4\pi} \int_{B_{x^0}(0)}d^3 \vy ~ \frac{J_1(m\sqrt{(x^0)^2 - \vy^2})}{\sqrt{(x^0)^2 - \vy^2}}\\
  &\hspace{2cm} \times\phi(0,\vx+\vy),\label{eq:a4}
\end{align}
here \(\phi\in\mathcal{S}(\M,\mathbb{C}^4)\) and the dependence of $A_j^{(1)}$ and 
$A_j^{(3)}$ on $m$ is only for notational convenience.\\
We now turn to the question of a suitable Banach space for Eq.\ \eqref{eq:inteqschematic}.

\subsubsection{Choice of Banach space} \label{sec:choiceofB}

As we did in the last section, we would like to apply 
a contraction mapping argument, for that we need a 
proper Banach space \(\Banach\) as the domain of \(A\).
The results reviewed in section 
\ref{sec: direct interation previous} as well as 
the results of section \ref{sec:KG lightcones} 
suggest choosing
\begin{equation}
		\Banach_0 = L^\infty \left([0,\infty)^2_{(x_1^0,x_2^0)}, \,  L^2(\R^6,\CC^{16})_{(\vx_1,\vx_2)}\right)
	\label{eq:banach0}
\end{equation}
with norm
\begin{equation}
	\| \psi \|_{\Banach_0} = \esssup_{x_1^0,x_2^0 > 0} \, \| \psi(x_1^0,\cdot,x_2^0,\cdot)\|_{L^2}.
\end{equation}
However, as \eqref{eq:defa} involves the Dirac operators 
\(D_1\) and  \(D_2\), $\Banach_0$ is not sufficient for our 
problem. An appropriate Banach space $\Banach$ must allow 
us to take at least weak derivatives of $\psi$.  The choice 
of $\Banach$ is a delicate matter. One can easily go wrong 
with demanding too much regularity, as we shall see 
next.

%%%
\paragraph{Possible problems with the choice of space.}


The problem can best be illustrated with an example which is structurally related to \eqref{eq:twopartintgeneral} but otherwise simpler. Consider the equation
\begin{equation}
	f(t,x) = f^{\free}(t,z) + \int_0^t dz' \, K(z,z') \partial_t f(t,z'),
	\label{eq:modelinteq}
\end{equation}
where $f^{\free}, f, K : \R^2 \rightarrow \CC$ and $f^{\free}$ 
is given. Equation \eqref{eq:modelinteq} is inspired 
by the term 
$A_1 D_1$ in \eqref{eq:defa}.

We would like to set up an iteration scheme for 
\eqref{eq:modelinteq}. As we cannot integrate by parts to 
shift the $t$-derivative to $K$, we must demand at least 
weak differentiability of $f$ with respect to $t$. This 
suggests using a Sobolev space such as $\Banach = H^1(\R^2)$.
To prove that the integral operator in \eqref{eq:modelinteq} 
maps $\Banach$ to $\Banach$, 
we then have to estimate the $L^2$-norm of
\begin{equation}
	\partial_t \int_0^t dz' \, K(z,z') \partial_t f(t,z') = K(t,t) (\partial_t f)(t,t) + \int_0^t dz' \, K(z,z') \partial_t^2 f(t,z').
\end{equation}
This expression, however, contains $\partial_t^2 f$. For this to make sense, we must be allowed to take the second weak time derivative of $f$. This, in turn, requires to choose a different Sobolev space, such as $H^2(\R^2)$, and to estimate the $L^2$-norm of the second time derivative of the integral operator acting on $f$ which involves $\partial_t^3 f$, and so on. One is thus led to a Sobolev space where all weak $n$-th time derivatives have to exist. Such infinite-order Sobolev spaces have, in fact, been investigated in \cite{dubinskii_1991}. However, it does not seem realistic to get an iteration to converge on these spaces. We therefore take a different approach. 

%%%
\paragraph{A Banach space adapted to our integral equation.} Considering the form of the integral operator $A$ \eqref{eq:defa}, one can see that it is sufficient that the derivatives $D_1 \psi$, $D_2 \psi$ and $D_1 D_2 \psi$ exist in a weak sense. As we want to prove later that $A$ maps the Banach space to itself, we have to estimate, among other things, a suitable norm of $D_1 (A \psi)$. If $\psi \in \mathscr{D}$ is a test function and $K$ is smooth, we have
\begin{align}\nonumber
  D_1 (A \psi)(x_1,x_2) &= D_1 \int d^4 x_1' \, d^4 x_2' \, \mathscr{S}_1(x_1-x_2') \mathscr{S}_2(x_2-x_2')\\
  &\hspace{1cm}\times K(x_1',x_2') \psi(x_1',x_2')\nonumber\\
	&= \int d^4 x_2' \, \mathscr{S}_2(x_2-x_2') K(x_1,x_2') \psi(x_1,x_2')
\label{eq:d1apsi}
\end{align}
where we have used $D_1 \mathscr{S}_1(x_1-x_1') = \delta^{(4)}(x_1-x_1')$. The crucial point now is that \eqref{eq:d1apsi} does not contain higher-order derivatives such as $D_1^2 \psi$. The same holds true also for $D_2 (A \psi)$ and $D_1 D_2 (A\psi)$. Thus, the problem of the toy example \eqref{eq:modelinteq} is avoided.

Together with the previous considerations about $\Banach_0$ \eqref{eq:banach0}, we are led to define the Banach space $\Banach_{\weightf}$ as the completion of $\mathscr{D}$ with respect to the following Sobolev-type norm:
\begin{equation}
	\| \psi \|^2_{\weightf} = \esssup_{x_1^0,x_2^0 >0} \frac{1}{\weightf(x_1^0)\weightf(x_2^0)} [\psi]^2(x_1^0,x_2^0)
\label{eq:normpsi}
\end{equation}
where \(g : [0,\infty[ \rightarrow [0,\infty[ \) is a monotonically increasing function which is such that the function $1/g$ is bounded. We admit such a weight factor with hindsight. As we shall see, a suitable choice of $g$ will make a contraction mapping argument possible.

In \eqref{eq:normpsi} we use the notation
\begin{equation}
	[\psi]^2(x_1^0,x_2^0) ~= \sum_{k=0}^3 \| (\mathcal{D}_k \psi)(x_1^0, \cdot, x_2^0,\cdot)\|^2_{L^2(\R^6,\CC^{16})}
\label{eq:spatialnorm}
\end{equation}
with
\begin{equation}
	\mathcal{D}_k = \left\{ \begin{array}{cl} 1, &k=0\\ D_1, & k=1\\ D_2, & k=2 \\ D_1 D_2, & k=3 \end{array}\right. 
\label{eq:defdk}
\end{equation}

%%%
\begin{Remark} 
  One can see the purpose of integral equation \eqref{eq:twopartintgeneral} in 
  determining an interacting correction to a solution $\psi^{\free}$ 
  of the free multi-time Dirac equations $D_i \psi^{\free} = 0,~i=1,2$. 
  Therefore, it is important to check that sufficiently many 
  solutions of these free equations lie in $\Banach_{\weightf}$. This is 
  ensured by the following Lemma (see Sec. 
  \ref{sec:freesolutionsinbanach} for a proof).

\end{Remark}

\begin{Lemma}
  Let $\psi^{\free}$ be a solution of the free multi-time Dirac 
  equations $D_i \psi^{\free} = 0,~i=1,2$ with initial data 
  $\psi^{\free}(0,\cdot,0,\cdot) = \psi_0 \in C_c^\infty(\R^6,\CC^{16})$. 
  Furthermore, let $g : [0,\infty[ \rightarrow ]0,\infty[$ be a 
  monotonically increasing function with $\weightf(t) \rightarrow \infty$ 
  for $t \rightarrow \infty$. Then $\psi^{\free}$ lies 
  in $\Banach_{\weightf}$.
	\label{thm:freesolutionsinbanach}
\end{Lemma}

Given the definition of $A$ on $\mathscr{D}$ as in Sec.\ 
\ref{sec:aontestfunctions}, we shall now proceed with showing that 
$A$ is bounded on this space. Furthermore, we show that for a 
suitable choice of the weight factor $g$ in $\Banach_{\weightf}$, we can 
achieve $\| A\| < 1$ on $\mathscr{D}$. This allows to extend $A$ to 
a contraction on $\Banach_{\weightf}$ so that the Neumann series 
$\psi = \sum_{k=0}^\infty A^k \psi^{\free}$ yields the unique 
solution of $\psi = \psi^{\free} + A\psi$.

%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%
\subsection{Results} \label{sec:results}

%%%%%%%%%
\subsubsection{Results for a Minkowski half space} \label{sec:minkhalfspace}

The core of our results is the following Lemma which allows us to control the growth of the spatial norm of $\psi$ with the two time variables.

\begin{Lemma} \label{thm:boundsa} 
	Let $\psi \in \mathscr{D}$, $\slashed{\partial}_k = \gamma_k^\mu \partial_{k,\mu},~k=1,2$ and let $K \in C^2(\R^{8},\CC)$ with
	\begin{align}
    \| K \| := \sup_{x_1, x_2 \in \M } \max \left\{ |K(x_1,x_2)|, |\slashed{\partial}_1 K(x_1,x_2)|,\right.\\
    \left. |\slashed{\partial}_2 K(x_1,x_2)|, |\slashed{\partial}_1 \slashed{\partial}_2 K(x_1,x_2)|\right\} < \infty.
	\label{eq:normk}
  \end{align}
Then we have:
\begin{align}
		[ A \psi]^2(x_1^0,x_2^0)  ~\leq ~& \|K\|^2 \prod_{j=1,2} \big( \id + 8\mathcal{A}_j(m_j) \big) \, [\psi]^2(x_1^0,x_2^0),
\label{eq:spatialnormapsi}
\end{align}
where $\mathcal{A}_j(m) = \sum_{k=1}^4\mathcal{A}_j^{(k)}(m)$ with 
$\mathcal{A}_j^{(k)}$ as defined in \eqref{eq:defcurlyoperators}. 
The expression $[\psi ]^2(x_1^0,x_2^0)$ is understood as a function in 
$C^\infty\big( (\M)^2,\mathbb{R}^+_0\big)$ to which the operators in 
front of it are applied.
\end{Lemma}

The proof can be found in Sec.\ \ref{sec:proofboundsa}.

Lemma \ref{thm:boundsa} can now be used to identify (with some trial and error) a suitable weight factor $g$ which allows us to extend $A$ to a contraction on $\Banach_{\weightf}$. Our main result is:

%%%
\begin{Thm}[Existence and uniqueness of dynamics on a Minkowski half space.] \label{thm:minkhalfspace}
	Let $0 < \| K \| < 1$, $\mu = \max \{ m_1,m_2\}$ and
	\begin{align} 
		\weightf(t)& ~=~ \sqrt{1+b t^8}\, \exp(b t^8/16),	\label{eq:defg}\\
    		b& ~=~ \frac{\|K\|^4}{(1-\|K\|)^4} \left(16+\mu^4\right)^4. \label{eq:defb}
\end{align}
	Then for every $\psi^{\free} \in \Banach_{\weightf}$, the equation $\psi = \psi^{\free} + A \psi$ possesses a unique solution $\psi \in \Banach_{\weightf}$.
\end{Thm}

The proof is given in Sec.\ \ref{sec:proofminkhalfspace}.

%%%
\begin{Remark}
\begin{enumerate}
%
  \item Note that Thm. \ref{thm:minkhalfspace} establishes 
  the existence and uniqueness of a global-in-time solution. 
  The non-Markovian nature of the dynamics makes it 
  necessary to prove such a result directly instead of 
  concatenating short-time solutions. The key step in our 
  proof which makes the global-in-time result possible is 
  the suitable choice of the weight factor $\weightf$.
%
  \item The main condition in Thm.\ \ref{thm:minkhalfspace}
   is $\| K \| < 1$. This may be interpreted as the 
   interaction must not being too strong. A condition 
   of that kind is to be expected solely because of the 
   contribution $\| (D_1 D_2 (A \psi))(x_1^0,\cdot, x_2^0,\cdot)\|_{L^2} = \| K \psi(x_1^0,\cdot,x_2^0,\cdot)\|_{L^2}$ to $[A \psi](x_1^0,x_2^0)$. Taking our
strategy for setting up the Banach space for granted, we therefore think that one cannot avoid a condition on the interaction strength. Note that conditions on the interaction strength also occur at other places in quantum theory (albeit in a different sense). For example, the Dirac Hamiltonian plus a Coulomb potential is only self-adjoint if the prefactor of the latter is smaller than a certain value.
%
	\item \textit{Cauchy problem.} Thm.\ \ref{thm:minkhalfspace} shows that $\psi^{\free}$ uniquely determines the solution $\psi$. However, specifying a whole function in $\Banach_{\weightf}$ amounts to a lot of data. In case $\psi^{\free}$ is a solution of the free multi-time Dirac equations $D_1 \psi^{\free} = 0 = D_2 \psi^{\free}$ much less data are needed. $\psi^{\free}$ is then determined uniquely by Cauchy data, and hence $\psi$ is as well. 
Furthermore, if $\psi^{\free}$ is differentiable, \eqref{eq:twopartintgeneral} yields
\begin{equation}
		\psi(0,\vx_1,0,\vx_2) ~=~ \psi^{\free}(0,\vx_1,0,\vx_2).
	\label{eq:cauchyproblem}
	\end{equation}
	Thus, Cauchy data for $\psi^{\free}$ at $x_1^0 = x_2^0 = 0$ are also Cauchy data for $\psi$. The procedure works for arbitrary Cauchy data which are appropriate for the free multi-time Dirac equations.  Note, however, that a Cauchy problem for $\psi$ for times $x_1^0 = t_0 = x_2^0$ with $t_0 > 0$ is not possible. The reason is that $\psi(t_0,\vx_1,t_0,\vx_2) \neq \psi^{\free}(t_0,\vx_1,t_0,\vx_2)$ in general (and contrary to \eqref{eq:cauchyproblem} the point-wise evaluation may not make sense for $\psi$).
\end{enumerate}

\end{Remark}

%%%%%%%%%
\subsubsection{Results for a FLRW universe with a Big Bang singularity} \label{sec:flrw}
This section is analogous to subsection \ref{sec:KGcurvedspacetime},
we show that a Big Bang singularity provides a 
natural and covariant justification for the cutoff at $t = 0$. As 
this justification is our main goal, we make the point at the 
example of a particular class of  
FLRW spacetimes and do not strive to treat more general spacetimes 
here. The reason for studying these FLRW spacetimes is that they are 
conformally equivalent to $\frac{1}{2} \M$ \cite{ibison}. Together 
with the conformal invariance of the massless Dirac operator this 
allows for an efficient method of calculating the Green's functions 
which occur in the curved spacetime analog of the integral equation 
\eqref{eq:twopartintgeneral}. By doing this, we show that the existence and 
uniqueness result on these spacetimes can be reduced to Thm.\ 
\ref{thm:minkhalfspace}.

As shown in \cite{lienertcurved}, Eq.\ \eqref{eq:twopartintgeneral} possesses 
a natural generalization to curved spacetimes $\mathcal{M}$,
\begin{align}\nonumber
  \psi(x_1,x_2) = \psi^{\free}(x_1,x_2) &+ \int dV(x_1') \int dV(x_2') \, \mathscr{S}_1(x_1,x_1') \mathscr{S}_2(x_2,x_2')\\
  &\times K(x_1',x_2') \psi(x_1',x_2').
	\label{eq:inteqcurved}
\end{align}
Here, $dV(x)$ is the spacetime volume element, $\mathscr{S}_i$ are (retarded) 
Green's functions of the respective free Dirac equation, i.e.\
\begin{equation}
	D \mathscr{S}(x,x') = [-\weightf(x)]^{-1/2} \, \delta^{(4)}(x,x'),
	\label{eq:greensfndefcurved}
\end{equation}
where $\weightf(x)$ is the metric determinant, $D$ the covariant Dirac 
operator on $\mathcal{M}$, and $\psi$ a section of the tensor 
spinor bundle over $\mathcal{M} \times \mathcal{M}$.

In order to explicitly formulate \eqref{eq:inteqcurved}, we need 
to know the detailed form of $\mathscr{S}$. Note that results for 
general classes of spacetimes showing that $\mathscr{S}$ is a bounded 
operator on a suitable function space are not sufficient to obtain 
a strong (global in time) existence and uniqueness result. We 
therefore focus on the case of a flat FLRW universe where it is 
easy to determine the Green's functions explicitly. In that case, 
the metric is given by
\begin{equation}
	ds^2 = a^2(\eta) [d \eta^2 - d \vx^2]
	\label{eq:metricflrw}
\end{equation}
where, as before, $\eta$ is conformal time and $a(\eta)$ denotes the 
\textit{scale function}. The coordinate ranges are given 
by $\eta \in [0,\infty[$ and $\vx \in \R^3$. For a FLRW universe 
with a Big Bang singularity, $a(\eta)$ is a continuous, 
monotonically increasing function of $\eta$ with $a(\eta)=0$, 
corresponding to the Big Bang singularity. The spacetime volume 
element reads
\begin{equation}
	dV(x) = a^4(\eta) \, d \eta\, d^3 \vx.
\end{equation}
The crucial point now is that according to \eqref{eq:metricflrw} 
the spacetime is globally conformally equivalent to $\M$, 
with conformal factor
\begin{equation}
	\Omega(x) = a(\eta).
\end{equation}
In addition, for $m=0$, the Dirac equation is known to be 
conformally invariant (see e.g.\ \cite{silenko2015new,penrose_rindler}). More 
accurately, consider two spacetimes $\mathcal{M}$ and 
$\widetilde{\mathcal{M}}$ with metrics
\begin{equation}
	\widetilde{g}_{ab} = \Omega^2 \, g_{ab}.
\end{equation}
Then the massless Dirac operator $D$ on $\mathcal{M}$ is related to 
the massless Dirac operator $\widetilde{D}$ on 
$\widetilde{\mathcal{M}}$ by (see 
\cite{silenko2015new,fecko2006differential}):
\begin{equation}
	\widetilde{D} = \Omega^{-5/2} \, D \, \Omega^{3/2}.
	\label{eq:diracoperatortrafo}
\end{equation}
This implies the following transformation behavior of the Green's 
functions:
\begin{equation}
	\widetilde{G}(x,x') = \Omega^{-3/2}(x) \,\Omega^{-3/2}(x') \, G(x,x').
\end{equation}
One can verify this easily using \eqref{eq:diracoperatortrafo} and 
the definition of Green's functions on curved spacetimes 
\eqref{eq:greensfndefcurved}.

Denoting the Green's functions of the Dirac operator on Minkowski 
spacetime by $G(x,x')=S(x-x')$ and using coordinates $\eta, \vx$ 
we thus obtain the Green's functions $\widetilde{G}$ on flat FLRW 
spacetimes as:
\begin{equation}
	\widetilde{G}(\eta,\vx; \eta', {\vx}^{\,\prime}) = a^{-3/2}(\eta) a^{-3/2}(\eta')\, \mathscr{S}(\eta-\eta', \vx-{\vx}^{\,\prime}).
\end{equation}
With this result, we can write out in detail the multi-time integral 
equation \eqref{eq:inteqcurved} for massless Dirac particles on flat 
FLRW spacetimes (using retarded Green's functions):
\begin{align}\nonumber
  \psi(\eta_1,\vx_1,\eta_2,\vx_2) =& \psi^{\free}(\eta_1,\vx_1,\eta_2,\vx_2) + a^{-3/2}(\eta_1) a^{-3/2}(\eta_2) \\
  &\times \int_0^\infty d \eta_1' \int d^3 \vx_1' \int_0^\infty d \eta_2' \int d^3 \vx_2' \nonumber\\
  &\times a^{5/2}(\eta_1') a^{5/2}(\eta_2') \, \mathscr{S}_1^{\ret}(\eta_1-\eta_1', \vx_1-\vx_1')\\
  &\times \mathscr{S}_2^{\ret}(\eta_2-\eta_2',\vx_2-\vx_2') \, (K \psi)(\eta_1',\vx_1',\eta_2',\vx_2').
\end{align}
Note that we can regard $\psi$ as a map 
$\psi : (\M)^2 \rightarrow \CC^{16}$ as the coordinates 
$\eta, \vx$ cover the flat FLRW spacetime manifold globally.

It seems reasonable to allow for a singularity of the interaction 
kernel, i.e.\
\begin{equation}
	K(\eta_1,\vx_1,\eta_2,\vx_2) = a^{-\alpha}(\eta_1)  a^{-\alpha}(\eta_1) \, \widetilde{K}(\eta_1,\vx_1,\eta_2,\vx_2).
	\label{eq:ksingularity}
\end{equation}
Here, $\alpha \geq 0$. The singular behavior is motivated by that of 
the Green's functions of the conformal wave equation, 
see section \ref{sec:KGcurvedspacetime}. 
Recall from the introduction that the most 
natural interaction kernel on $\M$ would be 
$K(x_1,x_2)\propto \delta((x_1-x_2)_\mu(x_1-x_2)^\mu)$ which is a 
Green's function of the wave equation -- a concept that can be 
generalized to curved spacetimes using the conformal wave equation. 
Now, under conformal transformations, Green's functions of that 
equation transform as \eqref{eq: greens function singular interaction curved}
\begin{equation}
	\widetilde{G}(x,x') = \Omega^{-1}(x) \,\Omega^{-1}(x') \, G(x,x'),
\end{equation}
which corresponds to $\alpha = 1$ in \eqref{eq:ksingularity}.

Considering \eqref{eq:ksingularity}, our integral equation becomes:
\begin{align}\nonumber
  \psi(\eta_1,\vx_1,\eta_2,\vx_2) &= \psi^{\free}(\eta_1,\vx_1,\eta_2,\vx_2) + a^{-3/2}(\eta_1) a^{-3/2}(\eta_2) \int_0^\infty d \eta_1' \\
  &\times \int d^3 \vx_1' \int_0^\infty d \eta_2' \int d^3 \vx_2'\nonumber\\\nonumber
  &\times a^{5/2-\alpha}(\eta_1') a^{5/2-\alpha}(\eta_2') \, \mathscr{S}_1^{\ret}(\eta_1-\eta_1', \vx_1-\vx_1')\\
  &\times  \mathscr{S}_2^{\ret}(\eta_2-\eta_2',\vx_2-\vx_2') \, (\widetilde{K} \psi)(\eta_1',\vx_1',\eta_2',\vx_2').
\label{eq:inteqcurvedexplicit}
\end{align}
Apart from the scale factors which produce a certain singularity of 
$\psi$ for $\eta_1,\eta_2 \rightarrow 0$, this integral equation has 
the form of \eqref{eq:twopartintgeneral} on $\M$. Indeed, we can use 
the transformation
\begin{equation}
	\chi(\eta_1,\vx_1,\eta_2,\vx_2) = a^{3/2}(\eta_1) a^{3/2}(\eta_2)\, \psi(\eta_1,\vx_1,\eta_2,\vx_2)
	\label{eq:psichi}
\end{equation}
to transform the two equations into each other. We arrive at the 
following result.

%%%
\begin{Thm}[Existence and uniqueness of dynamics on a flat 
  FLRW universe] \label{thm:flrw}
	Let, $0 \leq \alpha \leq 1$ and let $a : [0,\infty) \rightarrow [0,\infty)$ be a differentiable function with $a(0)=0$ and $a(\eta) >0$ for $\eta>0$. Moreover, assume that $\widetilde{K} \in C^2 \left( ([0,\infty)\times \R^3)^2,\CC\right)$ with
  \begin{equation}
		\| a^{1-\alpha}(\eta_1) a^{1-\alpha}(\eta_2) \, \widetilde{K} \| <1.
	\label{eq:ktildecondition}
	\end{equation}
 Then for every $\psi^{\free}$ with 
 $a^{3/2}(\eta_1) a^{3/2}(\eta_2) \psi^{\free} \in \Banach_{\weightf}$, 
 \eqref{eq:inteqcurvedexplicit} has a unique solution $\psi$ with 
 $a^{3/2}(\eta_1) a^{3/2}(\eta_2)\psi \in \Banach_{\weightf}$ (and with \(g\) 
 as in Thm. \ref{thm:minkhalfspace}).
\end{Thm}

\begin{proof}
	Multiplying \eqref{eq:inteqcurvedexplicit} with $a^{3/2}(\eta_1) a^{3/2}(\eta_2)$ and using the relation yields
	\begin{align}\nonumber
  \chi(\eta_1,\vx_1,\eta_2,\vx_2) =& \chi^{\free}(\eta_1,\vx_1,\eta_2,\vx_2) +\int_0^\infty d \eta_1' \int d^3 \vx_1 \int_0^\infty d \eta_2'\\
  &\times~a^{1-\alpha}(\eta_1') a^{1-\alpha}(\eta_2') \nonumber\\\nonumber
  &\times  \, \mathscr{S}_1^{\ret}(\eta_1-\eta_1', \vx_1-\vx_1') \mathscr{S}_2^{\ret}(\eta_2-\eta_2',\vx_2-\vx_2') \\
  &\times (\widetilde{K} \chi)(\eta_1',\vx_1',\eta_2',\vx_2').
\label{eq:inteqcurvedexplicit2}
\end{align}
This equation has the form of 
\eqref{eq:twopartintgeneral} on $\M$ with $K$ 
replaced by\linebreak
 $a^{1-\alpha}(\eta_1') a^{1-\alpha}(\eta_2') 
\widetilde{K}$. Thus, using the same distributional 
understanding of the Green's functions as before, thm. 
\ref{thm:minkhalfspace} yields the claim. 
\end{proof}

%%%
\begin{Remark}
\begin{enumerate}
	\item Both $\psi^{\free}$ and $\psi$ have a singularity proportional to $a^{-3/2}(\eta_1)a^{-3/2}(\eta_2)$ for $\eta_1, \eta_2 \rightarrow 0$.
%
	\item For $\alpha < 1$, $\widetilde{K}$ has to compensate the singularities caused by $a^{-3/2}(\eta_1) a^{-3/2}(\eta_2)$ in order for \eqref{eq:ktildecondition} to hold. In the most natural case $\alpha = 1$, however, $\widetilde{K}$ only needs to satisfy $\| \widetilde{K} \| < 1$, i.e.\, the same condition as for $K$ in Thm.\ \ref{thm:minkhalfspace}. 
%
	\item Let $\chi^{\free} = a^{3/2}(\eta_1) a^{3/2}(\eta_2) \psi^{\free}$ be differentiable and let $\chi$ be the unique solution of \eqref{eq:inteqcurvedexplicit2}. Then, by \eqref{eq:inteqcurvedexplicit2}, we have:
  \begin{equation}
		\chi^{\free}(0,\vx_1,0,\vx_2) = \chi(0,\vx_1,0,\vx_2),
	\end{equation}
	i.e.\, $\chi$ satisfies a Cauchy problem "at the Big Bang".
%
  \item Remarkably, Thm.\ \ref{thm:flrw} covers a class of manifestly 
  covariant, interacting integral equations in 1+3 dimensions. Then 
  the interaction kernel $\widetilde{K}$ has to be covariant as 
  well. A class of examples (see also \cite{lienertcurved}) is 
  given by $\alpha = 1$ and 
  \begin{equation}
	\widetilde{K}(x_1,x_2) = \left\{ \begin{array}{cl} f(d(x_1,x_2))& \text{if } x_1, x_2 \text{ are time-like related}\\ 0 &  \text{else}, \end{array} \right.
\end{equation}
where \(d(x_1,x_2)\) denotes the geodesic distance 
of time-like separated the events $x_1 = (\eta_1,\vx_1)$ and 
$x_2 = (\eta_2,\vx_2)$, and $f$ is an arbitrary smooth function 
which leads to $\| \widetilde{K} \| < 1$.

\end{enumerate}
\end{Remark}


%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%
\subsection{Proofs} \label{sec:proofs}

%%%%%
\begin{proof}[Proof of lemma \ref{thm:freesolutionsinbanach}]
\label{sec:freesolutionsinbanach}

Consider a solution $\psi$ of $D_i \psi^{\free} = 0,~i=1,2$ for 
compactly supported initial data at $x_1^0 = 0 = x_2^0$. As the 
Dirac equation has finite propagation speed, $\psi^{\free}$  is 
spatially compactly supported for all times. Without loss of 
generality we may assume 
\(\|\psi^{\free} (t_1,\cdot,t_2,\cdot)\|_{L^2(\mathbb{R}^6)}=1\) for 
all times \(t_1,t_2\), so it follows that also 
\([\psi^{\free}](t_1,t_2)=1\). In the following we will construct a 
sequence of test functions \((\psi_m)_{m\in\mathbb{N}}\) 
satisfying \(\psi_m \xrightarrow[\|\cdot\|_{\weightf} ]{m\rightarrow \infty} 
\psi^{\free}\). Let \(\eta : \mathbb{R}\rightarrow \mathbb{R}\) be 
zero for arguments less than \(0\), be \(1\) for 
arugments greater than \(1\) and in 
between given by (see also Fig. \ref{fig:eta})
\begin{equation}
	\eta(t)=  \exp\left(-\frac{1}{t} \exp\left({\frac{1}{t-1}}\right)\right).
\end{equation}
%
\begin{figure}
	\centering
	\begin{tikzpicture}
  \begin{axis}[
      xlabel={$t$}, 
      ylabel={$\eta$},
      samples=500,
      xmin=-0,
      xmax=1,
      ymin=-0.1,
      ymax=1.1,
      enlarge y limits=false,
      axis x line=middle,
      axis y line=middle,
      axis line style={-},
      width=10. cm,
      height=6. cm,
      yticklabel style={xshift=7.5mm},
      ylabel style={xshift=-3mm,yshift=5mm},
      xlabel style={xshift=5mm,yshift=-2.4mm},
      ticklabel style={font=\small}
    ]
    \addplot[black,thick,domain=-0.1:0.001](x,0);
    \addplot [black,thick,domain=0.001:0.999] (x, {pow(e,-1/x * pow(e,1/(x-1)))});
    \addplot[black,thick,domain=0.999:1.1] (x,1);
    \end{axis}
\end{tikzpicture}
	\caption{The function \( \eta(t)\).}
	\label{fig:eta}
\end{figure}
%
 Note that $\eta$ is smooth and monotonically increasing. Next, we 
 define for every \(m\in\mathbb{N}\)
 \begin{equation}
 \psi^{\free}_m(t_1,\vx_1, t_2, \vx_2)\! :=\! e^{-(t_1-m) \eta(t_1-m) } e^{-(t_2-m) \eta(t_2-m)} \psi^{\free}(t_1,\vx_1, t_2, \vx_2).
 \end{equation}
 This function is smooth and decreases rapidly in all variables and 
 thus lies in \(\mathscr{D}\). Now we estimate
  \(\|\psi^{\free}-\psi_m\|_{\weightf}\). Pick \(m\in\mathbb{N}\). First 
  consider \(\|\psi^{\free} -\psi_m\|_{L^2(\mathbb{R}^6)}(t_1,t_2)\). 
  This function is identically zero for all \(t_1<m\) and 
  \(t_2<m\), so we obtain the estimate
 \begin{align}
    & \sup_{t_1,t_2>0} \frac{1}{\weightf(t_1)^2\weightf(t_2)^2} \|\psi^{\free}- \psi_m\|^2_{L^2(\mathbb{R}^6)}\nonumber\\
     =&\sup_{t_1,t_2>0} \frac{1}{\weightf(t_1)^2\weightf(t_2)^2} \left|1-e^{-\eta(t_1-m)(t_1-m)}e^{-\eta(t_2-m)(t_2-m)}\right|\\
     & ~\le~\frac{1}{\weightf(0)^2\weightf(m)^2}.
\end{align}
For the other terms we use that \(\psi^{\free}\) solves the free Dirac 
equation in each variable and that 
\(\sup_{t>0}\partial_{t} e^{-\eta(t)t}=:\alpha<\infty\) is realized 
for some positive value of \(t\). So we find for \(i\in \{0,1\}\):
 \begin{align}
& \sup_{t_1,t_2>0}\frac{1}{\weightf(t_1)^2\weightf(t_2)^2}\|D_i (\psi^{\free}-\psi_m)\|^2_{L^2(\mathbb{R}^6)}(t_1,t_2)\nonumber\\
= &\sup_{t_1,t_2>0}\frac{1}{\weightf(t_1)^2\weightf(t_2)^2}
 \\
 &\times\|\gamma_{i}^0 \psi^{\free}(t_1,\cdot,t_2,\cdot) e^{-\eta(t_{3-i}-n)(t_{3-i}-n)}\partial_{t_i}e^{-\eta(t_i-n)(t_i-m)} \|^2_{L^2(\mathbb{R}^6)}\\
 &\le~ \frac{\alpha}{\weightf(0)^2\weightf(m)^2}.
 \end{align}
For the inequality it has been used that the factor with a 
derivative vanishes for \(t_i<m\). 

An analogous estimate repeated for the \(D_1D_2\)-term yields
\begin{equation*}
     \sup_{t_1,t_2>0} \frac{1}{\weightf(t_1)^2\weightf(t_2)^2}\|D_1D_2(\psi^{\free} \!\!-\! \psi_m)\|^2_{L^2(\mathbb{R}^6)}(t_1,t_2)\!\le\! \frac{\alpha^2}{\weightf(m)^4} \!\le\! \frac{\alpha^2}{\weightf(0)^2\weightf(m)^2}.
 \end{equation*}
All in all, adding the estimates and taking the square root we 
find \(\|\psi^{\free} - \psi_n\|_{\weightf} \le \frac{1+\alpha}{\weightf(0)\weightf(n)}\), which 
together with the asymptotic behavior of \(g\) implies convergence. 
It follows that the free solution \(\psi^{\free}\) can be approximated 
by Cauchy sequences in \(\mathscr{D}\) and hence is contained in 
\(\mathscr{B}_{\weightf}\) which, we recall, has been defined as the 
completion of $\mathscr{D}$ with respect to $\| \cdot \|_{\weightf}$. 
\end{proof}


%%%%%
\subsubsection{Proof of Lemma \ref{thm:boundsa}} \label{sec:proofboundsa}

Throughout the following subsections, let $\psi \in \mathscr{D}$ and 
$K : \R^8 \rightarrow \CC$ be a smooth function. Furthermore define 
\(\delta:= 1-\|K\|^2>0, \mu=\text{max}\{m_1,m_2\}\) and let \(g\) 
be as in the statement of Thm. \ref{thm:minkhalfspace}.

We begin with some lemmas which are useful for estimating \\
$[A\psi]^2(x_1^0,x_2^0)$.

\begin{Lemma} \label{thm:estimatetensoroperators}
	Let the following operators be defined on $C([0,\infty))$:
	\begin{align}
		\big(\mathcal{A}^{(1)}(m) f\big)(t) ~&=~ t \int_0^{t} d \rho ~ (t-\rho)^2\,  f(\rho),\nonumber\\
		\big(\mathcal{A}^{(2)}(m) f \big)(t) ~&=~ \frac{m^4 t^4}{2^4 \,3^2} \int_0^{t} d\rho ~(t-\rho)^3 \, f(\rho),\nonumber\\
		\big(\mathcal{A}^{(3)}(m) f\big)(t) ~&=~ t^2 \, f(0),\nonumber\\
		\big(\mathcal{A}^{(4)}(m) f \big)(t) ~&=~ \frac{m^4 t^6}{2^2\, 3^2} \, f(0).
	\label{eq:defcurlyoperators}
	\end{align}
  Then, for $j=1,2$ and $k=1,2,3,4$, we define the operator 
  $\mathcal{A}_j^{(k)}(m)$ acting on functions 
  $\phi \in C([0,\infty)^2)$ by letting $\mathcal{A}^{(k)}(m)$ act 
  on the $j$-th variable of $\phi(t_1,t_2)$.
Then we have for all $\psi \in \mathscr{D}$, all $m_1,m_2\geq 0$ and 
all $k,l=1,2,3,4$:
\begin{equation}
		\left\| A_1^{(k)}(m_1) A_2^{(l)}(m_2)  \psi(t_1,\cdot,t_2,\cdot) \right\|^2_{L^2} \!\!\leq\! \mathcal{A}_j^{(k)}(m_1) \mathcal{A}_j^{(l)}(m_2)\, \|\psi(t_1,\cdot,t_2,\cdot)\|^2_{L^2}.\label{eq:aestimate}
	\end{equation}
Here, it is understood that the operators $\mathcal{A}_j^{(k)}$ 
are applied to the functions defined by the norms which follow them, 
e.g.\, \\
$\mathcal{A}_1^{(4)}(m_1)\, \|\psi(t_1,\cdot,t_2,\cdot)\|^2_{L^2} = \frac{m^4_1 t_1^6}{2^2\, 3^2} \, \|\psi(0,\cdot,t_2,\cdot)\|^2_{L^2}$.
\end{Lemma}

\begin{proof}
  We prove \eqref{eq:aestimate} for $k=1$, $ l=2$ and $k=3$, $l=4$. 
  The remaining cases can be treated in the same way. We begin with 
  $k=1$, $l=2$, using $|J_1(x)/x| \leq \frac{1}{2}$:
\begin{align}
	&\| A_1^{(1)}(m_1) A_2^{(2)}(m_2)\, \psi(x_1^0,\cdot,x_2^0,\cdot) \|^2_{L^2} ~= \frac{m_2^2}{(4\pi)^4} \int_{\R^3 \times \R^3} \!\!\! d^3 \vx_1 \, d^3 \vx_2 \\
&\hspace{-1cm}\times \left| \int_{B_{x_1^0}(0)} \!\!\! d^3\vy_1 \int_{-x_2^0}^0 dy_2^0 \int_{B_{|y_2^0|}(0)} \!\!\! d^3 \vy_2 ~\frac{1}{|\vy_1|}  \frac{J_1(m_2\sqrt{y_2^2})}{\sqrt{y_2^2}}\psi(x_1+y_1,x_2+y_2)|_{y^0_1=-|\vy_1|} \right|^2\nonumber\\
&\leq \frac{m_2^2}{(4\pi)^4} \int_{\R^3 \times \R^3}  \!\!\! d^3 \vx_1 \, d^3 \vx_2 \notag\\
&\times \left( \int_{B_{x_1^0}(0)} \!\!\! d^3\vy_1 \int_{-x_2^0}^0 dy_2^0 \int_{B_{|y_2^0|}(0)} \!\!\! d^3 \vy_2~ \frac{1}{|\vy_1|^2} \left| \frac{J_1(m_2\sqrt{y_2^2})}{\sqrt{y_2^2}} \right|^2 \right)\nonumber\\
&~\times \left( \int_{B_{x_1^0}(0)} \!\!\! d^3\vy_1 \int_{-x_2^0}^0 dy_2^0 \int_{B_{|y_2^0|}(0)} \!\!\! d^3 \vy_2 ~|\psi|^2(x_1+y_1,x_2+y_2)|_{y^0_1=-|\vy_1|} \right)\nonumber\\
&\leq~  \frac{m_2^2}{(4\pi)^4} \int_{\R^3 \times \R^3}  \!\!\! d^3 \vx_1 \, d^3 \vx_2 ~4\pi x_1^0 \left( \frac{\pi m_2^2 (x_2^0)^4}{12}\right) \nonumber\\
&~\times \left( \int_{B_{x_1^0}(0)} \!\!\! d^3\vy_1 \int_{-x_2^0}^0 dy_2^0 \int_{B_{|y_2^0|}(0)} \!\!\! d^3 \vy_2 ~|\psi|^2(x_1+y_1,x_2+y_2)|_{y^0_1=-|\vy_1|} \right)\nonumber\\
&\leq~  \frac{m_2^4 \, x_1^0 \,  (x_2^0)^4}{3 \pi^2\, 2^8 } \int_{\R^3 \times \R^3}  \!\!\! d^3 \vx_1 \, d^3 \vx_2  \int_{B_{x_1^0}(0)} \!\!\! d^3\vy_1 \int_{-x_2^0}^0 dy_2^0 \int_{B_{|y_2^0|}(0)} \!\!\! d^3 \vy_2\nonumber\\
&~\times |\psi|^2(x_1^0 - |\vy_1|,\vx_1+\vy_1,x_2^0 + y_2^0,\vx_2+\vy_2).
\label{eq:a1a2estimate1}
\end{align}
Exchanging the $x$ and $y$ integrals yields:
\begin{align}\nonumber
&\eqref{eq:a1a2estimate1} \leq  \frac{m_2^4 \, x_1^0\,  (x_2^0)^4}{3 \pi^2\, 2^8 } \int_{B_{x_1^0}(0)} \!\!\! d^3\vy_1 \int_{-x_2^0}^0 dy_2^0 \int_{B_{|y_2^0|}(0)} \!\!\! d^3 \vy_2 \\
&\hspace{3cm}\times\| \psi(x_1^0 - |\vy_1|,\cdot,x_2^0 + y_2^0,\cdot)\|_{L^2} \nonumber\\\nonumber
&\leq~  \frac{m_2^4 \, x_1^0\,  (x_2^0)^4}{3 \pi^2\, 2^8 } \, 4\pi \int_{0}^{x_1^0} \!\!\! d r_1 ~r_1^2 \int_{-x_2^0}^0 dy_2^0 ~\frac{4\pi}{3} |y_2^0|^3 \\\nonumber
&\hspace{3cm}\times \| \psi(x_1^0 - |\vy_1|,\cdot,x_2^0 + y_2^0,\cdot)\|_{L^2} \nonumber\\
&\leq~  \frac{m_2^4 \, x_1^0 \,  (x_2^0)^4}{2^4 \, 3^2} \int_{0}^{x_1^0} \!\!\! d \rho_1 ~(x_1^0-\rho_1)^2 \int_{0}^{x_2^0} d\rho_2 ~(x_2^0-\rho_2)^3 \, \| \psi(\rho_1,\cdot,\rho_2,\cdot)\|_{L^2} \nonumber\\
&=~ \mathcal{A}_1^{(1)}(m_1) \mathcal{A}_2^{(2)}(m_2)\, \|\psi(x_1^0,\cdot,x_2^0,\cdot)\|^2_{L^2}.
\end{align}

Next, we turn to the case $k=3, l=4$. Using that the modulus of the 
largest eigenvalue of $\gamma^0$ is 1, we obtain:
\begin{align}
	&\| A_1^{(3)}(m_1) A_2^{(4)}(m_2)\, \psi(x^0_1,\cdot,x_2^0,\cdot) \|^2_{L^2} ~\leq~ \frac{m_2^2}{(4\pi)^4 (x_1^0)^2} \int_{\R^3\times \R^3} \!\!\! d^3 \vx_1 \, d^3 \vx_1\nonumber\\
 &\hspace{-0.5cm}\times \left|\int_{\partial B_{x_1^0}(0)} \!\!\! d \sigma(\vy_1) \int_{B_{x_2^0}(0)} \!\!\! d^3 \vy_2 ~\frac{J_1\left( m_2\sqrt{(x_2^0)^2-\vy_2^2}\right)}{\sqrt{(x_2^0)^2-\vy_2^2}} |\psi|(0,\vx_1+\vy_2,0,\vx_2+\vy_2) \right|^2\nonumber\\
&\leq \frac{m_2^4}{(4\pi)^4 (x_1^0)^2} \int_{\R^3\times \R^3} \!\!\! d^3 \vx_1 \, d^3 \vx_1\nonumber\\
& \times\left(\int_{\partial B_{x_1^0}(0)} \!\!\! d \sigma(\vy_1) \int_{B_{x_2^0}(0)} \!\!\! d^3 \vy_2 \left|\frac{J_1\left( m_2\sqrt{(x_2^0)^2-\vy_2^2}\right)}{m_2\sqrt{(x_2^0)^2-\vy_2^2}}\right|^2 \right)\nonumber\\
& \times \left( \int_{\partial B_{x_1^0}(0)} \!\!\! d \sigma(\vy_1) \int_{\partial B_{x_2^0}(0)} \!\!\! d \sigma(\vy_2) ~|\psi|^2(0,\vx_1+\vy_2,0,\vx_2+\vy_2)\right)\nonumber\\
&=~ \frac{m_2^4}{(4\pi)^4 (x_1^0)^2} \, 4\pi (x_1^0)^2 \, \frac{\pi (x_2^0)^3}{3} \int_{\R^3\times \R^3} \!\!\! d^3 \vx_1 \, d^3 \vx_1 \int_{\partial B_{x_1^0}(0)} \!\!\! d \sigma(\vy_1)  \nonumber\\
&~~~~~\times\int_{B_{x_2^0}(0)} \!\!\! d^3 \vy_2 ~|\psi|^2(0,\vx_1+\vy_2,0,\vx_2+\vy_2).
\label{eq:a3a4estimate1}
\end{align}
Exchanging the order of the $x$ and $y$ integrals yields:
\begin{align}
	\eqref{eq:a3a4estimate1} ~&=~ \frac{m_2^4}{3 (4\pi)^3} \pi (x_2^0)^3\int_{\partial B_{x_1^0}(0)} \!\!\! d \sigma(\vy_1) \int_{B_{x_2^0}(0)} \!\!\! d^3 \vy_2 ~\|\psi(0,\cdot,0,\cdot)\|^2_{L^2}\nonumber\\
&=~ \frac{m_2^4 \, (x_1^0)^2 \, (x_2^0)^6}{2^2 \, 3^2} \, \|\psi(0,\cdot,0,\cdot)\|^2_{L^2}\nonumber\\
&= ~ \mathcal{A}_1^{(3)}(m_1) \mathcal{A}_2^{(4)}(m_2) \,  \|\psi(x_1^0,\cdot,x_2^0,\cdot)\|^2_{L^2}.
\end{align} 
\end{proof}


%%%
\begin{Lemma} \label{thm:spatialnormestimates}
	For $j=1,2$ let $\mathcal{A}_j(m) = \sum_{k=1}^4 \mathcal{A}_j^{(k)}(m)$. Then the following estimates hold:
\begin{align}
		& \!\| (A \psi)(x_1^0,\cdot,x_2^0,\cdot)\|^2_{L^2} ~\leq ~64 \, \|K\|^2 \mathcal{A}_1(m_1) \mathcal{A}_2(m_2) \, [\psi]^2(x_1^0,x_2^0),
	\label{eq:apsiestimate}\\
		&\! \| (D_1(A \psi))(x_1^0,\cdot,x_2^0,\cdot) \|^2_{L^2}~\leq~8 \, \| K \|^2 \, \mathcal{A}_2(m_2) \, [\psi](x_1^0,x_2^0),
	\label{eq:d1apsiestimate}\\
		&\! \| (D_2(A \psi))(x_1^0,\cdot,x_2^0,\cdot) \|^2_{L^2} ~\leq~8 \, \| K \|^2 \, \mathcal{A}_1(m_1) \, [\psi](x_1^0,x_2^0),
	\label{eq:d2apsiestimate}\\
		&\! \| (D_1 D_2(A \psi))(x_1^0,\cdot,x_2^0,\cdot) \|^2_{L^2} ~\leq~ \| K \|^2 \, [\psi]^2(x_1^0,x_2^0),
	\label{eq:d1d2apsiestimate}
	\end{align}
	where $[\psi]^2(x_1^0,x_2^0)$ is regarded as a function of $x_1^0,x_2^0$ to which the operators in front of it are applied.
\end{Lemma}

\begin{proof}
	We start with \eqref{eq:apsiestimate}. Recalling \eqref{eq:defa}, the expression $A\psi$ contains terms such as $D_1 D_2 (K \psi)$ and $D_i(K\psi)$, $i=1,2$. Recalling also the definition of $\mathcal{D}_k$ (Eq.\ \eqref{eq:defdk}), we have:
\begin{equation}
	D_1 D_2 (K\psi) = \sum_{k=0}^3 (\bm{\nabla}_{3-k}K)(\mathcal{D}_k \psi)
\end{equation}
with
\begin{equation}
\bm{\nabla}_k := \left\{\begin{array}{cl} 1, & k=0\\ i\slashed{\partial}_1, & k=1 \\ i \slashed{\partial}_2, & k=2 \\ -\slashed{\partial}_1\slashed{\partial}_2, & k=3. \end{array}\right.
\end{equation}
Hence, noting \eqref{eq:normk}:
\begin{equation}
	|D_1D_2 \psi| \leq \| K \| \sum_{k=0}^3 |\mathcal{D}_k \psi|.
\end{equation}
Similarly, we find:
\begin{equation}
	D_i (K\psi) \leq \| K\| \sum_{k=0}^3 |\mathcal{D}_k \psi|,~~i=1,2.
\end{equation}
Considering the definition of $A_j^{(k)}(m),$ $j=1,2$, $k=1,2,3,4$ 
it follows that
\begin{align}\nonumber
  |A\psi| ~\leq ~\|K\| \sum_{k=0}^3   \prod_{j=1,2} \big[ &A_j(m_j)^{(1)} + A_j^{(2)}(m_j) + A_j^{(3)}(m_j)\\
  & + A_j^{(4)}(m_j)\big]  |\mathcal{D}_k \psi|.
\end{align}
In slight abuse of notation, we here use the same symbols for the 
operators $A_j^{(k)}(m)$ acting on functions with and without spin 
components.

The idea now is to make use of lemma 
\ref{thm:estimatetensoroperators}. In order to be able to apply the 
lemma, we first note that by Young's inequality for 
$a_1,...,a_N \in \R$, we have 
$\left(\sum_{i=1}^N a_i\right)^2 \leq N \sum_{i=1}^N a_i^2$ and thus:
\begin{equation}
	|A\psi (x_1,x_2)|^2 ~\leq~ 64\, \|K\|^2 \sum_{i,j=1}^4 \sum_{k=0}^3 \big| A_1^{(i)}(m_1) A_2^{(j)}(m_2) \, |\mathcal{D}_k \psi|\big|^2.
\end{equation}
Integrating over this expression and using lemma 
\ref{thm:estimatetensoroperators}, we obtain:
\begin{align}\nonumber
    \| (A \psi)(x_1^0,\cdot,x_2^0,\cdot)\|^2_{L^2} ~\leq ~64 \, &\|K\|^2\sum_{i,j=1}^4 \sum_{k=0}^3 \mathcal{A}_1^{(i)}(m_1) \mathcal{A}_2^{(j)}(m_2) \,\\
    &\times \| (\mathcal{D}_k \psi)(x_1^0,\cdot,x_2^0,\cdot) \|^2_{L^2}.
\end{align}
Recalling the definition of $[\psi]^2(x_1^0,x_2^0)$, Eq.\ 
\eqref{eq:spatialnorm} yields \eqref{eq:apsiestimate}.

Next, we turn to \eqref{eq:d1apsiestimate}. We start from the initial 
form of the integral equation \eqref{eq:twopartintgeneral} and use that as a 
distributional identity on test functions $\psi \in \mathscr{D}$, 
we have $D_1 \mathscr{S}^{\ret}(x_1-x_1') = \delta^{(4)}(x_1-x_1')$. Thus, we 
obtain:
\begin{equation}
	(D_1 A \psi)(x_1,x_2) = \int_{\tfrac{1}{2} \M} d^4 x_2' ~\mathscr{S}_2^{\ret}(x_2-x_2') (K \psi)(x_1,x_2').
\end{equation}
Proceeding similarly as for \eqref{eq:defa} we rewrite this as:
\begin{equation}
	D_1 (A \psi)\! =\! \left( A_2^{(1)}(m_2)\, D_2\! +\! A_2^{(2)}(m_2) D_2 \!+\! A_2^{(3)}(m_2) \!+\! A_2^{(4)}(m_2)\right)\! (K\psi).
\end{equation}
Considering the form of $A_j^{(k)}(m_j)$ this implies:
\begin{equation}
	|D_1 (A \psi)| ~\leq~  \| K \| \sum_{i=1}^4 \sum_{k\in \{ 0,2\}} A_2^{(i)}(m_2)\, |\mathcal{D}_k \psi|.
\end{equation}
We now square and use Young's inequality, finding:
\begin{equation}
	|D_1 (A \psi)|^2 ~\leq~  8 \, \| K \|^2 \sum_{i=1}^4 \sum_{k\in \{ 0,2\}} A_2^{(i)}(m_2) \, | \mathcal{D}_k \psi|^2.
\end{equation}
Integrating and using lemma \ref{thm:estimatetensoroperators} yields:
\begin{align}\nonumber
  \| D_1 (A \psi)(x_1^0,\cdot,x_2^0,\cdot)\|^2_{L^2} ~\leq~ 8 \, &\| K \|^2 \sum_{i=1}^4 \sum_{k\in \{ 0,2\}} \mathcal{A}_2^{(i)}(m_2)\,\\
  & \| (\mathcal{D}_k \psi)(x_1^0,\cdot,x_2^0,\cdot) \|^2_{L^2}.
\end{align}
Adding the terms with $k=1,3$ and using the definition of 
$[\psi]^2(x_1^0,x_2^0)$ gives us \eqref{eq:d1apsiestimate}.

The estimate \eqref{eq:d2apsiestimate} follows in an analogous way.

Finally, for \eqref{eq:d1d2apsiestimate} we also start from the 
initial integral equation \eqref{eq:twopartintgeneral} and use 
$D_i \mathscr{S}_i^{\ret}(x_i-x_i') = \delta^{(4)}(x_i-x_i')$. This results in:
\begin{equation}
	D_1 D_2 (A \psi) = K \psi.
\end{equation}
Squaring and integrating gives us:
\begin{align}\nonumber
  \| D_1 D_2 (A \psi)(x_1^0,\cdot,x_2^0,\cdot) \|^2 ~ &\leq ~\| K \|^2 \, \| \psi(x_1^0,\cdot,x_2^0,\cdot) \|^2_{L^2} \\
  \leq~ \| K \|^2 \, [\psi]^2(x_1^0,x_2^0),
\end{align}
which yields \eqref{eq:d1d2apsiestimate}. 
\end{proof}

These estimates are the core of:

%%%
\begin{proof}[Proof of Lemma\ \ref{thm:boundsa}:]
	
	We use lemma \ref{thm:spatialnormestimates} together with the definition of $[\psi]^2(x_1^0,x_2^0)$ to obtain:
  \begin{equation}
		[A \psi]^2(x_1^0,x_2^0) ~\leq~ \eqref{eq:apsiestimate} + \eqref{eq:d1apsiestimate}+ \eqref{eq:d2apsiestimate}+ \eqref{eq:d1d2apsiestimate}.
  \end{equation}
	Summarizing the operators into a product yields \eqref{eq:spatialnormapsi}.

\end{proof}

%%%%%%%
\subsubsection{Proof of Theorem \ref{thm:minkhalfspace}} \label{sec:proofminkhalfspace}

In order to prove Thm. \ref{thm:minkhalfspace}, we combine the 
previous estimates to show that \(\|A\|<1\), first on test 
functions $\psi \in \mathscr{D}$ and by linear extension also on the 
whole of $\Banach_{\weightf}$ . We start with Eq. \eqref{eq:spatialnormapsi} 
of lemma \ref{thm:boundsa} using the definition of 
\(\mathcal{A}_j\) for \(j=1,2\), as well as the following 
estimate, valid for all \(\psi \in \mathscr{D}, t_1,t_2>0\):
\begin{equation}
	[\psi](t_1,t_2) ~=~ [\psi](t_1,t_2) \, \frac{\weightf(t_1)\weightf(t_2)}{\weightf(t_1)\weightf(t_2)} ~\le~ \|\psi\|_{\weightf}\, \weightf(t_1)\weightf(t_2).
\end{equation}
Using this in \eqref{eq:spatialnormapsi} yields:
\begin{align}
\|A\psi\|^2_{\weightf} \!&\le\! \sup_{x_1^0,x_2^0>0}\frac{1}{(\weightf(x_1^0)\weightf(x_2^0))^2} \,  \|K\|^2 \prod_{j=1,2} \left( \id + 8\mathcal{A}_j(m_j) \right) [\psi]^2(x_1^0,x_2^0),\\\nonumber
&\le\! \sup_{x_1^0,x_2^0>0} \frac{\|\psi\|^2}{(\weightf(x_1^0)\weightf(x_2^0))^2} \,  \|K\|^2\\
& \hspace{2cm}\times\prod_{j=1,2} \left( \id + 8\mathcal{A}_j(m_j) \right) \, (g^2\otimes g^2)(x_1^0,x_2^0),\\
&\le~ \|K\|^2\, \|\psi\|^2_{\weightf} \left( \sup_{t>0}\frac{1}{\weightf(t)^2} \left( \id + 8\mathcal{A}(\mu) \right)g^2 (t) \right)^2,
\label{est:NormA1}
\end{align}
where $\mu = \max \{ m_1,m_2\}$ and 
$\mathcal{A}(\mu) = \sum_{k=1}^4 \mathcal{A}^{(k)}(\mu)$ with 
$ \mathcal{A}^{(k)}(\mu)$ as in \eqref{eq:defcurlyoperators}.

Next, we shall estimate the term in the big round bracket. To this 
end, we first note some special properties of \(g^2\), which 
motivated choosing $g$ as in \eqref{eq:defg}.
%%%
\begin{Lemma}\label{lem:int}
 For all \(t>0\), we have
\begin{equation}
	\int_0^t d\tau \, g^2(\tau) = \frac{t}{1+b t^8} \, g^2(t).
\end{equation}
\end{Lemma}
\begin{proof}[Proof:] Differentiating the right side of the equation 
  and using the concrete function \(g^2\) as in \eqref{eq:defg} shows 
  that it is, indeed, the anti-derivative of \(g^2\). Since this 
  function vanishes at \(t=0\), the claim follows. 
\end{proof}

%%%
\begin{Lemma}\label{lem:someidentities}
For $c<8$ we have
\begin{equation}
	\sup_{t>0} \frac{t^c}{1+b t^8}  ~=~\frac{c}{8}\,  b^{-c/8} \left( \frac{8}{c}-1\right)^{1-c/8},
	\label{eq:firstequality}
\end{equation}
and furthermore for $c=8$:
\begin{equation}
	\sup_{t>0} \frac{t^8}{1+b t^8} ~=~\frac{1}{b}.
	\label{eq:secondequality}
\end{equation}
\end{Lemma}

\begin{proof}
To prove \eqref{eq:firstequality}, considering the shape of the 
function $h(t)= t^c/(1+b t^8)$ we find that the supremum is in 
fact a maximum which is located at 
\(t = b^{-1/8} \left(8/c-1\right)^{-1/8}\). Inserting this back into 
the function $h(t)$ yields \eqref{eq:firstequality}.  
Equation \eqref{eq:secondequality} follows from 
$\frac{t^8}{1+b t^8} = \frac{1}{b} \frac{1}{1/(b t^8) +1} \leq 
\frac{1}{b}$. 
\end{proof}

\begin{proof}[Proof of Thm. \ref{thm:minkhalfspace}:] Applying 
Lemma \ref{lem:int} to \(\mathcal{A}(\mu) \,g^2\) yields:

\begin{align}
    \big(\mathcal{A}^{(1)}(\mu) \, g^2\big)(t)&~=~ t \int_0^t d\rho \, (t-\rho)^2\, g^2(\rho)~\le~ t^3 \int_0^t d\rho \,g^2(\rho)\nonumber\\
    &\hspace{2cm} = \frac{t^4}{1+b t^8} \,g^2(t),\nonumber\\
     \big(\mathcal{A}^{(2)}(\mu) \, g^2\big)(t)&~=~ \frac{\mu^4\, t^4}{2^4\, 3^2} \int_0^t d\rho\, (t-\rho)^3\, g^2(\rho)~\le~ \frac{\mu^4\, t^8}{2^4 \,3^2} \frac{g^2(t)}{1+b t^8},\nonumber\\
    \big( \mathcal{A}^{(3)}(\mu) \, g^2\big) (t) &~=~ t^2,\nonumber\\
    \big( \mathcal{A}^{(4)}(\mu) \, g^2 \big)(t) &~=~ \frac{\mu^4\, t^6}{2^2\, 3^2}.
\end{align}
Multiplying with \(1/g^2(t)\) and using Lemma 
\ref{lem:someidentities} as well as $1/\weightf(t)^2 \le (1+b t^8)^{-1}$, 
we find:
\begin{align}
    g^{-2}(t)\, \big(\mathcal{A}^{(1)}(\mu) \,g^2\big)(t) & ~\le~ \sqrt{2} b^{-\frac{1}{2}},\nonumber\\
    g^{-2}(t)\, \big(\mathcal{A}^{(2)}(\mu) \,g^2\big)(t) & ~\le~ \frac{\mu^4}{2^4 \,3^2 \,b},\nonumber\\
    g^{-2}(t)\, \big( \mathcal{A}^{(3)}(\mu) \, g^2\big)(t) & ~\le~ \frac{3^{3/4}}{2^2\, b^{1/4}},\nonumber\\
   g^{-2}(t)\, \big( \mathcal{A}^{(4)}(\mu) \, g^2\big) (t) & ~\le~ \frac{\mu^4}{2^4 \, 3^{5/4}} \, b^{-3/4}.
\label{eq:gtotheminus2estimates}
\end{align}
Using \eqref{est:NormA1}, we can employ these inequalities (whose 
right hand sides are inversely proportional to powers of $b$) to 
estimate the norm of $A$. According to \eqref{est:NormA1}, we have, 
first on $\mathscr{D}$ and by linear extension also on the whole of 
$\Banach_{\weightf}$: 
\begin{equation}
	\|A\| ~\leq~ \|K\| \, \sup_{t>0}\, g^{-2}(t) \big((\id + 8\mathcal{A}(\mu)) \, g^2 \big)(t) .
\end{equation}
Now we use \eqref{eq:gtotheminus2estimates} for the various 
contributions 
$A^{(k)}(\mu) $ to $\mathcal{A}(\mu) = \sum_{k=1}^4 A^{(k)}(\mu)$, 
finding:
\begin{align}
	\|A\| & ~\le~ \|K\| + \frac{2^{3.5} \|K\|}{b^{1/2}} + \frac{\mu^4 \|K\|}{18 b} + \frac{3^{3/4} 2 \|K\|}{b^{1/4}} + \frac{\mu^4 \|K\|}{2 (3^5 b^3)^{1/4}}\nonumber\\
&\overset{b\ge 1}{\le}~ \|K\| + \frac{\|K\|}{b^{1/4}} \left(2^{3.5}+ \mu^4/18 + 3^{3/4} 2 + \mu^4/(2 \cdot 3^{5/4})\right)\\
&<~ \|K\| + \frac{\|K\|}{b^{1/4}} (16 + \mu^4 ).
\end{align}
Recalling that $b=\frac{\|K\|^4}{(1-\|K\|)^4} (16+\mu^4)^4$ (see 
\eqref{eq:defb}), we finally obtain that:
\begin{equation}
	\|A\| ~<~ \|K\| + \frac{\|K\|}{b^{1/4}} (16 + \mu^4 ) ~= ~ \|K\| + 1-\|K\| =1.
\end{equation}
We have thus shown that $A$ defines (by linear extension) a 
contraction on $\Banach_{\weightf}$. Thus, the Neumann series 
$\psi = \sum_{k=0}^\infty A^k \psi^{\free}$ yields the unique 
(global-in-time) solution of the equation 
\(\psi=\psi^{\free}+A\psi\). 
\end{proof}


\section{Summary and Conclusions}
%%%%%%%%%%%%%%%%
In this chapter we have extended 
the analysis of spin-0 and spin-1/2 delayed-equations.
The resulting degree of understanding is quite different 
in the two cases.

Extending previous work for Klein-Gordon particles 
\cite{mtve,lienertcurved} to the Dirac case, we have established the 
existence of dynamics for a class of integral equations 
\eqref{eq:twopartintgeneral} which express 
direct interactions with time delay at the quantum level. To obtain 
this result, we have used both simplifying assumptions 
\ref{matt simplifying assumption 1} of a cutoff of the spacetime before $t=0$, 
and \ref{matt simplifying assumption 2} of a smoother interaction 
kernel than the choice \eqref{eq:twopartkernel1/2}. 
While we have tried
to justify assumption \ref{matt simplifying assumption 1}  
by considering the equation on the FLRW universe that features a 
big bang, no physical justification has been given for 
assumption \ref{matt simplifying assumption 2}.

In fact, assumption \ref{matt simplifying assumption 2} consists 
of two parts here:

Firstly, we have assumed that $K$ is complex-valued while it could 
be matrix-valued in the most general case. The reason for this 
assumption is that our proof requires the integral operator $A$ to 
be a map from a certain Sobolev space onto itself in which weak 
derivatives with respect to the Dirac operators of the two particles 
can be taken. If $K$ were matrix-valued, it would not commute with 
these Dirac operators in general. Then $A \psi$ would contain new 
types of weak derivatives which cannot be taken in the initial 
Sobolev space. As illustrated in Sec. \ref{sec:choiceofB}, this 
creates a situation where more and more derivatives have to be 
controlled, possibly up to infinite order where the success of an 
iteration scheme seems unlikely. At present, we do not know how to 
deal with this issue. 
Improving on this point, however, defines an important task for 
future research, as e.g. electromagnetic interactions involve 
interaction kernels proportional to $\gamma_1^\mu \gamma_{2\mu}$ 
(see \cite{direct_interaction_quantum}).

Secondly, the physically most 
natural interaction kernel is given by a delta function along the 
light cone, $K(x_1,x_2) \propto \delta((x_1-x_2)_\mu 
(x_1-x_2)^\mu)$. In the Dirac 
case, the distributional derivatives make generalizations of 
results about more singular interaction kernels 
obtained in the KG case such as \cite{mtve,lienertcurved} difficult, 
and we have not attempted it here. 
Another interesting question is whether the smallness condition on 
$K$ can be alleviated such that arbitrarily peaked functions are 
admitted. This could allow taking a limit where $K$ approaches the 
delta function along the light cone.

Improving upon any of these two points would be very desirable.

In the case of scalar particles, we have proved the existence and 
uniqueness of solutions of the fully singular  
scalar integral equation 
\eqref{eq:KGtwopartint} and its $N$-particle generalization 
\eqref{eq:npartint}. Following previous works and the 
Dirac case, we have depended upon assumption 
\ref{matt simplifying assumption 1}, i.e.
a cutoff in time; however, in contrast to 
those cases considering a more regular interaction 
kernel than what is present in \eqref{eq:KGtwopartint}, i.e. 
assumption \ref{matt simplifying assumption 2} was not necessary.
We have given the same justification for 
assumption \ref{matt simplifying assumption 1} as in the Dirac case and 
in \cite{lienertcurved}
by extending the main part of our result to the FLRW spacetime.

We have worked with a 
weighted $L^\infty$ norm both for time and space variables 
in the case of scalar particles, 
while it would be more natural 
to use a weighted $L^\infty L^2$ norm 
instead ($L^\infty$ for the time variables and $L^2$ for the 
space variables). It would then be a challenging task to 
find the right inequalities to obtain similar estimates as we 
did. Moreover, one could also try to prove higher regularity 
not only in the sense of integrability but also 
differentiability. An interesting question, for example, 
is whether one can apply the Klein-Gordon operators 
$(\Box_k + m_k^2)$ to the solutions of \eqref{eq:KGtwopartint} in 
a weak sense. 


This work provides a rigorous proof of the existence of 
interacting relativistic quantum dynamics in 1+3 spacetime 
dimensions; in particular, this model does not suffer from 
ultraviolet divergences which are typically encountered in 
quantum field theoretic models. Of course, the model does not 
describe particle creation and annihilation and is therefore a 
toy model rather than an alternative to QFT. Nevertheless, one 
might find the fact that direct interactions, even singular ones 
along the light cone, can be made mathematically rigorous, 
remarkable. One might wonder whether in the long 
run the mechanism of 
interaction through multi-time integral equations and direct 
interactions could contribute to a rigorous formulation of 
quantum field theory.










\chapter[Quantum Field Theoretic Approach to Interactions][Interaction in QFT]{Quantum Field Theoretic Approach to Interactions} \label{chap:QFT}

\section{Introduction}\label{sec: intro QED}
\subsection{Motivation}\label{sec: mot QED}

In this chapter we will turn our attention to the 
more widely accepted way of 
introducing interaction into relativistic quantum 
mechanics, Quantum Field Theory. For the motivation and 
introduction we closely follow \cite{deckert2016perspective}.
While the rigorous quantum field theoretic formulation of free 
relativistic fermions is textbook material
\cite{derezinski2013mathematics} the introduction of interaction faces 
difficulties. In fact, introducing an external electromagnetic field
acting on the fermions, 
while neglecting all interactions between the 
fermions already is a nontrivial 
matter. The completely satisfactory formulation of such an 
\emph{external field quantum electrodynamics} (QED) is, 
to the best of my 
knowledge, still to be formulated, despite the combined 
effort of such bright 
minds as those of Dirac\cite{dirac1934theorie}, 
 Feynman\cite{feynman1949theory} 
and Schwinger\cite{schwinger1951gauge}. 
In more recent years there have been several independend attempts 
to remedy the remaining difficulties such as the construction 
of the fermionic projector \cite{finster2016fermionic} 
and the construction of the geometric phase \cite{mickelsson2014phase}.
We will seek to extend the construction along the lines of 
\cite{ivp0,ivp1,ivp2}, which will be motivated and summarised
now. 

When Dirac found the equation now bearing his name he 
recognised that the accessible range of kinetic energies 
to the particles described by it is 
\(]-\infty, -m]\cup[m, \infty[\). So he was worried that 
particles coupled to an electromagnetic field might radiate 
and lower their kinetic energy without bound. Since particles 
capable of such behavior would not form stable matter he 
devised a way to introduce a stable ground state into the 
system. Instead of applying the Dirac equation
\begin{equation}\label{dirac free}
  0= (i\slashed{\partial}-m) \psi,
\end{equation}
to a fixed finite number of electrons, he sought to apply 
it's evolution to an antisymmetric product 
\begin{equation}\label{infinite wedge}
  \Omega= \varphi_1\wedge \varphi_2\wedge \dots,
\end{equation}
where \((\varphi_k)_{k\in\mathbb{N}}\) forms an ONB of the negative spectral 
subspace \(\mathcal{H}^-\). Thus making use of 
Pauli's exclusion principle for 
fermions no particle is any longer able to lower it's kinetic 
energy.  This \emph{Dirac sea} \(\Omega\) might be evolved 
by a one-particle evolution \(U:\mathcal{H}\righttoleftarrow\)
according to 
\begin{equation}
  \mathcal{L}_U \Omega= U\varphi_1\wedge U \varphi_2\wedge \dots.
\end{equation}

The vacuum \(\Omega\) does most likely not coincide with the 
ground state of a full theory of QED. As we do not have 
such a theory at hand; 
however, one might hope that due to the homogeneity and isotropy 
of such a ground state the choice \(\Omega\) is close enough as a
first approximation in situations where the external field is large 
and the homogeneity and isotropy of the true state 
effectively cancels the direct 
interactions between the electrons.  Furthermore, 
expectation values with respect to \(\Omega\) are 
used also in the
calculations of QED showing agreement with experiments to a remarkable 
degree giving us all the more reason to use it as a starting point. 

The first step towards a theory including interactions is to allow 
for an external field \(A\) to act upon the particles, changing 
\eqref{dirac free} to

\begin{equation}\label{dirac ext field}
  0= (i\slashed{\partial}-\slashed{A}-m ) \psi,
\end{equation}

where we have set the electric charge of the electron to one.
We might now imagine a field \(A\) that acts only during a 
brief period of time. Such a field could pull a particle 
of the Dirac Sea \(\Omega\), say 
\(\varphi_1\), out of \(\mathcal{H}^-\) and  
onto the surface \(U^A \varphi_1=\xi \in \mathcal{H}^+\).
Such a field might not disturb the other wavefunctions much 
and the Dirac Sea after the action of the field might be 
represented by 

\begin{equation}\label{toy example dirac sea}
  \Psi= \xi\wedge \varphi_2\wedge \varphi_3 \wedge \dots.
\end{equation}

Now, since \(\xi \in \mathcal{H}^+\) the corresponding particle 
behaves qualitatively differently compared to the remaining 
part of the 
Dirac sea which consists of wavefunctions taken from 
\(\mathcal{H}^-\). This particle appears above the Dirac sea
where it leaves behind a hole, the missing wavefunction 
\(\varphi_1\in\mathcal{H}^-\). These holes are also called positrons. 
Whenever the wavefunctions 
at greater depth are left relatively unperturbed by the action 
of the process, according to Dirac, we can switch to a leaner  
description. If \(\Omega\) remains completely unchanged below a 
certain level, such as in our example,  it
suffices to follow the generated particles  
e.g. \(\xi\) and the created holes e.g. \(\varphi_1\). If on the 
other hand all wavefunctions are affected one has to keep track
of a net evolution of \(\Omega\) as well. As in this description
the particle number is not a constant, creation operators 
are introduced. These act as 
\begin{equation}
a^*(\xi)\varphi_2\wedge \varphi_3\wedge\dots = \xi\wedge \varphi_2\wedge \varphi_3\wedge\dots.
\end{equation}
The adjoint of the creation operator, called 
annihilation operator, is of equal importance.  
Using these equation \eqref{toy example dirac sea}
can be condensed to 
\begin{equation}
\Psi= a^*(\xi)a(\varphi_1)\Omega.
\end{equation}
Given a one-particle time evolution operator \(U^A\), its 
\emph{lift} \(\tilde{U}^A\) acting on objects like the 
wedge product \eqref{infinite wedge}
needs to fulfil
\begin{equation}\label{intro lift condition}
\tilde{U}^A a^*(\psi)=a^*(U^A\psi )\tilde{U}^A.
\end{equation}
Requirement \eqref{intro lift condition} is enough to fix 
\(\tilde{U}^A\) up to a phase. Now, still \(a^*(\chi)\Omega\)
behaves differently for \(\chi\in\mathcal{H}^+\) compared to 
\(\chi\in\mathcal{H}^-\), so in order to completely forget 
about the Dirac sea in the notation one performs the splitting 
\begin{equation}
a^*(f)= b^*(f)+ c^*(f) \quad, b^*(f)=a^*(P^+f),\quad c^*(f)=a^*(P^-f),
\end{equation}
exploiting linearity of \(a^*\).  Now the space generated by 
elements of the form \(b^*(f_1)b^*(f_2)\dots b^*(f_n)\Omega\)
is called electron Fock space while the space generated by
\(c(f_1)c(f_2)\dots c(f_n)\Omega\) is called hole 
Fock space,
\begin{equation}
  \mathcal{F}_e= \bigoplus_{k\in\mathbb{N}_0} (\mathcal{H}^+)^{\wedge k},\quad 
  \mathcal{F}_h= \bigoplus_{k\in\mathbb{N}_0} (\mathcal{H}^-)^{\wedge k}.
\end{equation}
Here, the hole Fock space is generated by the annihilation 
operators of negative energy acting on the vacuum, which is 
another remnant of 
the fact that \(\Omega\) is not a state devoid of particles.
This can be hidden by one more change in notation
\begin{equation}
d^*(f)= c(f),
\end{equation}
Since \(c\) is antilinear, but \(d^*\) is supposed to be linear, one 
replaces \(\mathcal{H}^-\) by \(\overline{\mathcal{H}^-}\) as the domain of definition of \(d^*\).
By \(\overline{\mathcal{H}^-}\) we denote the space that is identical to 
\(\mathcal{H}^-\) as a set, but differs in its definition of multiplication:

\begin{equation}
\mathbb{C}\times \overline{\mathcal{H}^-} \ni (\lambda, f)\mapsto \lambda^* f.
\end{equation}

Resulting in a replacement of \(\mathcal{F}_h\) by 

\begin{equation}
\overline{\mathcal{F}}_h=\bigoplus_{k\in\mathbb{N}_0} \overline{\mathcal{H}^-}^{\wedge k},
\end{equation}
this results for the full space in 

\begin{equation}
\mathcal{F}= \mathcal{F}_e \otimes \overline{\mathcal{F}}_h.
\end{equation}

Using this we can represent \(\Omega\) by \(|0\rangle = 1\otimes 1\)
and \(\Psi\) by \(b^*(\xi)d^*(\varphi_1)|0\rangle \). 

Forgetting about the structure of \(\Omega\) leads to problems, 
as we will see now. Picking an ONB \((\varphi_{n})_{n\in\mathbb{N}}\)
of \(\mathcal{H}^+\) and \((\varphi_{-n})_{n\in\mathbb{N}}\)
of \(\mathcal{H}^-\) we might express the probability of 
creation of at least one pair due to time evolution from \(t_0\)
to \(t_1\)  
subject to an external 
potential \(A\) to first order in the expansion of 
the scalar product by 
\begin{equation}\label{pair creation prob}
\sum_{k,n\in\mathbb{N}}|\langle \varphi_k,U^A(t_1,t_0) \varphi_{-n}\rangle|^2
=\|U^A_{+-}\|^2_{I_2},
\end{equation}

where \(U_{\pm \mp}:= P^\pm U P^\mp\) for any operator \(U\)
and \(\|\cdot\|_{I_2}\) is the Hilbert-Schmidt norm. The space of 
operators of type \(\mathcal{H}\righttoleftarrow\) induced by this norm 
is denoted by \(I_2(\mathcal{H})\).
Furthermore the orthogonal projectors onto the negative and
positive energy
subspaces of \(\mathcal{H}\) will be denoted by 
\begin{align}\label{def: Ppm}
P^-:\mathcal{H}\rightarrow \mathcal{H}^-\\
P^+:=1-P^-,
\end{align}
respectively.
As a probability the expression \eqref{pair creation prob} needs to 
be bounded by one; however,this is not always the case.

\begin{Thm}[Ruijsenaars \cite{ruijsenaars1977charged}]\label{thm ruisnaar}
The right hand side of \(\eqref{pair creation prob}<\infty\)
for all times \(t_0,t_1\in\mathbb{R}\)
if and only if \(\vec{A}=0\).
\end{Thm}

There is one more classical theorem to take note of in this context.

\begin{Thm}[Shale-Stinespring \cite{shale1965spinor}]\label{thm shale stinepsirng}
The one-particle operator \(U\) has a lift 
\(\tilde{U}:\mathcal{F}\righttoleftarrow\) satisfying 
\eqref{intro lift condition} if and only if 
\(U_{\pm}, U_{\mp}\in I_2(\mathcal{H})\). 
\end{Thm}

Combined these theorems imply that unless the in the light of  
Lorentz and gauge invariance
highly artificial condition \(\vec{A}=0\) is 
fulfilled there is no representation of the time evolution 
operator subject to the field \(A\) into Fock space. 

Stated in this way the last statement might nudge one
into concluding that the Fock space representation 
is a dead end. In fact, the situation is more subtle. 
To get a heuristic idea, recall that positive and negative 
energy states differ in the direction of their spinors. 
Meaning that multiplying a negative energy  with state
e.g. \(\gamma\) matrices will in general result in 
a mixture of positive and negative energy states. 
Incidentally, this is exactly what happens in the Hamiltonian 
\begin{equation}
H^A=\gamma^0(-i\vec{\gamma}\cdot \grad +m) + A_0 -\gamma^0\vec{\gamma}\cdot\vec{A}.
\end{equation}
Since there are infinitely many particles in the wedge 
product of \(\Omega\) and there is no mechanism of suppression 
for states of large momentum, the sum in 
\eqref{pair creation prob} does not converge for \(\vec{A}\neq 0\).
However, as it turns out
there is a \(\tilde{U}^A(t_1,t_0):\mathcal{F}\righttoleftarrow\)
whenever \(\vec{A}(t_1)=0=\vec{A}(t_0)\). This implies 
that once the vector parts \(\vec{A}\) vanishes, only 
finitely many pairs remain, justifying the term ``virtual pairs''
for the infinity of pairs that appear and vanish together with 
\(\vec{A}\).


As we can read off of our construction of Fock space, this space 
consists of infinite wedge products that are sufficiently close 
to the initial state \(\Omega\). We just found out that, 
this space is not large enough to contain the state also at 
later times when the external field is nonzero, but that does 
not mean that we cannot find a mapping from the initial state 
to the later ones. It would be enough to adapt the choice of 
space at later times to the external field present at that time. 
These spaces will in general not give a physically meaningful 
distinction between electrons and parts of the Dirac sea. 
Such a distinction may have to wait 
for a full interacting theory of QED, where it may be given 
in terms of ground states or states homogeneous and isotropic 
enough such that excitations above it behave effectively free. 
However, such a distinction is not necessary to answer 
physical questions such as which currents are 
induced by strong external fields or how Maxwell's 
equations are modified by those currents.  

In the last decade progress has been made to construct 
the evolution operator of external 
field QED mapping states of one Fock space to another and 
to identify the remaining freedom of picking Fock spaces 
at each hypersurface or point in time. The results generalise 
theorems \ref{thm ruisnaar} and \ref{thm shale stinepsirng}
in a way that exposes the gauge and relativistic invariance 
inherent to the problem, which is not apparent 
in the original versions. In order to state those theorems 
we need some mathematical notation which we introduce first.


\subsection{Overview of Previous Results}\label{sec: qft intro}

This section will first introduce some notation of 
\cite{ivp0,ivp1,ivp2,deckert2016perspective} in order to 
state the results of \cite{ivp2} and prepare for the sections 
to come. While doing so we will closely follow 
\cite{deckert2016perspective}.
Throughout the whole chapter the class of four potentials we 
are
interested in is 
\begin{equation}
  \mathcal{V}:= C_c^\infty(\mathbb{R}^4,\mathbb{R}^4).
\end{equation}
All of the results could be extended with a reasonable 
amount of additional work to slightly more general 
four-potentials, but not to physically realistic ones such as 
the Coulomb potential.  

Any notion of time evolution in a relativistic setting needs to 
generalise the notion of simultaneity. For this reason we 
introduce Cauchy surfaces.


\begin{Def}[Cauchy surface, def 2.1 of \cite{deckert2016perspective}]
  A Cauchy surface \(\Sigma\subset \mathbb{R}^4\) is a smooth, 
  3-dimensional submanifold of \(\mathbb{R}^4\) that fulfills
  the following three conditions:
  \begin{enumerate}[label=\alph*)]
  \item Every inextensible, two-sided, time- or light-like, continuous path in \(\mathbb{R}^4\) intersects \(\Sigma\) in a unique point.
  \item For every \(x\in\Sigma\), the tangential space \(T_x\Sigma\) is space-like.
  \item The tangential spaces to \(\Sigma\) are bounded away from light-like directions in the following sense: The only light-like accumulation point of 
  \(\bigcup_{x\in \Sigma} T_x \Sigma\) is zero.
  \end{enumerate}
\end{Def}

\begin{Def}[\(\mathcal{H}_\Sigma\), def 2.2 of \cite{deckert2016perspective}]
For every Cauchy surface \(\Sigma\) there is a parametrisation
\begin{equation}
\Sigma= \{ \pi_\Sigma(\vec{x}):=(t_\Sigma(\vec{x}),\vec{x})\mid \vec{x}\in\mathbb{R}^3\},
\end{equation}
with a smooth function 
\(t_\Sigma: \mathbb{R}^3\rightarrow \mathbb{R}\). 
Agreeing with standard notation, 
\(d^4x=dx^0dx^1dx^2dx^3\) denotes the standard volume form over 
\(\mathbb{R}^4\),
where the product of forms is 
the wedge product. By \(d^3x\) we denote 
the form \(d^3x=dx^1dx^2dx^3\) both on \(\mathbb{R}^4\) and 
on \(\mathbb{R}^3\). When contracting a form 
\(\omega\) with a vector \(v\) we 
will be denoting this by \(i_v(\omega)\). 
We will keep writing \(i_v(\omega)\) 
also for the spinor matrix valued 
vector \(\gamma= (\gamma^0,\gamma^1,\gamma^2,\gamma^3)
=\gamma^\mu e_\mu\):

\begin{equation}
i_\gamma(d^4x)=\gamma^\mu i_{e_\mu}(d^4x).
\end{equation}

For any \(x\in \Sigma\) restricting the 
3-form \(i_\gamma(d^4x)\) to the tangent space 
\(T_x\Sigma\) results in 
\begin{equation}
i_\gamma(d^4x)=\slashed{n}(x)i_n(d^4x)
= \left(\gamma^0-\sum_{\mu=1}^3 \gamma^\mu 
\frac{\partial t_\Sigma (\vec{x})}{\partial x^\mu}\right) d^3x
%=:\Gamma(\vec{x})d^3x.
\end{equation}
Being able to write a Poincaré covariant measure on Cauchy sufaces we 
may introduce the scalar product 
\begin{equation}
  \phi,\psi \mapsto \int_{\Sigma} \overline{\phi}(x) i_{\gamma}(d^4\gamma) \psi(x)
  =:\langle \phi,\psi\rangle
\end{equation}
and \(\overline{\phi}=\phi^\dagger\gamma^0\).
with respect to this salar product we define 
\(\mathcal{H}_{\Sigma}=L^2(\Sigma, \mathbb{C}^4)\).
\end{Def}

As is well known(e.g. \cite{bar2007wave,ivp1}) the Dirac equation coupled to an external 
potential, equation \eqref{dirac ext field}, has a 
one-particle evolution operator for each pair of Cauchy surfaces \(\Sigma, \Sigma'\)
\begin{equation}
U_{\Sigma',\Sigma}:\mathcal{H}_\Sigma \rightarrow \mathcal{H}_{\Sigma'},
\end{equation}

Using this covariant replacement of the standard Hilbert-space we 
repeat the Fock space construction of section \ref{sec: mot QED} 
in a slightly more general fashion.

\begin{Def}[Fock space of generalised polarisation, def 2.4 of \cite{deckert2016perspective}]
  Let \(\text{Pol} (\mathcal{H}_\Sigma)\) denote the set of all 
  closed, linear subspaces \(V\subset \mathcal{H}\)
  such that both \(V\) and \(V^\perp\) are infinite dimensional. 
  Any \(V\in \text{Pol}(\mathcal{H}_\Sigma)\) is called 
  \emph{polarisation} of \(\mathcal{H}_\Sigma\). For 
  \(V\in \text{Pol}(\mathcal{H}_\Sigma)\), let 
  \(P_\Sigma^V:\mathcal{H}_{\Sigma}\rightarrow V\) 
  denote the orthogonal projection of \(\mathcal{H}_\Sigma\) onto 
  \(V\).
  The Fock space corresponding to \(V\) on the Cauchy surface 
  \(\Sigma\) is defined to be
  \begin{equation}
  \mathcal{F}(V,\mathcal{H}_\Sigma) := \bigoplus_{c\in\mathbb{Z}} \mathcal{F}_c (V,\mathcal{H}_\Sigma), \quad 
  \mathcal{F}_c(V,\mathcal{H}_\Sigma):= \bigoplus_{\overset{n,m\in\mathbb{N}_0}{c=m-n}}(V^\perp)^{\wedge n} \otimes \overline{V}^{\wedge m},
  \end{equation}
  
  where \(\bigoplus\) is the Hilbert space direct sum, \(\wedge\) 
  the antisymmetric tensor product of Hilbert spaces and 
  \(\overline{V}\) is the conjugate complex vector space of 
  \(V\), introduced in section \ref{sec: mot QED}.
\end{Def}

Pick Cauchy surfaces \(\Sigma, \Sigma'\) and polarisations 
\(V\in \text{Pol}(\mathcal{H}_\Sigma) \),
\(V'\in \text{Pol}(\mathcal{H}_{\Sigma'}) \)
then we can 
give the analogue of the lift condition  
\eqref{intro lift condition} in 
this setting: for all \(\psi \in \mathcal{H}_{\Sigma}\)

\begin{equation}\label{lift condition}
  \tilde{U}^A_{V',\Sigma'; V,\Sigma} a_\Sigma^*(\psi)
  =a^*_{\Sigma'}(U^A_{\Sigma',\Sigma}\psi )\tilde{U}^A_{V',\Sigma';V,\Sigma},\tag{lift condition}
\end{equation}
holds, where \(a^*_{\Sigma'}\) and \(a^*_{\Sigma}\) are the 
creation operator associated to 
\(\mathcal{F}(V,\mathcal{H}_{\Sigma})\) and 
\(\mathcal{F}(V',\mathcal{H}_{\Sigma'})\) respectively. 

The rephrasing of theorem \ref{thm shale stinepsirng} 
adapted to the more general notation we have developed now is
\begin{Thm}[\cite{ivp2}, also Cor 2.5 of \cite{deckert2016perspective})]
Let \(\Sigma, \Sigma'\) be Cauchy surfaces, 
\(V\in \text{Pol}(\mathcal{H}_\Sigma)\), and 
\(V'\in \text{Pol}(\mathcal{H}_{\Sigma'})\) be polarisations. 
Then the following two statements are equivalent:
\begin{enumerate}[label=\alph*)]
\item There is a unitary operator 
\(\tilde{U}^A_{V',\Sigma';V, \Sigma}:
\mathcal{F}(V,\Sigma)\rightarrow \mathcal{F}(V',\Sigma')\)
that satisfies the \eqref{lift condition}
\item The operators 
\(P^{{V'}\perp}_{\Sigma'}U^A_{\Sigma'.\Sigma}P^{{V}}_{\Sigma}\) and
\(P^{{V'}}_{\Sigma'}U^A_{\Sigma'.\Sigma}P^{{V}^\perp}_{\Sigma}\) are 
Hilbert-Schmidt operators.
\end{enumerate}
\end{Thm}

So the question given an initial state in an initial Fock space 
\(\mathcal{F}(V,\Sigma)\),
which Fock space we may pick at a final Cauchy surface \(\Sigma'\)
such that there is a lift fulfilling the \eqref{lift condition}
now becomes a question of polarisations. We know a priori 
that \(U^A_{\Sigma',\Sigma}\) has a lift from 
\(\mathcal{F}(V,\Sigma)\) to 
\(\mathcal{F}(U^A_{\Sigma',\Sigma}V,\Sigma')\). Furthermore, we have a 
distinguished polarisation for very early times, namely the negative 
energy states with respect to the free Hamiltonian. Thus, we may 
characterize all relevant polarisation classes into the following
equivalence classes 

\begin{Def}[polarisation classes, def 2.6 of \cite{deckert2016perspective}]\label{def pol class}
For a Cauchy surface \(\Sigma\) and a potential \(A\in\mathcal{V}\) 
we define 
\begin{equation}
C_{\Sigma}(A):=\big\{W\in\text{Pol}(\mathcal{H}_\Sigma)\mid 
W \approx U^A_{\Sigma,\Sigma_{\mathrm{in}}}\mathcal{H}^-_{\Sigma_{\mathrm{in}}}\big\},
\end{equation}
where \(\Sigma_{\mathrm{in}}\) is a Cauchy surface earlier than \(\supp A\),
\(\mathcal{H}^-_{\Sigma_{\text{in}}}\) is the subspace spanned by the wavefunctions 
in the negative spectrum of the free Dirac Hamiltonian. Furthermore, for 
\(V,V'\in\text{Pol}(\mathcal{H}_{\Sigma})\) we may write \(V\approx V'\)
whenever \(P^V_{\Sigma}-P^{V'}_{\Sigma}\) is a Hilbert-Schmidt operator. 
\end{Def}

Using this we immediately find 
\begin{Corollary}[polarisation classes and lifts, cor 2.7 of \cite{deckert2016perspective}]\label{cor: pol class lift}
Let \(\Sigma, \Sigma'\) be Cauchy surfaces and 
\(V\in C_\Sigma(A), V'\in \text{Pol}(\mathcal{H}_{\Sigma'})\) be 
polarisations. Then there is a unitary operator 
\(\tilde{U}^A_{V',\Sigma'; V,\Sigma}:\mathcal{F}(V,\Sigma)
\rightarrow \mathcal{F}(V',\Sigma')\) satisfying the
\eqref{lift condition} if and only if 
\(V'\in C_{\Sigma'}(A)\).
\end{Corollary}

The definition \ref{def pol class} suggests a dependence of 
\(C_{\Sigma}(A)\) on all of \(A\) as a function of time. 
As indicated in the last section,
this is not the case.

\begin{Thm}[\(C_{\Sigma}(A)\) depends on \(A|_{T\Sigma}\), thm. 1.5 of \cite{ivp2}]\label{thm: pol class history}
Pick a Cauchy surface \(\Sigma\) and \(A,A'\in \mathcal{V}\). 
Then we have 
\begin{equation}
  C_{\Sigma}(A)=C_{\Sigma}(A') \iff A|_{T\Sigma}=A'|_{T\Sigma},
\end{equation}
where \(A|_{T\Sigma}=A'|_{T\Sigma}\) means that for all \(x\in \Sigma\)
and \(y\in T_x\Sigma\) the relation 
\(A_\mu(x) y^\mu=A_\mu'(x) y^\mu\) holds. 
\end{Thm}

This is a version of theorem \ref{thm ruisnaar} for general 
Cauchy surfaces.
The next theorem shows how the polarisation classes change 
with the gauge and Lorentz transforms.

\begin{Thm}[transformation of polarisation classes, thm. 1.6 of \cite{ivp2}]\label{thm: pol class transform}
Let \(A\in\mathcal{V}\) be a four-potential and \(\Sigma\) 
a Cauchy surface.

\begin{enumerate}[label=\alph*)]
\item Let \((\mathfrak{s},\Lambda)\in \mathbb{C}^{4\times 4}\times \mathrm{SO}^{\uparrow}(1,3)\)
be an orthochronous Lorentz transform, i.e. the tuple fulfills
\(\Lambda^{\mu}_{\, \sigma}g_{\mu \nu}\Lambda^\nu_{\, \tau}=g_{\sigma, \tau}\) 
and \(\quad \Lambda^\mu_{\, \nu}\gamma^\nu = \mathfrak{s}^{-1} \gamma^\mu \mathfrak{s}\) 
and acts on wavefunctions as \(\psi\mapsto \mathfrak{s}\psi(\Lambda^{-1}\cdot)\) (see sec. 2.3 of \cite{ivp1}). 
Then we have
\begin{equation}
V\in C_{\Sigma}(A) \iff (\mathfrak{s},\Lambda)V \in C_{\Lambda \Sigma}(\Lambda A (\Lambda^{-1}\cdot)).
\end{equation}
\item Let \(A'=A+d\zeta\) be the gauge transformed potential, 
for some \(\zeta \in C_c^\infty(\mathbb{R}^4,\mathbb{R})\). Then
the gauge transformation acts on wavefunctions as 
\(e^{-i\zeta}:\mathcal{H}_{\Sigma}\righttoleftarrow,\psi\mapsto e^{-i\zeta}\psi\)
and one obtains 
\begin{equation}
V\in C_{\Sigma}(A) \iff e^{-i\zeta}V \in C_{\Sigma}(A+d\zeta).
\end{equation}
\end{enumerate}
\end{Thm}

Theorems \ref{thm: pol class transform}, \ref{thm: pol class history}
and corollary \ref{cor: pol class lift} make clear in which way
the original plan to work in a single Fock space was misguided and 
how it may be adapted to make it work.

When trying to construct an evolution operator from a Cauchy surface \(\Sigma\)
to a second one \(\Sigma'\) subject to an external field \(A\),
one has to choose an initial polarisation \(V\in C_{\Sigma}(A)\)
and a final polarisation \(V'\in C_{\Sigma'}(A)\). 
Then there is an evolution operator 
\(\tilde{U}^A_{V',\Sigma';V,\Sigma}\), unique up to a phase. 
Picking polarisations is akin to picking a patch 
of coordinates on a 
nontrivial manifold, in the sense that there may not be a 
canonical choice and the choice is going to influence the 
representation of all the relevant objects. Nevertheless,
one can obtain valuable information from calculations done 
with respect to one such choice and always transform the 
results to the representation induced by any other choice. 
Carrying out such a procedure will  for every 
\(\Phi\in \mathcal{F}(V,\Sigma)\) and 
\(\Psi\in \mathcal{F}(V',\Sigma')\) result in finite 
transition probabilities
\(|\langle \Psi, \tilde{U}^A_{V',\Sigma',V,\Sigma} \Phi\rangle |^2\)
without the need for renormalisation. 

A key ingredient in the proofs of the last few theorems was 
a particular operator \(P^A_\Sigma\) which is Hilbert-Schmidt
close to a projector. This operator is also examined in 
this thesis in section \ref{sec: hadamard}, 
see definition \ref{def:lambda}.

To make the discussion more concrete, we are going to 
introduce a particular representation of the Fock spaces 
and evolution operators discussed so far. This representation 
is heavily inspired by Diracs orignal idea discussed in section 
\ref{sec: mot QED} and is usually referred to as inifinite wedge
space. For further details please have a look at section 2 of 
\cite{ivp0}. 

The basic idea behind this representation is a generalisation of 
the following point of view of the scalar product of finitely many 
fermions but works for any Hilbert space \(\mathcal{H}\). 
Pick \(N\in\mathbb{N}\) and two states 
\(\mathsf{\Lambda}\Psi,\mathsf{\Lambda}\Phi\in \mathcal{H}^{\wedge N}\) that can be written 
as the wedge product of \(N\) wavefunctions

\begin{align}
  \mathsf{\Lambda}\Psi= \psi_1\wedge \dots \psi_N\\
  \mathsf{\Lambda}\Phi=\phi_1\wedge \dots \phi_N,
\end{align}
then the standard scalar product \(\langle \Psi,\Phi\rangle\)
in \(\mathcal{H}^{\wedge N}\) can be written as a determinant
\begin{equation}\label{wedge space scalar product}
  \det_{\mathbb{R}^N} (\Psi^* \Phi),
\end{equation}
where \(\Phi\) and \(\Psi\) are interpreted to be linear maps
of type \(\mathbb{R}^N\rightarrow \mathcal{H}\) 
\begin{align}
  \forall k: \Psi: e_k \mapsto \psi_k\\
  \forall k: \Phi: e_k \mapsto \phi_k
\end{align}
where \((e_k)_{k\in\{1,\dots, N\}}\) is an ONB 
of \(\mathbb{R}^N\) and the star denotes the adjoint. Non 
product states first have to be decomposed into a sum of 
product states, then the determinant is continued to be 
linear in the left and right factor. Replacing 
\(\mathbb{R}^N\) by an index space \(\ell\), e.g. \(l^2(\mathbb{N})\)
the space of square summable sequences,  and
using the Fredholm 
determinant this particular 
representation of the scalar product of \(\mathcal{H}^N\)
can be directly generalized to an infinite number of particles. 
In this representation, product states \(\Phi\) can be thought of as maps
\begin{equation}
  \Phi: \ell \rightarrow \mathcal{H}, e_k\mapsto \varphi_k.
\end{equation}
Such maps will be called \emph{Dirac seas}.
The corresponding wedge product can be thought of as 
\begin{equation}
  \mathsf{\Lambda}\Phi=\varphi_1\wedge \varphi_2\dots .
\end{equation}
However, as operators on an infinite dimensional 
Vector space \(\mathcal{\ell}\) only have a Fredholm determinant 
if they are in the set \(1+I_1(\mathcal{\ell})\) (here \(I_1\) 
denotes the space of operators with finite trace-norm), 
only Dirac seas 
\(\Phi,\Psi: \ell \rightarrow \mathcal{H}\) satisfying
\begin{equation}\label{wedge space condition}
\Psi^*\Phi,\Psi^*\Psi,\Phi^*\Phi\in 1+I_1(\ell)
\end{equation}
have a scalar product. 
Starting with one particular 
infinite wedge product \(\mathsf{\Lambda}\Phi\) and collecting all infinite 
wedge products \(\mathsf{\Lambda}\Psi\) such that \eqref{wedge space condition}
is fulfilled and formal linear combinations thereof and 
taking the completion with respect to 
the pairing \eqref{wedge space scalar product} results in 
what is referred to as infinite wedge space 
\(\mathcal{F}_{\mathsf{\Lambda} \Phi}\). For a rigorous construction 
please have a look at \cite[section 2.1]{ivp0}. 

It is worth noticing here, that if one starts from some other
inifinite wedge product \(\mathsf{\Lambda}\Psi\) such that 
\(\Phi^*\Psi \in 1+I_1(\ell)\) to construct 
\(\mathcal{F}_{\mathsf{\Lambda} \Psi}\) one finds 
\(\mathcal{F}_{\mathsf{\Lambda} \Psi}=\mathcal{F}_{\mathsf{\Lambda} \Phi}\),
so there is no unique vacuum state in the infinite wedge space.
Pick a second Hilbert space \(\mathcal{H}'\) and some unitary 
operator \(U:\mathcal{H}\rightarrow \mathcal{H}'\), which 
can be thought of as \(U^A_{\Sigma',\Sigma}\). Next we define 
the operation form the left of \(U\) by 
\begin{align}
  \mathcal{L}_{U}:\mathcal{F}_{\mathsf{\Lambda}\Phi}&\rightarrow \mathcal{F}_{\mathsf{\Lambda}U\Phi}, \\
  \mathcal{L}_U \mathsf{\Lambda}\Psi= \mathsf{\Lambda}U\Psi&= (U\psi_1)\wedge (U\psi_2)\wedge\dots, 
\end{align}
where \(\Psi:\ell\rightarrow \mathcal{H}\) satisfies 
\(\Psi^*\Phi\in 1+I_1(\ell)\). The operator \(\mathcal{L}_U\)
is a lift of \(U\) in the sense of the
\eqref{lift condition} and maps one Fock space 
to another. 
The resulting target space 
\(\mathcal{F}_{\mathsf{\Lambda}U\Phi}\) is quite implicit 
and for \(\mathcal{H}=\mathcal{H}_{\Sigma}\),
\(\mathcal{H}'=\mathcal{H}_{\Sigma'}\) and 
\(U=U^A_{\Sigma',\Sigma}\) in general not identical to 
\(\mathcal{F}_{\mathsf{\Lambda}\Phi'}\) for some 
\(\Phi':\ell \rightarrow \mathcal{H}'\) even if 
\(\mathrm{range}(\Phi)\in C_\Sigma(A) \) and 
\(\mathrm{range}(\Phi')\in C_{\Sigma'}(A)\) hold. 
This shortcoming of the construction can be overcome 
by adding an additional operation from the right.
Let \(\Psi:\ell' \rightarrow \mathcal{H}_{\Sigma'}\) such 
that \(\mathrm{range}(\Psi)=\mathrm{range}(\Phi')\)
holds, then there is a unitary 
\(R:\ell'\rightarrow \ell\) such that 
\(\Phi'=\Psi R\). Analogously to the action from the left
we define one from the right:
\begin{align}
  \mathcal{R}_{R}:\mathcal{F}_{\mathsf{\Lambda}\Psi}&\rightarrow \mathcal{F}_{\mathsf{\Lambda}\Phi'}, \\
  \mathcal{R}_R \mathsf{\Lambda}\Phi'&= \mathsf{\Lambda}(\Phi' R),
\end{align}
also here the \(\Phi'\) generate the infinite wedge space 
\(\mathcal{F}_{\mathsf{\Lambda}\Psi}\). The spaces 
\(\mathcal{F}_{\mathsf{\Lambda}\Psi}\) and 
\(\mathcal{F}_{\mathsf{\Lambda}\Psi R}\) only coincides if 
\(\ell'=\ell\) and
\(R\) has a determinant, i.e. \(R\in 1+I_1(\ell)\). The next
theorem helps us to decide in which cases there is a unitary 
\(R:\ell'\rightarrow \ell\) such that 
\(\mathcal{F}_{\mathsf{\Lambda}U\Phi R}
=\mathcal{F}_{\mathsf{\Lambda}\Phi' }\) holds. 
\begin{Thm}[{thm. \ref{thm shale stinepsirng} for \(\mathcal{L}\) and \(\mathcal{R}\), \cite[thm. 2.26]{ivp0}, \cite[thm 3.1]{deckert2016perspective} }]\label{thm: L R shale Stinespring}
Let \(\mathcal{H}, \ell, \mathcal{H}',\ell'\) be Hilbert spaces, 
\(V\in\mathrm{Pol}(\mathcal{H})\) and \(V'\in\mathrm{Pol}(\mathcal{H}')\) 
polarisations, \(\Phi:\ell\rightarrow  \mathcal{H}\) and 
\(\Phi':\ell'\rightarrow \mathcal{H}'\) be Dirac seas 
such that \(\mathrm{range}(\Phi)=V\) and \(\mathrm{range}(\Phi')=V'\)
Then the following two statements are equivalent
\begin{enumerate}[label=\alph*)]
  \item The off diagonal operators \(P^{{V'}^\perp}U P^V\) and 
  \(P^{V'}UP^{V^\perp}\) are Hilbert-Schmidt operators.
  \item There is a unitary \(R:\ell\rightarrow \ell'\) such 
  that \(\mathcal{F}_{\mathsf{\Lambda}\Phi'}=
  \mathcal{F}_{\mathsf{\Lambda}U\Phi R}\).
\end{enumerate}
\end{Thm}

So returning to \(\Phi:\ell\rightarrow \mathcal{H}_\Sigma\), 
\(\Phi':\ell\rightarrow \mathcal{H}_{\Sigma'}\), 
with
\(\mathrm{range}(\Phi)\in C_{\Sigma}(A),\\
\mathrm{range}(\Phi')\in C_{\Sigma'}(A)\) for some 
Cauchy surfaces \(\Sigma, \Sigma'\) and some \(A\in\mathcal{V}\),
condition a) of the last theorem is satisfied so 
the existence of \(R:\ell \rightarrow \ell\) 
such that the evolution operator 
\begin{equation}
  \tilde{U}^A_{V',\Sigma',V,\Sigma}:\mathcal{F}_{\mathsf{\Lambda}\Phi}\rightarrow \mathcal{F}_{\mathsf{\Lambda}\Phi'},
  \quad \tilde{U}^A_{V',\Sigma',V,\Sigma}= \mathcal{L}_{U^A_{\Sigma',\Sigma}} \circ \mathcal{R}_R
\end{equation}
is well-defined and unitary is ensured. 
The operators 
\(\mathcal{R}_R\) are unique up to a phase, see 
\cite[Cor. 2.28]{ivp0}, as might have been expected since 
the \eqref{lift condition} allows for 
exactly this much freedom. A simple choice of 
\(\ell, \ell'\) that makes it possible to guess a 
choice for \(R\) is \(\ell=\mathrm{range}(\Phi)\subseteq \mathcal{H}_\Sigma\),
\(\ell'=\mathrm{range}(\Phi')\subseteq \mathcal{H}_{\Sigma'}\).
As discussed in section \ref{sec: mot QED} one might hope 
that the motion of the electrons of very negative energy
is irrelevant for understanding excitations at the surface. 
However, as we saw the motion of the electrons at great depth
made it impossible to directly compare the time evolved 
states with the original ones.
We can use \(R\) to revert this motion.  
So the idea is to pick \(R'= (P^{V'}U P^V)^{-1}\) 
whenever \(P^{V'}U P^V\) is invertible, but 
this choice is not unitary. 
If \(P^{V'}U P^V\) is not invertible one can perform the construction 
outlined next
in several steps and assemble a lift of the total operator \(U\).
This is possible, because of for two unitary operators \(U_1,U_2\)
and corresponing lifts \(\tilde{U}_1,\tilde{U}_2\),
\begin{equation}
  \tilde{U}_1\tilde{U}_2
\end{equation}
is a lift of \(U_1 U_2\).
By virtue of the scalar product 
of two infinite wedge products being a determinant and 
the equation 
\begin{align}\label{right op calculation}
  \det((A R)^* B R)= \det(R^* A^* B R)
  = \det (R R^* A^* B)\\
  = \det (R R^*) \det (A^* B)
  =\det ( R^* R) \det (A^* B),
\end{align}
is also true for bounded operators \(A,B,R\) 
of apropriate type whenever 
\(R\) is invertible and \(R^* R\), \(A^*B\) each have 
a determinant. So the operation from the 
right \(\mathcal{R}_{R'}\) may still be defined and
a posteriori be corrected by a factor of 
\(\sqrt{\det ( {R'}^* R')^{-1}}\) to turn 
it into a unitary operator.
Using
\begin{equation}
1= {U^A}^* U^A =(P^V+P^{V^\perp}) {U^A}^* (P^{V'}+P^{{V'}^\perp}) U^A (P^V+P^{V^\perp}),
\end{equation}
and splitting 
the equation up according to the different initial and 
target spaces,this implies 
\begin{equation}
  P^V {U^A}^* P^{V'}U^A P^V = 1- P^{V}{U^A}^* P^{{V'}^\perp} U^A P^{V}.
\end{equation}
Polarisations \(V,V'\) belonging to the apropriate polarisation 
classes \(V\in C_\Sigma(A), V'\in C_{\Sigma'}(A)\) satisfy
condition a) of 
theorem \ref{thm: L R shale Stinespring} and because 
the product of Hilbert-Schmidt operators is traceclass
 \({R'}^*R'\in 1 +I_1(V)\), i.e.
has a determinant. Hence we may define 
\begin{align}
  &\tilde{U}^A_{V',\Sigma',V,\Sigma}:\mathcal{F}_{\mathsf{\Lambda}\Phi}\rightarrow \mathcal{F}_{\mathsf{\Lambda}\Phi'},\\
  &\tilde{U}^A_{V',\Sigma',V,\Sigma}=\det|(P^{V'} U^A_{\Sigma',\Sigma} P^V)| \mathcal{R}_{(P^{V'} U^A_{\Sigma',\Sigma} P^V)} \circ \mathcal{L}_{U^A_{\Sigma',\Sigma}}.
\end{align}
Well-definedness can be checked directly, the operator
\begin{equation}
  {\Phi'}^* U^A_{\Sigma',\Sigma} \Phi R' 
  =P^{V'} U_{\Sigma',\Sigma}^A P^{V}R' 
  = 1_{V'}
\end{equation}
clearly has a determinant on \(V'\). By similar 
calculations as \eqref{right op calculation} 
it follows that also all operators 
\(\tilde{\Phi}'U^A_{\Sigma',\Sigma} \tilde{\Phi}R'\)
with \(\mathsf{\Lambda}\tilde{\Phi}'\in \mathcal{F}_{\mathsf{\Lambda}\Phi'}\),
\(\mathsf{\Lambda}\tilde{\Phi}\in \mathcal{F}_{\mathsf{\Lambda}\Phi}\)
have a determinant.

So the construction of a evolution operator in external field 
QED was successful.


\section{Geometric Construction of the Phase}\label{chapter geometery}
In this chapter we perform a geometric construction of the phase 
of the evolution operator from an object \(c^+\) having properties 
inspired by physical intuition. This object \(c^+\) has not 
itself been constructed yet, but the author and his supervisors 
hope to construct it in the near future. 
We restrict ourselves to the scattering regime, because it reduces 
the available freedom. More precisely, in the scattering regime 
there is a canonical polarisation in the initial and final Hilbert-space.



Because our notion of argument of a complex number and an 
invertible bounded operator is non standard, we introduce it next. 
\begin{Def}[polar decomposition and spectral projections]
We denote by \(\mathcal{H}=L^2(\mathbb{R}^3,\mathbb{C})\).
For \(X:\mathcal{H}\rightarrow \mathcal{H}\) bounded
\begin{equation}\label{def AG}
\AG(X):=X |X|^{-1}.
\end{equation}
Furthermore, we define for any complex number \(z\in \mathbb{C}\backslash \{0\}\)
\begin{equation}
\ag(z):=\frac{z}{|z|}.
\end{equation}
In abuse of notation we will define the expression
\begin{equation}
\partial_t \ln f(t):=\frac{\partial_t f(t)}{f(t)},
\end{equation}
for any differentiable \(f:\mathbb{R}\rightarrow \mathbb{C}\backslash \{0\} \), 
even if the expression \(\ln f(t)\) cannot be interpreted as the principle
branch of the logarithm.

We also introduce \(S^1:=\{z\in\mathbb{C}\mid |z|=1\}\).
We will denote the space of bounded linear functions from 
one normed Vektorspace \(V\) into itself by \(\mathcal{B}(V)\).

Lastly we introduce the partial derivative in 
the direction of any four-potential \(F\) of an operator valued 
function \(F:\mathcal{V}\rightarrow \mathcal{B}(\mathcal{F})\) by
\begin{equation}\label{def derivative}
\partial_F T(F):=\partial_{\varepsilon}T(\varepsilon F)|_{\varepsilon =0},
\end{equation}
where the limit is taken with respect to the operator norm topology.

\end{Def}





\begin{Def}[scattering operator and phases]\label{def: S bar, gamma, cA}
We define for all \(A,B\in\mathcal{V} \)
\begin{align}
S_{A,B}:=U^{A}_{\Sigma_{\mathrm{in}},\Sigma_{\mathrm{out}}}U^{B}_{\Sigma_{\mathrm{out}},\Sigma_{\mathrm{in}}},
\end{align}
where \(\Sigma_{\mathrm{out}}\) and \(\Sigma_{\mathrm{int}}\)  are Cauchy-surfaces of Minkowski spacetime such that 
\begin{align}
&\forall (x,y)\in \supp A\cup\supp B\times \Sigma_{\mathrm{in}}: (x-y)^2 \ge 0\Rightarrow x^0>y^0,\\
&\forall (x,y)\in \supp A\cup\supp B\times \Sigma_{\mathrm{out}}: (x-y)^2 \ge 0\Rightarrow x^0<y^0
\end{align}
holds.
Define for any \(a,b\) elements of the same real or complex 
vectorspace the linesegment connecting them 
\begin{equation}
  \overline{a~b}:=\{sa+(1-s)b\mid s\in[0,1]\}.
\end{equation}
Let 
\begin{align}
\mathrm{dm}:=\{(A,B)\in\mathcal{V}^2\mid P^- S_{A,B}P^-\text{ and }\\
 P^- S_{B,A}P^-:\mathcal{H}^- \righttoleftarrow  \text{ are invertible}\},
\end{align}
we define
\begin{equation}\label{dom s bar}
\dom\overline{S}:=\{(A,B)\in \mathrm{dm}\mid  \overline{A~B}\times\overline{A~B} \subseteq \mathrm{dm} \}.
\end{equation}
Furthermore, we choose for all \(A,B\in \dom \overline{S}\) the lift the lift discussed at 
the end of the last section
\begin{align}
\overline{S}_{A,B}=\mathcal{R}_{\AG((P^- S_{A,B}P^-)^{-1})} \mathcal{L}_{S_{A,B}}.
\end{align}

For \((A,B),(B,C), (C,A)\in\dom\overline{S}\), we define 
 the complex numbers 
\begin{align}\label{def: gamma}
\gamma_{A,B,C}&:=\det_{\mathcal{H}^-} (P^- S_{A,B} P^- S_{B,C} P^- S_{C,A}P^-),\\
\Gamma_{A,B,C}&:=\ag(\gamma_{A,B,C}).\label{def: Gamma}
\end{align}
We will see in lemma \ref{gamma attri} that 
\(\gamma_{A,B,C}\neq 0\) and
\( P^-S_{A,B}P^-S_{B,C}P^-S_{C,A}\in 1+I_1(\mathcal{H}^-)\), so 
that \(\Gamma_{A,B,C}\) is well-defined.
Next, we introduce for \(A,B,C\in\mathcal{V}\) the function
\begin{equation}
c_A(F,G):=-i \partial_F \partial_G  \Im \tr [P^- S_{A,A+F} P^+ S_{A,A+G} P^-] .
\end{equation}
Finally, 
let \(a,b\) be two subsets of Minkowski spacetime, we say \(a\prec b\) 
(in words: ``\(a\) is causally prior to \(b\)'') if 
and only if for all \((x,y)\in a \times b\)
\begin{equation}
  \big((x-y)^2\ge 0\wedge x\neq y\big) \Rightarrow x^0<y^0
\end{equation}
holds. For \(A,B\in \mathcal{V}\) in the expressions 
\(a\prec A, A\prec a, A\prec B \) the four-potentials \(A,B\)
are to be interpreted as \(\supp A, \supp B\) respectively.
\end{Def}

\begin{Lemma}[properties of \(\dom\overline{S}\)]\label{lem properties of dom s bar}
The set \(\dom \overline{S}\) has the following properties:
\begin{enumerate}
\item contains the diagonal: \(\{(A,A)\mid A\in\mathcal{V}\}\subseteq \dom\overline{S}\).
\item openness: \(\forall n \in \mathbb{N}: \left\{s\in\mathbb{R}^{2n}\mid \left(\sum_{k=1}^n s_k A_k,\sum_{k=n+1}^{2n} s_{k} A_{k} \right)\in \dom\overline{S}\right\}\) is an open subset of \(\mathbb{R}^{2n}\) for all \(A_1,\dots A_{2n}\in\mathcal{V}\).
\item symmetry:  \((A,A')\in\dom\overline{S}\iff (A',A)\in\dom\overline{S}\)
\item star-shaped: \((A,t A)\in \dom\overline{S}\Rightarrow \forall s\in \overline{1~~t} : (A,s A)\in\dom\overline{S}\)
\item well-defined-ness of \(\overline{S}\): \(\dom\overline{S}\subseteq \{A,B\in\mathcal{V}\mid P^- S_{A,B} P^-:\mathcal{H}^- \righttoleftarrow \text{is invertible} \}\).
\end{enumerate}
We will only prove openness, as the other properties follow directly from the definition \eqref{dom s bar}. So pick \(n\in\mathbb{N}\), 
\(A_i\in\mathcal{V}\) for \(i\in \mathbb{N}, i\le 2 n\) and \(s\in\mathbb{R}^{2n}\)
such that \(\left(\sum_{k=1}^n s_k A_k,\sum_{k=n+1}^{2n} s_{k} A_{k} \right)\in\dom\overline{S}\). 
We have to find a neighbourhood \(U\subseteq \mathbb{R}^{2n}\) of \(s\) such that 
\(\{ \left(\sum_{k=1}^n s_k' A_k,\sum_{k=n+1}^{2n} s_{k}' A_{k} \right) \mid s'\in U\}\subseteq \dom\overline{S}\) holds. 
In doing so we have to ensure that the square

\begin{align}
  \overline{\sum_{k=1}^n s_k' A_k~~~\sum_{k=n+1}^{2n} s_{k}' A_{k} }^2
\end{align}
stays a subsets of \(\mathrm{dm}\) for all \(s'\in U\). 
Now pick a metric \(d\) on \(\mathbb{R}^{2n}\) and define 
\begin{align}\nonumber
&r:=\inf \left\{d(s,s')\mid \overline{\sum_{k=1}^n s_k' A_k~~\sum_{k=n+1}^{2n} s_k' A_k }^2 ~~\cap \mathrm{dm}^c\neq \emptyset \right\}.
\end{align}
It cannot be the case that \(r=0\), because the 
metric is continuous, the square compact in 
\(\mathbb{R}^{2n}\) 
and the set of invertible bounded operators 
(defining \(\mathrm{dm}\)) is open in the topology 
generated by the operator norm.
If \(r=\infty\) then \(U=\mathbb{R}^{2n}\) will 
suffice. If \(r\in\mathbb{R}^+\) then \(U=B_r(s,t)\) 
the open ball of radius \(r\) around \(s\) works.
\end{Lemma}

\subsection{Main Result of Construction}


\begin{Def}[causal splitting]
We define a causal splitting as a function 
\begin{align}
&c^+:\mathcal{V}^3\rightarrow \mathbb{C}, \\
&(A,F,G)\mapsto c_A^+(F,G),
\end{align}
such that \(c^+\) restricted to any finite dimensional subspace is smooth in the 
first argument and linear in the second and third argument.
Furthermore \(c^+\) should satisfy
\begin{align}\label{c+ 1}
c_A(F,G)=c_A^+(F,G)-c_A^+(G,F),\\\label{c+ 2}
\partial_H c^+_{A+H}(F,G)=\partial_G c^+_{A+G}(F,H),\\\label{c+ 3}
\forall F \prec G: c_A^+(F,G)=0.
\end{align}
\end{Def}

\begin{Def}[current]
Given a lift \(\hat{S}_{A,B}\) of the one-particle scattering operator \(S_{A,B}\) for which the derivative in the following expression exists,
 we define the associated current by Bogolyubov's formula:
\begin{equation}
j_A^{\hat{S}}(F):=i\partial_F \left\langle \Omega, \hat{S}_{A,A+F} \Omega\right\rangle.
\end{equation}
\end{Def}

\begin{Thm}[existence of causal lift]\label{thm: geometry}
Given a causal splitting \(c^+\), there is a second quantised scattering operator \(\tilde{S}\), lift of the one-particle scattering operator \(S\)
with the following properties
\begin{align}
&\forall A,B,C\in \mathcal{V}:\tilde{S}_{A,B}\tilde{S}_{B,C}=\tilde{S}_{A,C}\label{prop S tilde 1}\\
&\forall F\prec G: \tilde{S}_{A,A+F}=\tilde{S}_{A+G,A+F+G}\label{prop S tilde 2}
\end{align}
and the associated current satisfies
\begin{equation}\label{jurrent S tilde}
\partial_G j_{A+G}^{\tilde{S}}(F)=\left\{\begin{matrix} -2i c_A(F,G)  &\text{ for } G\prec F\\ 0 &\text{ for } F\prec G  \end{matrix} \right.
\end{equation}
\end{Thm}

\begin{Remark}\label{rmk phase construction}
One may wonder why we construct a lift with the properties 
\eqref{prop S tilde 1} and \eqref{prop S tilde 2}. 
The project of finding a rigorous formulation of external 
field QED can be considered a success once a lift 
\(\tilde{U}^A_{\Sigma',\Sigma}\) of the evolution from 
one cauchy surface to another \(U_{\Sigma',\Sigma}\) 
has been constructed 
from which a current can be calculated that agrees 
with experiments to the degree that the approximations 
inherent to the model are applicable. In the light of 
this goal properties \eqref{prop S tilde 1} and 
\eqref{prop S tilde 2} should be judged. Property 
\eqref{prop S tilde 1} is a basic requirement,
any phase that does not fulfil it will not be directly 
generalisable to the the evolution between different 
Cauchy surfaces. In the proof of the theorem we will see 
that in order to 
satisfy it, it suffices to construct any global section, i.e.
a lift of \(S_{0,A}\) for any \(A\in\mathcal{V}\). 
In order to see why \eqref{prop S tilde 2} is a reasonable 
second requirement we may quickly go through its proof in 
the one-particle situation. Let \(A,F,G\in\mathcal{V}\) 
such that \(F\prec G\). We may then pick  a Cauchy 
surface \(\Sigma'\) such that \(\supp F\prec \Sigma'\) 
and \(\Sigma'\prec \supp G\). 
This implies 
\begin{align}
  S_{A+G,A+G+F}=U^{A+G}_{\Sigma_{\text{in}},\Sigma_{\text{out}}} U^{A+G+F}_{\Sigma_{\text{out}},\Sigma_{\text{in}}}\\
  = U^{A+G}_{\Sigma_{\text{in}},\Sigma'}U^{A+G}_{\Sigma',\Sigma_{\text{out}}}U^{A+G+F}_{\Sigma_{\text{out}},\Sigma'}U^{A+G+F}_{\Sigma',\Sigma_{\text{in}}}\\
  \overset{*}{=}U^{A}_{\Sigma_{\text{in}},\Sigma'}U^{A+G}_{\Sigma',\Sigma_{\text{out}}}U^{A+G}_{\Sigma_{\text{out}},\Sigma'}U^{A+F}_{\Sigma',\Sigma_{\text{in}}}
  =U^{A}_{\Sigma_{\text{in}},\Sigma'}U^{A+F}_{\Sigma',\Sigma_{\text{in}}}\\
  =U^{A}_{\Sigma_{\text{in}},\Sigma'}U^{A}_{\Sigma',\Sigma_{\text{out}}}U^{A}_{\Sigma_{\text{out}},\Sigma'}U^{A+F}_{\Sigma',\Sigma_{\text{in}}}
  =U^{A}_{\Sigma_{\text{in}},\Sigma_{\text{out}}} U^{A+F}_{\Sigma_{\text{out}},\Sigma_{\text{in}}}
  =S_{A,A+F},
\end{align}
where for the marked equality we used the support properties 
of \(F\) and \(G\) relative to \(\Sigma'\) and that 
\(S^A_{\Sigma',\Sigma}\) only depends on values of \(A\) in 
the volume delimited by \(\Sigma'\) and \(\Sigma\). 
For a lift 
of \(U^A_{\Sigma',\Sigma}\) we would expect the last calculation 
to hold in the second quantised language as well. So 
property \eqref{prop S tilde 2} is a way of incorporating
attributes of the lift of the time evolution 
between different hypersurfaces 
without mentioning those hypersurfaces directly.
\end{Remark}

\subsection{Proof of Theorem \ref{thm: geometry}}


Since the phase of a lift relative to any other lift is fixed by a single 
matrix element, we may use the vacuum expectation values to characterise the
phase of a lift. The function \(c\) captures the dependence of this object on 
variations of the external field, the connection between vacuum expectation
values and \(c\) becomes clearer with the next lemma.

\begin{Lemma}[properties of \(\Gamma\)]\label{gamma attri}
The function \(\Gamma\) has the following properties for all  \(A,B,C,D\in\mathcal{V}\) such that the expressions occurring in each equation are well-defined:
\begin{align}\label{gamma attri0}
&\gamma_{A,B,C}\neq 0\\\notag
&\Gamma_{A,B,C}=\det_{\mathcal{H}^-}(P^--P^-S_{A,C}P^+S_{C,A}P^- \\\label{gamma attri1}
&\hspace{5cm}- P^- S_{A,B} P^+ S_{B,C} P^- S_{C,A} P^-)\\\label{gamma attri2}
&\Gamma_{A,B,C}^{-1}=\ag(\langle \Omega, \overline{S}_{A,B} \overline{S}_{B,C} \overline{S}_{C,A}\Omega\rangle )\\\label{gamma attri3}
&\Gamma_{A,B,C}=\Gamma_{B,C,A}=\frac{1}{\Gamma_{B,A,C}}\\\label{gamma attri4}
&\Gamma_{A,A,B}=1\\\label{gamma attri5}
&\Gamma_{A,B,C}\Gamma_{B,A,D}\Gamma_{A,C,D}\Gamma_{C,B,D}=1 \\\label{gamma attri6}
&\Gamma_{A,B,C}=\Gamma_{D,B,C}\Gamma_{A,D,C}\Gamma_{A,B,D} \\\label{gamma attri7}
&\overline{S}_{A,C}=\Gamma_{A,B,C}\overline{S}_{A,B}\overline{S}_{B,C}\\\label{gamma attri8}
&c_A(B,C)=\partial_B \partial_C \ln \Gamma_{A,A+B,A+C}.
\end{align}
\end{Lemma}
\begin{proof}
Pick  \(A,B,C\in\mathcal{V}\) such that \((X,Y)\in \dom\overline{S}\) for \(X,Y\in\{A,B,C\}\). 
By definition \(\gamma\) is
\begin{equation}
\gamma_{A,B,C}=\det_{\mathcal{H}^-}(P^- S_{A,B} P^- S_{B,C} P^- S_{C,A} P^-).
\end{equation}
The operator whose determinant we take in the last line is a product
\begin{equation}
P^- S_{A,B} P^- S_{B,C} P^- S_{C,A} P^-=P^- S_{A,B}P^-~~ P^- S_{B,C}P^-~~ P^- S_{C,A} P^-.
\end{equation}
The three factors appearing in this product are all invertible due to the definition of 
\(\dom\overline{S}\), 
therefore if the determinant exists we have \(\gamma_{A,B,C}\neq 0\).
To see that it does exist, we reformulate
\begin{align}
&\gamma_{A,B,C}=\det_{\mathcal{H}^-}(P^- S_{A,B} P^- S_{B,C} P^- S_{C,A} P^-)\\
&=\det_{\mathcal{H}^-}(P^-S_{A,C}P^-S_{C,A}P^- - P^- S_{A,B} P^+ S_{B,C} P^- S_{C,A} P^-)\\\label{eq: gamma proof of first attri}
&=\det_{\mathcal{H}^-}(P^--P^-S_{A,C}P^+S_{C,A}P^- - P^- S_{A,B} P^+ S_{B,C} P^- S_{C,A} P^-),
\end{align}
now we know by theorem \ref{thm ruisnaar} of Ruisnaars that \(P^+S_{X,Y}P^-\) 
is a Hilbert-Schmidt operator for our setting,
hence \(\gamma\) and also \(\Gamma\) are well-defined.

 Equation 
\eqref{eq: gamma proof of first attri} also proves \eqref{gamma attri1}. Next we show \eqref{gamma attri2}. 
In the notation of the last section we have \(\Omega=\bigwedge \Phi\) 
with the injection \(\Phi: \mathcal{H}^-\hookrightarrow\mathcal{H}\). 
We begin by reformulating the right hand side of  \eqref{gamma attri2}
\begin{align}
 &\langle \Omega, \overline{S}_{A,B} \overline{S}_{B,C} \overline{S}_{C,A}\Omega\rangle \\\notag
&=\langle \bigwedge \Phi, \bigwedge \left(S_{A,B}S_{B,C}S_{C,A}\Phi \AG(P^-S_{C,A} P^-)^{-1}\right.\\\notag
&\hspace{3cm}\left. \AG(P^-S_{B,C} P^-)^{-1} \AG(P^-S_{A,B} P^-)^{-1}  \right)\rangle \\
&=\langle \bigwedge \Phi, \bigwedge \left(\Phi \AG(P^-S_{C,A} P^-)^{-1}\right.\\\notag
&\hspace{3cm}\times\left. \AG(P^-S_{B,C} P^-)^{-1} \AG(P^-S_{A,B} P^-)^{-1}  \right)\rangle \\
&=\det_{\mathcal{H}^-}\left( (\Phi)^*  \left[\Phi \AG(P^- S_{C,A} P^-)^{-1} \AG(P^-S_{B,C} P^-)^{-1}\right.\right.\\\notag
&\hspace{6cm}\times\left.\left. \AG(P^-S_{A,B} P^-)^{-1} \right] \right)\\
&=\det_{\mathcal{H}^-}  \left(\AG(P^- S_{C,A} P^-)^{-1} \AG(P^- S_{B,C} P^-)^{-1}\right.\\ \notag
&\hspace{6cm}\left.\times\AG(P^-S_{A,B} P^-)^{-1}\right)  \\\label{eq:1/arg}
&=\frac{1}{\det_{\mathcal{H}^-}  \AG(P^- S_{A,B} P^-) \AG(P^- S_{B,C} P^-) \AG(P^-S_{C,A} P^-) }.
\end{align}
We first note that \(\det_{\mathcal{H}^-}|P^- S_{X,Y}P^-|\in\mathbb{R}^+\) for \(X,Y\in \{A,B,C\}\). This is well-defined because 
\begin{align}
&\langle \Omega, \overline{S}_{X,Y}\Omega\rangle
=\langle \bigwedge \Phi, \bigwedge(S_{X,Y}\Phi \AG(P^- S_{X,Y}P^-)^{-1})\rangle\\
&=\det_{\mathcal{H}^-} \left( \Phi^* S_{X,Y}\Phi \AG(P^- S_{X,Y}P^-)^{-1}\right)\\
&=\det_{\mathcal{H}^-} \left( P^- S_{X,Y} P^- \AG(P^- S_{X,Y}P^-)^{-1}\right)\\
&=\det_{\mathcal{H}^-} \left(\AG(P^- S_{X,Y}P^-)^{-1} P^- S_{X,Y} P^- \right)\\
&=\det_{\mathcal{H}^-} \left(\AG(P^- S_{X,Y}P^-)^{-1} \AG(P^- S_{X,Y}P^-) |P^- S_{X,Y} P^-| \right)\\
&=\det_{\mathcal{H}^-} |P^- S_{X,Y}P^-|
\end{align}
holds. Moreover this determinant does not vanish, since the\\ \(P^- S_{X,Y}P^-\) is invertible. Also clearly the eigenvalues are positive
since \(|P^- S_{X,Y}P^-|\) is an absolute value. We continue with the result of \eqref{eq:1/arg}. Thus, we find
\begin{align}\label{eq: arg representation}
&\langle \Omega, \overline{S}_{A,B} \overline{S}_{B,C} \overline{S}_{C,A}\Omega\rangle^{-1}\\
&=\det_{\mathcal{H}^-}\left(  \AG(P^- S_{A,B} P^-) \AG(P^- S_{B,C} P^-) \AG(P^-S_{C,A} P^-)  \right)\\\notag
&=\det_{\mathcal{H}^-}\left(  \AG(P^- S_{A,B} P^-) \AG(P^- S_{B,C} P^-) P^-S_{C,A} P^-\right.\\
&\hspace{7.5cm}\times\left. |P^-S_{C,A} P^-|^{-1}  \right)\\\notag
&=\det_{\mathcal{H}^-}\left(  \AG(P^- S_{A,B} P^-) \AG(P^- S_{B,C} P^-) P^-S_{C,A} P^-  \right)\\
&\hspace{7cm}\times \det_{\mathcal{H}^-}|P^-S_{C,A} P^-|^{-1} \\\notag
&=\det_{\mathcal{H}^-}\left( P^-S_{C,A} P^- \AG(P^- S_{A,B} P^-) \AG(P^- S_{B,C} P^-)  \right)\\
&\hspace{7cm}\times \det_{\mathcal{H}^-}|P^-S_{C,A} P^-|^{-1} \\
&=\frac{\det_{\mathcal{H}^-}\left(P^- S_{A,B} P^- P^- S_{B,C} P^- P^-S_{C,A} P^-  \right)}
{\det_{\mathcal{H}^-}\!|P^- S_{A,B} P^-| \cdot \det_{\mathcal{H}^-}\!|P^-S_{B,C} P^-|\cdot \det_{\mathcal{H}^-}\!|P^-S_{C,A} P^-|}.
\end{align}
Now since the denominator of this fraction is real we can use \eqref{def: Gamma} to identity
\begin{equation}
\ag(\langle \Omega, \overline{S}_{A,B} \overline{S}_{B,C} \overline{S}_{C,A}\Omega\rangle)=\Gamma_{A,B,C}^{-1},
\end{equation}
which proves \eqref{gamma attri2}.

For the first equality in \eqref{gamma attri3} we use \(\det (X (1+Y) X^{-1})=\det (1+Y)\) for any \(Y\) trace-class and 
 \(X\) bounded and invertible. So we can cyclicly permute the factors \(P^- S_{X,Y}P^-\) in the determinant and find
\begin{align*}
&\Gamma_{A,B,C}=\ag(\det_{\mathcal{H}^-} P^- S_{A,B}P^-S_{B,C}P^-S_{C,A}P^- )\\
&\quad=\ag(\det_{\mathcal{H}^-} P^-S_{C,A}P^- S_{A,B}P^-S_{B,C}P^- )
=\Gamma_{C,A,B}.
\end{align*}
For the second equality of \eqref{gamma attri3} we use \eqref{def: Gamma}
to represent both \(\Gamma_{A,B,C}\) and \(\Gamma_{B,A,C}\). Using this and the manipulations of the determinant 
we already employed, we arrive at
\begin{align}
&\Gamma_{A,B,C}\Gamma_{B,A,C}\\
&=\ag(\det_{\mathcal{H}^-} (P^-S_{A,B}P^-S_{B,C}P^-S_{C,A}P^-))\\
&\quad\times\ag(\det_{\mathcal{H}^-} (P^-S_{B,A}P^-S_{A,C}P^-S_{C,B}P^-))\\
&=\ag(\det_{\mathcal{H}^-} (P^-S_{A,B}P^-S_{B,C}P^-S_{C,A}P^-))\\
&\quad\times(\ag(\det_{\mathcal{H}^-} (P^-S_{B,C}P^-S_{C,A}P^-S_{A,B}P^-)))^*\\
&=\ag(\det_{\mathcal{H}^-} (P^-S_{A,B}P^-S_{B,C}P^-S_{C,A}P^-))\\
&\quad\times(\ag(\det_{\mathcal{H}^-} (P^-S_{A,B}P^-S_{B,C}P^-S_{C,A}P^-)))^*\\
&=|\ag(\det_{\mathcal{H}^-} (P^-S_{A,B}P^-S_{B,C}P^-S_{C,A}P^-))|^2=1,
\end{align}
which proves \eqref{gamma attri3}. 

Next, using \eqref{def: gamma} inserting twice the same argument yields
\begin{equation}
\gamma_{A,A,C}=\det_{\mathcal{H}^-} P^-S_{A,C}P^-S_{C,A}P^-
=\det_{\mathcal{H}^-} (P^- S_{C,A} P^-)^*P^-S_{C,A}P^-\in \mathbb{R}^+,
\end{equation}
hence \eqref{gamma attri4} follows.


For proving \eqref{gamma attri5} we will use the definition of \(\Gamma\) directly and repeatedly use that we can cyclicly permute operator groups of the form
\(P^- S_{X,Y}P^-\) for \(X,Y\in \{A,B,C,D\}\) in the determinant, i.e.
\begin{equation}\label{tetraeder 1}
\det P^- S_{X,Y}P^- O = \det O P^- S_{X,Y}P^-,\tag{\(\circlearrowleft\)}
\end{equation}
whenever \(O\) has a determinant.
This is possible, because \(P^- S_{X,Y}P^-\) is bounded and invertible. Furthermore we will use that 
\begin{equation}\label{tetraeder 2}
\det O_1 O_2 = \det O_1 \det O_2\tag{\(\leftrightarrow\)}
\end{equation}
holds whenever 
both \(O_1\) and \(O_2\) have a determinant. Moreover for any  \((P^- S_{X,Y}P^-)^*P^- S_{X,Y}P^-\) is the modulus squared of an invertible operator and hence
its determinant is positive which means that 
\begin{equation}\label{tetraeder 3}
\ag \det (P^- S_{X,Y}P^-)^*P^- S_{X,Y}P^-=1.\tag{\(\ag\!|\,\, |\)}
\end{equation}
These three rules will be repeatedly used. We calculate
\begin{align}
&\Gamma_{A,B,C}\Gamma_{B,A,D}\Gamma_{A,C,D}\Gamma_{C,B,D}\\\notag
&=\ag \det_{\mathcal{H}^-}P^- S_{A,B}P^- S_{B,C}P^- S_{C,A}P^- \\
&\hspace{1,5cm}\times\ag \det_{\mathcal{H}^-}P^- S_{B,A}P^- S_{A,D}P^- S_{D,B}P^-~~ \Gamma_{A,C,D}\Gamma_{C,B,D}\\\notag
&\overset{\eqref{tetraeder 1}}{=}
\ag \det_{\mathcal{H}^-}P^-S_{A,D}P^- S_{D,B}P^- S_{B,A}P^- \\
&\hspace{1.5cm}\times \ag \det_{\mathcal{H}^-}P^- S_{A,B}P^- S_{B,C}P^- S_{C,A}P^- ~~  \Gamma_{A,C,D}\Gamma_{C,B,D}\\\notag
&\overset{\eqref{tetraeder 2}}{=}
\ag \det_{\mathcal{H}^-}\big(P^-S_{A,D}P^- S_{D,B} \big[P^- S_{B,A} P^- S_{A,B}P^-\big]\\
&\hspace{5cm}\times S_{B,C}P^- S_{C,A}P^-\big) ~ \Gamma_{A,C,D}\Gamma_{C,B,D}\\\notag
&\overset{\eqref{tetraeder 1}}{=}
\ag \det_{\mathcal{H}^-}P^-S_{B,C}P^- S_{C,A}P^-S_{A,D}P^- S_{D,B} \big[P^- S_{B,A} P^- S_{A,B}P^-\big]  \\
&\hspace{8cm}\times \Gamma_{A,C,D}\Gamma_{C,B,D}\\\notag
&\overset{\eqref{tetraeder 2}}{=}
\ag \det_{\mathcal{H}^-}P^-S_{B,C}P^- S_{C,A}P^-S_{A,D}P^- S_{D,B}P^-\\
&  \hspace{4cm}\times\ag \det_{\mathcal{H}^-} P^- S_{B,A} P^- S_{A,B}P^-  ~~ \Gamma_{A,C,D}\Gamma_{C,B,D}\\
&\overset{\eqref{tetraeder 3}}{=}
\ag \det_{\mathcal{H}^-}P^-S_{B,C}P^- S_{C,A}P^-S_{A,D}P^- S_{D,B}P^-   ~~ \Gamma_{A,C,D}\Gamma_{C,B,D}\\
&\overset{\eqref{tetraeder 1}}{=}
\ag \det_{\mathcal{H}^-}P^-S_{A,D}P^- S_{D,B}P^-S_{B,C}P^- S_{C,A}P^-   ~~ \Gamma_{A,C,D} \Gamma_{C,B,D}\\\notag
&=\ag \det_{\mathcal{H}^-}P^- S_{A,C}P^- S_{C,D}P^- S_{D,A}P^-\\
&\hspace{1.5cm}\times\ag \det_{\mathcal{H}^-}P^-S_{A,D}P^- S_{D,B}P^-S_{B,C}P^- S_{C,A}P^-   ~~ \Gamma_{C,B,D}\\\notag
&\overset{\eqref{tetraeder 2}}{=}
\ag \det_{\mathcal{H}^-}\big(P^- S_{A,C}P^- S_{C,D}P^-\big[ P^- S_{D,A}P^-P^-S_{A,D}P^- \big]\\
&\hspace{4cm}\times  S_{D,B}P^-S_{B,C}P^- S_{C,A}P^-\big)   ~~ \Gamma_{C,B,D}\\\notag
&\overset{\eqref{tetraeder 1}}{=}
\ag \det_{\mathcal{H}^-}\big(P^- S_{D,B}P^-S_{B,C}P^- S_{C,A}P^- S_{A,C}P^- S_{C,D}P^-\\
&\hspace{4cm}\times\big[P^- S_{D,A}P^-P^-S_{A,D}P^- \big]\big)    ~~ \Gamma_{C,B,D}\\\notag
&\overset{\eqref{tetraeder 2}}{=}
\ag \det_{\mathcal{H}^-}P^- S_{D,B}P^-S_{B,C}P^- S_{C,A}P^- S_{A,C}P^- S_{C,D}P^- \\
&\hspace{4cm}\times\ag \det_{\mathcal{H}^-} P^-S_{D,A}P^-P^-S_{A,D}P^-    ~~ \Gamma_{C,B,D}\\\notag
&\overset{\eqref{tetraeder 3}}{=}
\ag \det_{\mathcal{H}^-}\big(P^- S_{D,B}P^-S_{B,C}P^-\big[P^- S_{C,A}P^- S_{A,C}P^-\big]\\
&\hspace{7cm}\times P^- S_{C,D}P^-\big)     \Gamma_{C,B,D}\\\notag
&\overset{\eqref{tetraeder 1}}{=}
\ag \det_{\mathcal{H}^-}P^- S_{C,D}P^- S_{D,B}P^-S_{B,C}P^- \big[P^- S_{C,A}P^- S_{A,C}P^-\big]\\     
&\hspace{9cm}\times \Gamma_{C,B,D}\\\notag
&\overset{\eqref{tetraeder 2}}{=}
\ag \det_{\mathcal{H}^-}P^- S_{C,D}P^- S_{D,B}P^-S_{B,C}P^-\\
&\hspace{4cm}\times \ag \det P^- S_{C,A}P^- S_{A,C}P^-     ~~ \Gamma_{C,B,D}\\
&\overset{\eqref{tetraeder 3}}{=}
\ag \det_{\mathcal{H}^-}P^- S_{C,D}P^- S_{D,B}P^-S_{B,C}P^-  ~~ \Gamma_{C,B,D}\\\notag
&=
\ag \det_{\mathcal{H}^-}P^- S_{C,D}P^- S_{D,B}P^-S_{B,C}P^- \\
&\hspace{4cm}\times \ag \det_{\mathcal{H}^-} P^- S_{C,B}P^- S_{B,D}P^- S_{D,C}P^- \\
&=
|\ag \det_{\mathcal{H}^-}P^- S_{C,D}P^- S_{D,B}P^-S_{B,C}P^-|^2=1. 
\end{align}

Equation \eqref{gamma attri6} is a direct consequence of \eqref{gamma attri5} and \eqref{gamma attri3}.

For \eqref{gamma attri7} we realise that according to \cite{ivp0} that two lifts can only differ by a phase,
that is
\begin{equation}
\overline{S}_{A,C}=\xi \overline{S}_{A,B} \overline{S}_{B,C}
\end{equation}
for some \(\xi\in \mathbb{C}, |\xi|=1\). 

In order to identify \(\xi\) we recognise that \(\overline{S}_{X,Y}=\overline{S}_{Y,X}^{-1}\) for four potentials \(X,Y\) 
and find
\begin{equation}
1 \xi^{-1}= \overline{S}_{A,B} \overline{S}_{B,C}\overline{S}_{C,A}.
\end{equation}
Now we take the vacuum expectation value on both sides of this equation and use \eqref{gamma attri2} to find
\begin{equation}
\xi^{-1}=\langle\Omega,\overline{S}_{A,B} \overline{S}_{B,C}\overline{S}_{C,A}\Omega\rangle = \Gamma_{A,B,C}^{-1}.
\end{equation}

Finally we prove \eqref{gamma attri8}. We start from the right hand side of this equation 
and work our way towards the left hand side of it. In the following calculation we will repeatedly make use of the fact that 
\((P^-S_{A,A+B}P^-S_{A+B,A}P^- )\) is the absolute value squared of an invertible operator and has a determinant, which is therefore positive. 
For the marked equality we will use that for a differentiable function \(z:\mathbb{R}\rightarrow \mathbb{C}\) at points \(t\) where \(z(t)\in\mathbb{R}^+\)
holds, we have
\begin{align}\notag
(z/|z|)'(t)=\frac{z'}{|z|}(t)+\frac{-z}{|z|^2}\frac{z'z^*+ {z^*}'z}{2|z|}(t) =\frac{z'}{2|z|}(t)-\frac{z^2{z^*}'}{2 |z|^3}(t)\\
=i (\Im (z'))/z(t).
\end{align}
Furthermore, we will use the following  expressions for the derivative of 
the determinant which holds for all operator valued functions on the reals
\(M:\mathbb{R}\rightarrow 1+I_1(\mathcal{H})\) such that \(M\) is invertible 
for all \(t\in\mathbb{R}\)
\begin{align}\label{diff det}
\partial_\varepsilon \det M(\varepsilon)|_{\varepsilon=0}=\det M(0) \tr (M^{-1}(0)\partial_\varepsilon M(\varepsilon)|_{\varepsilon}),
\end{align}
likewise we need the following expression for the derivative of \(M^{-1}\) for 
\(M:\mathbb{R}\rightarrow (\mathcal{H}\rightarrow \mathcal{H})\) such that \(M(t)\) is invertible and bounded for every \(t\in\mathbb{R}\)
\begin{equation}
\partial_{\varepsilon}M^{-1}(\varepsilon)|_{\varepsilon=0}=-M^{-1}(0) \partial_{\varepsilon}M(\varepsilon)|_{\varepsilon=0}M^{-1}(0).
\end{equation}
The handling of derivatives of operators in the 
following calculation is justified by 
the chapter on regularity \ref{chap:regularity of S}. 
We compute
\begin{align}
\partial_B \partial_C \ln \Gamma_{A,A+B,A+C}\\
\overset{\eqref{def: Gamma}}{=} 
\partial_B \partial_C \ln \ag(\det_{\mathcal{H}^-} (P^-S_{A,A+B}P^-S_{A+B,A+C}P^- S_{A+C,A}P^-))\\
=\partial_B \frac{\partial_C\ag(\det_{\mathcal{H}^-}(P^-S_{A,A+B}P^-S_{A+B,A+C}P^- S_{A+C,A}P^-))}{\ag(\det_{\mathcal{H}^-} (P^-S_{A,A+B}P^-S_{A+B,A}P^- ))}\\
=\partial_B \partial_C\ag(\det_{\mathcal{H}^-}(P^-S_{A,A+B}P^-S_{A+B,A+C}P^- S_{A+C,A}P^-))\\
\overset{*}{=}
i\partial_B \frac{\Im \partial_C \det_{\mathcal{H}^-}(P^-S_{A,A+B}P^-S_{A+B,A+C}P^- S_{A+C,A}P^-)}{\det_{\mathcal{H}^-}(P^-S_{A,A+B}P^-S_{A+B,A}P^-)}\\\notag
=i\partial_B \Big[\frac{\det_{\mathcal{H}^-}(P^-S_{A,A+B}P^-S_{A+B,A}P^-)}{\det_{\mathcal{H}^-}(P^-S_{A,A+B}P^-S_{A+B,A}P^-)}\\\notag
\times \Im  \tr ((P^-S_{A,A+B}P^-S_{A+B,A}P^-)^{-1}\\
\times\partial_C P^-S_{A,A+B}P^-S_{A+B,A+C}P^- S_{A+C,A}P^-)\Big]\label{eq ca 1}
\end{align}
The fraction in front of the trace equals \(1\). As a next step we replace the second but last projector \(P^-=1-P^+\), the resulting first summand vanishes,
because the dependence on \(C\) cancels. This results in 
\begin{align}\notag
&\eqref{eq ca 1}=-i\partial_B \Im \tr((P^-S_{A,A+B}P^-S_{A+B,A}P^-)^{-1}\\
&\hspace{3cm}\times\partial_C P^-S_{A,A+B}P^-S_{A+B,A+C}P^+ S_{A+C,A}P^-).\label{eq ca 2}
\end{align}
Now, because \(P^+P^-=0\) only one summand of the product rule survives:
\begin{align}\notag
&\eqref{eq ca 2}=-i\partial_B \Im \tr((P^-S_{A,A+B}P^-S_{A+B,A}P^-)^{-1}\\
&\hspace{3cm}\times\partial_C P^-S_{A,A+B}P^-S_{A+B,A}P^+ S_{A+C,A}P^-).\label{eq ca 3}
\end{align}
Next we use 
\((M N )^{-1}= N^{-1} M^{-1}\) for invertible operators \(M\) and \(N\) for the first factor in the trace and cancel as much as possible of
the second factor:
\begin{align}\notag
\eqref{eq ca 3}=-i\partial_B \Im \tr((P^-S_{A+B,A}P^-)^{-1}  P^-S_{A+B,A}\\
\times P^+ \partial_C S_{A+C,A}P^-)\\\notag
=-i \Im \tr(\partial_B[(P^-S_{A+B,A}P^-)^{-1}  P^-S_{A+B,A}\\
\times P^+ \partial_C S_{A+C,A}P^-])\\
=-i \Im \tr(\partial_B  P^-S_{A+B,A}P^+ \partial_C S_{A+C,A}P^-)\\
=-i \Im \tr(\partial_B  P^-S_{A,A+B}P^+ \partial_C S_{A,A+C}P^-)\\
=-i \partial_B\partial_C\Im \tr(  P^-S_{A,A+B}P^+  S_{A,A+C}P^-)
\end{align}
which proves the claim.

\end{proof}



In order to construct the lift announced in theorem \ref{thm: geometry}, we first construct a reference lift \(\hat{S}\), that is well-defined on all of \(\mathcal{V}\). 
Afterwards we will study the dependence of the relative phase between 
this global lift \(\hat{S}_{0,A}\) and a local lift given by \(\hat{S}_{0,B}\overline{S}_{B,A}\) for \(B-A\) small. 
By exploiting properties of this phase and the causal splitting \(c^+\) we will construct a global lift that has the desired properties.

Since \(\mathcal{V}\) is star shaped, we may reach any four-potential \(A\) from \(0\) through the straight line
\(\{t A\mid t \in [0,1]\}\). 

\begin{Def}[ratio of lifts]\label{def:ratio}
For any  \(A,B\in\mathcal{V}\) and any two lifts \(S_{A,B}', S_{A,B}''\) of the  one-particle scattering operator \(S_{A,B}\)
we define the ratio
\begin{equation}
\frac{S_{A,B}'}{S_{A,B}''}\in S^1
\end{equation}
to be the unique complex number \(z\in S^1\) such that 
\begin{equation}
z ~S_{A,B}'' = S_{A,B}'
\end{equation}
holds.
\end{Def}

\begin{Thm}[existence of global lift]\label{thm: ex s hat}
  There is a unique map \(\hat{S}_{0,\cdot}:\mathcal{V}\to U(\mathcal{F})\) 
    which maps  \(A\in\mathcal{V}\) to a lift of \(S_{0,A}\) and solves the 
    parallel transport differential equation
\begin{equation}\label{diff s hat}
A,B\in\mathcal{V}\text{ linearly dependent}\Rightarrow \partial_B \frac{\hat{S}_{0,A+B}}{\hat{S}_{0,A}\overline{S}_{A,A+B}}=0,
\end{equation}
subject to the initial condition \(\hat{S}_{0,0}=1\).
\end{Thm}

The proof of theorem \ref{thm: ex s hat} is divided into two lemmas due to its length. We will introduce the integral flow \(\phi_A\) associated 
with the differential equation \eqref{diff s hat} for some \(A\in\mathcal{V}\). We will then study the properties of \(\phi_A\)
in the two lemmas and finally construct \(\hat{S}_{0,A}:=\phi_A(0,1)\). In the first lemma we will establish the existence of a 
local solution. The solution will be constructed along the line \(\overline{0 ~~ A}\). In the second lemma we patch local solutions together
to a global one.



\begin{Lemma}[\(\phi\) local existence and uniqueness]\label{lem phi local}
There is a unique \(\phi_A:\{(t,s)\in\mathbb{R}^2\mid (t A, s A)\in \dom\overline{S}\} \rightarrow U(\mathcal{F})\) for every \(A\in\mathcal{V}\)
satisfying
\begin{align}\label{phi prop1}
\forall (t,s)\in \dom \phi_A: \phi_A(t,s) \text{ is a lift of } S_{tA, sA}\\\label{phi prop2}
\forall (t,s),(s,l),(l,t)\in \dom\phi_A: \phi_A(t,s)\phi_A(s,l)=\phi_A(t,l)\\\label{phi prop3}
\forall t\in\mathbb{R}: \phi_A(t,t)=1\\\label{phi prop4}
\forall s\in\mathbb{R}: \partial_{t} \left.\frac{\phi_A(s,t)}{\overline{S}_{sA,tA}}\right|_{t=s}=0.
\end{align}
\end{Lemma}
\begin{proof}
We first define the phase
\begin{align}\label{def local z}
z:\{(A,B)\in\dom\overline{S}\mid A, B \text{ linearly dependent}\} \rightarrow S^1
\end{align}
by the differential equation
\begin{equation}\label{diff eq z local}
\frac{d}{d x} \ln z(t A, x A) = - \left.\left( \frac{d}{dy} \ln \Gamma_{tA,x A, yA}\right)\right|_{y=x}
\end{equation}
and the initial condition 
\begin{equation}\label{z initial}
z(A,A)=1
\end{equation}
 for any \(A\in \mathcal{V}\). The phase \(z\) takes the form
\begin{equation}\label{z solution}
z(tA,xA)=\exp\left(-\int_{t}^x dx' \left.\left( \frac{d}{dx'} \ln \Gamma_{tA,y A, x' A}\right)\right|_{y=x'}\right).
\end{equation}
Please note that both differential equation and initial condition are invariant under rescaling of the potential \(A\), so \(z\) is well-defined. 
We will now construct a local solution to \eqref{diff s hat} and define \(\phi_A\) using this solution.
Pick \(A\in \mathcal{V}\) the expression
\begin{equation}\label{loc s hat}
\hat{S}_{0,s A} = \hat{S}_{0, A} \overline{S}_{ A, s A} z( A, s A)
\end{equation}
solves \eqref{diff s hat} locally. Local here means that \(s\) is close enough to \(1\) such that \(( A, s A)\in\dom\overline{S}\).
Calculating the argument of the derivative of \eqref{diff s hat} we find:
\begin{align}
 \frac{\hat{S}_{0,(s+\varepsilon) A}}{\hat{S}_{0,s A}\overline{S}_{s A, (s+\varepsilon)A}}
= \frac{\hat{S}_{0,A} \overline{S}_{A, (s+\varepsilon)A} z(A, (s+\varepsilon)A)}
{\hat{S}_{0, A} \overline{S}_{ A, s A} \overline{S}_{s A,(s+\varepsilon)}z( A, s A)}\\
\overset{\eqref{gamma attri6}}{=}
 \frac{\hat{S}_{0,A}\overline{S}_{ A, s A} \overline{S}_{s A,(s+\varepsilon)} \Gamma_{A, sA, (s+\varepsilon)A} z(A, (s+\varepsilon)A)}
{\hat{S}_{0, A} \overline{S}_{ A, s A} \overline{S}_{s A,(s+\varepsilon)}z( A, s A)}\\
= \frac{\Gamma_{A,sA,(s+\varepsilon)A}z(A, (s+\varepsilon)A)}{z( A, sA)}
\end{align}
Now we take the derivative with respect to \(\varepsilon\) at \(\varepsilon=0\), 
cancel the factor that does not depend on \(\varepsilon\) and relabel \(s=x\) to obtain
\begin{align}
0=\left.\left(\frac{d}{dy}(\Gamma_{ A, x A, y A} ~z( A, y A))\right)\right|_{y=x}\\
\iff \frac{d}{dx}\ln z(tA, xA)=\left.\left(-\frac{d}{dy}\ln \Gamma_{t A, xA, yA}\right)\right|_{y=x},
\end{align}
which is exactly the defining differential equation of \(z\). The initial condition of \(z\) equation \eqref{z initial} 
is necessary to match the initial condition in \eqref{loc s hat} for \(s=1\).
The connection to \(\phi\) from the statement of the lemma can now be made.
We define 
\begin{equation}\label{def phi}
\phi_A(t,s):=z(t A, s A) \overline{S}_{t A, s A},
\end{equation}
for \((tA,sA)\in\dom\overline{S}\). Since \(\overline{S}\) is a lift of \(S\), we see that
 \eqref{phi prop1} holds. Equation \eqref{phi prop3} follows from \eqref{z initial} and 
 \(\overline{S}_{tA, tA}=1\) for general \(t\in\mathbb{R}\).
 Equation \eqref{phi prop4} follows by plugging in 
\eqref{def phi} and using the defining differential equation for
 \(z\) \eqref{diff eq z local} as well as its initial 
condition \eqref{z initial} and the property 
\eqref{gamma attri3} of \(\Gamma\):
\begin{align}
\partial_s \left.\frac{\phi_A(t,s)}{\overline{S}_{t A,sA}}\right|_{s=t}
=\partial_s \left.\frac{z(tA,sA)\overline{S}_{t A, sA}}{\overline{S}_{t A, s A}}\right|_{s=t}\\
=\partial_s \left.z(tA, sA)\right|_{t=s}
=z(t A,t A)\bigg(\frac{d}{d s}\ln \Gamma_{t A, t A, s A}\bigg)\bigg|_{s=t}=0.
\end{align}


It remains to see that \eqref{phi prop2}, i.e. that 

\begin{align}\label{consistency phi}
\phi_A(t,s)\phi_A(s,l)=\phi_A(t,l)
\end{align}
holds for \((tA,sA),(sA,lA),(tA,lA)\in\dom\overline{S}\). 
In order to do so we plug in the definition \eqref{def phi} of \(\phi_A\) and obtain
\begin{align}
\phi_A(t,s)\phi_A(s,l)=\phi_A(t,l)\\
\iff z(tA,sA) z(sA,lA)\overline{S}_{tA,sA}\overline{S}_{sA,lA}=z(tA,lA)\overline{S}_{tA,lA}\\
\iff z(tA,sA) z(sA,lA)\overline{S}_{tA,sA}\overline{S}_{sA,lA}\\
=z(tA,lA)\overline{S}_{tA,s A} \overline{S}_{sA,lA}\Gamma_{tA,sA,lA}\\
\iff z(tA,sA) z(sA,lA)z(tA,lA)^{-1}=\Gamma_{tA,sA,lA}.
\end{align}
In order to check the validity of the last equality we plug in the 
integral formula \eqref{z solution} for \(z\), we also abbreviate 
\(\frac{d}{d x}=\partial_x\)

\begin{align}
z(tA,sA) z(sA,lA)z(tA,lA)^{-1}\\
=e^{-\int_t^s d x' \left.(\partial_{x'} \ln \Gamma_{tA,yA,x'A} )\right|_{y=x'} -\int_s^l d x' \left.(\partial_{x'} \ln \Gamma_{sA,yA,x'A} )\right|_{y=x'} }\\
\times e^{   +\int_t^l d x' \left.(\partial_{x'} \ln \Gamma_{tA,yA,x'A} )\right|_{y=x'}  }\\
=e^{-\int_l^s d x' \left.(\partial_{x'} \ln \Gamma_{tA,yA,x'A} )\right|_{y=x'}  -\int_s^l d x' \left.(\partial_{x'} \ln \Gamma_{sA,yA,x'A} )\right|_{y=x'} }\\
\overset{\eqref{gamma attri6}}{=}
e^{-\int_l^s d x' \left.(\partial_{x'} \ln \Gamma_{sA,yA,x'A} )\right|_{y=x'} 
-\int_l^s d x' \left.(\partial_{x'} \ln \Gamma_{tA,sA,x'A} )\right|_{y=x'}}\\ 
\times e^{-\int_l^s d x' \left.(\partial_{x'} \ln \Gamma_{tA,yA,sA} )\right|_{y=x'} 
 -\int_s^l d x' \left.(\partial_{x'} \ln \Gamma_{sA,yA,x'A} )\right|_{y=x'} }\\
 =e^{-\int_l^s d x' \left.(\partial_{x'} \ln \Gamma_{tA,sA,x'A} )\right|_{y=x'}}\\
  =e^{-\int_l^s d x'\partial_{x'} \ln \Gamma_{tA,sA,x'A} }\\
  \overset{\eqref{gamma attri4}}{=}\Gamma_{t A, s A, l A},
\end{align}
which proves the validity of the consistency relation 
\eqref{consistency phi}.

In order to prove uniqueness we pick \(A\in \mathcal{V}\) 
and assume there is \(\phi'\) also defined on \(\dom \phi_A\) 
and satisfies \eqref{phi prop1} to \eqref{phi prop4}. Then we may 
use \eqref{phi prop1} to conclude that for any \((t,s)\in\dom\phi_A\) 
there is
\(\gamma(t,s)\in S^1\) such that
\begin{equation}
\phi_A(t,s)=\phi'(t,s) \gamma(t,s)
\end{equation}
holds true. Picking \(l\) such that \((t,s),(s,l),(t,l)\in \dom\phi_A\) and  using \eqref{phi prop2} we find

\begin{align}
\phi'(t,s) \gamma(t,s)=\phi_A(t,s)=\phi_A(t,l)\phi_A(l,s)\\
=\gamma(t,l)\phi'(t,l) \gamma(l,s)\phi'(l,s)=\gamma(t,l) \gamma(l,s)\phi'(t,s) ,
\end{align}
hence we have
\begin{equation}
 \gamma(t,s)=\gamma(t,l) \gamma(l,s).
\end{equation}
From property \eqref{phi prop3} we find
\begin{equation}
\gamma(t,t)=1,
\end{equation}
for any \(t\).
Using equation \eqref{phi prop4} we conclude that 

\begin{align}
0=\partial_t \left.\frac{\phi'(s,t)}{\overline{S}_{sA,tA}}\right|_{t=s}
=\partial_t \left.\frac{\phi_A(s,t) \gamma(s,t)}{\overline{S}_{sA,tA}}\right|_{t=s}\\
=\partial_t \left.\gamma(s,t) \frac{\phi_A(s,t)}{\overline{S}_{sA,tA}}\right|_{t=s}
=\partial_t \left.\gamma(s,t)\right|_{t=s} + \partial_t  \left.\frac{\phi_A(s,t)}{\overline{S}_{sA,tA}}\right|_{t=s}\\
=\partial_t \left.\gamma(s,t)\right|_{t=s}.
\end{align}
Finally we find for general \((s,t)\in \dom\phi_A\):
\begin{equation}
\partial_x \gamma(s,x)|_{x=t}=\partial_x ( \gamma(s,t) \gamma(t,x))|_{x=t}=\gamma(s,t) \partial_x \gamma(t,x)|_{x=t}=0.
\end{equation}
So \(\gamma(t,s)=1\) everywhere. We conclude \(\phi_A=\phi'\).

\end{proof}



\begin{Lemma}[\(\phi\) global existence and uniqueness]\label{lem: phi global}
For any \(A\in\mathcal{V}\) the map \(\phi_A\) constructed in 
lemma \ref{lem phi local} 
can  be uniquely extended to all of \(\mathbb{R}^2\)
keeping its defining properties 
\begin{align}\label{global phi prop1}
\forall (t,s)\in \mathbb{R}^2: \phi_A(t,s) \text{ is a lift of } S_{tA, sA}\\\label{global phi prop2}
\forall (t,s),(s,l),(l,t)\in \mathbb{R}^2: \phi_A(t,s)\phi_A(s,l)=\phi_A(t,l)\\\label{global phi prop3}
\forall t\in\mathbb{R}: \phi_A(t,t)=1\\\label{global phi prop4}
\forall s\in\mathbb{R}: \partial_{t} \left.\frac{\phi_A(s,t)}{\overline{S}_{sA,tA}}\right|_{t=s}=0.
\end{align}
\end{Lemma}
\begin{proof}
Pick \(A\in\mathcal{V}\). For \(x\in\mathbb{R}\) we define the set
\begin{equation}\label{def U x}
U_x:=\{y\in\mathbb{R}\mid (x A, y A)\in \dom\overline{S}\},
\end{equation}
which according to properties 2 and 4 of lemma 
\ref{lem properties of dom s bar} is an open interval and
fulfills that \(\bigcup_{x\in\mathbb{R}} U_x\times U_x\) is an open 
neighbourhood of the diagonal \(\{(x,x)\mid x \in\mathbb{R}\}\).
Therefore \(\phi_A\) is defined for arguments that are
close enough to each other. Since 
properties \eqref{global phi prop4} and \eqref{global phi prop3} 
only concern the behavior of \(\phi_A\) at the diagonal any
extension fulfils them. 

We pick a sequence \((x_k)_{k\in\mathbb{N}}\subset \mathbb{R}\) such
that 
\begin{equation}\label{open cover of R}
\bigcup_{k\in\mathbb{N}_0} U_{x_k} = \mathbb{R}
\end{equation}
holds and 
\begin{equation}
  \forall n \in \mathbb{N}_0: \bigcup_{k=0}^n U_{x_k}=:\dom_n
\end{equation}
is an open interval. Please note that such a sequence always exists. 
We are going to prove that for any \(n\in\mathbb{N}_0\) 
There is a function \(\psi_n:\dom_n\times\dom_n\to U(\mathcal{F})\), 
which satisfies the conditions
\begin{align}\label{induction psi1}
\forall (t,s)\in \dom_n\times \dom_n: \psi_n(t,s) \text{ is a lift of } S_{tA, sA}\\\label{induction psi2}
\forall s,k,l\in\dom_n: \psi_n(k,s)\psi_n(s,l)=\psi_n(k,l)\\\label{induction psi3}
\forall x,y\in\dom_n: (xA, yA)\in\dom\overline{S}\Rightarrow  \psi_n(x,y)=\phi_A(x,y)
\end{align}
and is the unique function to do so, i.e. 
any other function \(\tilde{\psi}_{n}\) fulfilling properties 
\eqref{induction psi1}-\eqref{induction psi3} possibly being defined
on a larger domain coincides with \(\psi_n\) on \(\dom_n\times\dom_n\).

We start with \(\psi_0=\phi_A\)  
restricted to \(U_{x_0} \times U_{x_0}\).
This function is a restriction of \(\phi_A\) and because of 
lemma \ref{lem phi local} it 
fulfils all of the required properties directly. 
 
For the induction step we pick \(t\in \dom_n\cap U_{x_{n+1}}\) 
and define \(\psi_{n+1}\) on the domain 
\(\dom_{n+1}\times \dom_{n+1}\) by
 \begin{equation}\label{def psi induction}
 \psi_{n+1}(x,y):=\left\{\begin{matrix}
 \psi_n(x,y) \quad &\text{for }x,y\in \dom_n\\
 \phi_A(x,y) \quad &\text{for } x,y\in U_{x_{n+1}}\\
 \psi_n(x,t)\phi_A(t,y)\quad &\text{for } x\in \dom_n, y\in U_{x_{n+1}}\\
 \phi_A(x,t)\psi_n(t,y)\quad &\text{for } y\in \dom_n, x\in U_{x_{n+1}}.
 \end{matrix} \right.
 \end{equation} 
In order to complete the induction step we have to show that 
\(\psi_{n+1}\) is well-defined and fulfils properties
\eqref{induction psi1}-\eqref{induction psi3} 
with \(n\) replaced by \(n+1\) and is the unique function 
to do so.
  
To see that \(\psi_{n+1}\) is well-defined we have to check 
that the cases in the definition agree when they overlap. 
\begin{enumerate}
  \item If we have \(x,y \in \dom_n\cap U_{x_{n+1}}\) all four cases overlap; however, the 
  alternative definitions all equal \(\phi_A(x,y)\):
\begin{align}\nonumber
  \psi_n(x,y)\overset{\eqref{induction psi3}}{=}\phi_A(x,y)\overset{\eqref{phi prop2}}{=}\phi_A(x,t) \phi_A(t,y)
  \\
\overset{\eqref{induction psi3}}{=}\left\{\begin{matrix}\psi_n(x,t) \phi_n(t,y)\\ \phi_A(x,t) \psi_n(t,y).\end{matrix}\right.
  \end{align}
  \item Furthermore, if we have \(x\in \dom_n\), \(y\in \dom_n\cap U_{x_{n+1}}\) cases one 
  and three overlap. Here both alternatives are equal to
  \(\psi_n(x,y)\), since \(x,y\in \dom_n\) and we obtain:
  \begin{equation}
  \psi_n(x,y)\overset{\eqref{induction psi2}}{=}\psi_n(x,t)\psi_n(t,y)\overset{\eqref{induction psi3}}{=}\psi_n(x,t)\phi_A(t,y).
  \end{equation}
  \item Additionally, if \(y\in \dom_n\), \(x\in \dom_n\cap U_{x_{n+1}}\) cases one and four overlap. 
  Here they are equal to
  \(\psi_n(x,y)\), since \(x,y\in \dom_n\) a quick calculation yields:
  \begin{equation}
  \psi_n(x,y)\overset{\eqref{induction psi2}}{=}\psi_n(x,t)\psi_n(t,y)\overset{\eqref{induction psi3}}{=}\phi_A(x,t)\psi_n(t,y).
  \end{equation}
  \item Moreover, if we have \(y\in U_{x_{n+1}}\), \(x\in \dom_n\cap U_z\) 
  cases two and three overlap. Here both candidate definitions are equal to
  \(\phi_A(x,y)\), since \(x,t\in U_z\) we arrive at:
  \begin{equation}
  \phi_A(x,y)\overset{\eqref{phi prop2}}{=}\phi_A(x,t)\phi_A(t,y)\overset{\eqref{induction psi3}}{=}\psi_n(x,t)\phi_A(t,y).
  \end{equation}
  \item Also, if we have \(x\in U_{x_{n+1}}\), \(y\in \dom_n\cap U_{x_{n+1}}\) 
  cases two and four overlap. In this case both alternatives are equal to
  \(\phi_A(x,y)\), since \(y,t\in U_{x_{n+1}}\) we get:
    \begin{equation}
  \phi_A(x,y)\overset{\eqref{phi prop2}}{=}\phi_A(x,t)\phi_A(t,y)\overset{\eqref{induction psi3}}{=}\phi_A(x,t)\psi_n(t,y).
  \end{equation}
  \end{enumerate}
We proceed to show the induction claim, 
starting with \(\eqref{induction psi1}_{n+1}\). By the induction 
hypothesis we know that \(\psi_n(x,y)\) as well as 
\(\phi_A(x,y)\) are lifts of \(S_{xA,yA}\) for any \((x,y)\) in their 
domain of definition. Therefore we have for \(x,y\in \dom_n \cup U_{x_{n+1}}\)
 \begin{equation}\tag{\ref{def psi induction}}
 \psi_{n+1}(x,y)=\left\{\begin{matrix}
 \psi_n(x,y) \quad &\text{for }x,y\in \dom_n,\\
 \phi_A(x,y) \quad &\text{for } x,y\in U_{x_{n+1}},\\
 \psi_n(x,t)\phi_A(t,y)\quad &\text{for } x\in \dom_n, y\in U_{x_{n+1}},\\
 \phi_A(x,t)\psi_n(t,y)\quad &\text{for } y\in \dom_n, x\in U_{x_{n+1}},
 \end{matrix} \right.
 \end{equation} 
where each of the lines is a lift of \(S_{xA,y A}\) whenever the expression is defined.


Equation \(\eqref{induction psi2}_{n+1}\) we will again show in a case 
by case manner depending on the \(s,k\) and \(l\):
\begin{enumerate}
\item \(s,k,l\in \dom_{n}\): 
\(\eqref{induction psi2}_{n+1}\) follows directly from the induction hypothesis;
\item  \(s,k\in \dom_{n}\) and \(l\in U_{x_{n+1}}\):
\begin{align}\nonumber
\psi_{n+1}(s,k)\psi_{n+1}(k,l)=\psi_n(s,k)\psi_n(k,t)\phi_A(t,l)\\
\overset{\eqref{induction psi2}}{=} \psi_n(s,t)\phi_A(t,l)=\psi_{n+1}(s,l),
\end{align}
\item \(s,l\in \dom_n\) and  \(k\in U_{x_{n+1}}\): 
\begin{align*}
\psi_{n+1}(s,k)\psi_{n+1}(k,l)=\psi_{n}(s,t)\phi_A(t,k)\phi_A(t,k)\psi_n(t,l)\\
\overset{\eqref{phi prop3},\eqref{phi prop2}}{=}\psi_{n}(s,t)\psi_n(t,l)\overset{\eqref{induction psi2}}{=}\psi_n(s,l)=\psi_{n+1}(s,l),
\end{align*}
\item  \(s\in \dom_n\) and  \(k,l\in U_{x_{n+1}}\):
\begin{align*}
\psi_{n+1}(s,k)\psi_{n+1}(k,l)=\psi_n(s,t)\phi_A(t,k)\phi_A(k,l)\\
\overset{\eqref{phi prop2}}{=}\psi_n(s,t)\phi_A(t,l)
=\psi_{n+1}(s,l),
\end{align*}
\item \(k,l\in \dom_n\) and  \(s\in U_{x_{n+1}}\): 
\begin{align*}
\psi_{n+1}(s,k)\psi_{n+1}(k,l)=\phi_A(s,t)\psi_n(t,k)\psi_n(k,l)\\
\overset{\eqref{induction psi2}}{=}\phi_A(s,t)\psi_n(t,l)=\psi_{n+1}(s,l),
\end{align*}
\item  \(k\in \dom_n\) and  \(s,l\in U_{x_{n+1}}\):
\begin{align*}
\psi_{n+1}(s,k)\psi_{n+1}(k,l)=\phi_A(s,t)\psi_n(t,k)\psi_n(k,t)\phi_A(t,l)\\
\overset{\eqref{induction psi2}}{=}\phi_A(s,t)\psi(t,t)\phi_A(t,l)
\overset{\eqref{induction psi3},\eqref{phi prop3}}{=}\phi_A(s,t)\phi_A(t,l)\\
\overset{\eqref{phi prop2}}{=} \phi_A(s,l)=\psi_{n+1}(s,l),
\end{align*}
\item \(l\in \dom_n\) and  \(s,k\in U_{x_{n+1}}\):
\begin{align*}
\psi_{n+1}(s,k)\psi_{n+1}(k,l)=\phi_A(s,k)\phi_A(k,t)\psi_n(t,l)\\
\overset{\eqref{phi prop2}}{=}\phi_A(s,t)\psi_n(t,l)=\psi_{n+1}(s,l),
\end{align*}
\item and if \(s,k,l\in U_z\): 
\begin{align*}
\psi_{n+1}(s,k)\psi_{n+1}(k,l)=\phi_A(s,k)\phi_A(k,l)\\
\overset{\eqref{phi prop2}}{=}\phi_A(s,l)=\psi_{n+1}(s,l).
\end{align*}
\end{enumerate}

To see \(\eqref{induction psi3}_{n+1}\), i.e. that  \(\psi_{n+1}\) is 
coincides with \(\phi_A\) where both functions are defined pick 
\(x,y\in \dom_{n+1}\) such that \((xA,yA)\in\dom\overline{S})\).
Recall the definition of \(\psi_{n+1}\)

\begin{equation}\tag{\ref{def psi induction}}
  \psi_{n+1}(x,y)=\left\{\begin{matrix}
  \psi_n(x,y) \quad &\text{for }x,y\in \dom_n,\\
  \phi_A(x,y) \quad &\text{for } x,y\in U_{x_{n+1}},\\
  \psi_n(x,t)\phi_A(t,y)\quad &\text{for } x\in \dom_n, y\in U_{x_{n+1}},\\
  \phi_A(x,t)\psi_n(t,y)\quad &\text{for } y\in \dom_n, x\in U_{x_{n+1}}.
  \end{matrix} \right.
\end{equation} 

Therefore if \(x,y\in\dom_{n}\) we may use the induction hypothesis directly
and if \(x,y\in U_{x_{n+1}}\) we also arrived a the claim we want to prove.
Excluding these cases, we are left with rows number three and four of this
definition with the restriction
\begin{enumerate}
  \item[3.] \(x\in \dom_n\backslash~ U_{x_{n+1}}, y\in U_{x_{n+1}}\backslash~ \dom_n \) or
  \item[4.] \(y\in \dom_n\backslash~ U_{x_{n+1}}, x\in U_{x_{n+1}}\backslash~ \dom_n \),
\end{enumerate}
respectively.
Because \(t\) satisfies
\(t\in \dom_n\cap U_{x_{n+1}}\), we have in both cases \(t\in \overline{x~y}\).
By using property 4 of lemma \ref{lem properties of dom s bar} we infer 
from \((xA,yA)\in \dom\overline{S}\) that in both cases
 \((xA, t A),(tA, y A)\in \dom \overline{S}\)
also holds. Hence we may apply the induction hypothesis 
\(\eqref{induction psi3}_{n}\).

It remains to show uniqueness. 
So let \(\tilde{\psi}_{n+1}\) be defined 
on \(\dom_{n+1}\times\dom_{n+1}\) fulfil 
 \begin{align}\label{uniqueness psi1}\tag{\(\ref{induction psi1}_{\tilde{\psi}}\)}
  \forall (t,s)\in \dom_{n+1}\times \dom_{n+1}: \tilde{\psi}(t,s) \text{ is a lift of } S_{tA, sA},\\\label{uniqueness psi2}\tag{\(\ref{induction psi2}_{\tilde{\psi}}\)}
\forall s,k,l\in\mathbb{R}: \tilde{\psi}(k,s)\tilde{\psi}(s,l)=\tilde{\psi}(k,l),\\\label{uniqueness psi3}\tag{\(\ref{induction psi3}_{\tilde{\psi}}\)}
\forall (x,y)\in\dom_{n+1}: (xA, yA)\in\dom\overline{S}\Rightarrow  \tilde{\psi}(x,y)=\phi_A(x,y).
\end{align}
Now pick \(x,y \in \dom_{n+1}\). We proceed 
in a case by case manner
\begin{enumerate}
\item If \(x,y\in\dom_n\) holds, then 
\(\psi_{n+1}(x,y)=\tilde{\psi}_{n+1}(x,y)\) follows directly
from the induction hypothesis.
\item Similarly if \(x,y\in U_{x_{n+1}}\) holds, we have
\begin{equation}
  \psi_{n+1}(x,y)=\phi_A(x,y)=\tilde{\psi}_{n+1}(x,y).
\end{equation}
\item Additionally, if 
\(x\in \dom_n, y \in U_{x_{n+1}}\) holds, then 
\begin{align}
\psi_{n+1}(x,y)
\overset{\eqref{def psi induction}}{=}
\psi_{n}(x,t)\phi_{A}(t,y)\\
\overset{t\in \dom_n\cap U_{x_{n+1}}}{=}\tilde{\psi}_{n+1}(x,t)\tilde{\psi}_{n+1}(t,y)
\overset{\eqref{uniqueness psi2}}{=}
\tilde{\psi}_{n+1}(x,y)
\end{align}
is satisfied. 
\item Conversely, if 
\(y\in \dom_n, x \in U_{x_{n+1}}\) holds, we may 
use the same calculation to obtain 
\begin{align}
\psi_{n+1}(x,y)
\overset{\eqref{def psi induction}}{=}
\phi_{A}(x,t)\psi_{n}(t,y)\\
\overset{t\in \dom_n\cap U_{x_{n+1}}}{=}\tilde{\psi}_{n+1}(x,t)\tilde{\psi}_{n+1}(t,y)
\overset{\eqref{uniqueness psi2}}{=}
\tilde{\psi}_{n+1}(x,y).
\end{align}
\end{enumerate}

Now we have established a unique extension \(\psi_n\) of \(\phi_A\)
fulfilling properties \eqref{induction psi1}-\eqref{induction psi3}.

We know that for each \(n\in\mathbb{N}\) the function
\(\psi_{n+1}:\dom_{n+1}^2\rightarrow U(\mathcal{F})\) is 
an extention of 
\(\psi_{n+1}:\dom_{n}^2\rightarrow U(\mathcal{F})\).
Furthermore, the sets \(\dom_n\) cover 
\(\mathbb{R}\) according 
to equation \eqref{open cover of R}. Consequently 
there is a unique common extension, by small abuse of 
notation again called 
\(\phi_A:\mathbb{R}^2\to U(\mathcal{F})\), 
of all \(\psi_n\). This function fulfills the claim 
\eqref{global phi prop1}-\eqref{global phi prop4}, because 
any \(t,l,s\in\mathbb{R}\) are contained in some \(\dom_n\).



\end{proof}

Lemma \ref{lem: phi global} enables us to define a global lift.
\begin{Def}[global lift]\label{de: s hat}
For any \(A\in\mathcal{V}\) we define 
\begin{equation}
\hat{S}_{0,A}:=\phi_A(0,1).
\end{equation}
\end{Def}
Using lemma  \ref{lem: phi global} we are now in a position
to prove theorem \ref{thm: ex s hat}.
\begin{proof}[proof of theorem \ref{thm: ex s hat}]
The operator \(\hat{S}\) fulfils the claimed differential 
equation \eqref{diff s hat} due to the global 
multiplication property 
\eqref{global phi prop2} and the differential 
equation \eqref{global phi prop4}.
Its uniqueness is inherited from the 
uniqueness of \(\phi_A\) for \(A\in\mathcal{V}\)
from lemma \ref{lem: phi global}.
\end{proof}


%The lift \(\hat{S}_{0,A}\) can also be calculated differently: pick \(N\in\mathbb{N}\) and a series \((\delta_k)_{k\in\mathbb{N}}\subset \mathbb{R}^+\)
% such that \(\|\mathds{1}-S_{\sum_{k=1}^{n-1}\delta_k A,\sum_{k=1}^{n}\delta_k A}\|<1\)  holds true for all \(k\) and \(\sum_{k=1}^{N}\delta_k=1\). 
%Then 

%\textcolor{red}{is there some kind of direct correspondence between \(\|1-S_{0,\delta_n A}\|\) and \(\|1-S_{\sum_{k=1}^{n-1}\delta_k A,\sum_{k=1}^{n}\delta_k A}\|\)??}
%\begin{equation}
%P^-S_{\sum_{k=1}^{n-1}\delta_k A,\sum_{k=1}^{n}\delta_k A}P^-
%\end{equation}
%is invertible. Now, 

%Before proving this claim, we notice the following property of \(\overline{S}\): For any  \(A\in\mathcal{V}\) and \(\alpha, \beta, \gamma>0\)
% such that all factors exist the following identity holds
%\begin{align}
%\overline{S}_{\alpha A, \gamma A} = \overline{S}_{\alpha A, \beta A} \overline{S}_{\beta A, \gamma A}.
%\end{align}
%This property is by \eqref{gamma attri6} equivalent to 
%\begin{equation}\label{gamma equal 1}
%\Gamma_{\alpha A, \beta A, \gamma A}=1.
%\end{equation}
%This claim can be reduced to the one where \(\alpha=1\) by the following renaming scheme
%\begin{align}
%\alpha A&=: \tilde{A}\\
%\beta/\alpha &=: \tilde{\beta}\\
%\gamma/\alpha&=:\tilde{\gamma}.
%\end{align}
%In fact, the claim holds, as
%the following calculation shows:
%\begin{align}
%\ln &\Gamma_{A,\beta A, \gamma A} = \int_1^\beta d \beta' \partial_{\beta'}\ln \Gamma_{A,\beta' A, \gamma A} 
%+ \overbrace{\ln \Gamma_{A,A,\gamma A}}^{\overset{\eqref{gamma attri4}}{=}0}\\
%&= \int_1^\beta d\beta' \left(\int_1^\gamma d\gamma' \partial_{\gamma'}\partial_{\beta'} \ln \Gamma_{A,\beta' A, \gamma' A} 
%+ \partial_{\beta'} \overbrace{\ln \Gamma_{A,\beta' A, A}}^{\overset{\eqref{gamma attri4}}{=}0} \right)\\
%&=\int_1^\beta d\beta' \int_1^\gamma d\gamma' c_A((\beta'-1) A, (\gamma'-1) A)\\
%&=\int_1^\beta d\beta' \int_1^\gamma d\gamma'  (\beta'-1) (\gamma'-1) \overbrace{c_A( A,  A) }^{\overset{\eqref{gamma attri3},\eqref{gamma attri8}}{=}0}=0,
%\end{align}
%where we have used various properties of lemma \ref{gamma attri}.
%
%\textcolor{blue}{generalisation:}
%claim: for all \(A,B\in \mathcal{A}\) and all \(\alpha,\beta\in\mathbb{R}\), \(|\alpha|,|\beta|\) small enough, such that the expression appearing is well-defined
%\begin{equation}
%\Gamma_{A,A+\alpha B, A+ \beta B} =1.
%\end{equation}
%proof:
%\begin{align}
%\ln \Gamma_{A,A+\alpha B, A+ \beta B} = \overbrace{\ln \Gamma_{A,A+\alpha B, A}}^{=0}+ \int_0^{\beta} d\beta' \partial_{\beta'} \ln \Gamma_{A,A+\alpha B, A+ \beta' B}\\
%=\int_0^{\beta} d\beta' \partial_{\beta'} \left(\overbrace{\ln \Gamma_{A,A, A+ \beta' B}}^{=0}+ \int_0^{\alpha}d\alpha' \partial_{\alpha'} \ln \Gamma_{A,A+\alpha' B, A+ \beta' B}\right)\\
%=\int_0^{\beta} d\beta'  \int_0^{\alpha}d\alpha' \partial_{\beta'} \partial_{\alpha'} \ln \Gamma_{A,A+\alpha' B, A+ \beta' B}\\
%=\int_0^{\beta} d\beta'  \int_0^{\alpha}d\alpha' c_A(\alpha' B, \beta' B) 
%=\int_0^{\beta} d\beta'  \int_0^{\alpha}d\alpha' \alpha' \beta' \overbrace{ c_A( B,  B)}^{=0}.
%\end{align}


%Because of \eqref{gamma equal 1} we see that \eqref{hat finite spacing} is actually independent of the choice of sequence \((\delta_k)_{k}\).
%The right side of equation \eqref{hat finite spacing} satisfies the initial condition of the ordinary differential equation, so we only need to check the differential equation itself.
%Next we reformulate the ordinary differential equation \eqref{diff s hat}, pick \(B=t A\) then we have
%\begin{equation}
%0=\partial_B \frac{\hat{S}_{0,A+B}}{\hat{S}_{0,A}\overline{S}_{A,A+B}}
%=\partial_\varepsilon \frac{\hat{S}_{0,A(1+\varepsilon t)}}{\hat{S}_{0,A}\overline{S}_{A,A(1+\varepsilon t)}}
%=t\partial_\varepsilon \frac{\hat{S}_{0,A(1+\varepsilon)}}{\hat{S}_{0,A}\overline{S}_{A,A(1+\varepsilon)}}
%\end{equation}


%What is more, we can pick \((\delta_k)_k\) such that \(\sum_{k=1}^N \delta_k=1\) and \(\delta_{N+1}=\varepsilon\) then we have

%\begin{align}
%\hat{S}_{0,A(1+\varepsilon)}=\prod_{n=0}^{N+1} \overline{S}_{\sum_{k=1}^{n-1}\delta_k A,\sum_{k=1}^{n}\delta_kA}
%=\prod_{n=0}^{N} \overline{S}_{\sum_{k=1}^{n-1}\delta_k A,\sum_{k=1}^{n}\delta_kA}~ \overline{S}_{A,A(1+\varepsilon)}\\
%=\hat{S}_{0,A}\overline{S}_{A,A+B},
%\end{align}

%or in other words

%\begin{equation}
%\frac{\hat{S}_{0,A+B}}{\hat{S}_{0,A}\overline{S}_{A,A+B}}=1.
%\end{equation}
%If \(A=0\) holds, we see directly that 

%\begin{equation}
%\frac{\hat{S}_{0,B}}{\hat{S}_{0,0}\overline{S}_{0,B}}= 1,
%\end{equation}

%so in both cases the ordinary differential equation is satisfied. 
%\end{Remark}

\begin{Def}[relative phase]\label{def relative phase}
Let \((A,B) \in\dom\overline{S}\), we define \(z(A,B)\in S^1\) by
\begin{equation}\label{def z}
z(A,B):=\frac{\hat{S}_{0,B}}{\hat{S}_{0,A}\overline{S}_{A,B}}.
\end{equation}
Please note that for such \(A,B\) the lift \(\bar{S}_{A,B}\) 
is well-defined. This means that the product in the 
denominator is a lift of \(S_{0,B}\)
and according to definition \ref{de: s hat} the 
ratio is well-defined. 
\end{Def}

\begin{Remark}
The function \(z\) defined here is an extension 
of the funtion \(z\) appearing locally 
in the 
the proof of lemma \ref{lem phi local},
cf. formula \eqref{def local z}.

Please note that \(z\) is smooth
when restricted to  \(\mathcal{W}^2\cap \dom\overline{S}\) 
for any finite dimensional subspace
\(\mathcal{W}\subseteq \mathcal{V}\), since 
\(\hat{S}\) is smooth as a solution to a differential 
equation with smooth initial conditions. 
The parameter \(\overline{S}\) appearing in the defining 
differential equation of \(\hat{S}\) is smooth 
since it is directly constructed in terms of 
the  one-particle scattering operator which is smooth 
due to chapter \ref{chap:regularity of S} in the
appendix.
\end{Remark}


\begin{Lemma}[properties of the relative phase]
For all \\
\((A,F),(F,G),(G,A)\in\dom\overline{S}\), as well as 
or all \(H,K\in \mathcal{V}\), we have
\begin{align}\label{z antisym}
z(A,F)&=z(F,A)^{-1}\\\label{z gamma}
z(F,A)z(A,G)z(G,F)&=\Gamma_{F,A,G}\\\label{z c}
\partial_{H}\partial_{K}\ln  z(A+ H,A+ K)&=c_A(H,K).
\end{align}
\end{Lemma}
\begin{proof}
Pick \(A,F,G\in\mathcal{V}\) as in the lemma. We start off by analysing
\begin{align}
&\hat{S}_{0,F}\overline{S}_{F,G}\overset{\eqref{def z}}{=}z(A,F)\hat{S}_{0,A}\overline{S}_{A,F}\overline{S}_{F,G}\\\label{phase comparison}
&\overset{\eqref{gamma attri7}}{=}z(A,F) \Gamma_{A,F,G}^{-1} \hat{S}_{0,A} \overline{S}_{A,G}.
\end{align}
Exchanging  \(A\) and \(F\) in this equation yields
\begin{equation}
\hat{S}_{0,A}\overline{S}_{A,G}=z(F,A) \Gamma_{F,A,G}^{-1} \hat{S}_{0,F} \overline{S}_{F,G}.
\end{equation}
This is equivalent to
\begin{equation}
\hat{S}_{0,F} \overline{S}_{F,G}=z(F,A)^{-1} \Gamma_{F,A,G} \hat{S}_{0,A}\overline{S}_{A,G}~.
\end{equation}
Comparing the last equation with 
formula \eqref{phase comparison} 
and taking the permutation properties 
 \eqref{gamma attri3} of \(\Gamma\) into 
 account this implies that 
\begin{equation}
z(A,F)=z(F,A)^{-1}
\end{equation}
holds true. Equation \eqref{phase comparison} solved for \(\hat{S}_{0,A}\overline{S}_{A,G}\) also gives us

\begin{align}
\hat{S}_{0,G}\overset{\eqref{def z}}{=}z(A,G)\hat{S}_{0,A}\overline{S}_{A,G}\\
\overset{\eqref{phase comparison}}{=}z(A,G)z(A,F)^{-1}\Gamma_{A,F,G}\hat{S}_{0,F}\overline{S}_{F,G}.
\end{align}
The latter equation compared with 
\begin{equation}
\hat{S}_{0,G}\overset{\eqref{def z}}{=}z(F,G)\hat{S}_{0,F}\overline{S}_{F,G},
\end{equation}
yields  a direct connection between \(\Gamma\) and \(z\):
\begin{equation}
\frac{z(A,G)}{z(A,F)}\Gamma_{A,F,G}=z(F,G),
\end{equation}
which we rewrite using the antisymmetry 
\eqref{z antisym} of \(z\)  as
\begin{equation}
\Gamma_{A,F,G}=z(F,G)z(A,F)z(G,A).
\end{equation}
Finally, in this equation, we substitute 
\(F=A+\varepsilon_1 H\) as well as  
\(G=A+\varepsilon_2 K\), where 
\(\varepsilon_1,\varepsilon_2\) is small enough so that 
\(z\) and \(\Gamma\) are still well-defined. Then we 
take the second logarithmic derivative to find
\begin{align}\notag
 \partial_{\varepsilon_1}\partial_{\varepsilon_2}\ln  z(A+\varepsilon_1 H,A+\varepsilon_2 K)=\partial_{\varepsilon_1}\partial_{\varepsilon_2}\ln\Gamma_{A,A+\varepsilon_1 H,A+\varepsilon_2 K}\\
 \overset{\eqref{gamma attri8}}{=}c_A(H,K). 
\end{align}

\end{proof}

So we find that \(c_A\) is the second mixed logarithmic 
derivative of \(z\). In the following we will 
characterise \(z\) more thoroughly by \(c\) and \(c^+\).
\begin{Def}[\(p\)-forms of four potentials, phase integral]
For \(p\in\mathbb{N}\), we introduce the set \(\Omega^p\) 
of \(p\)-forms 
to consist of all maps 
\(\omega: \mathcal{V}\times \mathcal{V}^{p}\rightarrow \mathbb{C}\)
such that \(\omega\) is linear and antisymmetric in its 
\(p\) last arguments and smooth in its first argument
when restricted to any finite
dimensional subspace of \(\mathcal{V}\).

Additionally, we define the \(1\)-form 
\(\chi\in \Omega^1\) by
\begin{equation}\label{de chi}
\chi_A(B):=\partial_B\ln z(A,A+B)
\end{equation}
for all \(A,B\in\mathcal{V}\).
Furthermore, for \(p\in\mathbb{N}\) and any differential 
form \(\omega\in \Omega^p\), 
we define its exterior derivative, 
\(d \omega\in\Omega^{p+1}\) by
\begin{equation}
(d\omega)_A(B_1,\dots, B_{p+1}):=\sum_{k=1}^{p+1} (-1)^{k+1} 
\partial_{B_k}\omega_{A+B_k}(B_1,\dots , \widehat{B_k},\dots, B_{p+1}),
\end{equation}
for \(A,B_1,\dots, B_{p+1}\in\mathcal{V}\), where 
the notation \(\widehat{B_k}\) denotes that \(B_k\) is  
dropped as an argument.

\end{Def}

\begin{Lemma}[connection between \(c\) and the relative phase]\label{connection between c and the relative phase}
The differential form \(\chi\) fulfils 
\begin{equation}
(d\chi)_A(F,G)=2 c_A(F,G)
\end{equation}
for all \(A,F,G\in\mathcal{V}\).
\end{Lemma}
\begin{proof}
Pick \(A,F,G\in \mathcal{V}\), we calculate
\begin{align}\nonumber
&(d\chi)_A(F,G)=\partial_F\partial_G \ln z(A+F,A+F+G)\\
&\hspace{3cm}-\partial_F \partial_G \ln z(A+G,A+F+G)\\
&=\partial_F\partial_G (\ln  z(A,A+F+G)+\ln z(A+F,A+G))\\
 &\hspace{1cm} - \partial_F\partial_G(  \ln z(A,A+F+G)+\ln z(A+G,A+F))\\
&\overset{\eqref{z antisym}}{=} 2 \partial_F\partial_G \ln z(A+F,A+G)\overset{\eqref{z c}}{=}2 c_A(F,G).
\end{align}
\end{proof}

Now since \(d c=0\), we might use Poincaré's lemma as a method independent of \(z\) to construct a differential form \(\omega\) such that \(d\omega=c\). 
In order to execute this plan, we first need to prove Poincaré's lemma for our setting:

\begin{Lemma}[Poincaré]\label{lem poincare}
Let \(\omega\in \Omega^p\) for 
\(p\in\mathbb{N}\) be closed, i.e. \(d \omega =0\). 
Then \(\omega\) is also exact, more precisely we have
\begin{equation}
\omega=d \int_{0}^1 \iota^*_t i_X f^* \omega dt,
\end{equation}
where \(X\), \(\iota_t\) for \(t\in\mathbb{R}\) and \(f\) are given by
 \begin{align}
 &X: \mathbb{R}\times\mathcal{V}\rightarrow \mathbb{R}\times\mathcal{V},\\
 &\hspace{2cm} (t,B)\mapsto (1,0) \\
&\forall t \in \mathbb{R}: \iota_t: \mathcal{V}\rightarrow \mathbb{R}\times\mathcal{V},\\
&\hspace{2cm} B\mapsto (t,B)\\
&f:\mathbb{R}\times \mathcal{V}\mapsto \mathcal{V},\\
&\hspace{2cm} (t,B) \mapsto t B\\
&i_W: \Omega^p\rightarrow \Omega^{p-1},\\
&\hspace{2cm} \omega \mapsto ((A;Y_1,\dots, Y_{p-1})\mapsto \omega_A(W,Y_1,\dots,Y_{p-1}))
 \end{align}
\end{Lemma}
For a proof see section \ref{sec:proof of poincare} of the appendix. This 
lemma gives the next definition meaning.

\begin{Def}[antiderivative of a closed \(p\) form]\label{antiderivative}
For a closed exterior form \(\omega\in\Omega^{p}\) we define the form \(\Pi [\omega]\)
\begin{equation}
\Omega^{p-1}\ni\Pi\![\omega]:=\int_{0}^1 \iota^*_t i_X f^* \omega dt.
\end{equation}
For \(A,B_1,\dots , B_{p-1}\in\mathcal{V}\) it takes the form 
\begin{equation}
\Pi\![\omega]_A(B_1,\dots, B_{p-1})=\int_0^1 t^{p-1} \omega_{tA}(A,B_1,\dots, B_{p-1})dt.
\end{equation}
By lemma \ref{lem poincare} we know \(d\Pi [\omega]=\omega\) if \(d\omega=0\).
\end{Def}

Now we found two one forms each produces \(c\) when the exterior derivative is taken. The next lemma informs us about their relationship.

\begin{Lemma}[inversion of lemma \ref{connection between c and the relative phase}]
The following equality holds
\begin{equation}
\chi=2 \Pi\![c].
\end{equation}
\end{Lemma}
\begin{proof}
By definition \ref{antiderivative} of \(\Pi\) and 
lemma \ref{connection between c and the relative phase}
we have \(d(\chi-2 \Pi\![c])=0\). Hence, 
by the Poincaré lemma 
\ref{lem poincare}, we know that there is 
\(v:\mathcal{V}\rightarrow \mathbb{R}\) such that
\begin{equation}
dv=\chi-2 \Pi\![c]
\end{equation}%{def relative phase}
holds. Using the definition \ref{def relative phase} of \(z\), 
 the parallel transport equation \eqref{diff s hat} 
 translates into the 
following ODE for \(z\):
\begin{equation}
\partial_B \ln z(0,B)=0, \quad \partial_\varepsilon \ln z(A,(1+\varepsilon)A)|_{\varepsilon =0}=0
\end{equation}
for all \(A,B\in\mathcal{V}\). Therefore have
\begin{equation}
\chi_0(B)=0=\Pi\![c]_0(B), \quad \chi_{A}(A)=0=\Pi\![c]_A(A),
\end{equation}
which implies
\begin{equation}
\partial_\varepsilon v_{\varepsilon A}|_{\varepsilon=0}=0, 
\quad \partial_\varepsilon v_{A+\varepsilon A}|_{\varepsilon=0}=0.
\end{equation}
In conclusion, \(v\) is constant.
\end{proof}


From this point on we will assume the existence of  a function \(c^+\) fulfilling \eqref{c+ 1},\eqref{c+ 2} and \eqref{c+ 3}.
Recall property \eqref{c+ 2}: 
\begin{equation}
\forall A,F,G,H: \partial_H c_{A+H}^+(F,G)=\partial_G c^+_{A+G}(F,H).
\end{equation}

For a fixed \(F\in\mathcal{V}\), this condition can be 
read as \(d( c^+_{\cdot} (F,\cdot))=0\). As a 
consequence we can apply Poincaré's lemma 
\ref{lem poincare} to define a one form.

\begin{Def}[integral of the causal splitting]
For any \(A,F\in\mathcal{V}\), we define

\begin{equation}\label{eq: def beta}
\beta_A(F):=2 \Pi\![c^+_{\cdot}(F,\cdot)]_A.
\end{equation}
\end{Def}

\begin{Lemma}[relation between the integral of the causal splitting and the phase integral]
The following two equations hold:
\begin{align}\label{beta c}
&d \beta=-2 c,\\
&d(\beta +\chi)=0.
\end{align}
\end{Lemma}
\begin{proof}
We start with the exterior derivative of \(\beta\). Pick \(A,F,G\in\mathcal{V}\):
\begin{align}
d\beta_A(F,G)=\partial_F \beta_{A+F}(G)-\partial_G \beta_{A+G}(F)\\
=d\Big(2\Pi\![c^+_\cdot(G,\cdot)]\Big)_A(F)-d\Big(2\Pi\![c^+_\cdot(F,\cdot)]\Big)_A(G)\\
=2 c^+_A(G,F)-2 c_A^+(F,G)\overset{\eqref{c+ 1}}{=}-2 c_A(F,G).
\end{align}
This proves the first equality. The second equality follows directly by \(d \chi=2 c\).
\end{proof}

\begin{Def}[corrected lift]
Since \(\beta+\chi\) is closed, we may use lemma \ref{lem poincare} again to define the phase
\begin{equation}\label{def alpha}
\alpha:=\Pi\![\beta+\chi].
\end{equation}
Furthermore, for all \(A,B\in\mathcal{V}\) we define the corrected second quantised scattering operator 
\begin{align}\label{eq def tilde S}
&\tilde{S}_{0,A}:=e^{-\alpha_A} \hat{S}_{0,A},\\
&\tilde{S}_{A,B}:=\tilde{S}^{-1}_{0,A}\tilde{S}_{0,B}.
\end{align}
\end{Def}

Using this definition one immediately gets:
\begin{Corollary}[group structure of the corrected lift]\label{cor: geometry group structure}
We have\\
 \(\tilde{S}_{A,B} \tilde{S}_{B,C}=\tilde{S}_{A,C}\) for all \(A,B,C\in\mathcal{V}\).
\end{Corollary}



\begin{Thm}[causality of the corrected lift]\label{thm: geometry causality}
The corrected second quantised scattering operator fulfils the following causality condition for all \(A,F,G\in \mathcal{V}\) such that \(F\prec G\):
\begin{equation}
\tilde{S}_{A,A+F}=\tilde{S}_{A+G,A+G+F}.
\end{equation}
\end{Thm}
\begin{proof}
Let \(A,F,G\in\mathcal{V}\) such that \(F\prec G\). For the first quantised scattering operator we have
\begin{equation}
S_{A+G,A+G+F}=S_{A,A+F},
\end{equation}
which we proved in remark \ref{rmk phase construction}. 
So that by definition of \(\overline{S}\) we obtain
\begin{equation}\label{s bar causal}
\overline{S}_{A+G,A+G+F}=\overline{S}_{A,A+F}.
\end{equation}
Therefore any lift this equality is true up to a phase, meaning that 

\begin{equation}\label{f causal}
f(A,F,G):=\frac{\tilde{S}_{A+G,A+G+F}}{\tilde{S}_{A,A+F}}
\end{equation}
is well-defined. We see immediately
\begin{equation}\label{vanish at axis}
f(A,0,G)=1=f(A,F,0).
\end{equation}

Pick \(F_1,F_2\prec G_1,G_2\). We abbreviate \(F=F_1+F_2, G=G_1+G_2\) and we calculate
\begin{align}
&f(A,F,G)=\frac{\tilde{S}_{A+G,A+F+G}}{\tilde{S}_{A,A+F}}\\
&=\frac{\tilde{S}_{A+G,A+F+G}}{\tilde{S}_{A+G_1,A+G_1+F}}\frac{\tilde{S}_{A+G_1,A+G_1+F}}{\tilde{S}_{A,A+F}}\\
&=\frac{\tilde{S}_{A+G,A+G+F_1} \tilde{S}_{A+G+F_1,A+F+G}}{\tilde{S}_{ A+G_1,A+F_1+G_1} \tilde{S}_{ A+G_1+F_1,A+G_1+F}}  \frac{\tilde{S}_{A+G_1,A+G_1+F}}{\tilde{S}_{A,A+F}}\\
&=\frac{\tilde{S}_{A+G,A+G+F_1}}{\tilde{S}_{A+G_1,A+F_1+G_1}} \frac{\tilde{S}_{A+G+F_1,A+F+G}}{\tilde{S}_{A+G_1+F_1,A+G_1+F}}  f(A,G_1,F_1+F_2)\\
&=f(A+G_1,F_1,G_2)f(A+G_1+F_1,G_2,F_2)
 f(A,G_1,F_1+F_2).
\end{align}
Taking the mixed logarithmic derivative we find:
\begin{equation}\label{shift to small G,F}
\partial_{F_2}\partial_{G_2}\ln f(A,F_1+F_2,G_1+G_2)=\partial_{F_2}\partial_{G_2}\ln f(A+F_1+G_1,F_2,G_2).
\end{equation}
Next we pick \(F_2=\alpha_1 F_1\) and \(G_2=\alpha_2 G_1\) 
for \(\alpha_1,\alpha_2\in\mathbb{R}^+\) small enough so that
\((A+(1+\alpha_1)F_1+(1+\alpha_2)G_1,A+F_1+G_1),(A+(1+\alpha_1)F_1+(1+\alpha_2)G_1,A+F_1+(1+\alpha_2)G_1),
 (A+(1+\alpha_1)F_1+(1+\alpha_2)G_1,A+(1+\alpha_1)F_1+G_1)\in\dom\overline{S}\) holds.
 %\begin{align}
 %\|1-S_{A+F_1+F_2+G_1+G_2,A+F_1+G_1}\|<1\\
 %\|1-S_{A+F_1+F_2+G_1+G_2,A+F_1+G_1+G_2}\|<1\\
 %\|1-S_{A+F_1+F_2+G_1+G_2,A+F_1+F_2+G_1}\|<1
 %\end{align} 
 %hold. 
 We abbreviate \(A'=A+G_1+F_1\), use 
 the definition of \(z\) \eqref{def z} and compute
 
 \begin{align}\notag
 &f(A',F_2,G_2)\\\notag
 &\overset{\eqref{eq def tilde S}}{=}
 \exp(-\alpha_{A'+F_2+G_2}+\alpha_{A'+G_2}+\alpha_{A'+F_2}-\alpha_{A'})\\
 &\hspace{2cm}\times\frac{\hat{S}_{0,A'+G_2}^{-1}\hat{S}_{0,A'+G_2+F_2}}{\hat{S}_{0,A'}^{-1}\hat{S}_{0,A'+F_2}}
 \\\notag
 &\overset{\eqref{def z}}{=}
 \exp(-\alpha_{A'+F_2+G_2}+\alpha_{A'+G_2}+\alpha_{A'+F_2}-\alpha_{A'})\\
 &\hspace{2cm}\times \frac{z(A'+G_2,A'+G_2+F_2) }{z(A',A'+F_2)} \frac{\overline{S}_{A'+G_2,A'+G_2+F_2}}{\overline{S}_{A',A'+F_2}}\\\notag
 &\overset{F_2\prec G_2 }{=}\exp(-\alpha_{A'+F_2+G_2}+\alpha_{A'+G_2}+\alpha_{A'+F_2}-\alpha_{A'})\\
 &\hspace{2cm}\times \frac{z(A'+G_2,A'+G_2+F_2) }{z(A',A'+F_2)}
 \end{align}

Most of the factors do not depend on both \(F_2\) and 
\(G_2\), so taking the mixed logarithmic derivative things 
simplify:
\begin{align}\notag
&\partial_{G_2}\partial_{F_2} \ln f(A',F_2,G_2)= \\
&\partial_{G_2}\partial_{F_2} ( -\alpha_{A'+F_2+G_2} + \ln z(A'+G_2,A'+G_2+F_2))\\
&\overset{\eqref{def alpha}, \eqref{de chi}}{=}  \partial_{G_2} (-\beta_{A'+G_2}(F_2)-\chi_{A'+G_2}(F_2) + \chi_{A'+G_2}(F_2))\\
&\overset{\eqref{eq: def beta}}{=}-2 c^+_{A'}(F_2,G_2)\overset{F_2\prec G_2, \eqref{c+ 3}}{=}0.
\end{align}
So by \eqref{shift to small G,F} we also have
\begin{align}
\partial_{F_2}\partial_{G_2}\ln f(A,F_1+F_2,G_1+G_2)=0\\
=\partial_{\alpha_1}\partial_{\alpha_2}\ln f(A,F_1(1+\alpha_1),G_1(1+\alpha_2)).
\end{align}
Using this then we can integrate and obtain
\begin{align}
&0=\int_{-1}^0d \alpha_1 \int_{-1}^0d \alpha_2  \partial_{\alpha_1}\partial_{\alpha_2}\ln f(A,F_1(1+\alpha_1),G_1(1+\alpha_2))\\
&=\ln f(A,F_1,G_1)-\ln f(A,0,G_1)-\ln f(A,F_1,0)\\\notag 
&\hspace{3cm}+ \ln f(A,0,0)\\
&\overset{\eqref{vanish at axis}}{=}\ln f(A,F_1,G_1).
\end{align}
Recalling equation \eqref{f causal}, the definition of \(f\),  this ends our proof.
\end{proof}

Next, we investigate the current associated with \(\tilde{S}\).


\begin{Thm}[evaluation of the current of the corrected lift]\label{thm geometry current}
For general \(A,F\in\mathcal{V}\) we have
\begin{equation}
j_A^{\tilde{S}}(F)=-i\beta_A(F).
\end{equation}
So in particular for \(G\in\mathcal{V}\)
\begin{equation}
\partial_G j_{A+G}^{\tilde{S}}(F)=-2i c^+_A(F,G).
\end{equation}
holds.
\end{Thm}
\begin{proof}
Pick \(A,F\in\mathcal{V}\) as in the theorem. We calculate
\begin{align}
i\partial_F \ln \left\langle\Omega, \tilde{S}_{A,A+F}\Omega\right\rangle\\
\overset{\eqref{eq def tilde S}}{=}i\partial_F\left( -\alpha_{A+F}-\alpha_A + \ln \left\langle\Omega, \hat{S}_{0,A}^{-1} \hat{S}_{0,A+F}\Omega\right\rangle\right)\\
\overset{\eqref{def z}}{=}i\partial_F\left( -\alpha_{A+F}+\ln z(A,A+F) + \ln \left\langle\Omega, \overline{S}_{A,A+F}\Omega\right\rangle\right)
\end{align}
The last summand vanishes, as can be seen by the following calculation
\begin{align}
\partial_{F} \ln \left\langle \Omega, \overline{S}_{A,A+F}\Omega\right\rangle\\
=i\partial_F\ln \det_{\mathcal{H}^-} (P^-S_{A,A+F}P^-\AG(P^-S_{A,A+F}P^-)^{-1})\\
\overset{\eqref{def AG}}{=}i\partial_F\ln \det_{\mathcal{H}^-} |P^-S_{A,A+F}P^-|\\
=\frac{i}{2} \partial_F \ln \det_{\mathcal{H}^-} ((P^- S_{A,A+F}P^-)^*P^- S_{A,A+F}P^-)\\
=\frac{i}{2} \partial_F \det_{\mathcal{H}^-} (P^- S_{A+F,A}P^-S_{A,A+F}P^-)\\
=\frac{i}{2}\tr(\partial_F P^-S_{A+F,A}P^-S_{A,A+F}P^-)\\
=\frac{i}{2}\tr(\partial_F P^-S_{A,A+F}P^-+\partial_F P^-S_{A+F,A}P^-)=0\end{align}
where we made use of \eqref{diff det}.
Theorem \ref{thm smoothness of S} serves 
to justify the necessary regularity.
So we are left with
\begin{align}
j_A(F)=i\partial_F (-\alpha_{A+F}+\ln z(A,A+F))\\
=i(-\beta_A(F)-\chi_A(F)+\chi_A(F))=-i\beta_A(F).
\end{align}

Finally by taking the derivative with respect to \(G\in\mathcal{V}\) and using the definition of \(\beta\) we find
\begin{equation}
\partial_G j_{A+G}(F)=-2i c_A^+(F,G).
\end{equation}

\end{proof}

\begin{proof}[proof of theorem \ref{thm: geometry}]
  The operator \(tilde{S}\) constructed in this section 
  fulfills properties \eqref{prop S tilde 1} and 
  \eqref{prop S tilde 2} by corollary \ref{cor: geometry group structure}
  and theorem \ref{thm: geometry causality}. The characterisation 
  of the current \eqref{jurrent S tilde} follows form 
  theorem \ref{thm geometry current} and the properties of 
  \(c^+\), \eqref{c+ 1} to \eqref{c+ 3}.
\end{proof}


\section[Analyticity of the Scattering Operator][Analyticity]{Analyticity of the Scattering Operator}


In this chapter we will present a relatively simple 
formula for the second quantised scattering operator 
in terms of the one-particle scattering operator. 
This formula is valid for small external fields, where 
``small'' will be made precise later. The formula has 
implications for the analyticity of the second quantised 
scattering operator for general external fields, which 
we will also present. Also this chapter is concerned 
with the scattering regime, hence we will be working 
with a Hilbert space \(\mathcal{H}\) which can be 
thought \(\mathcal{H}_{\Sigma}\), where \(\Sigma\)
is a Cauchy surface prior to any external field 
we are going to consider in this section, and 
the standard polarisation and its projectors 
\(P^\pm\). The shorthand defined next will turn out 
to be useful. Let \(B:\mathcal{H}\rightarrow \mathcal{H}\)
be linear and bounded, then we introduce 

\begin{equation}
  B_{\#,\tilde{\#}}=P^{\#}B P^{\tilde{\#}},
\end{equation}
where \(\#,\tilde{\#}\in \{+,-\}\) holds.
Recall the definition of Fock space in this setting 

\begin{equation}
  \mathcal{F}:=\bigoplus_{m,p=0}^\infty \left(\mathcal{H}^+ \right)^{\wedge m} \otimes \left(\overline{\mathcal{H}^- }\right)^{\wedge p},
\end{equation}
where \(\bigoplus\) is the Hilbert space direct sum. 
We denote the sectors of Fock space of fixed particle
numbers by \(\mathcal{F}_{m,p}\). The element of
\(\mathcal{F}_{0,0}\) of norm \(1\) will be 
denoted by \(\Omega\).

The
annihilation operator \(a\) acts on an arbitrary sector of Fock space
\(\mathcal{F}_{m,p}\), for any \(m,p\in\mathbb{N}_0\) with the operator type

\begin{align}
a: &\overline{\mathcal{H}}\times \mathcal{F}_{m,p} \rightarrow \mathcal{F}_{m-1,p}\oplus \mathcal{F}_{m,p+1},
\end{align}
where the second argument is usually not included in the parenthesis, as is 
common practice for bounded operators on a Hilbert space.
We start out by defining \(a\) on elements of 
\(\{\bigwedge_{l=1}^m \varphi_l \otimes \bigwedge_{c=1}^p \phi_c  \mid \forall c:  \varphi_c \in \mathcal{H}^+, \phi_c \in \mathcal{H}^-   \}\)
which spans a dense subset of \(\mathcal{F}_{m,p}\), then one continues this operator uniquely by 
linearity and finally by the bounded linear extension theorem to all of \(\mathcal{F}_{m,p}\) and then 
again by linearity to all of \(\overline{\mathcal{H}}\otimes \mathcal{F}_{m,p}\).
\begin{align}
&a(\phi)  \bigwedge_{l=1}^m \varphi_l \otimes \bigwedge_{c=1}^p \phi_c\\
&= \sum_{k=1}^m (-1)^{1+k} \langle P^+ \phi, \varphi_k\rangle \bigwedge_{\overset{l=1}{l\neq k}}^m \varphi_l \otimes \bigwedge_{c=1}^p \phi_c + \bigwedge_{l=1}^m \varphi_l \otimes P^- \phi \wedge \bigwedge_{c=1}^p \phi_c
\end{align}

where \(\langle, \rangle\) denotes that the scalar product of 
\(\mathcal{H}\). The first summand on the right hand side is 
taken to vanish for \(m=0\). The operator norm of \(a\) is 
given by 
\begin{equation}
  \|a(\phi)\|=\|\phi\|.
\end{equation}

The operators \(a\) and its adjoint \(a^*\) fulfil the
canonical anticommutation relations:
\begin{align}
  \forall \phi,\psi: \{a(\phi),a^*(\psi)\}=a(\phi)a^*(\psi)+a^*(\psi)a(\phi)=\langle \phi,\psi\rangle\\
  \forall \phi,\psi: \{a^*(\phi),a^*(\psi)\}=\{a(\phi),a(\psi)\}=0.
\end{align}

Now for the construction of the second quantised 
\(S\)-matrix please 
recall the lift condition 

\begin{align}
\forall \phi\in \mathcal{H}:& \hspace{0.5cm} \tilde{S}^A \circ a(\phi)=a\left( S^A \phi \right)  \circ \tilde{S}^A\tag{\ref{lift condition}},
\end{align}
which is to be satisfied by any lift \(\tilde{S}^A\)  
of the one-particle scattering matrix \(S^A\).

In the appendix we carry out an explicit, albiet heuristic, 
construction of a power series expression of a lift of \(S^A\)
 in chapter 
\ref{sec:heuristic construction} that culminates in 
the formula which will be directly verified in 
this chapter.

In order to state this formula, we have to introduce 
some more notation.

\subsection{Differential second quantisation}

Let \(B:\mathcal{H}\rightarrow\mathcal{H}\) be a bounded
operator on \(\mathcal{H}\), such that \(i B\) is self 
adjoint and \(B_{+-}\) is a Hilbert-Schmidt operator. 
We would like to construct a version \(\mathrm{d}\Gamma(B)\) 
of \(B\) that acts on Fock space and also is skew adjoint.
The proof of the skew adjointness of 
\(\mathrm{d}\Gamma(B)\) is a bit lengthy, as is typical 
of such proofs. Even though one might speed it 
up a little by using the tools available e.g. in 
\cite{derezinski2013mathematics} the author is of the 
opinion that it is instructive to give a direct proof.
In this section we will associate with every set 
\(C\subset\mathbb{N}\) such that \(|C|<\infty\) the 
sequence \((C_k)_{1\le k\le |C|}\) such that
\begin{align}
  \forall 1\le k \le |C|: C_k\in C\\
  \forall 1\le k<l\le |C|: C_k<C_l
\end{align}
hold. This notation is confined to within the 
proofs of this section.
The strategy of this section is to construct an operator in 
two steps that is essentially self adjoint on the domain 
of the Fock space of 
finitely many particles, a dense subset of Fock space. It is 
denoted by

\begin{Def}
\begin{equation}
\mathcal{F}':=\bigobot_{m,p=0}^\infty \mathcal{F}_{m,p},
\end{equation}
where \(\bigobot\) refers to the algebraic direct sum.
Furthermore, we define
\begin{equation}
\mathcal{F}^0\subset \mathcal{F}'
\end{equation}
such that for each element \(\alpha\in\mathcal{F}^0\) there is 
a basis an ONB \((\tilde{\varphi}_{k})_{k\in\mathbb{N}}\)
of \(\mathcal{H}^+\) and an ONB 
\((\tilde{\varphi}_{-k})_{k\in\mathbb{N}}\)
of \(\mathcal{H}^-\) such that 
\begin{align}
  &\alpha\in \mathrm{span}\Bigg\{\prod_{k=1}^m \!a^*\!(\tilde{\varphi}_{L_k}\!)\!\prod_{c=1}^p\!\! a(\tilde{\varphi}_{-C_c})\Omega \\
  &\hspace{0.5cm}\mid m,p \in \mathbb{N}, (L_k)_k, (C_c)_c \subset \mathbb{N}, |L|\!=\!m,|C|\!=\!p\! \Bigg\}
\end{align}
holds.
\end{Def}

Constructing \(\mathrm{d}\Gamma\) piecewise turns out to be advantageous. 

\begin{Def}
We define the following operators of type \(\mathcal{F}^0\rightarrow \mathcal{F}\)

\begin{align}\label{predefdGamma}
\mathrm{d}\Gamma(B_{++})&:= \sum_{n\in\mathbb{N}}  a^*(B_{++} \varphi_n) a(\varphi_n) \\
\mathrm{d}\Gamma(B_{--})&:= -\sum_{n\in\mathbb{N}}   a(\varphi_{-n})a^*(B_{--} \varphi_{-n}) \\
\mathrm{d}\Gamma(B_{-+})&:= \sum_{n\in\mathbb{N}}  a^*(B_{-+}\varphi_{n}) a(\varphi_n)
\end{align}
where the sum converges in the strong operator topology and 
\((\varphi_n)_n \), \((\varphi_{-n})_n\) are arbitrary 
ONBs of \(\mathcal{H}^+\) and \(\mathcal{H}^-\).
\end{Def}



\begin{Lemma}\label{d Gamma norms}
The operators 
\(\mathrm{d}\Gamma(B_{++}),\mathrm{d}\Gamma(B_{--})\) and 
\(\mathrm{d}\Gamma(B_{-+})\) 
restricted to \(\mathcal{F}^0_{m,p}\) have the following 
type
\begin{align}
\mathrm{d}\Gamma(B_{++})|_{\mathcal{F}^0_{m,p}}&: \quad \mathcal{F}^0_{m,p} \rightarrow \mathcal{F}_{m,p}\\
\mathrm{d}\Gamma(B_{--})|_{\mathcal{F}^0_{m,p}}&: \quad \mathcal{F}^0_{m,p} \rightarrow \mathcal{F}_{m,p}\\
\mathrm{d}\Gamma(B_{-+})|_{\mathcal{F}^0_{m,p}}&: \quad \mathcal{F}^0_{m,p} \rightarrow \mathcal{F}_{m-1,p-1}
\end{align}
 and fulfil
the following bounds for all \(m,p\)
\begin{align}
\|\mathrm{d}\Gamma(B_{++})|_{\mathcal{F}^0_{m,p}}\|&\le (m+4)\|B_{++}\|\\
\|\mathrm{d}\Gamma(B_{--})|_{\mathcal{F}^0_{m,p}}\|&\le (p+4)\|B_{--}\|\\
\|\mathrm{d}\Gamma(B_{-+})|_{\mathcal{F}^0_{m,p}}\|&\le 2 \|B_{-+}\|_{I_2},
\end{align}
Moreover the operator \(\mathrm{d}\Gamma(B_{-+})|_{\mathcal{F}^0_{m,p}}\)
also assumes the following form
\begin{equation}\label{dGamma form for adjoint}
  \mathrm{d}\Gamma(B_{-+})|_{\mathcal{F}^0_{m,p}}=\!-\!\sum_{k\in\mathbb{N}}a^*(\varphi_{-k})a(B_{+-}\varphi_{-k})|_{\mathcal{F}^0_{m,p}}.
\end{equation}
The equality of operators can then be continued to all of \(\mathcal{F}\).
\end{Lemma}
\begin{proof}
Pick \(\alpha\in\mathcal{F}^0_{m,p}\) for \(m,p\in\mathbb{N}_0\), \(\alpha\) can be expressed in terms of some ONB 
\((\tilde{\varphi}_k)_{k\in\mathbb{N}}\) of \(\mathcal{H}^+\) and \((\tilde{\varphi}_{-k})_{k\in\mathbb{N}}\) of \(\mathcal{H}^-\)
\begin{equation}
\alpha=\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\!\!\!\!\!\!\alpha_{L,C} \prod_{l=1}^m a^*(\tilde{\varphi}_{L_l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C_c}) \Omega.
\end{equation}
In this expansion only finitely many coefficients \(\alpha_{\cdot, \cdot}\) are nonzero. Our operators all map the vacuum onto the zero vector, so commuting them 
through the products of of creation and annihilation operators in the expansion of \(\alpha\) we can make the action of them more explicit:
\begin{align}\nonumber
\mathrm{d}\Gamma(B_{++}) \alpha =\hspace{-0.5cm} &\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\!\!\!\!\!\!\alpha_{L,C} \sum_{b=1}^m 
\prod_{l=1}^{b-1} a^*(\tilde{\varphi}_{L_l})  \sum_{n\in\mathbb{N}} a^*(B_{++}\varphi_n) \langle \varphi_n, \tilde{\varphi}_{L_b}\rangle \\
&\times \prod_{l=b+1}^m a^*(\tilde{\varphi}_{l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C_c}) \Omega\\
=\!\!\!\!\!\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\!\!\!\!\!\!\alpha_{L,C} \sum_{b=1}^m 
&\prod_{l=1}^{b-1} a^*(\tilde{\varphi}_{L_l})  a^*(B_{++} \tilde{\varphi}_{L_b})  \!\!\!
\prod_{l=b+1}^m a^*(\tilde{\varphi}_{l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C_c}) \Omega.
\end{align}
We notice, that \(\mathrm{d}\Gamma(B_{++})\alpha \in \mathcal{F}_{m,p}\) holds. What is left to show for the first operator is therefore
its norm. For estimating this we see that \(B_{++}\) in the last line can be replaced by 
\begin{equation}
B^L_{L_b}:=\left(1-\sum_{\overset{l=1}{l\neq b}}^m |\tilde{\varphi}_{L_l}\rangle \langle \tilde{\varphi}_{L_l}|\right) B_{++},
\end{equation}
due to the antisymmetry of fermions. Expanding 
\begin{align}\nonumber
&\|\mathrm{d}\Gamma(B_{++})\alpha\|^2 = \langle \mathrm{d}\Gamma(B_{++})\alpha, \mathrm{d}\Gamma(B_{++})\alpha \rangle \\\nonumber
&= \hspace{-1cm}\sum_{\overset{L,C, L',C'\subset \mathbb{N}}{|L'|=|L|=m,|C'|=|C|=p}}\hspace{-1cm}\overline{\alpha_{L,C}}\alpha_{L',C'} \sum_{b,b'=1}^m 
\left\langle \prod_{l=1}^{b-1} a^*(\tilde{\varphi}_{L_l})  ~~ a^*(B^{L}_{L_b} \tilde{\varphi}_{L_b})\right.  \\\nonumber
&\prod_{l=b+1}^m a^*(\tilde{\varphi}_{L_l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C_c}) \Omega, 
\prod_{l=1}^{b'-1} a^*(\tilde{\varphi}_{L'_l})  ~~ a^*(B_{L'_{b'}}^{L'} \tilde{\varphi}_{L'_b})  \\
&\left.\prod_{l=b'+1}^m a^*(\tilde{\varphi}_{L'_l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C'_c}) \Omega\right\rangle
\end{align}
we see that in fact \(C\) and \(C'\) need to agree, because 
we can just commute the corresponding annihilation operators 
from one end of the 
scalar product to the other. Furthermore only a single 
wavefunction on each side of the scalar product is modified, 
this implies that in order for the
scalar product not to vanish \(|L\cap L'|\ge m-2\) has to 
hold. For the case  \(L\neq L'\) we split up the sum over sets 
into the sum over a new \(L\) such that \(|L|=m-2\) holds 
and an additional sum 
over four indices \(n_1<n_2, p_1<p_2\). 
The double sum over \(b,b'\) only has  
contribution where 
\(b=n_1\) or \(b=2_2\) and \(b'=p_1\) or \(b'=p_2\) 
are selected. Because each factor in the first half is
orthogonal to each other factor in this half and analogously 
for the second half, this will result in a sum of eight terms. 
In the case 
\(L'=L\) the full sum contributes, yielding 
\begin{align}\nonumber
&\|\mathrm{d}\Gamma(B_{++})\alpha\|^2 = \\\nonumber
&= \hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\sum_{\overset{n_1<n_2,p_1<p_2\in\mathbb{N}\backslash L }{\{n_1,n_2\}\neq \{p_1,p_2\}}}
\hspace{-0.4cm}\overline{\alpha_{L\cup\{n_1,n_2\},C}}\alpha_{L\cup\{p_1,p_2\},C}
\left[\begin{matrix}n_1\\n_2\end{matrix}\right]\left[\begin{matrix}p_1\\p_2\end{matrix}\right]\\\label{B++estimate}
  &\times \bigg(\langle \tilde{\varphi}_{n_1},\tilde{\varphi}_{p_1} \rangle \langle B^{L\cup\{n_1,n_2\}}_{n_2} \tilde{\varphi}_{n_2}, B^{L\cup\{p_1,p_2\}}_{p_2}\tilde{\varphi}_{p_2}\rangle\\
  &\hspace{1cm}-\langle \tilde{\varphi}_{n_1},B^{L\cup\{p_1,p_2\}}_{p_2}\tilde{\varphi}_{p_2} \rangle \langle B^{L\cup\{n_1,n_2\}}_{n_2} \tilde{\varphi}_{n_2}, \tilde{\varphi}_{p_1}\rangle \\
  &+\langle B^{L\cup\{n_1,n_2\}}_{n_1}\tilde{\varphi}_{n_1},\tilde{\varphi}_{p_1} \rangle \langle  \tilde{\varphi}_{n_2}, B^{L\cup\{p_1,p_2\}}_{p_2}\tilde{\varphi}_{p_2}\rangle\\
  &\hspace{1cm}-\langle B^{L\cup\{n_1,n_2\}}_{n_1} \tilde{\varphi}_{n_1},B^{L\cup\{p_1,p_2\}}_{p_2}\tilde{\varphi}_{p_2} \rangle \langle  \tilde{\varphi}_{n_2}, \tilde{\varphi}_{p_1}\rangle \\
  & +\langle \tilde{\varphi}_{n_1},B^{L\cup\{p_1,p_2\}}_{p_1}\tilde{\varphi}_{p_1} \rangle \langle B^{L\cup\{n_1,n_2\}}_{n_2} \tilde{\varphi}_{n_2}, \tilde{\varphi}_{p_2}\rangle\\
  &\hspace{1cm}-\langle \tilde{\varphi}_{n_1},\tilde{\varphi}_{p_2} \rangle \langle B^{L\cup\{n_1,n_2\}}_{n_2} \tilde{\varphi}_{n_2},B^{L\cup\{p_1,p_2\}}_{p_1} \tilde{\varphi}_{p_1}\rangle \\
  & +\langle B^{L\cup\{n_1,n_2\}}_{n_1} \tilde{\varphi}_{n_1},B^{L\cup\{p_1,p_2\}}_{p_1}\tilde{\varphi}_{p_1} \rangle \langle  \tilde{\varphi}_{n_2}, \tilde{\varphi}_{p_2}\rangle\\
  &\hspace{1cm}-\langle B^{L\cup\{n_1,n_1\}}_{n_1} \tilde{\varphi}_{n_1},\tilde{\varphi}_{p_2} \rangle \langle  \tilde{\varphi}_{n_2},B^{L\cup\{p_1,p_2\}}_{p_1} \tilde{\varphi}_{p_1}\rangle \bigg)\\
&+\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\hspace{-0.4cm} |\alpha_{L,C}|^2
 \sum_{b,b'=1}^m 
\left\langle \prod_{l=1}^{b-1} a^*(\tilde{\varphi}_{L_l})  ~~ a^*(B^{L}_{L_b} \tilde{\varphi}_{L_b})\right.  \\\nonumber
&\prod_{l=b+1}^m a^*(\tilde{\varphi}_{L_l}) \Omega, 
\prod_{l=1}^{b'-1} a^*(\tilde{\varphi}_{L_l})  ~~ a^*(B_{L_{b'}}^{L} \tilde{\varphi}_{L_b})  \left.\prod_{l=b'+1}^m a^*(\tilde{\varphi}_{L_l}) ) \Omega\right\rangle,
\end{align}
where 
\begin{equation}
\left[\begin{matrix}n_1\\n_2\end{matrix}\right]:=(-1)^{|\{l\in L \mid l<n_1\}|+|\{l\in L \mid l<n_2\}|}
\end{equation} 
keeps track of the number of anti commutations. This is 
non standard notation but it is meant to keep the notation
as compact as possible and its use is 
contained to this section.

Due to the antisymmetry each summand containing 
a factor without an occurrence of the \(B\) operator are only 
nonzero if \(n_1=p_1\) or \(n_2=p_2\). Each factor containing 
exactly one occurrence of \(B\) obtains a similar restriction. 
So we can split the block of terms into one corresponding 
to the two cases just mentioned. 

\begin{align}\nonumber
  &\|\mathrm{d}\Gamma(B_{++})\alpha\|^2 = \\\nonumber
  &= \hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\hspace{-0.2cm}\sum_{\overset{n_1<n_2,p_1<p_2\in\mathbb{N}\backslash L }{\{n_1,n_2\}\neq \{p_1,p_2\}}}
  \hspace{-0.4cm}\overline{\alpha_{L\cup\{n_1,n_2\},C}}\alpha_{L\cup\{p_1,p_2\},C}
\left[\begin{matrix}n_1\\n_2\end{matrix}\right]
\left[\begin{matrix}p_1\\p_2\end{matrix}\right]\\\label{B++ long estimate}
    &\times \bigg(
    -\langle \tilde{\varphi}_{n_1},B^{L\cup\{p_1,p_2\}}_{p_2}\tilde{\varphi}_{p_2} \rangle \langle B^{L\cup\{n_1,n_2\}}_{n_2} \tilde{\varphi}_{n_2}, \tilde{\varphi}_{p_1}\rangle 1_{n_1\neq p_1}\\
    &+\langle B^{L\cup\{n_1,n_2\}}_{n_1}\tilde{\varphi}_{n_1},\tilde{\varphi}_{p_1} \rangle \langle  \tilde{\varphi}_{n_2}, B^{L\cup\{p_1,p_2\}}_{p_2}\tilde{\varphi}_{p_2}\rangle 1_{n_2\neq p_1}\notag\\
    &+\langle \tilde{\varphi}_{n_1},B^{L\cup\{p_1,p_2\}}_{p_1}\tilde{\varphi}_{p_1} \rangle \langle B^{L\cup\{n_1,n_2\}}_{n_2} \tilde{\varphi}_{n_2}, \tilde{\varphi}_{p_2}\rangle 1_{n_1\neq p_2}\notag\\
    &-\langle B^{L\cup\{n_1,n_2\}}_{n_1} \tilde{\varphi}_{n_1},\tilde{\varphi}_{p_2} \rangle \langle  \tilde{\varphi}_{n_2},B^{L\cup\{p_1,p_2\}}_{p_1} \tilde{\varphi}_{p_1}\rangle 1_{n_2\neq p_2} \bigg)\notag\\
  &+\hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-1}}}\hspace{-0.2cm}\sum_{n\neq p\in\mathbb{N}\backslash L }
  \hspace{-0.4cm}\overline{\alpha_{L\cup\{n\},C}}\alpha_{L\cup\{p\},C}
\left[\begin{matrix}n\\p\end{matrix}\right] \langle B^{L\cup\{n\}}_{n} \tilde{\varphi}_{n}, B^{L\cup\{p\}}_{p}\tilde{\varphi}_{p}\rangle\label{B++ short estimate}\\
  &+\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\hspace{-0.4cm} |\alpha_{L,C}|^2
   \sum_{b,b'=1}^m 
  \left\langle \prod_{l=1}^{b-1} a^*(\tilde{\varphi}_{L_l})  ~~ a^*(B^{L}_{L_b} \tilde{\varphi}_{L_b})\right.  \label{B++ m squared term}\\\nonumber
  &\prod_{l=b+1}^m a^*(\tilde{\varphi}_{L_l}) \Omega, 
  \prod_{l=1}^{b'-1} a^*(\tilde{\varphi}_{L_l})  ~~ a^*(B_{L_{b'}}^{L} \tilde{\varphi}_{L_b})  \left.\prod_{l=b'+1}^m a^*(\tilde{\varphi}_{L_l}) ) \Omega\right\rangle,
\end{align}
where we also summarised the terms of the second block. the restrictions \(n_1<n_2\)
and \(p_1<p_2\) have the effect that the negative terms sum up to just one term
without restrictions, while the positive terms add up to two such terms. 



For the term \eqref{B++ short estimate} we add and subtract the 
term where \(n=p\). The enlarged sum can then be reformulated

\begin{align}\nonumber
&\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|L|=m-1}{|C|=p}}}\hspace{-0.1cm}\sum_{n,n'\in\mathbb{N}\backslash L} \hspace{-0.3cm}\overline{\alpha_{L\cup\{n\},C}}\alpha_{L\cup\{n'\},C} 
 \langle B^{L\cup\{n\}}_n \tilde{\varphi}_{n}, B^{L\cup\{n'\}}_{n'}\tilde{\varphi}_{n'}\rangle \left[\begin{matrix}n\\n'\end{matrix}\right]\\\nonumber
 &=\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m-1,|C|=p}}\left\|\sum_{n\in\mathbb{N}\backslash L}\alpha_{L\cup\{n\},C}  B^{L\cup\{n\}}_n \tilde{\varphi}_{n} \left[\begin{matrix}n\\0\end{matrix}\right] \right\|^2\\\label{B++ first term}
&=\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|L|=m-1}{|C|=p}}}\left\|\left(1-\sum_{l\in L}|\tilde{\varphi}_l\rangle\langle \tilde{\varphi}_l | \right)B_{++}\hspace{-0.2cm}\sum_{n\in\mathbb{N}\backslash L}\hspace{-0.2cm}\alpha_{L\cup\{n\},C}  \tilde{\varphi}_{n} \left[\begin{matrix}n\\0\end{matrix}\right]\right\|^2
\end{align}
Now the operator product inside the norm has operator norm \(\|B_{++}\|\) and so we can estimate the whole object by
\begin{equation}\label{B++estimatefinal1}
\eqref{B++ first term}\le \|\alpha\|^2 \|B_{++}\|^2.
\end{equation}
We need to estimate the term we added to complete the norm square in \eqref{B++ short estimate}, 
this is done as follows
\begin{align}\nonumber
&\sum_{\overset{L,C\subset\mathbb{N}}{|L|=m-1,|C|=p}} \hspace{-0.4cm}\sum_{n\in\mathbb{N}\backslash L} |\alpha_{L\cup\{n\},C}|^2 \|B_n^{L\cup\{n\}} \tilde{\varphi}_{n}\|^2\\\label{B++estimatefinal2}
&\le \hspace{-0.6cm}\sum_{\overset{L,C\subset\mathbb{N}}{|L|=m,|C|=p}}\hspace{-0.5cm} \|B_{++}\|^2|\alpha_{L,C}|^2 =\|\alpha\|^2 \|B_{++}\|^2.
\end{align}
For \eqref{B++ long estimate} and the following 3 lines we notice that 
we may replace all  one-particle operators with \(B_{++}\), since 
the projector acts as the identity in these cases. Subsequently, the 
two terms of equal sign are identical except for the extra 
condition on the sum, resulting in 

\begin{align}
  &\eqref{B++ long estimate} =\notag\\
  &\hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\hspace{-0.2cm}\sum_{\overset{n_1<n_2,p_1<p_2\in\mathbb{N}\backslash L }{\{n_1,n_2\}\neq \{p_1,p_2\}}}
  \hspace{-0.4cm}\overline{\alpha_{L\cup\{n_1,n_2\},C}}\alpha_{L\cup\{p_1,p_2\},C}
\left[\begin{matrix}n_1\\n_2\end{matrix}\right]\left[\begin{matrix}p_1\\p_2\end{matrix}\right]\\
    &\times \bigg(
    \langle B_{++}\tilde{\varphi}_{n_1},\tilde{\varphi}_{p_1} \rangle \langle  \tilde{\varphi}_{n_2}, B_{++}\tilde{\varphi}_{p_2}\rangle (1_{n_1\neq p_2}+1_{n_2\neq p_1})\label{skew adj est B++1}\\
    &-\langle \tilde{\varphi}_{n_1},B_{++}\tilde{\varphi}_{p_2} \rangle \langle B_{++} \tilde{\varphi}_{n_2}, \tilde{\varphi}_{p_1}\rangle(1_{n_1\neq p_1}+1_{n_2\neq p_2})\bigg).\label{skew adj est B++2}
\end{align}

Next, we are going to repeatedly add and subtract terms, such that we may
factorise the \(n\) and the \(p\) sums. In order to do so we impose the 
condition \(\{n_1,n_2\}\neq \{p_1,p_2\}\) in the sum by the factor \(1-\delta_{n_1,p_1}\delta_{n_2,p_2}\). 
Similarly we rewrite the other conditions in the following way
\begin{align}
  1_{n_1\neq p_2}+1_{n_2\neq p_1}=2-\delta_{n_1,p_2}-\delta_{n_2,p_1},\\
  1_{n_1\neq p_1}+1_{n_2\neq p_2}=2-\delta_{n_1,p_1}-\delta_{n_2,p_2}.
\end{align}

These are to be multiplied by \(1-\delta_{n_1,p_1}\delta_{n_2,p_2}\)
resulting in the two expressions
\begin{align}\label{skew adj est cases 1}
  2-\delta_{n_1,p_2}-\delta_{n_2,p_1}-2 \delta_{n_1,p_1}\delta_{n_2,p_2}\\
  2-\delta_{n_1,p_1}-\delta_{n_2,p_2},
\end{align}
wehre the upper expression yields the restrictions on the sum of 
over \(\langle B_{++}\tilde{\varphi}_{n_1},\tilde{\varphi}_{p_1} \rangle \langle  \tilde{\varphi}_{n_2}, B_{++}\tilde{\varphi}_{p_2}\rangle\)
and the lower expression analogously for 
\(\langle \tilde{\varphi}_{n_1},B_{++}\tilde{\varphi}_{p_2} \rangle \langle B_{++} \tilde{\varphi}_{n_2}, \tilde{\varphi}_{p_1}\rangle\).
For the term without further restrictions we may add the sum of the 
terms \eqref{skew adj est B++1} and \eqref{skew adj est B++2}, the rest 
is treated separately.

%So in a first step we add and subtact the 
%terms where \(\{n_1,n_2\}\cap \{p_1,p_2\}\neq \emptyset\):

%\begin{align}
%  &\eqref{B++ long estimate} =\notag\\
%  &2\hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\hspace{-0.2cm}\sum_{\overset{n_1<n_2\in\mathbb{N}\backslash L }{p_1<p_2\in\mathbb{N}\backslash L }}
%  \hspace{-0.4cm}\overline{\alpha_{L\cup\{n_1,n_2\},C}}\alpha_{L\cup\{p_1,p_2\},C}
%\left[\begin{matrix}n_1\\n_2\end{matrix}\right]\left[\begin{matrix}p_1\\p_2\end{matrix}\right]\\
%    &\times \bigg(
%    \langle B_{++}\tilde{\varphi}_{n_1},\tilde{\varphi}_{p_1} \rangle \langle  \tilde{\varphi}_{n_2}, B_{++}\tilde{\varphi}_{p_2}\rangle
%    -\langle \tilde{\varphi}_{n_1},B_{++}\tilde{\varphi}_{p_2} \rangle \langle B_{++} \tilde{\varphi}_{n_2}, \tilde{\varphi}_{p_1}\rangle\bigg)\\
%    &\times (1- \delta_{n_1,p_1}-\delta_{n_1,p_2}-\delta_{n_2,p_1}-\delta_{n_2,p_2}+\delta_{n_1,p_1}\delta_{n_2,p_2}).
%\end{align}
%These five terms will be estimated separately. 
The terms 
are all estimated after rewriting the scalar products as a 
single sum of two scalar products in \(\mathcal{H}^+\otimes \mathcal{H}^+\).

\(\boldsymbol{2:}\) 

\begin{align}
  &2\hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\hspace{-0.2cm}\sum_{\overset{n_1<n_2\in\mathbb{N}\backslash L }{p_1<p_2\in\mathbb{N}\backslash L }}
  \hspace{-0.4cm}\overline{\alpha_{L\cup\{n_1,n_2\},C}}\alpha_{L\cup\{p_1,p_2\},C}
\left[\begin{matrix}n_1\\n_2\end{matrix}\right]\left[\begin{matrix}p_1\\p_2\end{matrix}\right]\\
    &\times \bigg(
    \langle  B_{++}\tilde{\varphi}_{n_1},\tilde{\varphi}_{p_1} \rangle \langle  \tilde{\varphi}_{n_2}, B_{++}\tilde{\varphi}_{p_2}\rangle
    -\langle \tilde{\varphi}_{n_1},B_{++}\tilde{\varphi}_{p_2} \rangle \langle B_{++} \tilde{\varphi}_{n_2}, \tilde{\varphi}_{p_1}\rangle\bigg)\\
    &\hspace{-0.9cm}= 2 \!\!\!\!\!\!\!\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\!\!\!\!\!\bigg\langle \sum_{n_1<n_2\in\mathbb{N}\backslash L}
    \!\!\left[\begin{matrix}n_1\\n_2\end{matrix}\right]\alpha_{L\cup\{n_1,n_2\},C} B_{++}\tilde{\varphi}_{n_1}\otimes \tilde{\varphi}_{n_2}, \\
    &\hspace{3cm}\sum_{p_1<p_2\in\mathbb{N}\backslash L}\!\!\left[\begin{matrix}p_1\\p_2\end{matrix}\right]\alpha_{L\cup\{p_1,p_2\},C} \tilde{\varphi}_{p_1}\otimes B_{++}\tilde{\varphi}_{p_2}\bigg\rangle\\
    &\hspace{-0.9cm}-2 \!\!\!\!\!\!\!\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\!\!\!\!\!\bigg\langle \sum_{n_1<n_2\in\mathbb{N}\backslash L}
    \!\!\left[\begin{matrix}n_1\\n_2\end{matrix}\right]\alpha_{L\cup\{n_1,n_2\},C} \tilde{\varphi}_{n_1}\otimes B_{++}\tilde{\varphi}_{n_2}, \\
    &\hspace{3cm}\sum_{p_1<p_2\in\mathbb{N}\backslash L}\!\!\!\!\!\left[\begin{matrix}p_1\\p_2\end{matrix}\right]\alpha_{L\cup\{p_1,p_2\},C} B_{++}\tilde{\varphi}_{p_2}\otimes \tilde{\varphi}_{p_1}\bigg\rangle\\
    &\le 4 \|B_{++}\|^2 \|\alpha\|^2
\end{align}

\(\boldsymbol{\delta_{n_1,p_1}:}\) 
\begin{align}
  &\hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\hspace{-0.2cm}\sum_{\overset{n_1<n_2\in\mathbb{N}\backslash L }{p_1<p_2\in\mathbb{N}\backslash L }}
  \hspace{-0.4cm}\overline{\alpha_{L\cup\{n_1,n_2\},C}}\alpha_{L\cup\{p_1,p_2\},C}
\left[\begin{matrix}n_1\\n_2\end{matrix}\right]\left[\begin{matrix}p_1\\p_2\end{matrix}\right]\delta_{n_1,p_1}\\
    &\times 
    \langle \tilde{\varphi}_{n_1},B_{++}\tilde{\varphi}_{p_2} \rangle \langle B_{++} \tilde{\varphi}_{n_2}, \tilde{\varphi}_{p_1}\rangle\\
  &=\hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\hspace{-0.2cm}\sum_{n,p,l \in\mathbb{N}\backslash L }
  \hspace{-0.4cm}\overline{\alpha_{L\cup\{l,n\},C}}\alpha_{L\cup\{l,p\},C}
\left[\begin{matrix}0\\n\end{matrix}\right]\left[\begin{matrix}0\\p\end{matrix}\right]\\
    &\times 
    \langle \tilde{\varphi}_{l},B_{++}\tilde{\varphi}_{p} \rangle \langle B_{++} \tilde{\varphi}_{n}, \tilde{\varphi}_{l}\rangle\\
    &=
  \hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\hspace{-0.2cm}\sum_{l \in\mathbb{N}\backslash L }
\!\!\!\left\langle \tilde{\varphi}_{l} ,B_{++}\!\!\!\!\!\sum_{p\in\mathbb{N}\backslash L}\alpha_{L\cup \{l,p\},C}\!\!\left[\begin{matrix}0\\p\end{matrix}\right]\!\! \tilde{\varphi}_{p}  \!\!\!\right\rangle\\
&\hspace{2cm}\times \left\langle B_{++}\sum_{n\in\mathbb{N}\backslash L}\!\!\!\!\alpha_{L\cup \{l,n\},C}\left[\begin{matrix}0\\n\end{matrix}\right] \!\!\tilde{\varphi}_{n} , \tilde{\varphi}_{l}  \!\!\!\right\rangle\\
  &\le \|B_{++}\|^2 \|\alpha\|^2
\end{align}
\(\boldsymbol{-\delta_{n_1,p_2}-\delta_{n_2,p_1}:}\)
\begin{align}
&-\hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\hspace{-0.2cm}\sum_{\overset{n_1<n_2\in\mathbb{N}\backslash L }{p_1<p_2\in\mathbb{N}\backslash L }}
\hspace{-0.4cm}\overline{\alpha_{L\cup\{n_1,n_2\},C}}\alpha_{L\cup\{p_1,p_2\},C}
\left[\begin{matrix}n_1\\n_2\end{matrix}\right]\left[\begin{matrix}p_1\\p_2\end{matrix}\right](\delta_{n_1,p_2}+\delta_{n_2,p_1})\\
&\times 
\langle B_{++}\tilde{\varphi}_{n_1},\tilde{\varphi}_{p_1} \rangle \langle  \tilde{\varphi}_{n_2}, B_{++}\tilde{\varphi}_{p_2}\rangle\\
&=-\hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\hspace{-0.2cm}\sum_{n,p,l\in\mathbb{N}\backslash L }
\hspace{-0.4cm}\overline{\alpha_{L\cup\{l,n\},C}}\alpha_{L\cup\{l,p\},C}
\left[\begin{matrix}0\\n\end{matrix}\right]\left[\begin{matrix}0\\p\end{matrix}\right]\\
&\times \bigg( 1_{p<l<n}
\langle B_{++}\tilde{\varphi}_{l},\tilde{\varphi}_{p} \rangle \langle  \tilde{\varphi}_{n}, B_{++}\tilde{\varphi}_{l}\rangle\\
&+1_{n<l<p}\langle B_{++}\tilde{\varphi}_{n},\tilde{\varphi}_{l} \rangle \langle  \tilde{\varphi}_{l}, B_{++}\tilde{\varphi}_{p}\rangle\bigg)\\
&\hspace{-0.4cm}=-\hspace{-0.4cm}\!\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\!\!\sum_{l\in\mathbb{N}\backslash L}\\
&\Bigg[\left\langle\!\!\! B_{++} \tilde{\varphi}_{l}, \!\!\!\!\sum_{\overset{p\in\mathbb{N}\backslash L}{p<l}}\!\!\left[\begin{matrix}0\\p\end{matrix}\right] \!\alpha_{L\cup\{l,p\},C}\tilde{\varphi}_p \!\!\!\right\rangle \left\langle \sum_{\overset{n\in\mathbb{N}\backslash L}{l<n}} \!\!\left[\begin{matrix}0\\n\end{matrix}\right]\!\!\alpha_{L\cup \{l,n\},C} \tilde{\varphi}_n,  B_{++} \tilde{\varphi}_l \!\!\!\right\rangle\\
&+\left\langle\!\!\! B_{++} \tilde{\varphi}_{l}, \!\!\!\!\sum_{\overset{p\in\mathbb{N}\backslash L}{p>l}}\!\!\left[\begin{matrix}0\\p\end{matrix}\right] \!\alpha_{L\cup\{l,p\},C}\tilde{\varphi}_p \!\!\!\right\rangle \left\langle \sum_{\overset{n\in\mathbb{N}\backslash L}{l>n}} \!\!\left[\begin{matrix}0\\n\end{matrix}\right]\!\!\alpha_{L\cup \{l,n\},C} \tilde{\varphi}_n,  B_{++} \tilde{\varphi}_l \!\!\!\right\rangle\Bigg]\\
&\le 2\|B_{++}\|^2 \|\alpha\|^2
\end{align}

\(\boldsymbol{\delta_{n_2,p_2}:}\) completely analogous to \(\delta_{n_1,p_1}\) one arrives at 
\begin{equation}
  \le \|B_{++}\|^2\|\alpha\|^2.
\end{equation}

\(\boldsymbol{\delta_{n_1,p_1}\delta_{n_2,p_2}:}\)
\begin{align}
&-2\hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\hspace{-0.2cm}\sum_{\overset{n_1<n_2\in\mathbb{N}\backslash L }{p_1<p_2\in\mathbb{N}\backslash L }}
\hspace{-0.4cm}\overline{\alpha_{L\cup\{n_1,n_2\},C}}\alpha_{L\cup\{p_1,p_2\},C}
\left[\begin{matrix}n_1\\n_2\end{matrix}\right]\left[\begin{matrix}p_1\\p_2\end{matrix}\right]\delta_{n_1,p_1}\delta_{n_2,p_2}\\
&\times
\langle B_{++}\tilde{\varphi}_{n_1},\tilde{\varphi}_{p_1} \rangle \langle  \tilde{\varphi}_{n_2}, B_{++}\tilde{\varphi}_{p_2}\rangle\\
&=-2\hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-2}}}\hspace{-0.2cm}\sum_{n< p\in\mathbb{N}\backslash L }
\hspace{-0.4cm}|\alpha_{L\cup\{n,p\},C}|^2
\langle B_{++}\tilde{\varphi}_{n},\tilde{\varphi}_{n} \rangle \langle  \tilde{\varphi}_{p}, B_{++}\tilde{\varphi}_{p}\rangle\\
&\le 2 \|B_{++}\|^2 \|\alpha\|^2
\end{align}
So all together we have 
\begin{equation}\label{B++ long estimate final}
  \eqref{B++ long estimate}\le 10 \|B_{++}\|^2 \|\alpha\|^2
\end{equation}

What remains is term \eqref{B++ m squared term}, for this term there are two cases.  If \(b=b'\) then the scalar product is 
equal to \(\langle B_{L_b}^L \tilde{\varphi}_b, B_{L_{b}}^L \tilde{\varphi}_{b}\rangle\). If \(b\neq b'\) the scalar product is, up to a sign,
equal to \(\langle B_{L_b}^L \tilde{\varphi}_b,\tilde{\varphi}_{b}\rangle \langle \tilde{\varphi}_{b'}, B_{L_{b'}}^L \tilde{\varphi}_{b'}\rangle\).
However both of these terms can be estimated by \(\|B_{++}\|^2\). So all \(m^2\) summands of this sum contribute \(\|B_{++}\|^2\). Overall 
this estimate yields
\begin{align}\nonumber
&\|\mathrm{d}\Gamma(B_{++})\alpha\|^2 \le \eqref{B++estimatefinal1}+\eqref{B++estimatefinal2}+\eqref{B++ long estimate final} + \|\alpha\|^2 m^2 \|B_{++}\|^2 \\\nonumber
&= \|\alpha\|^2 (12+m^2) \|B_{++}\|^2.
\end{align}
For convenience of notation the estimate can be weakened to 
\begin{equation}
\|\mathrm{d}\Gamma(B_{++})\alpha\| \le (m+4) \|B_{++}\|\|\alpha\|.
\end{equation}
A completely analogous argument works for 
\(\mathrm{d}\Gamma(B_{--})\). 
So lets move on to \(\mathrm{d}\Gamma(B_{-+})\). Applying it 
to the same \(\alpha\in \mathcal{F}^0_{m,p}\) again we 
permute all the operators
to the right, where they annihilate the vacuum. The remaining 
terms are

\begin{align}\nonumber
\sum_{n\in\mathbb{N}} a^*(B_{-+}\varphi_n)a(\varphi_{n})\hspace{-0.5cm}\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}  \hspace{-0.5cm}\alpha_{L,C} 
\prod_{l=1}^m a^*(\tilde{\varphi}_{L_l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C_c}) \Omega  \\\nonumber
=\!\sum_{n\in\mathbb{N}}\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\hspace{-0.5cm}\alpha_{L,C}\!\!\sum_{b=1}^m\sum_{d=1}^p(-1)^{m-1+b+d}\langle \varphi_n, \tilde{\varphi}_{L_b}\rangle \langle \tilde{\varphi}_{-C_d},B_{-+}\varphi_n\rangle\\
\times \prod_{\overset{l=1}{l\neq b}}^m a^*(\tilde{\varphi}_{L_l})
\prod_{\overset{c=1}{c\neq d}}^p a(\tilde{\varphi}_{-C_c})\Omega.
\end{align}
From here we can eliminate the sum over \(n\), and reintroduce a sum 
over the ONB of \(\mathcal{H}^-\) to arrive at the 
expression for \(\mathrm{d}\Gamma(B_{-+})\):
\begin{align}
=\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\hspace{-0.5cm} \alpha_{L,C} \sum_{b=1}^m \sum_{d=1}^p (-1)^{m+b+d} \langle B_{+-} \tilde{\varphi}_{-C_d},\tilde{\varphi}_{L_b}\rangle \notag\\
\times\prod_{\overset{l=1}{l\neq b}}^m a^*(\tilde{\varphi}_{L_l})
\prod_{\overset{c=1}{c\neq d}}^p a(\tilde{\varphi}_{-C_c})\Omega\label{estimate dGamma +-}\\
=\!\!\!\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\hspace{-0.5cm} \alpha_{L,C} \sum_{b=1}^m \sum_{d=1}^p \sum_{k\in\mathbb{N}}(-1)^{m+b+d} \langle \tilde{\varphi}_{-C_d},\varphi_{-k}\rangle \langle B_{+-}\varphi_{-k},\tilde{\varphi}_{L_b}\rangle \notag\\
\times\prod_{\overset{l=1}{l\neq b}}^m a^*(\tilde{\varphi}_{L_l})
\prod_{\overset{c=1}{c\neq d}}^p a(\tilde{\varphi}_{-C_c})\Omega\\
=\!-\!\sum_{k\in\mathbb{N}}a^*(\varphi_{-k})a(B_{+-}\varphi_{-k})\hspace{-0.5cm}\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\hspace{-0.6cm}\alpha_{L,C}\prod_{l=1}^m a^*(\tilde{\varphi}_{L_l})\prod_{c=1}^pa(\tilde{\varphi}_{-C_c})\Omega.
\end{align}
For the estimate of the operator norm we continue with expression 
\eqref{estimate dGamma +-}.
By counting the remaining creation and annihilation operators 
we immediately see that \(\mathrm{d}\Gamma(B_{-+})\alpha\in 
\mathcal{F}_{m-1,p-1}\). We take the norm squared of the 
expression and notice that the scalar product is only 
not zero in cases where \(|L\backslash L'|\le 1\) and 
\(|C\backslash C'|\le 1\). Furthermore, whenever 
\(L = L'\) holds, the two sums of \(1\le b,b'\le m\)
collapses to a single sum over this range and analogously
for \(C = C'\) and \(d,d'\). In case \(L \neq L'\)
no sum over \(b\) or \(b'\) remains for the same reason.
Hence we arrive at


\begin{align}
&\|\mathrm{d}\Gamma(B_{-+})\alpha \|^2
\le \sum_{\scaleto{\begin{matrix}C,L\subset \mathbb{N} \\|L|=m-1\\|C|=p-1\end{matrix}}{20pt}}
\sum_{\scaleto{\begin{matrix}n_1,n_2\in\mathbb{N}\backslash L \\l_1,l_2\in\mathbb{N}\backslash C\end{matrix}}{15pt}}
  |\alpha_{L\cup \{n_2\},C\cup\{l_2\}}| |\alpha_{L\cup \{n_1\},C\cup\{l_1\}}|\\
&\Bigg[
    \delta_{n_1,n_2}\delta_{l_1,l_2} \sum_{b\in L\cup\{n_1\}} \sum_{d\in C\cup\{l_1\}} |\langle B_{+-}\tilde{\varphi}_{-d},\tilde{\varphi}_{b} \rangle|^2\\
    &+(1-\delta_{n_1,n_2})\delta_{l_1,l_2}\sum_{d\in C\cup\{l_1\}} |\langle B_{+-} \tilde{\varphi}_{-d},\tilde{\varphi}_{n_1}\rangle||\langle \tilde{\varphi}_{n_2},B_{+-}\tilde{\varphi}_{-d}\rangle |\\
    &+\delta_{n_1,n_2}(1-\delta_{l_1,l_2})\sum_{b\in L\cup\{n_1\}} |\langle B_{+-}\tilde{\varphi}_{-l_1},\tilde{\varphi}_{b}\rangle| |\langle \tilde{\varphi}_{b},B_{+-}\tilde{\varphi}_{-l_2}\rangle |\\
    &+\!(1\!-\!\delta_{n_1,n_2})(1\!-\!\delta_{l_1,l_2})|\langle B_{+-}\tilde{\varphi}_{-C_{l_1}},\tilde{\varphi}_{n_1}\rangle| | \langle \tilde{\varphi}_{n_2},B_{+-}\tilde{\varphi}_{-C_{l_2}}\rangle |
  \Bigg].
\end{align}

In the next step we split the sum into the four already indicated,
estimate the terms \((1-\delta)\le 1\) and eliminate sums with
the remaining Kronecker deltas. For the first term, we subsequently 
enlarge the sum over part of the Basis 
\(\tilde{\varphi}\) in the scalar product to the sum 
over all basis elements, yielding
\begin{align}
  &\|\mathrm{d}\Gamma(B_{-+})\alpha \|^2
  \le 
  \|\alpha\|^2 \sum_{b\in\mathbb{N}} \sum_{c\in\mathbb{N}} |\langle B_{+-}\tilde{\varphi}_{-c},\tilde{\varphi}_{b} \rangle|^2\\
      &+\sum_{\scaleto{\begin{matrix}C,L\subset \mathbb{N} \\|L|=m-1\\|C|=p\end{matrix}}{20pt}}
      \sum_{n_1,n_2\in\mathbb{N}\backslash L }
      |\alpha_{L\cup \{n_2\},C}| |\alpha_{L\cup \{n_1\},C}|\\
      &\hspace{1.5cm}\times \sum_{d\in C} |\langle B_{+-} \tilde{\varphi}_{-d},\tilde{\varphi}_{n_1}\rangle||\langle \tilde{\varphi}_{n_2},B_{+-}\tilde{\varphi}_{-d}\rangle |\\
      &+\sum_{\scaleto{\begin{matrix}C,L\subset \mathbb{N} \\|L|=m\\|C|=p-1\end{matrix}}{20pt}}
      \sum_{l_1,l_2\in\mathbb{N}\backslash C }
      |\alpha_{L,C\cup\{l_2\}}| |\alpha_{L,C\cup\{l_1\}}|\\
      &\hspace{1.5cm}\times \sum_{b\in L} |\langle B_{+-}\tilde{\varphi}_{-l_1},\tilde{\varphi}_{b}\rangle| |\langle \tilde{\varphi}_{b},B_{+-}\tilde{\varphi}_{-l_2}\rangle |\\
      &+\sum_{\scaleto{\begin{matrix}C,L\subset \mathbb{N} \\|L|=m-1\\|C|=p-1\end{matrix}}{20pt}}
      \sum_{\scaleto{\begin{matrix}n_1,n_2\in\mathbb{N}\backslash L \\l_1,l_2\in\mathbb{N}\backslash C\end{matrix}}{15pt}}
      |\alpha_{L\cup \{n_2\},C\cup\{l_2\}}| |\alpha_{L\cup \{n_1\},C\cup\{l_1\}}|\\
      &\hspace{1.5cm}\times| \langle B_{+-}\tilde{\varphi}_{-l_1},\tilde{\varphi}_{n_1}\rangle| | \langle \tilde{\varphi}_{n_2},B_{+-}\tilde{\varphi}_{-l_2}\rangle |.
\end{align}
Now we identity the sums over \(l_1,l_2\) and \(n_1,n_2\) as 
scalar products in tensor products of \(l^2(\mathbb{N})\) 
and apply the Cauchy-Schwarz inequality. Additionally, 
we identify 
\(\sum_{b\in\mathbb{N}}\sum_{c\in\mathbb{N}}|\langle B_{+-} 
\tilde{\varphi}_{-c},\tilde{\varphi}_{b}\rangle|^2
=\|B_{+-}\|^2_{I_2}\). This results in 
\begin{align}
  &\|\mathrm{d}\Gamma(B_{-+})\alpha \|^2
  \le 
  \|\alpha\|^2 \|B_{-+}\|^2_{I_2}\\
  &+\sum_{\scaleto{\begin{matrix}C,L\subset \mathbb{N} \\|L|=m-1\\|C|=p\end{matrix}}{20pt}}
  \sum_{n\in\mathbb{N}\backslash L }
  |\alpha_{L\cup \{n\},C}|^2 \sum_{d\in C} \sum_{u\in\mathbb{N}\backslash L}|\langle B_{+-} \tilde{\varphi}_{-d},\tilde{\varphi}_{u}\rangle|^2 \\
  &+\sum_{\scaleto{\begin{matrix}C,L\subset \mathbb{N} \\|L|=m\\|C|=p-1\end{matrix}}{20pt}}
  \sum_{l\in\mathbb{N}\backslash C }
  |\alpha_{L,C\cup\{l\}}|^2 \sum_{b\in L} \sum_{u\in\mathbb{N}\backslash C }|\langle B_{+-}\tilde{\varphi}_{-u},\tilde{\varphi}_{b}\rangle|^2 \\
  &+\sum_{\scaleto{\begin{matrix}C,L\subset \mathbb{N} \\|L|=m-1\\|C|=p-1\end{matrix}}{20pt}}
  \sum_{\scaleto{\begin{matrix}n \in\mathbb{N}\backslash L \\l \in\mathbb{N}\backslash C\end{matrix}}{15pt}}
    |\alpha_{L\cup \{n\},C\cup\{l\}}|^2
  \sum_{\scaleto{\begin{matrix}u \in\mathbb{N}\backslash L \\d \in\mathbb{N}\backslash C\end{matrix}}{15pt}} |\langle B_{+-}\tilde{\varphi}_{-d},\tilde{\varphi}_{u}\rangle|^2\\
  &\le 4 \|\alpha\|^2 \|B_{-+}\|^2_{I_2}.
\end{align}


\end{proof}

\begin{Corollary}
The operators \(\mathrm{d}\Gamma(B_{--})\) and \(\mathrm{d}\Gamma(B_{++})\) can be extended by continuity on \(\mathcal{F}^0_{m,p}\) to unbounded operators on all of \(\mathcal{F}'\).
The operator \(\mathrm{d}\Gamma(B_{-+})\) can be continuously extended to all of \(\mathcal{F}\).
\end{Corollary}

\begin{Lemma}
The operator \(\left(\mathrm{d}\Gamma(B_{-+})\right)^*\)  acts on elements of \(\mathcal{F}^0\) as

\begin{equation}
- \sum_{n\in\mathbb{N}} a^*(B_{+-}\varphi_{-n}) a(\varphi_{-n})=:-\mathrm{d}\Gamma(B_{+-}).
\end{equation}
So also \(\mathrm{d}\Gamma(B_{+-}):\mathcal{F}^0\rightarrow \mathcal{F}\) can be extended continuously to all of \(\mathcal{F}\).
Moreover \(\mathrm{d}\Gamma(B_{-+})+\mathrm{d}\Gamma(B_{+-})\) is skew-adjoint.
\end{Lemma}
\begin{proof}
Pick \(\beta,\alpha \in \mathcal{F}^0\). We use the form 
\eqref{dGamma form for adjoint} to obtain

\begin{align}\nonumber
&\langle \beta, \mathrm{d}\Gamma(B_{-+}) \alpha \rangle=\left\langle \beta, -\sum_{n\in\mathbb{N}} a^*(\varphi_{-n})a(B_{+-}\varphi_{-n}) \alpha \right\rangle\\\nonumber
&=\!-\!\sum_{n\in\mathbb{N}} \langle \beta , a^*(\varphi_{-n})a(B_{+-}\varphi_{-n}) \alpha\rangle
=\!-\!\sum_{n\in\mathbb{N}}  \langle a^*(B_{+-}\varphi_{-n})  a(\varphi_{-n})\beta , \alpha\rangle\\
&=\bigg\langle\!\!-\sum_{n\in\mathbb{N}} a^*(B_{+-}\varphi_{-n})  a(\varphi_{-n})\beta , \alpha\bigg\rangle
\end{align}
 So we see that \(\mathrm{d}\Gamma(B_{+-})\)
and \(\mathrm{d}\Gamma(B_{-+})^*\) agree on \(\mathcal{F}^0\) which is dense. So they are the same bounded and continuous operator on all of
Fock space. 
\end{proof}

\begin{Def}
We define the set 
\begin{equation}
  \mathfrak{B}:=\{B:\mathcal{H}\righttoleftarrow|\mathrm{linear},\|B\|\!+\!\|B_{+-}\|_{I_2}\!+\!\|B_{-+}\|_{I_2}\in\mathbb{R}, {B}^*\!=-B\}
\end{equation}
and the operator
\begin{equation}
  \mathrm{d}\Gamma(B):=\mathrm{d}\Gamma(B_{++})+\mathrm{d}\Gamma(B_{+-})+\mathrm{d}\Gamma(B_{-+})+\mathrm{d}\Gamma(B_{--}).
\end{equation}
Furhtermore, we endow \(\mathfrak{B}\) with the topology induced by 
the norm \(B\mapsto \|B\|+\|B_{+-}\|_{I_2}+\|B_{-+}\|_{I_2}\).
\end{Def}

\begin{Lemma}
The operator \(\mathrm{d}\Gamma(B)\)
is skew symmetric and real linear in its argument 
\(B\in\mathfrak{B}\).
Moreover, for each \(m,p\in\mathbb{N}\) the functional 
\(\mathrm{d}\Gamma(\cdot)|_{\mathcal{F}_{m,p}'}\)
is bounded and hence continuous as a map from \(\mathfrak{B}\)
to the set of bounded linear operators of type 
\(\mathcal{F}_{m,p}'\rightarrow \mathcal{F}_{m-1,p-1}'\oplus \mathcal{F}_{m,p}'\oplus\mathcal{F}_{m+1,p+1}'\).
\end{Lemma}
\begin{proof}
Since the sum of skew symmetric operators is skew symmetric, it suffices to show skew symmetry of \(\mathrm{d}\Gamma(B_{++})\) and \(\mathrm{d}\Gamma(B_{--})\).
Moreover since both of these operators are extended versions of operators of the same name of type \(\mathcal{F}^0\rightarrow \mathcal{F}\) it suffices to show skew symmetry
on this domain. We will only do the calculation for \(\mathrm{d}\Gamma(B_{++})\), the other calculation is analogous. 
Pick \(\beta,\alpha \in \mathcal{F}^0\) and basis \(\tilde{\varphi}\), \(\varphi'\)
such that \(\beta,\alpha\) are expressible with finite sums over 
elements of the generating sets with respect to their respective basis. 
We caculate
\begin{align}\nonumber
\left\langle \beta, \mathrm{d}\Gamma(B_{++}) \alpha \right\rangle
= \sum_{L,L',C,C'\subset \mathbb{N}} \overline{\beta}_{L',C'}\alpha_{L,C} 
\left\langle \prod_{l=1}^{|L'|}a^*(\tilde{\varphi}_{L_l'})\prod_{c=1}^{|C'|} a(\tilde{\varphi}_{-C_c'})\Omega,\right. \\ \nonumber
\left. \sum_{n\in\mathbb{N}} a^*(B_{++}\varphi_{n})a(\varphi_n) \prod_{l=1}^{|L|}a^*(\varphi_{L_l}')\prod_{c=1}^{|C|} a(\varphi_{-C_c}')\Omega\right\rangle\\\nonumber
= \sum_{L,L',C,C'\subset \mathbb{N}} \overline{\beta}_{L',C'}\alpha_{L,C} \sum_{n\in\mathbb{N}}
\left\langle \prod_{l=1}^{|L'|}a^*(\tilde{\varphi}_{L_l'})\prod_{c=1}^{|C'|} a(\tilde{\varphi}_{-C_c'})\Omega,\right. \\ \nonumber
\left. a^*(B_{++}\varphi_{n})a(\varphi_n) \prod_{l=1}^{|L|}a^*(\varphi_{L_l}')\prod_{c=1}^{|C|} a(\varphi_{-C_c}')\Omega\right\rangle\\\nonumber
= \sum_{L,L',C,C'\subset \mathbb{N}} \overline{\beta}_{L',C'}\alpha_{L,C} \sum_{n\in\mathbb{N}}
\left\langle a^*(\varphi_n) a(B_{++}\varphi_{n})\prod_{l=1}^{|L'|}a^*(\tilde{\varphi}_{L_l'})\prod_{c=1}^{|C'|} a(\tilde{\varphi}_{-C_c'})\Omega,\right. \\ \nonumber
\left.  \prod_{l=1}^{|L|}a^*(\varphi_{L_l}')\prod_{c=1}^{|C|} a(\varphi_{-C_c}')\Omega\right\rangle.
\end{align}
In the next step we perform the standard anticommutations to 
move the operator \(B_{++}\) from the annihilation operator to
the creation operator:
\begin{align}
  \sum_{L,C\subset \mathbb{N}}\beta_{L,C} \sum_{n\in\mathbb{N}}a^*(\varphi_n)a(B_{++}\varphi_n) \prod_{l=1}^{|L|}a^*(\tilde{\varphi}_{L_l})\prod_{c=1}^{|C|}a(\tilde{\varphi}_{-C_c})\Omega\\
  =\sum_{L,C\subset \mathbb{N}}\!\!\!\beta_{L,C}\!\sum_{b=1}^{|L|} \prod_{l=1}^{b-1}a^*(\tilde{\varphi}_{L_l}) (-1)a^*(B_{++}\tilde{\varphi}_{L_b})\\
  \times \prod_{l=b+1}^{|L|}a^*(\tilde{\varphi}_{L_l})\prod_{c=1}^{|C|}a(\tilde{\varphi}_{-C_c})\Omega\\
  =\sum_{L,C\subset \mathbb{N}}\beta_{L,C} (-1)\sum_{k\in\mathbb{N}}a^*(B_{++}\varphi_k)a(\varphi_k) \prod_{l=1}^{|L|}a^*(\tilde{\varphi_{L_l}})\prod_{c=1}^{|C|}a(\tilde{\varphi}_{-C_c})\Omega\\
  =-\sum_{k\in\mathbb{N}}a^*(B_{++}\varphi_k)a(\varphi_k)\beta,
\end{align}
where we used \(B_{++}^*=-B_{++}\).  
This yields
\begin{equation}
\left\langle \beta, \mathrm{d}\Gamma(B_{++})\alpha\right\rangle =- \left\langle \mathrm{d}\Gamma(B_{++})\beta, \alpha\right\rangle.
\end{equation}
Real linearity follows directly from the definition of 
\(\mathrm{d}\Gamma\) on \(\mathcal{F}^0\) and hence 
by extention on all of \(\mathcal{F}'\). Continuity 
of the restriction to any \(\mathcal{F}_{m,p}'\) follows 
directly from the forms of the bounds of lemma 
\ref{d Gamma norms}.
\end{proof}



Now we would like to define \(e^{\mathrm{d}\Gamma(B)}\), in order to do so, we will show that \(\mathrm{d}\Gamma(B)\) is essentially skew-adjoint. 
One way of doing so is by Nelson's analytic vector theorem. 

\begin{Thm}[Nelson's analytic vector theorem]
Let \(C\) be a symmetric operator on a Hilbert space \(\mathscr{H}\). If \(\dom(C)\) contains a total set 
\(S\subset \bigcap_{n=1}^\infty \dom(C^n)\) of analytic vectors, then \(C\) is essentially self adjoint. 
A vector \(\phi\in \bigcap_{n=1}^\infty \dom(C^n)\) is called analytic if there is \(t>0\) such that
\(\sum_{k=0}^\infty \frac{\|C^n \phi\|}{n!} t^n<\infty\) holds. A set \(S\) is said to be total if \(\overline{\text{span}(S)}=\mathscr{H}\)
\end{Thm}
For a proof see e.g. \cite{SimonReed2}.

\begin{Lemma}\label{Gamma exponential bound}
For any \( \alpha \in \mathcal{F}', t>0\) and \(B\in \mathfrak{B}\) the operator \(\mathrm{d}\Gamma(B):\mathcal{F}'\rightarrow \mathcal{F}\) satisfies
\begin{equation}
\sum_{k=0}^\infty \frac{\|\mathrm{d}\Gamma(B)^k \alpha\|}{k!} t^k <\infty.
\end{equation}
\end{Lemma}
\begin{proof}
 By definition of \(\mathcal{F}'\) there are \(m,p\in\mathbb{N}\) such that \(\alpha \in \bigobot_{l=0}^m\bigobot_{c=0}^p \mathcal{F}_{l,p}\). Fix \(t>0\). 
We dissect \(\alpha\) into its parts of fixed particle numbers:
\begin{equation}
\sum_{k=0}^\infty \frac{\|\mathrm{d}\Gamma(B)^k \alpha\|}{k!} t^k \le \sum_{l=0}^m\sum_{c=0}^p \sum_{k=0}^\infty \frac{\|\mathrm{d}\Gamma(B)^k \alpha_{l,c}\|}{k!} t^k .
\end{equation}
 Using the following abbreviations
\begin{align}
&\Gamma_{-1}:=\mathrm{d}\Gamma(B_{-+})\\
&\Gamma_0:=\mathrm{d}\Gamma(B_{++})+\mathrm{d}\Gamma(B_{--})\\
&\Gamma_{+1}:=\mathrm{d}\Gamma(B_{+-})\\
&\beta:=\max\{\|B_{++}\|+\|B_{--}\|,\|B_{-+},\|_{I_2}\}
\end{align}
we estimate
\begin{align}\nonumber
\|\mathrm{d}\Gamma(B)^k \alpha_{l,c}\|\le \sum_{x\in \{-1,0,+1\}^k} \left\| \prod_{b=1}^k \Gamma_{x_b}\alpha_{l,c}\right\|\\
\le  \sum_{x\in \{-1,0,+1\}^k} \prod_{b=1}^k \left\| \Gamma_{x_b}|_{\mathcal{F}_{l+\sum_{d=1}^{b-1} x_d,c+\sum_{d=1}^{b-1} x_d}}\right\| \|\alpha_{l,c}\|\\\label{essentialSelfadjointnessOperatorProduct}
\le 3^k \|\alpha\| \max_{x\in \{-1,0,+1\}^k} \prod_{b=1}^k\left\| \Gamma_{x_b}|_{\mathcal{F}_{l+\sum_{d=1}^{b-1} x_d,c+\sum_{d=1}^{b-1} x_d}}\right\|  .
\end{align}
At this point the factors only depend on the number of particles the Fock space 
vector attains as we act on it with the operators \(\Gamma_{\#}\) for 
\(\#\in \{-1,0,1\}\). 
As these bounds increase with the particle number we can restrict the set 
\(\{-1,0,+1\}\) in the last line to \(\{0,+1\}\).
We notice that the bound in \eqref{essentialSelfadjointnessOperatorProduct} 
will only increase if  we exchange each pair 
\(x_{i+1}=1, x_{i}=0\) by the pair \(x_{i}=1, x_{i+1}=0\) so 
that the norm of the operator that acts like
a particle number operator is taken after the particle number is increased. 
Therefore we for each fixed \(\sum_{b=1}^k x_b=d\)
we can estimate the maximum by lemma \ref{d Gamma norms} 
to be \(\beta^k (c+l+8+2d)^{k-d}\), which we bound 
by
\((2\beta)^k (c/2+l/2+4+d)^{k-d}\).
The Faktor constant in \(d\) will be omitted for the 
maximization problem. For maximising 
\begin{equation}
  (c/2+l/2+4+d)^{k-d}
\end{equation}
we treat \(d\) as a continuous variable take the derivative and set it to zero. From the form of the function to be maximised
it is clear that it is equal to \(1\) for \(d=k\) and at \(d=-c/2-l/2-3\), it is be bigger in between. We abbreviate \(y=c/2+l/2+4\).
\begin{align}
0= (y+d)^{k-d} (-\ln(y+d) + \frac{k-d}{y+d})\\
\iff \frac{k-d}{y+d}= \ln (y+d)\\
\iff \frac{k+y}{y+d}  -1 = -1 + \ln (e (y+d))\\
\iff e(k+y)=e(y+d)\ln(e(y+d))\\
\iff e(k+y)=\ln(e(y+d)) e^{\ln(e(y+d))}\\
\iff W_0(e(k+y))=\ln(e(y+d))\\
\iff e^{W_0(e(k+y))-1}-y=d,
\end{align}

where we made use of the Lambert W function, which 
is the inverse function of \(x\mapsto x e^x\) and has 
multiple branches; however as \(e(y+d)>0\) 
\(W_0\) is the only real branch which is applicable here, it corresponds to the inverse of \(x\mapsto x e^x\) for \(x>-1\). 
From the form of the maximising value we see, that it 
is always bigger than \(-y\). Plugging this back 
onto our function we find its maximum

\begin{align}\nonumber
&\max_{d\in ]-y,\infty[} (y+d)^{k-d}=e^{(W_0(e(k+y))-1) (k+y)- (W_0(e(k+y))-1)e^{W_0(e(k+y))-1}}\\\nonumber
&=e^{-(k+y) + (k+y)W_0(e(k+y)) + e^{W_0(e(k+y))-1} -((k+y)e)/e}\\\nonumber
&=e^{-2(k+y) + (k+y)W_0((k+y)e)+ \frac{e(k+y)}{eW_0((k+y)e)}}\\
&=e^{(k+y)(-2+W_0((k+y)e) + W_0((k+y)e)^{-1})},
\end{align}
where we repeatedly used \(W_0(x)e^{W_0(x)}=x\). Putting things together we find

\begin{align}
\|\Gamma(B)^k\alpha_{l,c}\|\le (6\beta )^k \|\alpha\| e^{(k+y)(-2+W_0((k+y)e) + W_0((k+y)e)^{-1})}.
\end{align}
Dividing this by \(k!\) and using the lower bound given by Sterling's formula we would like to prove that 

\begin{align}\label{essentialSelfadjointnessSimplifiedSum}
\sum_{k=1}^\infty (6\beta t )^k   e^{k(1-\ln(k))-\frac{1}{2}\ln(k) +(k+y)(-2+W_0((k+y)e) + W_0((k+y)e)^{-1})}<\infty
\end{align}
holds, where we neglected constant factors and the summand \(k=0\) which do not matter for the task at hand. Next we are going
to use an inequality about the growth of \(W_0\) proven in \cite{hoorfar2008inequalities}. For any \(x\ge e\) 
\begin{equation}
W_0(x)\le \ln(x)-\ln( \ln (x)) + \frac{e}{e-1}\frac{\ln (\ln (x))}{\ln (x)}
\end{equation}
holds true. Plugging this into our sum the exponent is bounded from above by

\begin{align}\nonumber
&k(1-\ln(k))-\frac{1}{2}\ln(k) +(k+y)\Big[-1+\ln(k+y) - \ln(1+ \ln (k+y))\\ \nonumber
&\left.+\frac{e}{e-1} \frac{\ln(1+\ln(k+y))}{1+\ln(k+y)} + W_0((k+y)e)^{-1}\right]\\\nonumber
&=-y + k \ln\left(1+\frac{y}{k}\right) + y \ln (k+y) -\frac{1}{2}\ln(k) +\\\nonumber
&(k+y)\left[ \ln (1+\ln(k+y))\frac{1-(e-1)\ln(k+y)}{(e-1)(1+\ln(k+y))} + W_0((k+y)e)^{-1}\right]\\\label{essentialSelfadjointnessExponent}
&\le y \ln (k+y) -\frac{1}{2}\ln(k) + (k+y)W_0((k+y)e)^{-1} +\\\nonumber
&(k+y) \ln (1+\ln(k+y))\frac{1-(e-1)\ln(k+y)}{(e-1)(1+\ln(k+y))} .
\end{align}
Now it is important to notice that the only remaining term that grows 
faster than linearly in magnitude is the last summand.
This term; however, is negative for large \(k\), as the fraction converges 
to \(-1\) for large \(k\), while the double logarithm
in front grows without bounds. So there is a \(k^*\) big enough such that  for all \(k>k^*\) \eqref{essentialSelfadjointnessExponent} 
is smaller than \(- k (\ln(6\beta t) + 1)\), proving that \eqref{essentialSelfadjointnessSimplifiedSum} in fact holds.

\end{proof}



\begin{Thm}\label{Gamma essential selfadjointness}
The operator \(\mathrm{d}\Gamma(B):\mathcal{F}'\rightarrow \mathcal{F}\) is 
essentially skew adjoint and hence by Stones theorem
 generates a strongly continuous unitary group 
 \(\left( e^{t ~\widehat{\mathrm{d}\Gamma(B)}}\right)_t\), where 
 \(\widehat{\mathrm{d}\Gamma(B)}\) is the closure of 
 \(\mathrm{d}\Gamma(B)\).
\end{Thm}
\begin{proof}
In order to apply Nelson's analytic vector theorem we pick \(S=\mathcal{F}'\). 
Pick \(\alpha \in\mathcal{F}'\). We need to show that there is \(t>0\) such 
that
\begin{equation}
\sum_{k=0}^\infty \frac{\|\mathrm{d}\Gamma(B)^k \alpha\|}{k!} t^k <\infty
\end{equation}
holds. This is guaranteed by the last lemma.
\end{proof}

Lastly in this chapter, we will investigate the commutation properties of \(\mathrm{d}\Gamma(B)\) with general creation and annihilation operators.
These properties are the reason we are interested in this operator, they will prove to be very useful in the next chapter.

\begin{Thm}
For \(\psi \in \mathcal{H}\) and \(\alpha\in \mathcal{F}'\) we have
\begin{equation}\label{Commutation Gamma}
[\mathrm{d}\Gamma(B),a^\# (\psi)]\alpha=a^\#(B\psi)\alpha,
\end{equation}
where \(a^\#\) can be either \(a\) or \(a^*\).
\end{Thm}
\begin{proof}
Because \(\mathrm{d}\Gamma(B)\) is defined as 
the extension of an operator on \(\mathcal{F}^0\) it 
suffices to show the desired identity on this space. 
 We will do the 
case \(a(\psi)\), the other case is completely analogous.  
As a first step we decompose \(\mathrm{d}\Gamma(B)\) into its four parts

\begin{align}
\left[ \mathrm{d}\Gamma(B),a(\psi) \right] = \left[ \mathrm{d}\Gamma(B_{++})
+\mathrm{d}\Gamma(B_{-+})+\mathrm{d}\Gamma(B_{-+})+\mathrm{d}\Gamma(B_{--}),a(\psi) \right],
\end{align}
each of those parts is evaluated directly. We begin with the \(B_{++}\) part, this can be expressed as

\begin{align}
\left[ \mathrm{d}\Gamma(B_{++}),a(\psi) \right] \\
= \sum_{n\in\mathbb{N}} a^*(B_{++}\varphi_n)a(\varphi_n) a(\psi) - \sum_{n\in\mathbb{N}} a(\psi) a^*(B_{++}\varphi_n)a(\varphi_n) \\\label{commutation calculation1}
=\sum_{n\in\mathbb{N}} \left[ -\langle \psi, B_{++} \varphi_n\rangle a(\varphi_n) +a(\psi) a^*(B_{++}\varphi_n)a(\varphi_n) \right]  \\\label{commutation calculation2}
- \sum_{n\in\mathbb{N}} a(\psi) a^*(B_{++}\varphi_n)a(\varphi_n).
\end{align}

Let \(\alpha \in \mathcal{F}^0\). Now applying the expression in the last 
two lines to \(\alpha\), considering each \(\alpha_{m,p}\in\mathcal{F}_{m,p}\)
separately and commuting the annihilation operators in \eqref{commutation calculation1} 
and \eqref{commutation calculation2} 
to the right, the sums over \(n\) will be absolutely convergent. hence
we may split the firs sum into two and observe the cancellation 
between the last two terms. Continuing we find

\begin{align}
\left[ \mathrm{d}\Gamma(B_{++}),a(\psi) \right] \alpha
=-\sum_{n\in\mathbb{N}}  \langle \psi, B_{++} \varphi_n\rangle a(\varphi_n)\alpha\\
=-a\left(\sum_{n\in\mathbb{N}} \langle B_{++}\varphi_n, \psi\rangle  \varphi_n  \right)\alpha
=a\left(\sum_{n\in\mathbb{N}} \langle \varphi_n, B_{++}\psi\rangle  \varphi_n  \right)\alpha\\
=a(B_{++}\psi)\alpha,
\end{align}

where we used \(B^*=-B^*\).  
The final extension of this equation to all \(\alpha \in \mathcal{F}'\) happens via the continuous linear
extension theorem on \(\mathcal{F}_{m,p}\) for each \(m,p\in\mathbb{N}\). 
The proof in all seven other cases are completely analogous,
except that the off diagonal terms switch. More precisely, from the excatly analogous 
calculation it follows that 
\begin{equation}
  \big[\mathrm{d}\Gamma(B_{-+}),a^\#(\psi)\big]\alpha=a^\#\left(B_{+-}\psi\right)\alpha
\end{equation}  
and 
\begin{equation}
  \big[\mathrm{d}\Gamma(B_{+-}),a^\#(\psi)\big]\alpha=a^\#\left(B_{-+}\psi\right)\alpha
\end{equation}  
hold.
Putting things together again we obtain

\begin{align}
\left[ \mathrm{d}\Gamma(B_{++}),a(\psi) \right] +\left[ \mathrm{d}\Gamma(B_{-+}),a(\psi) \right] \\
+\left[ \mathrm{d}\Gamma(B_{+-}),a(\psi) \right] +\left[ \mathrm{d}\Gamma(B_{--}),a(\psi) \right]  =\\
a(B_{++}\psi)+a(B_{+-}\psi)+a(B_{-+}\psi)+a(B_{--}\psi)\iff \\
\left[ \mathrm{d}\Gamma(B),a(\psi) \right] =a(B\psi)
\end{align}
on all of \(\mathcal{F}'\).

\end{proof}

 

\subsection{Presentation and Proof of the Formula}\label{sec:proof simple formula}

In this chapter we verify the formula for the \(S\)-matrix directly.
For a heuristic derivation see 
section \ref{sec:heuristic construction} of the 
appendix.



\begin{Thm}[Analyticity for small \(A\)]\label{sleek_second_quantised_scattering_operator}
Let \(A\in\mathcal{V}\) be such that the one 
particle scattering operator \(S^A\) fulfills
\begin{equation}
\|\id-S^A\|<1.
\end{equation}
Then the operator 
\begin{equation}\label{eq:sleek_scattering}
\tilde{S}^A=  e^{\mathrm{d}\Gamma(\ln (S^A))}
\end{equation}
is a lift of \(S^A\), where the logarithm is defined by its 
taylor series around the identity.
\end{Thm}
\begin{proof}
In order to establish this theorem we need to verify that the 
expression given in equation \eqref{eq:sleek_scattering} for the scattering 
operator
 is a well-defined object
and fulfils the \eqref{lift condition}.

Well-definedness is established, by theorem 
\ref{Gamma essential selfadjointness}, because for unitary \(S^A\)
with \(\|1-S^A\|<1\) the power series of the logarithm converges 
and fulfils
\begin{align}
\|\ln(S^A)\|=\|\ln (1-(1-S^A))\|= \left\| -\sum_{k=1}^\infty \frac{(1-S^A)^k}{k} \right\|\\
 \le  \sum_{k=1}^\infty \frac{\|1-S^A\|^k}{k}=-\ln(1-\|1-S^A\|)
\end{align}
implying that the power series of the logarithm around the 
identity is a well-defined map from the  one-particle 
operators of norm less than
one to the bounded  one-particle operators. Moreover this 
operator fulfils \([\ln (S^A)]^*=\ln (S^A)^*= \ln 
(S^A)^{-1}=-\ln (S^A)\), so 
\(\mathrm{d}\Gamma(\ln S^A)\) is a well-defined unbounded 
operator that is essentially skew adjoint on the finite 
particle sector of Fock space \(\mathcal{F}'\). Finally the 
off diagonal Hilbert-Schmidt norm can also be controlled by 
the same norm of \(S^A\):
\begin{align}
  \|P^+\ln(S^A)P^-\|_{I_2}=\|P^+\ln (1-(1-S^A))P^-\|_{I_2}\\
  = \left\| - P^+\sum_{k=1}^\infty \frac{(1-S^A)^k}{k} P^-\right\|_{I_2}\\
   \le  \|S^A_{+-}\|_{I_2}\sum_{k=1}^\infty \max\{\|1-S^A\|,\|P^--S^A_{--}\|\}^{k-1}\\
   =\frac{\|S^A_{+-}\|_{I_2}}{1-\|1-S^A\|}.
\end{align}


Let \(\varphi\in \mathcal{H}\) and \(\alpha\in \mathcal{F}'\), 
for any \(k\in \mathbb{N}_0\) we see applying the commutation 
relation of \(\mathrm{d}\Gamma\):
\begin{multline*}
\mathrm{d}\Gamma(\ln U) \sum_{l=0}^k \binom{k}{l} a \left(\left(\ln U\right)^l \varphi \right) \left(\mathrm{d}\Gamma(\ln U)\right)^{k-l} \alpha\\
=\sum_{l=0}^k \binom{k}{l} a \left(\left(\ln U\right)^{l+1} \varphi \right) \left(\mathrm{d}\Gamma(\ln U)\right)^{k-l}\alpha\\
+\sum_{l=0}^k \binom{k}{l} a \left(\left(\ln U\right)^l \varphi \right) \left(\mathrm{d}\Gamma(\ln U)\right)^{k-l+1}\alpha\\
= \sum_{b=0}^{k+1} \left( \binom{k}{b-1} + \binom{k}{b}\right) a\left( (\ln U)^b \varphi\right) \left( \mathrm{d}\Gamma(\ln U)\right)^{k+1-b}\alpha\\
=\sum_{b=0}^{k+1}  \binom{k+1}{b}  a\left( (\ln U)^b \varphi\right) \left( \mathrm{d}\Gamma(\ln U)\right)^{k+1-b}\alpha,
\end{multline*}
so we see that for \(k\in\mathbb{N}_0\)
\begin{equation}
\left(\mathrm{d}\Gamma(\ln U)\right)^k a (\varphi) \alpha= \sum_{b=0}^{k}  \binom{k}{b}  a\left( (\ln U)^b \varphi\right) \left( \mathrm{d}\Gamma(\ln U)\right)^{k-b}\alpha
\end{equation}
holds. Using what we just obtained, we conclude
\begin{multline*}
e^{\mathrm{d}\Gamma(\ln U)}a(\varphi) \alpha = \sum_{k=0}^\infty \frac{1}{k!} \left(\mathrm{d}\Gamma(\ln U)\right)^k a (\varphi)\alpha\\
=\sum_{k=0}^\infty \frac{1}{k!}  \sum_{b=0}^{k}  \binom{k}{b}  a\left( (\ln U)^b \varphi \right) \left( \mathrm{d}\Gamma(\ln U)\right)^{k-b}\alpha\\
\overset{*}{=}\sum_{c=0}^\infty \sum_{l=0}^\infty \frac{1}{c! l!} a\left( (\ln U)^c \varphi \right) \left( \mathrm{d}\Gamma(\ln U)\right)^{l}\alpha\\
=a\left( e^{\ln U} \varphi \right) e^{\mathrm{d}\Gamma( \ln U)}\alpha
=a\left( U \varphi \right) e^{\mathrm{d}\Gamma( \ln U)}\alpha.
\end{multline*}
For the marked equality changing oder of summation is justified, because by the bounds
 \(\|a((\ln U)^c \varphi)\|\le \|\ln U\|^c\) and  lemma \ref{Gamma exponential bound} the sum obtained by changing the order
 of summands converges absolutely.
Clearly multiplying the second quantised operator by an additional phase as in 
\eqref{sleek_second_quantised_scattering_operator} does not influence this calculation.
So \eqref{lift condition} holds when applied 
to any \(\alpha \in \mathcal{F}'\) and can be continued 
to all of \(\mathcal{F}\) by continuity of \(\tilde{S}\).
\end{proof}

The last theorem can be restated as for \(A\) small enough 
there is a power series of operators on \(\mathcal{F}\)
that converges against a lift of \(S^A\). Power series in \(A\) 
is used here in the sense that it is of the form 
\(\sum_{k\in\mathbb{N}_0} T_k(A)\), where \(T_K(A)\) is 
homogeneous in \(A\) of degree \(k\). The next Theorem 
establishes such a power series for all \(A\in\mathcal{V}\).

\begin{Thm}[Analyticity for all \(A\)]
  Let \(A\in\mathcal{V}\) and \(S^A\) the corresponding one-particle 
  scattering operator. There is a lift \(\tilde{S}^A\) of \(S^A\)
  that fulfills 
\begin{equation}
  \tilde{S}^A=\sum_{k\in\mathbb{N}_0} T_k(A),
\end{equation}
  where \(T_k(A)\) are unbounded operators defined on 
  \(\mathcal{F}'\) that are homogeneous of degree \(k\) in \(A\).
  This series is strongly convergent on \(\mathcal{F}'\).
\end{Thm}

\begin{proof}
Pick \(A\in\mathcal{V}\). Recall the definition 
\ref{def: S bar, gamma, cA} of 
the one-particle scattering operator 
\(S^A\) 
\begin{equation}
  S^A= U^0_{\Sigma_{\text{in}},\Sigma_{\text{out}}}U^A_{\Sigma_{\text{out}},\Sigma_{\text{in}}}.
\end{equation}
Pick \(N\in\mathbb{N}\) such that 
\begin{equation}
  S^A_k=U^{(k-1)A/N}_{\Sigma_{\text{in}},\Sigma_{\text{out}}}U^{A k/N }_{\Sigma_{\text{out}},\Sigma_{\text{in}}}
\end{equation}
fulfills 
\begin{equation}
\|1-S^A_k\|<1
\end{equation}
for all \(0<k<N\). Then by the theorem \ref{sleek_second_quantised_scattering_operator}
\begin{equation}
  \tilde{S}^A_k=e^{\mathrm{d}\Gamma(\ln(S^A_k))}
\end{equation}
is a lift of \(S^A_k\) for each \(k\), so the product
\begin{equation}
  \tilde{S}^A = \prod_{k=1}^N \tilde{S}^A_k
\end{equation}
is a lift of \(S^A\). Pick \(\alpha \in \mathcal{F}^0\), 
next we show that \(\tilde{S}^A\alpha\) is given by 
a convergent power series and hence by linear 
extension it is also convergent on \(\mathcal{F}'\), 
which finishes the proof.
Pick the basis \((\varphi_{k})_{k\in\mathbb{N}}\) and 
\((\varphi_{-k})_{k\in\mathbb{N}}\) of 
\(\mathcal{H}^+\) and \(\mathcal{H}^-\) respectively 
such that \(\alpha\) is a finite linear combination of 
the form 
\begin{equation}
\alpha=\sum_{\scaleto{\begin{matrix}L,C\subset \mathbb{N}\\|L|=m,|C|=p\end{matrix}}{15pt}}  
  \hspace{-0.5cm}\alpha_{L,C} \prod_{l=1}^m a^*(\varphi_{L_l})\prod_{k=1}^p a(\varphi_{-C_k})\Omega.
\end{equation}
We calculate
\begin{align}
  \tilde{S}^A\alpha = \prod_{k=1}^N \tilde{S}^A_k\alpha 
  =  \prod_{k=1}^{N-1}\tilde{S}^A_k \quad  \sum_{k_N\in\mathbb{N}_0}\frac{1}{k_N!}\bigg(\mathrm{d}\Gamma(\ln S^A_N)\bigg)^{k_N}\alpha\\
  =  \prod_{k=1}^{N-2}\tilde{S}^A_k \quad  \sum_{k_N\in\mathbb{N}_0}\tilde{S}_{N-1}^A \frac{1}{k_N!}\bigg(\mathrm{d}\Gamma(\ln S^A_N)\bigg)^{k_N}\alpha,
\end{align}
where by continuity of the unitary \(\tilde{S}_{l}^A\) we may pull them into the sum,
and expand the exponential, since inside the sum its argument is again in \(\mathcal{F}'\).
We may continue this process by induction. Since all of these sums are norm convergent, we 
may forget about the order in which they are to be carried out in our notation:
\begin{align}
  \tilde{S}^A\alpha = \sum_{k_1,\dots, k_N\in\mathbb{N}_0}\prod_{l=1}^N \frac{1}{k_l!}\bigg(\mathrm{d}\Gamma(\ln S^A_l)\bigg)^{k_l} \quad \alpha. 
\end{align}
Since \(\alpha\in\mathcal{F}'\), there is a maximal number 
of particles of each summand. This implies that \(d\Gamma\) is 
continuous as a function of \(\ln S^A_l\).
The logarithm of \(S^A_l\) is given by a norm convergent 
series in \(A\),
\begin{align}
  \ln S^A_l=-\sum_{k=1}^\infty \frac{1}{k} (1-S^A_l)^k
  =\sum_{k=1}^\infty \frac{(-1)^{k+1}}{k} \bigg(\sum_{c\in\mathbb{N}_0}\frac{1}{c!} Z_{l,c}^A\bigg)^k\\
=\sum_{\scaleto{\begin{matrix}k\in\mathbb{N}\\c\in\mathbb{N}_0^k\end{matrix}}{15pt}}
  \frac{(-1)^{k+1}}{k ~c!}  \prod_{v=1}^k Z_{l,c_v}^A.
\end{align}
This may be plugged into the expression for \(\tilde{S}^A\)
and the sum may be pulled out of \(\mathrm{d}\Gamma\) due to 
linearity and continuity 
\begin{align}
  \tilde{S}^A\alpha=
  \sum_{k\in\mathbb{N}_0^N}\frac{1}{k!} \prod_{l=1}^N
  \Bigg(\sum_{\scaleto{\begin{matrix}b\in\mathbb{N}\\c\in\mathbb{N}_0^b\end{matrix}}{15pt}}
    \frac{(-1)^{b+1}}{b ~c!}  \mathrm{d}\Gamma\bigg(\prod_{v=1}^b Z_{l,c_v}^A\bigg) \Bigg)^{k_l}\alpha.
\end{align}
Since all of these sums are absolutely convergent, 
we may pull out the innermost sums 
as well and finally change the order of summation according 
to the degree of 
homogeneity in \(A\) of the summands. The result is a 
strongly convergent power series 
on \(\mathcal{F}'\) as claimed in the theorem. 


\end{proof}


\section{The Relationship Between Hadamard States and Admissible Polarisation Classes}\label{sec: hadamard}



This section compares central objects of two different 
types of approaches to quantum field theory (QFT): 
The study of Hadamard states and admissible polarisation classes 
related to sections \ref{sec: mot QED} and \ref{sec: qft intro}
as well as \cite{ivp0,ivp1,ivp2} and future work 
generalising section \ref{chapter geometery} to finite times.
These approaches have different scopes and pursue different 
motivations, which makes a direct comparison difficult.
Nevertheless, the basic protagonists the two approaches 
share much more similarity than is apparent at first glance.
It is the purpose of this section to highlight these common features. 

In subsection \ref{sec:hadamard} we give the definition of a Hadamard 
state, briefly motivate it's usage 
and give its explicit form in the case of flat spacetime subject 
to an external field as computed in the physics literature 
\cite{schlemmer2015current}.

In subsection \ref{sec:pol classes} we briefly describe why 
in the approach of admissible polarisation classes one only keeps 
track of the time
evolution of the projector up to an error that is a 
Hilbert-Schmidt operator. Furthermore, we will give a class 
of candidate \(I_2\)-almost projectors
that have a simple time evolution.

In section \ref{sec:comparison hadamard pol} we find that each 
Hadamard state corresponds to an \(I_2\)-almost projector in a 
natural way.

We choose 
a fixed four-potential \(A\in \mathcal{V}\) 
and \(\Sigma_{\text{in}}\) denotes a 
Cauchy surface earlier than the support of \(A\).


For brevity of notation we denote the minimally coupled 
differential by \(\nabla_{\alpha} = \partial_{\alpha} + 
i A_{\alpha}\).


\subsection{Hadamard States}\label{sec:hadamard}
In the algebraic approach to QFT one puts less emphasise on the 
Hilbert space than is commonly done in non relativistic physics 
because 
it is not a relativistically invariant object.
Instead of introducing a sequence of Fock spaces as was motivated 
in sections \ref{sec: mot QED} and 
\ref{sec: qft intro}, one focuses on the algebra of operators that 
are chosen to do the bookkeeping of statistical 
outcomes of measurements. 

To infer predictions, some part of the necessary computation 
can be conducted on the level of this algebra. However,
eventually, expectation values are to be computed in a certain 
representation, usually found by the GNS construction
with respect to a certain state.
This choice has to be made on physical grounds. 
Hadamard states are often thought to be physically sensible 
states because they have positive energy in a certain sense.

In order to introduce Hadamard states first we have to define 
the notion of wavefront set, which itself needs some preliminaries. 
For the introduction of these concepts we follow 
Hömander \cite[Chapter 8]{hormander2003analysis}.

Throughout this section we will consider a fixed but 
arbitrary four-potential \(A\in\mathcal{V}\).
We begin by introducing the singular support of a distribution

\begin{Def}
Let for \(n,m\in\mathbb{N}\),  \(v\in (C^\infty(\mathbb{R}^n,\mathbb{C}^m))'\) the singular support of \(v\) is defined to be the subset of points \(x\in \mathbb{R}^n\) such
that there is no neighbourhood \(U\) of \(x\) such that there is a smooth function \(\phi_{x,v}\in C^\infty (\mathbb{R}^n,\mathbb{C}^m)\) such that \(v\) acts on 
test functions \(\varphi \in C^\infty_c (U,\mathbb{C}^m)\) as
\begin{align}
v(\varphi)=\int \phi^\dagger_{x,v} (x) \varphi(x) dx.
\end{align}
\end{Def}

The singular support contains all the points of a 
distribution such that the distribution does not act like 
a smooth function at that point. The wavefront set which we are
about to introduce gives additional directional information 
of where these singularities propagate. We incorporate this 
information by the Fourier transform 
in the following definition.

\begin{Def}
Let for \(n,m\in\mathbb{N}\),  \(v\in (C^\infty(\mathbb{R}^n,
\mathbb{C}^m))'\), we denote by \(\Xi(v)\subset \mathbb{R}^n
\backslash\{0\}\) the set of all \(\eta\) such that there is no
cone \(V_\eta\subset \mathbb{R}^n\), neighbourhood of \(\eta\), 
such that for all \(a\in\mathbb{N}\) there is a \(C_a>0\) such that for 
all \(\xi\in V_\eta\) we have
\begin{equation}
|\hat{v}(\xi)|\le \frac{C_a}{1+|\xi|^a}.
\end{equation}

Furthermore for each \(x\in \mathbb{R}^n\) we define 
\begin{equation}
\Xi_x (v) := \bigcap_{\overset{\phi \in C^\infty_c (\mathbb{R}^n)}{x\in \mathrm{supp}(\phi)}} \Xi(v \phi),
\end{equation}
Where \(v\phi\) is the pointwise multiplication of a distribution and a scalar test function, which acts as 
\(v\phi: C^\infty(\mathbb{R}^n,\mathbb{C}^m)\ni \psi\mapsto v(\psi \phi)\). 

Analogously for a tempered distribution that takes two arguments 
\(v:\mathcal{S}(\mathbb{R}^4)\times \mathcal{S}(\mathbb{R}^4)\rightarrow \mathbb{C}\)
we define 
\begin{equation}
  \Xi_{x,y} (v) := \bigcap_{\overset{\phi}{(x,y)\in \mathrm{supp}(\phi)}} \Xi(v \phi), 
\end{equation}
where now \(\phi_{x,y}=\psi_{x} \chi_y\in C_c^\infty(\mathbb{R}^8)\)
with \(\psi_{x} ,\chi_y\in C_c^\infty(\mathbb{R}^4)\)  and \(x\in\supp(\psi_x), y\in\supp(\chi_y)\).
\end{Def}

We have collected the tools to introduce the wavefront set and the notion of Hadamard states.

\begin{Def}[Definition 3.1 of \cite{zahn2014renormalized}]
Let for \(n,m\in\mathbb{N}\), \(v\in (\mathcal{S}(\mathbb{R}^n,\mathbb{C}^m))'\) be a tempered distribution. The wavefront set \(\mathrm{WF}(v)\) of 
the distribution \(v\) is defined as 
\begin{equation}
\mathrm{WF}(v):= \left\{(x,\xi)\in \mathbb{R}^n\times \mathbb{R}^n\mid \xi \in \Xi_x(v) \right\}.
\end{equation}
Analogously for a tempered distribution 
\(v:\mathcal{S}(\mathbb{R}^4,\mathbb{C}^4)\times \mathcal{S}(\mathbb{R}^4,\mathbb{C}^4)\rightarrow \mathbb{C}\)
we define the wavefront set as
\begin{equation}
  \mathrm{WF}(v):= \left\{(x,\xi;y,\xi')\in \mathbb{R}^{16}\mid (\xi,\xi') \in \Xi_{x,y}(v) \right\}.
\end{equation}
\end{Def}

\begin{Def}\label{def: hadamard}
A map \(H: \mathcal{S}(\mathbb{R}^4,\mathbb{C}^4)\times \mathcal{S}(\mathbb{R}^4,\mathbb{C}^4) \rightarrow \mathbb{C}\), is called Hadamard state if it fulfils
for all \( f,g\in \mathcal{S}(\mathbb{R}^4,\mathbb{C}^4)\):

\begin{align}
H(Df,g)=0\\
H(f,g)+H(g,f)=i S_{\text{prop}}(f,g)\\
\overline{H(f,g)}=H(\overline{f},\overline{g})\\
\text{WF}(H)\subset C_+,
\end{align}
where \(S_{\text{prop}}(f,g)\) is the propagator of the Dirac equation, 
  and  \(C_+:=\{(x,y;k_1,-k_1)\in\mathbb{R}^{16}\mid (x;k_1)\approx (y;k_2) , k_1^2\ge0, k_1^0>0\}\)
and \((x;k_1)\approx(y;k_2)\) holds whenever \((x-y)^2=0\) and \((y-x)\parallel k_1\).
\end{Def}
It is in the sense of the fourth condition that Hadamard states are of positive energy.

In the scenario of Minkowski spacetime in an external field Dirac \cite{Dirac34} already studied the Hadamard states, although that name was not established at the time.
More recently the subject has attracted considerable attention. 
The Hadamard states were computed in \cite{zahn2014renormalized, schlemmer2015current}. 
They are given in terms of the Klein-Gordon operator corresponding to Dirac's equation:


\begin{Def}
The Klein-Gordon operator corresponding to the Dirac 
equation in an external field \eqref{dirac ext field} reads
\begin{align}
&P: C^\infty(\mathbb{R}^4,\mathbb{C}^4)\rightarrow C^\infty(\mathbb{R}^4,\mathbb{C}^4)\\
&P=(i\slashed{\nabla}-m)(-i\slashed{\nabla}-m)=\nabla_\alpha \nabla^\alpha + \frac{i}{2} \gamma^\alpha \gamma^\beta F_{\alpha,\beta} +m^2,
\end{align}
where \(F_{\alpha,\beta}=\partial_\alpha A_\beta - \partial_\beta A_\alpha\) is the field strength tensor of the electromagnetic field. Furthermore we 
define for \(f\in \mathcal{C}^\infty(\mathbb{R}^4\times \mathbb{R}^4,\mathbb{C}^{16})\) the differential operator
\begin{equation}
\slashed{\nabla}^* f(x,x')=\left(\frac{\partial}{\partial y^\alpha} - i A_\alpha(y)\right)f(x,y)\gamma^\alpha.
\end{equation}
\end{Def}


For the special case of a Dirac field in Minkowski space-time Zahn \cite{schlemmer2015current} gave a more explicit form of
the Hadamard states \(H \in (\mathcal{S}(\mathcal{M},\mathbb{C}^4)\times \mathcal{S}(\mathcal{M},\mathbb{C}^4))'\)  on which we base our analysis below.
According to this, \(H\) 
acts for \(f_1,f_2\in C_c^\infty(\mathcal{M})\otimes \mathbb{C}^4\) as 
\begin{equation}\label{eq:hadamard1}
H(f_1,f_2)=\lim_{\varepsilon\searrow 0} \int_{\mathbb{R}^4}d^4 x \overline{f_1}(x) \int_{\mathbb{R}^4} d^4y ~h_\varepsilon(x,y) f_2(y),
\end{equation}
where \(h_\varepsilon\) is of the form

\begin{align}\nonumber
h_\varepsilon (x,y)&=\\\label{eq:hadamardexp1}
&\frac{-1}{2(2\pi)^2}(-i \slashed{\nabla} + i \slashed{\nabla}^\ast -2m)\Big[\frac{e^{-i (x-y)^\alpha\int_0^1 ds A_\alpha (x s + (1-s)y)}}{ (y-x-i \varepsilon e_0)^2}\Big]\\\label{eq:hadamardexp2}
+&\frac{-1}{2(2\pi)^2}(-i \slashed{\nabla} + i \slashed{\nabla}^\ast -2m)\Big[ V(x,y) \ln (-(y-x-i \varepsilon e_0)^2)\Big]\\\label{eq:hadamardexp3}
&+B(x,y),
\end{align}
%
%für das Vorzeichen, beachte, dass H^- aus dem Zahn paper genommen wird, was das gleiche ist wie x und y zu tauschen
%
where \(V,B:\mathbb{R}^4\rightarrow \mathbb{C}^4\) are smooth functions, \(B\) is completely arbitrary, 
whereas \(V\) is fixed by the external potential. The expansion
\begin{equation}
V^N(x,y):=\sum_{k=1}^N \frac{1}{ 4^{k} k!(k-1)!} V_k(x,y) \big((x-y)^2\big)^{k-1},
\end{equation}
is an asymptotic expansion for \(V\) for 
\(N\rightarrow \infty\), in the sense that
\((V-V^N)(x,y)\ln(-(x-y)^2)\) as a function of \(x\) and 
\(y\) is in \(C^{N-2}(\mathbb{R}^{4+4})\)
and \((V-V^N)(x,y)=\mathcal{O}\left(\left((x-y)^{2}\right)^{N-2}\right)\).
The functions \(V_k\) fulfil the recursive set of partial 
differential differential equations
\begin{align}\label{Hadamard recursive equ.}
(x-y)^\alpha (\partial_{x,\alpha}+i A_\alpha(x)) V_{n}(x,y) + n V_{n}(x,y)=-n P V_{n-1}(x,y),
\end{align}
where \(V_{0}(x,y)=e^{-i (x-y)^\alpha\int_0^1 ds A_\alpha (x s + (1-s)y)}\). 

For the rest of this paper, we assume that for any \(A\in C_c^\infty(\mathbb{R}^4)\) there are \(H\), \((h_\varepsilon)_{\varepsilon>0}\) and \(V\)
fulfilling all of the conditions described in this subsection.
 

\subsection{Projectors for Polarisation Classes}\label{sec:pol classes}

Polarisation classes as introduced in 
definition \ref{def pol class} can be represented by 
a projector onto a polarisation of that class. 
Alternatively it can also be represented by 
an operator that is Hilbert-Schmidt close to 
such a projector, these will be called 
\(I_2\)-almost projectors. 

We follow \cite{ivp2} in introducing the necessary 
notation to do so.
We start out by characterising the polarisation classes for free motion.
\begin{Def}[kernel fo \(P^-\)]
The projector \(P^{\mathcal{H}^-}_{\Sigma} \) has the well known representation 
as the weak limit of the integral operator 
with the kernel\cite{ivp2}

\begin{equation}
p^-_\varepsilon(x,y)= -\frac{m^2}{4\pi^2}(i\slashed{\partial}_x+m) \frac{K_1(m \sqrt{-(y-x-i \varepsilon e_0)^2})}{m \sqrt{-(y-x-i \varepsilon e_0)^2}},
\end{equation}
where the square is a Minkowski square, the 
square root denotes its principle value and 
\(K_1\) is a modified Bessel function. By weak 
limit we mean

\begin{align}
\langle \phi, P^{\mathcal{H}^-}_{\Sigma} \psi\rangle = \lim_{\varepsilon \searrow 0} \int_{\Sigma\times \Sigma} \overline{\phi}(x) i_\gamma(d^4x) p^-_\varepsilon(x,y ) i_\gamma(d^4y) \psi(y),
\end{align}

for general \(\phi, \psi \in \mathcal{H}_\Sigma\).
\end{Def}

\begin{Remark}
By inserting the expansion of \(K_1\) in terms of a Laurent series and a 
logarithm, \cite{abramowitz1965handbook} one obtains:

\begin{align}\label{K1series}
K_1(\xi) = \frac{1}{\xi}- \frac{\xi}{4} \sum_{k=0}^\infty \left(2 \psi(k+1)+\frac{1}{k+1}+2\ln 2 -2 \ln \xi \right) \frac{\left(\frac{\xi^2}{4}\right)^k}{k!^2 (k+1)}\\\label{def:Q}
:=\frac{1}{\xi} + \xi Q_1(\xi^2) \ln \xi +\xi Q_2(\xi^2)=:\frac{1}{\xi} + \xi Q_3(\xi).
\end{align}

It is not obvious from the equation \eqref{Hadamard recursive equ.} but well known that the
  vacuum of Minkowski spacetime does indeed
correspond to  a Hadamard state subject to vanishing four potential. In fact, the Hadamard states were constructed to 
agree with the Minkowski vacuum up to smooth terms.
\end{Remark}




Because all we are interested in is representations of 
equivalence classes, we are content with finding
objects that differ from a Projector onto 
\(U_{\Sigma,\Sigma_{\text{in}}}^A \mathcal{H}_{\Sigma_{in}}^-\) 
by a Hilbert-Schmidt operator.
Therefore we need not keep track of the exact evolution of 
the projectors, but define a whole class of admissible ones.

\begin{Def}[kernel of \(P^\lambda\), \(I_2\)-almost projectors]\label{def:lambda}
The set \(\mathcal{G}^A\) denotes the set of all functions \(\lambda^A \in C^\infty (\mathbb{R}^4\times \mathbb{R}^4, \mathbb{R})\) that satisfy
\begin{enumerate}[label= \roman*) ]
\item There is a compact set \(K\subset \mathbb{R}^4\) such that \(\supp \lambda \subseteq K\times \mathbb{R}^4 \cup \mathbb{R}^4 \times K\).
\item \(\lambda\) satisfies \(\forall x \in \mathbb{R}^4: \lambda(x,x)=0\).
\item On the diagonal the first derivatives fulfil 
\begin{equation}
\forall x,y\in\mathbb{R}^4: \partial_x \lambda(x,y)|_{y=x}=-\partial_y \lambda(x,y)|_{y=x} = A(x).
\end{equation}
\end{enumerate}
We futhermore define a corresponding \(I_2-\)almost projector \(P^\lambda\):
\begin{align}
\langle \phi, P^\lambda_\Sigma \psi\rangle =& \lim_{\varepsilon \searrow 0} \langle \phi, P^{A,\varepsilon}_\Sigma \psi\rangle ,\\\label{def:p lambda}
\langle \phi, P^{\lambda,\varepsilon}_\Sigma \psi\rangle :=&
\int_{\Sigma\times\Sigma}\overline{\phi}(x)i_\gamma(d^4x) 
\overbrace{e^{-i \lambda(x,y)} p^-_\varepsilon(y-x)}^{=:p^\lambda_\varepsilon(x,y)}i_\gamma(d^4y) \psi(y),
\end{align}
for general \(\phi, \psi \in \mathcal{H}_\Sigma\).
\end{Def}

\begin{Remark}[theorem 2.8 and  1.5 of \cite{ivp2}]\label{main results of ivp2}
\(P_{\Sigma}^\lambda\) and \( P_{\Sigma'}^\lambda\) are 
equivalent if transported appropriately by time evolution 
operators:

\begin{equation}
P_{\Sigma}^\lambda-U_{\Sigma,\Sigma'}^A P_{\Sigma'}^\lambda U_{\Sigma',\Sigma}\in I_2(\mathcal{H}_\Sigma).
\end{equation}
Also for four-potentials 
\(A,B\in \mathcal{V}\) 
the corresponding projectors are equivalent if and only 
if the four-potentials projected onto the hypersurface 
agree:

\begin{equation}\label{equiv:pLambda}
P_{\Sigma}^{\lambda^A} - P_{\Sigma}^{\lambda^B} \in I_2(\mathcal{H}_\Sigma) \iff \forall x\in \Sigma~ \forall z\in T_x \Sigma: z^\alpha(A_\alpha(x)-B_\alpha(x))=0.
\end{equation}
\end{Remark}



Taking into account the freedom within each classification the notions Hadamard state and  projectors of polarisation classes are extremely close. 
This is the topic of the next section.


\subsection{Comparing Hadamard States and \(P^\lambda_\Sigma\)}\label{sec:comparison hadamard pol}

The following theorems is the basis of our comparison 
between\linebreak Hadamard states and \(I_2-\) almost Projectors. 


\begin{Thm}\label{thm:hadamard=>Pol}
Given a four-potential \(A\in \mathcal{V}\), and a Hadamard state \(H\) of the form 
\eqref{eq:hadamard1} to \eqref{eq:hadamardexp3}, there is a family of smooth functions 
\((w_\varepsilon)_{\varepsilon>0}\) in 
\( C^\infty(\mathbb{R}^4\times \mathbb{R}^4,\mathbb{C}^{4\times 4})\), such that for any Cauchy surface 
\(\Sigma\) there is an operator  acting as
\begin{equation}
\mathcal{H}_{\Sigma} \ni \psi \mapsto \tilde{P}\psi= \lim_{\varepsilon \rightarrow 0} \int_{\Sigma} (h_\varepsilon - w_\varepsilon)(\cdot,y)i_{\gamma}(d^4y) \psi(y).
\end{equation}
This operator \(\tilde{P}\) is bounded on 
\(\mathcal{H}_\Sigma\) and fulfils 
\(P^{\lambda^A}-\tilde{P}\in I_2(\mathcal{H}_\Sigma)\) 
for any \(\lambda^A\in \mathcal{G}^A\) . 
Additionally, the pointwise limit of 
\((w_\varepsilon)_{\varepsilon}\) for 
\(\varepsilon \rightarrow 0\) is smooth.
\end{Thm}

\begin{Thm}\label{thm:Pol=>hadamard}
Given a four-potential \(A\in \mathcal{V}\) and a \(\lambda^A\in\mathcal{G}^A\), there is a family of functions
\((w_\varepsilon)_\varepsilon>0\) in \( C^\infty(\mathbb{R}^4 \times \mathbb{R}^4 ,\mathbb{C}^{4\times 4})\) such that for all Cauchy surfaces \(\Sigma\)
the restriction \(w_\varepsilon|_{\Sigma\times\Sigma}\) can be 
split
\begin{equation}
  w_\varepsilon|_{\Sigma\times\Sigma}=w_{1,\varepsilon}+w_{2,\varepsilon},
\end{equation}
such that \(w_{1,\varepsilon}\) has a \(L^2(\Sigma\times\Sigma,\mathbb{C}^{4\times4})\) 
limit for \(\varepsilon\rightarrow 0\) and 
\(w_{2,\varepsilon}\) has a smooth pointwise limit and  is continuous 
as a function of type \(\Sigma\times\Sigma\times[0,1]\rightarrow \mathbb{C}^{4\times 4}\). 
Furthermore, \(\tilde{H}\) acting on test functions \(f_1,f_2\in C^\infty(\mathbb{R}^{4}, \mathbb{C}^4)\) as

\begin{equation}
\tilde{H}(f_1,f_2)=\lim_{\varepsilon \rightarrow 0} \int_{\mathbb{R}^{4}\times\mathbb{R}^4} \overline{f_1}(x)
\left(p_\varepsilon^{\lambda^A}(x,y)-w_\varepsilon(x,y)\right)f_2(y) d^4x d^4y
\end{equation}

is a Hadamard state of the form \eqref{eq:hadamard1} to \eqref{eq:hadamardexp3}.
\end{Thm}

The proofs are to be found in section 
\ref{sec: proof hadamard} of the appendix.

\begin{Remark}
In the approach of polarisation classes, two projectors represent the same polarisation class if and only if their difference is a Hilbert-Schmidt operator. 
Because of this fact, it is enough to keep track of the time evolution of a projector only up to changes by a Hilbert-Schmidt operator, i.e. it is enough
to find the time evolution of an \(I_2\)-almost projector representing the correct polarisation class. 

Keeping this in mind,
theorem \ref{thm:hadamard=>Pol} states that, up to a \(C^\infty\) 
correction, the integral kernel of the Hadamard state is the integral 
kernel of a \(I_2\)-almost projector.
Theorem \ref{thm:Pol=>hadamard} states that, up to \(L^2+C^\infty\) 
corrections, the integral kernel of a \(I_2\)-almost projector is a 
Hadamard state.

The \(C^\infty\) freedom is due to the definition of a 
Hadamard state. The \(L^2\) freedom originates from the definition 
of \(I_2\)-almost projector.

In this sense, the relevant difference in  singularity structure 
between a Hadamard state and an 
\(I_2\)-almost projector is given by terms 
\eqref{wurm A} to  \eqref{wurm E} of the appendix.
\end{Remark}

\section{Summary and Conclusions}

In the third chapter of this thesis we worked on a quantum 
field theoretic formulation of electromagnetic interactions.
While this approach is more conventional than what was 
presented in chapter \ref{chap: direct interaction} 
that does not at all imply that the general theory has been worked 
out on a mathematically rigorous level. So much so that 
our work on external field QED, i.e. neglecting all 
interaction between particles, can be regarded as 
at the frontier of our present understanding. 
The chapter started with a short summary of the 
approach to construct a lift of the one-particle 
time evolution operator where we mentioned 
the shortcoming of the present method, not
uniquely identifying the phase of this operator.
Subsequently, we gave a geometric construction of 
said phase in the scattering regime 
from an object \(c^+\) very closely related to the 
current induced by an external field. If such an 
object were identified the residual freedom might be 
reduced to an irrelevant constant phase and a single 
number related to the charge of the electron.  
Furthermore we showed that there is a lift of the 
one-particle scattering operator that is analytic in the 
external field and gave a compact explicit fomula for 
weak fields. Furthermore, we saw that this implies 
that the scattering operator can be seen as a power 
series in the external field and that this also 
holds true for arbitrary four-potentials 
\(A\in\mathcal{V}\). Finally we gave theorems on how 
\(I_2-\)almost projectors representing the state 
of the fermion field are related to the approach we 
are following here compare to the concept of Hadamard 
state popular in the algebraic formulation of QFT.

I hope that in the near future the construction of 
\(c^+\) will succed, so that one can further analyse 
a self consisten model. In such a model one 
feeds the current generated by the 
fermion field induced by the action of an electrodynamic 
field into Maxwells equations and acts with the 
resulting fields again on the fermion field. Such a 
model would incorporate a mean field interaction between 
the fermions and would thus be a further 
step in the direction 
of a fully interacting theory.












\chapter{Appendix}




\section{Regularity of the One-Particle Scattering Operator}\label{chap:regularity of S}
In this section we analyse the construction of the  one-particle 
scattering operator \(S_A\)
carried out in \cite{ivp0} and answer the question whether
operators like
\begin{equation}
P^+ \partial_B S_{A}^* S_{A+B}P^-
\end{equation}
are Hilbert-Schmidt operators. This is important 
for the geometric construction carried out in 
chapter \ref{chapter geometery}. 

Since this section is heavily inspired by \cite{ivp0}, we need
to introduce some notation from this paper. 
\begin{Def}
Let \(A\in\mathcal{V}\), we define the the integral operator
\(Q^A:\mathcal{H}\righttoleftarrow\) by giving its integral kernel, which 
is also denoted by \(Q^A\):
\begin{align}
\mathbb{R}^3\times\mathbb{R}^3\ni (p,q)\mapsto Q^A(p,q)
:=\frac{Z^A_{+-}(p,q)-Z^A_{-+}(p,q)}{i(E(p)+E(q))}\\
\text{with }Z^A_{\pm\mp}(p,q):=P_\pm (p)Z^A(p-q)P_\mp (q),\\
Z^A=-i e\gamma^0 \gamma^\alpha \hat{A}_\alpha,\\
%\hat{A}_\mu(t):\mathcal{H} \righttoleftarrow, \hat{A}_\mu(t)\psi:= \hat{A}_\mu(t) \ast \psi,\\
\hat{A}_\mu := \frac{1}{(2\pi)^{3/2}}\int_{\mathbb{R}^3} A_\mu (x)e^{-i p x} d^3x,\\ 
\text{and } E(p):=\sqrt{m^2+|p|^2}.
\end{align}

\end{Def}



\begin{fact}
Plase recall that for general \(A,F\in\mathcal{V}\) 
and \(t_0,t_1\in\mathbb{R}\) 
we have the well known equations for
the one-particle time evolution operators

\begin{align}
U^A(t_1,t_0)=U^0(t_1,t_0) + \int_{t_0}^{t_1}dt~ U^0(t_1,t) Z^A(t) U^{A}(t,t_0)\\
U^{A+F}(t_1,t_0)=U^A(t_1,t_0) + \int_{t_0}^{t_1}dt ~U^A(t_1,t) Z^F(t) U^{A+F}(t,t_0).
\end{align}
\end{fact}


\begin{Def}
For any \(A\in\mathcal{V}\), we introduce the 
integral operator 
\({Q'}^A:\mathcal{H}\righttoleftarrow\) by it's kernel
\begin{equation}
\mathbb{R}\times\mathbb{R}^3\times\mathbb{R}^3
\ni(t,p,q)\mapsto {Q'}^A(t,p,q)=\partial_t Q^A(t,p,q),
\end{equation}
where the time dependence is due to the time dependence of the 
four-potential \(A\).
The following notion of even and odd part of 
an arbitrary bounded linear operator 
\(T:\mathcal{F}\righttoleftarrow\) on 
Fock space will come in handy:
\begin{align}
T_{\mathrm{odd}}&:=P^+TP^- + P^-TP^+\\
T_{\mathrm{ev}}&:=P^+TP^+ + P^-TP^-.
\end{align}

Additionally, we define the norm 
\begin{equation}
  T:\mathcal{H}\righttoleftarrow \|T\|_{\mathrm{op}+I_2}=\|T\|+\|T_{\odd}\|_{I_2},
\end{equation}
where \(\|\cdot\|\) is the operator norm and \(\|\cdot\|_{I_2}\) is the 
Hilbert-Schmidt norm and the space
\begin{equation}
I_2^{\odd}:=\{T:\mathcal{F}\rightarrow \mathcal{F}\mid
\|T\|<\infty, \|T_{\odd}\|_{I_2}<\infty\}.
\end{equation}

\end{Def}




\begin{Lemma}\label{completeness of I_2 odd}
The space \(I_2^{\odd}\)
equipped with the norm 
\(\|\cdot\|_{\mathrm{op}+I_2}\) is a 
Banach space.
\end{Lemma}
\begin{proof}
Let \((T_n)_{n\in\mathbb{N}}\subset I_2^{\odd}\)
be a Cauchy sequence with 
respect to \(\left\|\cdot\right\|_{\mathrm{op}+I_2}\). 
Then it follows directly that 
\((T_n)_{n\in\mathbb{N}}\)
is also a Cauchy sequence with 
respect to \(\|\cdot\|\) and
\((T_{n,\odd})_{n\in\mathbb{N}}\) is a Cauchy
sequence with respect to
\(\|\cdot\|_{I_2}\). Since 
the space of bounded operators equipped with
\(\|\cdot\|\) and
the space of Hilbert-Schmidt oeprators 
equipped with \(\|\cdot\|_{I_2}\) both are
complete we have

\begin{align}
T_n\xrightarrow[\|\cdot\|]{n\rightarrow \infty} T^1\\
T_{n,\odd}\xrightarrow[\|\cdot\|_{I_2}]{n\rightarrow \infty} T^2
\end{align}
for some bounded operator \(T^1\) and some 
Hilbert-Schmidt operator \(T^2\). Now because 
the Hilbert-Schmidt norm  fulfills
\begin{equation}
\|T\|\le \|T\|_{I_2},
\end{equation} 
we obtain directly
\begin{equation}
T_{n,\odd}\xrightarrow[\|\cdot\|]{n\rightarrow \infty} T^2,
\end{equation}
hence \(T^1_{\odd}=T^2\). 
Therefore, \(T^1\in I_2^{\odd}\) holds. 
Finally, since 
\(\|\cdot\|_{\mathrm{op}+I_2}
=\|\cdot\|+\|\cdot_{\odd}\|_{I_2}\) is true, 
we find 
\begin{equation}
T_n\xrightarrow[\|\cdot\|_{\mathrm{op}+I_2}]{n\rightarrow \infty} T^1,
\end{equation}
proving completeness.
\end{proof}


For the following theorem and lemma we are going to 
make use of the 
following shorthand notation of \cite{ivp0}. For operator valued maps 
\(T_1,T_2:\mathbb{R}^2\to \mathcal{B}(\mathcal{H}) \) we define 
for \(t_1,t_0\in\mathbb{R}\)
\begin{equation}
T_1T_2 := \int_{t_0}^{t_1}dt~ T_1(t_1,t)T_2(t,t_0),
\end{equation}
as a map of the same type as \(T_1\) and \(T_2\)
whenever this is well-defined. Furthermore, for operator valued functions
\(W_1,W_2:\mathbb{R}\to \mathcal{B}(\mathcal{H})\) we define
\begin{align}\label{ivp0 shortnotation 1}
T_1W_1~(t',t):=T_1(t',t)C_1(t)\\\label{ivp0 shortnotation 2}
W_1 T_1~(t',t):=W(t_1)T_1(t',t)\\
W_1W_2~(t):=W_1(t)W_2(t),
\end{align}
as maps of the same type as \(T_1, T_1\) and \(C_1\) 
respectively.

Pick \(k\in\mathbb{N}\), \(A,H_b\in\mathcal{V}\) for \(b\le k\) 
and \(t_1,t_0\) such that \(t_1\) is later and \(t_0\) is earlier 
than the support of \(A\) and all \(H_b\). Whenever the shorthand 
\eqref{ivp0 shortnotation 1} and \eqref{ivp0 shortnotation 2}
is used without specific arguments, by convention 
\(t'=t_1,t=t_0\).  We abbreviate
\begin{equation}
H:=\sum_{b=1}^k H_b, \quad B:=A+H.
\end{equation}
We introduce 
\begin{equation}
  R^B(t',t):=(1-Q^B)U^B(1+Q^B)(t',t),
\end{equation}
for general \(t',t\in\mathbb{R}\).
Because of the choice of \(t_1,t_0\) we have
\begin{equation}\label{def R}
R^B(t_1,t_0)=(1-Q^B)U^B(1+Q^B)=U^B(t_1,t_0),
\end{equation}
because \(B=0\) both at \(t_1\) and \(t_0\).

So it suffices to study the family of operators \(R^B\). 
As shown in the proof of \cite[lemma 3.5]{ivp0}
\(R^B\) for \(B\in\mathcal{V}\) is the limit in the sense of the 
operator norm of the sequence
\begin{align}
R^B_{0}:=0, \quad R^B_{n+1}:=U^0 \mathsf{F}^B R^B_{n}+ U^0 + \mathsf{G}^B,
\end{align}
where \(\mathsf{F}\) and \(\mathsf{G}\) are given By

\begin{align}
  \mathsf{F}^B:=& (-{Q'}^B+Z^B_{\ev}-Q^BZ^B)(1+Q^B),\\
  \mathsf{G}^B:=&- U^0Q^BQ^B \\
+& U^0(-{Q'}^B+Z_{\ev}-Q^B Z^B)Q^B Q^B U^B (1+Q^B).
\end{align}

Finally we introduce the auxiliary norms for operators \(T\) 
and \(W\) depending on one and two 
scalar variables respectively.

\begin{align}
  \|T \|_{\mathrm{op}+I_2,\gamma}
  &:=\sup_{t\in[t_1,t_0]}e^{-\gamma (t-t_0)} \|T(t)\|
  +\sup_{t\in[t_1,t_0]}e^{-\gamma (t-t_0)} \| T_{\odd}(t)\|_{I_2}\\
  \|T \|_{\gamma}&:=\sup_{t\in[t_1,t_0]}e^{-\gamma (t-t_0)} \|T(t)\|\\
  \|W \|_{0}&:=\sup_{t,t'\in[t_1,t_0]} \|W(t,t')\|\\
  \|T \|_{I_2 ,\gamma}&:=\sup_{t\in[t_1,t_0]}e^{-\gamma (t-t_0)} \| T(t)\|_{I_2},\\
  \|W \|_{I_2 ,0}&:=\sup_{t,t'\in[t_1,t_0]} \| W(t,t')\|_{I_2},
\end{align}
for \(\gamma\ge 0 \).

Now we have collected enough tools to proof 

\begin{Thm}[Smoothness of S]\label{thm smoothness of S}
Let \(n\in\mathbb{N}\),  \(A,H_{k}\in\mathcal{V}\) for 
\(k\le n\), pick \(t_1\) 
after \(\supp A\cup \bigcup_{k\le n}\supp H_k\) and \(t_0\)
before \(\supp A\cup\bigcup_{k\le n}\supp H_k\) then 
the derivative 
\begin{equation}
  \partial_{H_1}\dots \partial_{H_k}U^{A+\sum_{b=1}^k H_b}(t_1,t_0)
\end{equation}
exists with respect to the topology induced by 
the norm \(\|\cdot\|_{\mathrm{op}+I_2}\).
\end{Thm}
\begin{proof}
We will follow the corresponding proof in \cite{ivp0}.
In the proof of the Grönwall lemma in \cite[equation (3.42)]{ivp0}
we also have that the recursive equation 
\begin{align}
R^B_{n}=U^0\mathsf{F}^B_{\ev}R^B_{n-1}+U^0\mathsf{F}^B_{\odd} U^0\mathsf{F}^B R^B_{n-2}\\
+U^0 \mathsf{F}^B_{\odd}\mathsf{G}^B +U^0F^B_{\odd} U^0 + U^0 +\mathsf{G}^B
\end{align}
is fulfilled by the same sequence of operators for \(n\ge 2\).
Furthermore, we introduce the notation
\begin{align}\label{derivative set 1}
[k]&=\{l\in\mathbb{N}\mid l\le k\}\\\label{derivative set 2}
\forall u\subseteq [k]:\partial_{u}&=\prod_{k\in u}\partial_{H_k},\\
\Delta^n&=R^B_{n+1}-R^B_n,
\end{align}
where the product of derivatives is to be understood as the 
mixed derivative with respect to all the factors and 
we use the derivative defined in 
\eqref{def derivative}.

Hence we have for such \(n\):
\begin{align}\notag
  \Delta_{n}=&U^0\mathsf{F}^B_{\ev}\Delta_{n-1}
  +U^0\mathsf{F}^B_{\odd} U^0\mathsf{F}^B \Delta_{n-2}.
\end{align}
Abbreviating \(U^0\mathsf{F}^B_{\ev}=:a,\quad 
U^0\mathsf{F}^B_{\odd}U^0 \mathsf{F}^B:=b\), we obtain
\begin{align}\label{R recurisve}
  \Delta_{n}=a\Delta_{n-1}
  +b \Delta_{n-2}.
\end{align}

we estimate for any set \(u\subset [k]\):

\begin{align}
&\sup_{p\subseteq u}\|\partial_p \Delta^n_{\odd}(\cdot,t_0) \|_{I_2,\gamma}\\
&\le \sup_{p\subseteq u} \sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)}
\left\| \sum_{w\subseteq p} (\partial_{p\backslash w}a ~
\partial_w \Delta^{n-1}_{\odd})(t,t_0)\right\|_{I_2}\\
&+\sup_{p\subseteq u} \sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)}
\left\|P^+ \sum_{w\subseteq p} (\partial_{p\backslash w}b ~
\partial_w \Delta^{n-2})(t,t_0) P^-\right\|_{I_2}\\
&+\sup_{p\subseteq u} \sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)}
\left\|P^- \sum_{w\subseteq p} (\partial_{p\backslash w}b ~
\partial_w \Delta^{n-2})(t,t_0) P^+\right\|_{I_2}\\
&\le 
\sup_{p\subseteq u} \sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)} 
\sum_{w\subseteq p} 
\| (\partial_{p\backslash w}a ~
\partial_w \Delta^{n-1}_{\odd})(t,t_0)\|_{I_2}\\
&+2\sup_{p\subseteq u} \sup_{t\in[t_0,t_1]} 
e^{-\gamma(t-t_0)} \sum_{w\subseteq p} 
\|  (\partial_{p\backslash w}b ~
\partial_w \Delta^{n-2})(t,t_0) \|_{I_2}\\
&\le
\sup_{p\subseteq u}\sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)} 
\sum_{w\subseteq p} 
\int_{t_0}^{t}dt' 
\| \partial_{p\backslash w}a(t,t') ~
\partial_w \Delta^{n-1}_{\odd}(t',t_0)\|_{I_2}\\
&+2 \sup_{p\subseteq u}
\sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)}\sum_{w\subseteq p} 
\int_{t_0}^{t}dt'  
\|  \partial_{p\backslash w}b(t,t') ~
\partial_w \Delta^{n-2}(t',t_0) \|_{I_2}\\
&\le
\sup_{p\subseteq u}\sup_{t\in[t_0,t_1]} 
e^{-\gamma(t-t_0)} \sum_{w\subseteq p} 
\int_{t_0}^{t}dt' 
\| \partial_{p\backslash w}a\|_{0}
\|\partial_w \Delta^{n-1}_{\odd}(t',t_0)\|_{I_2}\\
&+2 \sup_{p\subseteq u}
\sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)}\sum_{w\subseteq p} 
\int_{t_0}^{t}dt'  
\|  \partial_{p\backslash w}b(t,t')\|_{I_2}
\|\partial_w \Delta^{n-2}(t',t_0) \|\\
&\le
\sup_{p\subseteq u}\sup_{t\in[t_0,t_1]} 
e^{-\gamma t} \sum_{w\subseteq p} 
\int_{t_0}^{t}dt' e^{\gamma t'}
\| \partial_{p\backslash w}a\|_{0}
\|\partial_w \Delta^{n-1}_{\odd}(\cdot,t_0)\|_{I_2,\gamma}\\
&+2 \sup_{p\subseteq u}\sup_{t\in[t_0,t_1]} 
e^{-\gamma t}\sum_{w\subseteq p} 
\int_{t_0}^{t}dt'  e^{\gamma t'}
\|  \partial_{p\backslash w}b\|_{I_2,0}
\|\partial_w \Delta^{n-2}(\cdot,t_0) \|_{\gamma}\\
&\le
\frac{1}{\gamma} \sup_{p\subseteq u} \sum_{w\subseteq p} 
\| \partial_{p\backslash w}a\|_{0}
\|\partial_w \Delta^{n-1}_{\odd}(\cdot,t_0)\|_{I_2,\gamma}\\
&+\frac{2}{\gamma} \sup_{p\subseteq u} \sum_{w\subseteq p} 
\|  \partial_{u\backslash w}b\|_{I_2,0}
\|\partial_w \Delta^{n-2}(\cdot,t_0) \|_{\gamma}\\
&\le
\frac{2^{|u|}}{\gamma} \sup_{u'\subseteq u} 
\| \partial_{u'}a\|_{0} \sup_{p\subseteq u} 
\|\partial_p \Delta^{n-1}_{\odd}(\cdot,t_0)\|_{I_2,\gamma}\\
&+\frac{2^{|u|+1}}{\gamma} \sup_{u'\subseteq u} 
\|  \partial_{u'}b\|_{I_2,0}\sup_{p\subseteq u}
\|\partial_p \Delta^{n-2}(\cdot,t_0) \|_{\gamma}
\end{align}

Similarly we compute the operator norm:

\begin{align}
  &\sup_{p\subseteq u}\|\partial_p \Delta^n (\cdot,t_0)\|_{\gamma}\\
  &\le 
  \sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)}\sup_{p\subseteq u} 
  \sum_{w\subseteq p} 
  \| (\partial_{p\backslash w}a ~
  \partial_w \Delta^{n-1})(t,t_0)\|\\
  &+\sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)}\sup_{p\subseteq u} 
  \sum_{w\subseteq p} 
  \|  (\partial_{p\backslash w}b ~
  \partial_w \Delta^{n-2})(t,t_0) \|\\
  &\le
  \sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)}
  \sup_{p\subseteq u} \sum_{w\subseteq p} 
  \int_{t_0}^{t}dt' 
  \| \partial_{p\backslash w}a(t,t') ~
  \partial_w \Delta^{n-1}(t',t_0)\|\\
  &+ \sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)}
  \sup_{p\subseteq u}\sum_{w\subseteq u} 
  \int_{t_0}^{t}dt'  
  \|  \partial_{p\backslash w}b(t,t') ~
  \partial_w \Delta^{n-2}(t',t_0) \|\\
  &\le
  \sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)}
  \sup_{p\subseteq u} \sum_{w\subseteq p} 
  \int_{t_0}^{t}dt' 
  \| \partial_{p\backslash w}a(t,t')\|
  \|\partial_w \Delta^{n-1}(t',t_0)\|\\
  &+ \sup_{t\in[t_0,t_1]} e^{-\gamma(t-t_0)}
  \sup_{p\subseteq u} \sum_{w\subseteq p} 
  \int_{t_0}^{t}dt'  
  \|  \partial_{p\backslash w}b(t,t')\|
  \|\partial_w \Delta^{n-2}(t',t_0) \|\\
  &\le
  \sup_{t\in[t_0,t_1]} e^{-\gamma t}
  \sup_{p\subseteq u} \sum_{w\subseteq p} 
  \int_{t_0}^{t}dt' e^{\gamma t'}
  \| \partial_{p\backslash w}a \|_{0}
  \|\partial_w \Delta^{n-1}(\cdot,t_0)\|_{\gamma}\\
  &+ \sup_{t\in[t_0,t_1]} e^{-\gamma t}
  \sup_{p\subseteq u}\sum_{w\subseteq p} 
  \int_{t_0}^{t}dt'  e^{\gamma t}
  \|  \partial_{u\backslash p}b\|_{0}
\|\partial_w \Delta^{n-2}(\cdot,t_0) \|_{\gamma}\\
&\le
\frac{1}{\gamma}\sup_{p\subseteq u} \sum_{w\subseteq p} 
\| \partial_{p\backslash w}a \|_{0}
\|\partial_w \Delta^{n-1}(\cdot,t_0)\|_{\gamma}\\
&+ \frac{1}{\gamma}
\sup_{p\subseteq u} \sum_{w\subseteq p} 
\|  \partial_{p\backslash w}b\|_{0}
\|\partial_w \Delta^{n-2}(\cdot,t_0) \|_{\gamma}\\
&\le
\frac{2^{|u|}}{\gamma}
\sup_{u'\subseteq u}\| \partial_{u'}a \|_{0}
  \sup_{w\subseteq u} 
\|\partial_w \Delta^{n-1}(\cdot,t_0)\|_{\gamma}\\
&+ \frac{2^{|u|}}{\gamma}
\sup_{u'\subseteq u}\| \partial_{u'}b \|_{0}
\sup_{w\subseteq u}
\|\partial_w \Delta^{n-2}(\cdot,t_0) \|_{\gamma}
\end{align}

We can summarise the last calculations more briefly
using the abbreviation
\begin{equation}
\alpha=\frac{2^{|u|+1}}{\gamma} \sup_{u'\subseteq u}
\left\{\|\partial_{u'}a\|_{0},
\|\partial_{u'}b\|_{I_2,\infty},
\|\partial_{u'}b\|_{0}  \right\}.
\end{equation}
Here \(\alpha\) is finite. This can be seen as follows:
firstly, \(\partial_u b=U^0 \partial_u \mathsf{F}^B_{\odd}U^0 \mathsf{F}^B\) 
vanishes if \(|u|\ge 7\) because the factors 
\({Q'}^B\), \(Q^B\) and \(Z^B\) are all linear in 
\(B\) and the longest product of such operators 
appearing in \(b\) has six factors, analogously 
all derivatives \(\partial_u a=0\) for \(|u|\ge 4\).
Secondly, each of the operators  \({Q'}^C\), \(Q^C\) 
and \(Z^C\) are bounded for every \(C\in\mathcal{V}\),
hence the polynomials \(a\) and \(b\) of these 
operators are also bounded. This shows finiteness 
of the two operator norms appearing in the expression 
for \(\alpha\). For the Hilbert-Schmidt norm we 
  see 
that \(\partial_u b\) is always a sum of terms 
where each term has a factor 
\(U^0 \partial_p \mathsf{F}_{\odd}^B U^0\) with \(p\subseteq u\).
This factor has finite Hilbert-Schmidt norm due to 
the \(I_2\) estimate lemma 
\ref{F, G off diagonal hilbert schmidt}.

We can thus summarise the last two calculations 

\begin{align}
&\begin{pmatrix} \sup_{p\subseteq u} \|\partial_p \Delta^{n} \|_{\mathrm{op}+I_2,\gamma}\\
\sup_{p\subseteq u} \|\partial_p \Delta^{n-1}\|_{\mathrm{op}+I_2,\gamma}\end{pmatrix}\\
&\le\begin{pmatrix}\alpha & \alpha \\ 1 & 0 \end{pmatrix}
\begin{pmatrix} \sup_{p\subseteq u} \|\partial_p \Delta^{n-1}\|_{\mathrm{op}+I_2,\gamma}\\
\sup_{p\subseteq u} \|\partial_p \Delta^{n-2}\|_{\mathrm{op}+I_2,\gamma} \end{pmatrix}\\\label{analyticity converging recursion}
&\le\begin{pmatrix}\alpha & \alpha \\ 1 & 0 \end{pmatrix}^{n-1}
  \begin{pmatrix} \sup_{p\subseteq u} \|\partial_p \Delta^{1}\|_{\mathrm{op}+I_2,\gamma}\\
  \sup_{p\subseteq u} \|\partial_p \Delta^{0}\|_{\mathrm{op}+I_2,\gamma} \end{pmatrix}.
\end{align}

This matrix can be diagonalised, it's eigenvalues are
\begin{align}
\lambda_{\pm}= \frac{\alpha}{2}\left(1\pm \sqrt{1+\frac{4}{\alpha}}\right).
\end{align}
The larger eigenvalue \(\lambda_+\) is less than \(1\) if
and only if
\(0<\alpha<0.5\) holds true, as can be seen from a quick 
calculation:
\begin{align}
\frac{\alpha}{2}\left(1+\sqrt{1+\frac{4}{\alpha}}\right)<1 \\
\iff \sqrt{1+\frac{4}{\alpha}}<\frac{2}{\alpha}-1.
\end{align}
If \(\alpha\ge \frac{1}{2}\) or \(\alpha<0\) this inequality is not satisfied, otherwise
we may square both sides to find
\begin{align}
1+\frac{4}{\alpha}<(2/\alpha -1)^2=4/\alpha^2 - 4/\alpha +1\\
\iff \alpha < \frac{1}{2}.
\end{align}
So we conclude that for \(\gamma\) large enough 
the right hand 
side of \eqref{analyticity converging recursion}
tends to zero as \(c \lambda_+^n\) for
\(n\rightarrow \infty\), with
\begin{equation}
c=\sqrt{\sup_{p\subseteq u} \|\partial_p \Delta^1\|^2_{\mathrm{op}+I_2,\gamma}
+\sup_{p\subseteq u} \|\partial_p \Delta^0\|^2_{\mathrm{op}+I_2,\gamma}}.
\end{equation}


Concerning the norms of \(\partial_p \Delta^1\)
and \(\partial_p \Delta^0\): the operator norms 
of these terms are finite, since they are polynomials 
of bounded operators linear in the external potential.
The Hilbert-Schmidt norm of the odd part of these 
terms can be bounded using lemma 
\ref{F, G off diagonal hilbert schmidt}.

That is, we have  
\begin{equation}
\sup_{p\subseteq u}
\|\partial_p \Delta^n\|_{\mathrm{op}+I_2,\gamma}
\le \lambda_+^n c
\xrightarrow{n\rightarrow \infty} 0.
\end{equation}
For \(2\le m\le n\) we obtain  
\begin{align}
&\sup_{p\subseteq u}\| \partial_p R^B_n -
\partial_p R^B_m\|_{\mathrm{op}+I_2,\gamma} 
\le 
\sum_{k=m}^{n-1}
\sup_{p\subseteq u}
\| \partial_p \Delta^k\|_{\mathrm{op}+I_2,\gamma} \\
&\le \sum_{k=m}^{\infty}
\lambda_+^k c
= \frac{\lambda_+^m }{1-\lambda_+} c
\xrightarrow{m\rightarrow \infty}0
\end{align}
since the the norms
\(\|\cdot\|_{\mathrm{op}+I_2}\) and
\(\|\cdot\|_{\mathrm{op}+I_2,\gamma}\) are 
equivalent, we have just proven 
that \(\partial_{[k]} R^B_m\) is a 
Cauchy sequence with respect to the norm 
\(\|\cdot\|_{\mathrm{op}+I_2}\) and 
hence convergence by 
lemma \ref{completeness of I_2 odd}.


\end{proof}

The following lemma is a necessary ingredient for
theorem \ref{thm smoothness of S}. Morally, it 
has already been proven in 
\cite[Lemma 3.7]{ivp0}; however, as that paper
was not concerned with multiple four-potentials 
the lemma was not formulated general enough 
for our needs here. So we restate it and 
show how to modify the original proof.

\begin{Lemma}[\(I_2\) estimates]\label{F, G off diagonal hilbert schmidt}
Let \(k\in\mathbb{N}\) and 
\(A,H_b\in\mathcal{V}\) for \(b\le k\). 
Using the abbreviations introduced in \eqref{derivative set 1}
and \eqref{derivative set 2}
we have for any \(u\subset [k]\) 
the following bounds:

\begin{align}\label{I2 estimate 1}
\|\partial_u U^0 \mathsf{F}_{\odd}^{A+\sum_{b=1}^k H_b} U^0\|_{I_2,0}&<\infty \\\label{I2 estimate 2}
\|\partial_u \mathsf{G}^{A+\sum_{b=1}^k H_b}\|_{I_2,0}&<\infty.
\end{align}
\end{Lemma}
\begin{proof}
For \(B\in\mathcal{V}\) recall 
\begin{align}
\mathsf{F}^B_{\odd}:=& ((-{Q'}^B+Z^B_{\mathrm{ev}}-Q^BZ^B)(1+Q^B))_{\odd}\\\label{Fodd sum}
=&-{Q'}^{B}+Z_{\ev}^B Q^B -Q^BZ^B_{\ev} - Q^B Z_{\odd}^B Q^B,\\
\mathsf{G}^B:=&- U^0Q^BQ^B \\
+& U^0(-{Q'}^B+Z_{\mathrm{ev}}-Q^B Z^B)Q^B Q^B U^B (1+Q^B).
\end{align}

Pick \(k\in\mathbb{N}\)
and  \(A,B, H_b\in\mathcal{V}\) for \(b\le k\).

According to \cite[lemma 3.7]{ivp0} the operators 
\(U^0Z_{\ev}^B Q^B U^0,\) \(U^0 Q^B Z_{\ev}^B U^0,\) 
\(U^0 {Q'}^{B}U^0,\) \(Q^B Q^B, {Q'}^B Q^B\) and 
\(Q^B Z^B Q^B\) are Hilbert-Schmidt operators.
Additionally, their  Hilbert-Schmidt norm is uniformly
bounded in time and \(\mathsf{F}\) and \(\mathsf{G}\) fulfil the following 
norm bound:

\begin{equation}
\|U^0 \mathsf{F}_{\odd}^BU^0\|_{I_2,0}<\infty 
\text{ and } \|\mathsf{G}^B\|_{I_2,0}<\infty.
\end{equation}

In fact, the proof given in \cite{ivp0} also workes
for non identical four-potentials \(A,B,C\in\mathcal{V}\)
proving

\begin{align}
&\| U^0Z_{\ev}^A Q^B U^0\|_{I_2,0}<\infty,\\
&\|U^0 Q^A Z_{\ev}^B U^0\|_{I_2,0}<\infty,\\ 
&\|U^0 {Q'}^{B}U^0\|_{I_2,0}<\infty,\\
&\|Q^B Q^A\|_{I_2,0}<\infty,\\ 
&\|{Q'}^B Q^A\|_{I_2,0}<\infty,\\ 
&\|Q^A Z^B Q^C\|_{I_2,0}<\infty
\end{align}
and therefore also 
\begin{equation}
\|\partial_u U^0 \mathsf{F}_{\odd}^{A+\sum_{b=0}^k H_b}U^0\|_{I_2,0}<\infty 
\text{ and } \|\partial_u \mathsf{G}^{A+\sum_{b=0}^k H_b}\|_{I_2,0}<\infty
\end{equation}
for any \(u\subseteq [k]\). 

For the benefit of the reader,
we will reproduce the proof of the estimate
\begin{equation}\label{HS property of G}
\|\partial_u \mathsf{G}^{A+\sum_{b=0}^k H_b}\|_{I_2,0}<\infty,
\end{equation}
to make clear the structure of the entire proof.

The operator \(\mathsf{G}^{A+\sum_{b=0}^k H_b}\) consists of 
two summands. Each summand is a product of operators 
with operator norm uniformly bounded in time and
containing a factor of 
\(Q^{A+\sum_{b=0}^k H_b} Q^{A+\sum_{b=0}^k H_b}\).
All the other factors contributing to \(\mathsf{G}\)
stay bounded when differentiated and
the map \(Q:\mathcal{V}\rightarrow I_2\) is 
linear, so the bound 
\begin{equation}
\|Q^{B} Q^{D}\|_{I_2,0}<\infty
\end{equation}
for general \(B,D\in\mathcal{V}\) will suffice to prove
\eqref{HS property of G}. 


Pick \(B,D\in\mathcal{V}\), we estimate 
\begin{align}\label{QQ norm}
\sup_{t\in \mathbb{R}}\| Q^B (t) Q^D(t)\|_{I_2}\\
\le \sum_{\mu,\nu=0}^3 
\big(\sup_{p,k,q\in\mathbb{R}^3} 
|P_+(p)\gamma^0\gamma^\mu P_-(k)\gamma^0\gamma^\nu P_+(q)|\\
+\sup_{p,k,q\in\mathbb{R}^3} 
|P_-(p)\gamma^0\gamma^\mu P_+(k)\gamma^0\gamma^\nu P_-(q)|\big)\\\label{QQ norm end}
\sup_{t\in\mathbb{R}}\left\| \int_{\mathbb{R}^3} dk 
\frac{\hat{B}_\mu (t,p-k)\hat{D}_\nu(t,k-q)|}{(E(p)+E(k))(E(k)+E(q))} 
\right\|_{I_2,(p,q)},
\end{align}
where the index in the norm indicates 
with respect to which variables the integral of the norm 
is to be performed. The prefactor is finite since 
\(P_\pm (p):\mathbb{C}^4\rightarrow\mathbb{C}^4\) 
is a projector for any \(p\in\mathbb{R}^3\).
Abbreviating 
\begin{align}
\tilde{c}:=\sum_{\mu,\nu=0}^3 
(\sup_{p,k,q\in\mathbb{R}^3} 
|P_+(p)\gamma^0\gamma^\mu P_-(k)\gamma^0\gamma^\nu P_+(q)|\\
+\sup_{p,k,q\in\mathbb{R}^3} 
|P_-(p)\gamma^0\gamma^\mu P_+(k)\gamma^0\gamma^\nu P_-(q)|),
\end{align}
and using the integral estimate lemma 
\cite[lemma 3.8 (iii)]{ivp0} we find
\begin{align}\label{QQ estimate final}
\eqref{QQ norm}\le 
\tilde{c}~ C_{8,\text{of }\cite{ivp0}} \sum_{\mu,\nu=0}^3 
\sup_{t\in\mathbb{R}}\|\hat{B}_\mu(t) \|_{I_1} \|\hat{D}_{\nu}(t) \|_{I_2}.
\end{align}
Because of 
\(B,D\in C_c^\infty(\mathbb{R}^4)\), we have
\(\hat{B}(t),\hat{D}(t)\) are analytic functions
decaying faster than any negative power at anfinity
for any \(t\), so \eqref{QQ estimate final} is finite. 

Also in order to proof the first estimate in 
\eqref{I2 estimate 1} the proof of \cite[lemma 3.7]{ivp0}
can be followed almost verbatim. 
First one dissects \(\mathsf{F}_{\odd}\) into the sum 
\(U^0\eqref{Fodd sum}U^0\),
next the summands have to be bounded individually.
This is achieved by repeating the proof of the
partial integration lemma \cite[lemma 3.6]{ivp0},
estimates of the form of \eqref{QQ norm}-\eqref{QQ norm end}
and making use of the integral estimate lemma 
\cite[lemma 3.8]{ivp0}.

\end{proof}








\begin{Thm}[Properties of Derivatives of S]
Let  \(A,H\in\mathcal{V}\), pick \(t_1\) 
after \(\supp A\cup\supp H\) and \(t_0\)
before \(\supp A\cup\supp H\), 
let \(T_1\in I_2(\mathcal{F})\) 
then the following equalities are satisfied:
\begin{align}\notag
&\partial_{H} \tr(T_1 P^\pm U^{A}(t_0,t_1)U^{A+H}(t_1,t_0)P^\mp)\\\label{pull derivative into trace}
&= \tr(T_1 P^\pm U^{A}(t_0,t_1)\partial_{H} U^{A+H}(t_1,t_0)P^\mp )
\end{align}
\end{Thm}
\begin{proof}
Let \(A,H\in\mathcal{V}\) and \(t_0,t_1\in\mathbb{R}\)
and \(T_1\) be 
as in the theorem. The proof of the two equalities is 
analogous, so we only explicitly prove the first one.
The trace is linear, so we have
\begin{align}\notag
&\bigg|
\tr\left(T_1 P^+ U^{A}(t_0,t_1) 
\frac{1}{\varepsilon}(U^{A+\varepsilon H}(t_1,t_0)-U^{A}(t_1,t_0))P^-\right)\\
&\quad- \tr(T_1 P^+ U^{A}(t_0,t_1)\partial_{H}U^{A+H}(t_1,t_0)P^-)\bigg|\\\notag
&\le \|T_1\|_{I_2} \bigg\|  P^+ U^{A}(t_0,t_1) 
\frac{1}{\varepsilon}\big(U^{A+\varepsilon H}(t_1,t_0)-U^{A}(t_1,t_0)\big)P^- \\\label{derivative trace estimate}
&\quad-P^+ U^{A}(t_0,t_1)\partial_{H}U^{A+H}(t_1,t_0)P^-\bigg\|_{I_2}
\end{align}

For the first summand we insert the identity in the 
form \(P^++P^-\) and obtain
\begin{align}
P^+ U^{A}(t_0,t_1) 
  \frac{1}{\varepsilon}\left(U^{A+\varepsilon H}(t_1,t_0)-U^{A}(t_1,t_0)\right)P^-\\
=P^+ U^{A}(t_0,t_1) P^+
\frac{1}{\varepsilon}\left(U^{A+\varepsilon H}(t_1,t_0)-U^{A}(t_1,t_0)\right)P^-\\
+P^+ U^{A}(t_0,t_1) P^-
\frac{1}{\varepsilon}\left(U^{A+\varepsilon H}(t_1,t_0)-U^{A}(t_1,t_0)\right)P^-.
\end{align}
Analogously for the second summand.
Now because of the Smoothness of S theorem 
\ref{thm smoothness of S}
we know that 
\begin{align}
  P^-
  \frac{1}{\varepsilon}\left(U^{A+\varepsilon H}(t_1,t_0)-U^{A}(t_1,t_0)\right)
  P^-\xrightarrow[\|\cdot\|]{\varepsilon\rightarrow 0} P^- \partial_H U^{A+H}(t_1,t_0)P^-\\
  P^+
  \frac{1}{\varepsilon}\left(U^{A+\varepsilon H}(t_1,t_0)-U^{A}(t_1,t_0)\right)
  P^-\xrightarrow[\|\cdot\|_{I_2}]{\varepsilon\rightarrow 0} P^+ \partial_H U^{A+H}(t_1,t_0)P^-
\end{align}
holds true. Hence we find in total 
\begin{align}
&\frac{\eqref{derivative trace estimate}}{\|T_1\|_{I_2}}\\
&\le \notag
\bigg\|  P^+ U^{A}(t_0,t_1)\bigg\| \bigg\| P^+
\frac{1}{\varepsilon}\big(U^{A+\varepsilon H}(t_1,t_0)-U^{A}(t_1,t_0)\big)P^- \\
&\quad- P^+\partial_{H}U^{A+H}(t_1,t_0)P^-\bigg\|_{I_2}\\
&+\bigg\|  P^+ U^{A}(t_0,t_1)P^- \bigg\|_{I_2} \bigg\|  \notag
\frac{1}{\varepsilon}\big(U^{A+\varepsilon H}(t_1,t_0)-U^{A}(t_1,t_0)\big)P^- \\
&\quad-\partial_{H}U^{A+H}(t_1,t_0)P^-\bigg\|\xrightarrow{\varepsilon \rightarrow 0} 0.
\end{align}

\end{proof}

\section{Lemma of Poincaré in infinite dimensions}\label{sec:proof of poincare}
In this section we give prove of the Poincaré's lemma 
in infinite dimensions used in section \ref{chapter geometery}.
First recall the lemma itself.

\begin{Lemma}[Poincaré]
  Let \(\omega\in \Omega^p(\mathcal{V})\) for 
  \(p\in\mathbb{N}\) be closed, i.e. \(d \omega =0\). 
  Then \(\omega\) is also exact, more precisely we have
  \begin{equation}
  \omega=d \int_{0}^1 \iota^*_t i_X f^* \omega dt,
  \end{equation}
  where \(X\), \(\iota_t\) for \(t\in\mathbb{R}\) and \(f\) are given by
   \begin{align}
   &X: \mathbb{R}\times\mathcal{V}\rightarrow \mathbb{R}\times\mathcal{V},\\
   &\hspace{2cm} (t,B)\mapsto (1,0) \\
  &\forall t \in \mathbb{R}: \iota_t: \mathcal{V}\rightarrow \mathbb{R}\times\mathcal{V},\\
  &\hspace{2cm} B\mapsto (t,B)\\
  &f:\mathbb{R}\times \mathcal{V}\mapsto \mathcal{V},\\
  &\hspace{2cm} (t,B) \mapsto t B\\
  &i_X: \Omega^p(\mathcal{V})\rightarrow \Omega^{p-1}(\mathcal{V}),\\
  &\hspace{2cm} \omega \mapsto ((A;Y_1,\dots, Y_{p-1})\mapsto \omega_A(X,Y_1,\dots,Y_{p-1}))
   \end{align}
  \end{Lemma}
  \begin{proof}

  Pick some \(\omega \in \Omega^p(\mathcal{V})\).
  We will first show the more general formula 
  \begin{equation}\label{poincare more general}
  f^*_b\omega-f^*_a \omega=d \int_{a}^b \iota_t^* i_X f^* \omega ~dt+ \int_{a}^b \iota_t^* i_X f^* d \omega dt,
  \end{equation}
  where \(f_t\) is defined as
  \begin{equation}
  \forall t \in \mathbb{R}: f_t:=f(t,\cdot).
  \end{equation}
  The lemma follows then by \(b=1, a= 0\), \(f^*_1\omega=\omega, f^*_0 \omega=0\) and \(d \omega=0\) for a closed \(\omega\). 
  We begin by rewriting the right hand side of \eqref{poincare more general}:
  \begin{align}\nonumber
  d \int_{a}^b \iota_t^* i_X f^* \omega ~dt+ \int_{a}^b \iota_t^* i_X f^* d \omega dt\\\label{poincare 1 manipulation}
  =\int_a^b (d\iota_t^* i_X f^* \omega+ \iota_t^* i_X f^* d \omega )dt.
  \end{align}
  Next we look at both of these terms separately. Let therefore \(p\in \mathbb{N}\), \(t, s_k\in \mathbb{R}\) and \(A,B_k\in \mathcal{V}\) for each \(p+1\ge k\in\mathbb{N}\).
  First, we calculate \(d \iota^*_t i_X f^* \omega\):
  \begin{align}
  &(f^*\omega)_{(t,A)}((s_1,B_1),\dots, (s_p,B_p))\\\nonumber
  &\hspace{3cm}=\omega_{tA}(s_1A+tB_1,\dots, s_p A+t B_p)\\[0.3cm]
  &\Rightarrow (i_X f^* \omega)_{(t,A)}((s_1,B_1),\dots, (s_{p-1},B_{p-1}))\\\nonumber
  &\hspace{3cm}=\omega_{tA}(A,s_1A+tB_1,\dots, s_{p-1}A + t B_{p-1})\\[0.3cm]
  &\Rightarrow (\iota^*_t i_X f^* \omega)_{A}(B_1,\dots, B_{p-1})= t^{p-1} \omega_{t A}(A,B_1,\dots, B_{p-1})\\[0.3cm]\notag
  &\Rightarrow (d\iota^*_t i_X f^* \omega)_{A}(B_1,\dots, B_{p}) \\
  &\quad=\partial_\varepsilon |_{\varepsilon=0} \sum_{k=1}^p (-1)^{k+1} t^{p-1} \omega_{t A + \varepsilon t B_k}(A,B_1,\dots, \widehat{B_k},\dots, B_p)\\
  &\quad+ \partial_\varepsilon|_{\varepsilon=0} \sum_{k=1}^p (-1)^{k+1} t^{p-1} \omega_{tA}(A+\varepsilon B_k,B_1,\dots, \widehat{B_k},\dots, B_p)\\\notag
  &=\partial_{\varepsilon}|_{\varepsilon=0}\sum_{k=1}^p t^p (-1)^{k+1} \omega_{tA+\varepsilon B_k}(A,B_1,\dots, \widehat{B_k},\dots, B_p)\\\label{li derivative 1}
  &\hspace{6cm}+p t^{p-1}\omega_{tA}(B_1,\dots, B_p).
  \end{align}
  
  
  Now, we calculate \(\iota^*_t i_X f^* d \omega\):
  \begin{align}\notag
  &(d\omega)_A(B_1,\cdots, B_{p+1})\\
  &\hspace{2cm}=\partial_\varepsilon |_{\varepsilon=0} \sum_{k=1}^{p+1} (-1)^{k+1} \omega_{A+\varepsilon B_k}(B_1,\dots , \widehat{B_k}, \dots, B_{p+1})\\[0.3cm]
  &(f^* d \omega){(t,A)}((s_1,B_1),\dots , (s_{p+1},B_{p+1}))\\\notag
  &= (d\omega)_{tA}(s_1A + t B_1, \dots, s_{p+1}A+t B_{p+1})\\
  &=\partial_{\varepsilon}|_{\varepsilon =0} \sum_{k=1}^{p+1}(-1)^{k+1}\\\notag
  &\quad \times\omega_{tA + \varepsilon(s_kA + t B_k)}(s_1A+tB_1, \dots,  \widehat{s_k A + t B_k},\dots , s_p A  + t B_p )\\[0.4cm]
  &(i_X f^* d \omega)_{(t,A)}((s_1,B_1),\dots , (s_p, B_p))\\\notag
  &\quad= \partial_{\varepsilon} |_{\varepsilon =0} \omega_{(t+\varepsilon)A}(s_1A+tB_1, \dots, s_pA+t B_p)\\\notag
  &+\partial_{\varepsilon}|_{\varepsilon=0} \sum_{k=1}^p (-1)^k\\\notag
  &\times\omega_{tA + \varepsilon(s_k A + t B_k)} (A,s_1A+t B_1, \dots, \widehat{s_k A + t B_k},\dots, s_p A + t B_p)\\
  &= t^p \partial_{\varepsilon}|_{\varepsilon=0}\omega_{(t+\varepsilon)A }(B_1,\dots,  B_p))\\
  &\hspace{0.5cm}+ \sum_{k=1}^p s_k t^{p-1} (-1)^{k+1} \partial_{\varepsilon}|_{\varepsilon=0}\omega_{(t+\varepsilon)A}(A,B_1,\dots,\widehat{B_k},\dots, B_p) \\
  &+\partial_{\varepsilon}|_{\varepsilon=0}\sum_{k=1}^p(-1)^k t^{p-1}(\omega_{(t+s_k\varepsilon)A}(A,B_1,\dots, \widehat{B_k},\dots, B_p) \\
  &\hspace{2cm} + \omega_{tA + \varepsilon t B_k}(A,B_1, \dots, \widehat{B_k},\dots, B_p))\\
  &=t^p\partial_{\varepsilon}|_{\varepsilon=0} \Big(\omega_{(t+\varepsilon)A}(B_1,\dots, B_p)\\\notag
  &\hspace{2cm} +\sum_{k=1}^p (-1)^k \omega_{tA+\varepsilon B_k}(A,B_1,\dots, \widehat{B_k},\dots, B_p)\Big)\\\label{li derivative 2}
  &(\iota_t^* i_X f^* d \omega)_{A}(B_1,\dots ,  B_p)=t^p\partial_{\varepsilon}|_{\varepsilon=0} \Big(\omega_{(t+\varepsilon)A}(B_1,\dots, B_p)\\\notag
  &\hspace{2cm}+\sum_{k=1}^p (-1)^k \omega_{tA+\varepsilon B_k}(A,B_1,\dots, \widehat{B_k},\dots, B_p)\Big)
  \end{align}
  
  Adding \eqref{li derivative 1} and \eqref{li derivative 2} we find for \eqref{poincare 1 manipulation}:
  
  \begin{align}
  \int_a^b (d\iota_t^* i_X f^* \omega+ \iota_t^* i_X f^* d \omega )dt=\\
  \int_a^b  \Big( t^p\partial_{\varepsilon}|_{\varepsilon=0} \omega_{(t+\varepsilon)A}(B_1,\dots, B_p)
  +p t^{p-1}\omega_{tA}(B_1,\dots, B_p)\Big) dt\\
  =\int_a^b  \frac{d}{dt} (t^p \omega_{tA}(B_1,\dots, B_p))dt =\int_a^b  \frac{d}{dt} (f^*_t \omega)_{A}(B_1,\dots, B_p)dt\\
  =(f^*_b\omega)_A(B_1,\dots,B_p)-(f^*_a\omega)_A(B_1,\dots,B_p).
  \end{align}
  
  \end{proof}



\section{Heuristic Construction of \(S\)-Matrix expression}\label{sec:heuristic construction}

This section is dedicated to the heuristic construction of 
the expression for the scattering operator stated in theorem 
\ref{sleek_second_quantised_scattering_operator}.

We start from the power series of the one-particle 
scattering operator \(S^A\):
\begin{equation}\label{U_expansion}
S^A = \sum_{k=0}^\infty \frac{1}{k!} Z_k(A),
\end{equation}
where \(Z_k(A)\) are bounded operators on \(\mathcal{H}\), 
which are homogeneous of degree \(k\) in \(A\).
Our strategy in this chapter is to try an analogous formal 
power series ansatz for the second quantised scattering 
operator \(\tilde{S}^A\)

\begin{equation}\label{S_expansion}
\tilde{S}^A=\sum_{k=0}^\infty \frac{1}{k!} T_k(A).
\end{equation}
Here \(T_k\) are assumed to be homogeneous of degree 
\(k\) in \(A\); however, they will only turn out to be 
bounded on
fixed particle number subspaces \(\mathcal{F}_{m,p}\) of 
Fock space. We will identify operators \(T_k\) such that 
\eqref{S_expansion}
holds up to a global phase. 
In order to fully characterise \(\tilde{S}^A\) it is enough 
to characterise all of the \(T_k\) operators. 
Using the \eqref{lift condition} one can derive commutation 
relations for the operators 
\(T_k\) by plugging in \eqref{U_expansion} and 
\eqref{S_expansion} into the \eqref{lift condition} 
and its adjoint
and collecting all terms with the same degree of homogeneity. 
They are given by

\begin{equation}\label{logarithmic lift condition}
\left[T_m(A) , a^\# (\phi)\right]= \sum_{j=1}^{m} \begin{pmatrix} m \\ j \end{pmatrix} a^\# \left(Z_j (A) \phi \right) T_{m-j}(A), 
\end{equation}
where \(a^\#\) is either \(a\) or \(a^*\).
In the following we will derive a recursive equation for the coefficients of the expansion 
of the second quantized scattering operator. The starting point of this derivation is 
the commutator of \(T_m\), equation \eqref{logarithmic lift condition}.

\subsection{Guessing Equations}

Looking at equation \eqref{logarithmic lift condition} for a while, one
comes to the conclusion that if one replaces \(T_m\) by 
\begin{equation}
T_m - \frac{1}{2} \sum_{k=1}^{m-1} \begin{pmatrix} m \\ k\end{pmatrix} T_k T_{m-k},
\end{equation}
no \(T_k\) with \(k>m-2\) will occur on the right hand side of the resulting equation.
So if one subtracts the right polynomial in \(T_k\) for suitable \(k\) one might achieve
a commutator which contains only the creation respectively annihilation operator 
concatenated with some  one-particle operator.

So having this in Mind we start with the ansatz

\begin{equation}\label{Def Gamma_m}
\Xi_m := \sum_{g=2}^m \sum_{\stackrel{b\in\mathbb{N}^g}{|b|=m}} c_{b} \prod_{k=1}^g T_{b_k}.
\end{equation}

Now in order to show that \(T_m\) and \(\Xi_m\) agree up to operators which have a commutation 
relation of the form \eqref{Commutation Gamma}, we calculate \(\left[ T_m-\Xi_m, a^\#(\varphi) \right]\)
for arbitrary \(\varphi\in\mathcal{H}\) and try to choose the coefficients \(c_b\) of \eqref{Def Gamma_m}
such that all contributions vanish which do not have the form \(a^\# \left( \prod_k Z_{\alpha_k}\varphi\right)\)
for any suitable \((\alpha_k)_k\subset \mathbb{N} \). If one does so, one is led to a system of equations
of which the first few are  written down 
to give an overview of its structure. The objects \(\alpha_k, \beta_l\) 
in the system of equations can be any 
natural Number for any \(k,l\in\mathbb{N}\).

\begin{align*}
&0 =c_{\alpha_1,\beta_1} + c_{\beta_1,\alpha_1}+ \binom{ \alpha_1 + \beta_1}{ \alpha_1} \\
&0 = c_{\alpha_1,\alpha_2,\beta_1} + c_{\beta_1,\alpha_1,\alpha_2} + c_{\alpha_2,\alpha_1,\beta_1} + 
\binom{\alpha_2 + \beta_1}{ \alpha_2} c_{\alpha_1,\alpha_2+\beta_1} \\
&\hspace{2cm}  +\binom{\alpha_1+\beta_1}{\alpha_1} c_{\alpha_1+\beta_1,\alpha_2}\\
&0= c_{\alpha_1,\alpha_2,\alpha_3,\beta_1} + c_{\alpha_1,\alpha_2,\beta_1,\alpha_3} 
+ c_{\alpha_1,\beta_1,\alpha_2,\alpha_3} + c_{\beta_1,\alpha_1,\alpha_2,\alpha_3}\\
&+\binom{\alpha_1+\beta_1}{\beta_1} 
c_{\alpha_1+\beta_1,\alpha_2,\alpha_3} 
+ \binom{\alpha_2+\beta_1}{\beta_1} c_{\alpha_1,\alpha_2+\beta_1,\alpha_3}\\
&\hspace{2cm} + \binom{\alpha_3+\beta_1}{\beta_1} c_{\alpha_1,\alpha_2,\alpha_3+\beta_1}\\
&0= c_{\alpha_1,\alpha_2,\beta_1,\beta_2} +c_{\alpha_1,\beta_1,\alpha_2,\beta_2} +
c_{\beta_1,\alpha_1,\alpha_2,\beta_2} +c_{\alpha_1,\beta_1,\beta_2,\alpha_2} \\
&+c_{\beta_1,\alpha_1,\beta_2,\alpha_2} +c_{\beta_1,\beta_2,\alpha_1,\alpha_2} 
+\binom{\alpha_1+\beta_1}{\alpha_1} (c_{\alpha_1+\beta_1,\alpha_2,\beta_2} \\
&+ c_{\alpha_1+\beta_1,\beta_2,\alpha_2})  
+\binom{\alpha_1+\beta_2}c_{\beta_1,\alpha_1+\beta_2,\alpha_1} \\
&+\binom{\alpha_2+\beta_1}{\alpha_2} c_{\alpha_1,\alpha_2+\beta_1,\beta_2}
+ \binom{\alpha_2+\beta_2}{\alpha_2} (c_{\alpha_1,\beta_1,\alpha_2+\beta_2}\\
&+ c_{\beta_1,\alpha_1,\alpha_2+\beta_2})
+ \binom{\alpha_1+\beta_1}{\alpha_1} \binom{\alpha_2+\beta_2}{\alpha_2}
 c_{\alpha_1+\beta_1,\alpha_2+\beta_2}\\
&0=c_{\alpha_1,\beta_1,\beta_2,\beta_3,\beta_4} 
+ c_{\beta_1,\alpha_1,\beta_2,\beta_3,\beta_4} 
+ c_{\beta_1,\beta_2,\alpha_1,\beta_3,\beta_4} \\
&\hspace{1cm}+ c_{\beta_1,\beta_2,\beta_3,\alpha_1,\beta_4} 
+ c_{\beta_1,\beta_2,\beta_3,\beta_4,\alpha_1} \\
&+\binom{\alpha_1+\beta_1}{\alpha_1} c_{\alpha_1+\beta_1,\beta_2,\beta_3,\beta_4}
+ \binom{\alpha_1+\beta_2}{\alpha_1} c_{\beta_1,\alpha_1+\beta_2,\beta_3,\beta_4}\\
&+ \binom{\alpha_1+\beta_3}{\alpha_1} c_{\beta_1,\beta_2,\alpha_1+\beta_3,\beta_4}
+ \binom{\alpha_1+\beta_4}{\alpha_1} c_{\beta_1,\beta_2,\beta_3,\alpha_1+\beta_4}\\
&0= c_{\alpha_1,\alpha_2,\beta_1,\beta_2,\beta_3} 
+c_{\alpha_1,\beta_1,\alpha_2,\beta_2,\beta_3} 
+c_{\beta_1,\alpha_1,\alpha_2,\beta_2,\beta_3} \\
&+c_{\alpha_1,\beta_1,\beta_2,\alpha_2,\beta_3} 
+c_{\beta_1,\alpha_1,\beta_2,\alpha_2,\beta_3} 
+c_{\beta_1,\beta_2,\alpha_1,\alpha_2,\beta_3} \\
&+c_{\alpha_1,\beta_1,\beta_2,\beta_3,\alpha_2} 
+c_{\beta_1,\alpha_1,\beta_2,\beta_3,\alpha_2} 
+c_{\beta_1,\beta_2,\alpha_1,\beta_3,\alpha_2} \\
&+c_{\beta_1,\beta_2,\beta_3,\alpha_1,\alpha_2} 
+\binom{\alpha_1+\beta_1}{\beta_1} (c_{\alpha_1+\beta_1,\alpha_2,\beta_2,\beta_3}\\
&+c_{\alpha_1+\beta_1,\beta_2,\alpha_2,\beta_3}
+c_{\alpha_1+\beta_1,\beta_2,\beta_3,\alpha_2})\\
&+\binom{\alpha_2+\beta_1}{\beta_1} c_{\alpha_1,\alpha_2+\beta_1,\beta_2,\beta_3}\\
&+\binom{\alpha_2+\beta_2}{\beta_2} (c_{\beta_1,\alpha_1,\alpha_2+\beta_2,\beta_3}
+c_{\alpha_1,\beta_1,\alpha_2+\beta_2,\beta_3})\\
&+\binom{\alpha_1+\beta_2}{\beta_2} (c_{\beta_1,\alpha_1+\beta_2,\alpha_2,\beta_3}
+c_{\beta_1,\alpha_1+\beta_2,\beta_3,\alpha_2})\\
&+\binom{\alpha_2+\beta_3}{\beta_3}( c_{\alpha_1,\beta_1,\beta_2,\alpha_2+\beta_3}
+c_{\beta_1,\alpha_1,\beta_2,\alpha_2+\beta_3}\\
&+c_{\beta_1,\beta_2,\alpha_1,\alpha_2+\beta_3})
+\binom{\alpha_1+\beta_3}{\beta_3} c_{\beta_1,\beta_2,\alpha_1+\beta_3,\alpha_2}\\
&+\binom{\alpha_1+\beta_1}{\alpha_1} \binom{\alpha_2+\beta_2}{\alpha_2} 
c_{\alpha_1+\beta_1,\alpha_2+\beta_2,\beta_3}\\
&+\binom{\alpha_1+\beta_2}{\alpha_1} \binom{\alpha_2+\beta_3}{\alpha_2} 
c_{\beta_1,\alpha_1+\beta_2,\alpha_2+\beta_3}\\
&+\binom{\alpha_1+\beta_1}{\alpha_1} \binom{\alpha_2+\beta_3}{\alpha_2} 
c_{\alpha_1+\beta_1,\beta_2,\alpha_2+\beta_3}\\
& \hspace{3cm} \vdots
\end{align*}

Solving the first few equations and plugging the solution into the consecutive
 equations one can see that at least the first few equations are solved by 
\begin{equation}
c_{\alpha_1,\dots, \alpha_k} = \frac{(-1)^k}{k} \begin{pmatrix}\sum_{l=1}^k \alpha_l\\ \alpha_1\ \alpha_2 \ \cdots \alpha_k\end{pmatrix},
\end{equation}
where the last factor is the multinomial coefficient of the indices\linebreak \(\alpha_1,\dots, \alpha_k\in\mathbb{N}\).

\subsection{Recursive equation for Coefficients of the second quantised scattering operator}

We are going to use the following definition of binomial coefficients:
\begin{Def}
For \(a\in\mathbb{C}, b\in\mathbb{Z}\) we define

\begin{equation}
\binom{a}{b} := \left\{\begin{matrix}
\prod_{l=0}^{b-1} \frac{a-l}{l+1} \quad \text{for } b\ge 0\\
0 \hspace{1.7cm} \text{otherwise.}
\end{matrix}\right.
\end{equation}
\end{Def}

Defining the binomial coefficient for negative lower index to be zero has the merit, that one can extend the
range of validity of many rules and sums involving binomial coefficients, also one does not have 
to worry about the range of summation in many cases.



The coefficients which we have already guessed 
result in the following
\begin{Conj}\label{thm: T_n recursive}
For any \(n\in\mathbb{N}\) the n-th expansion coefficient of the second quantised scattering operator \(T_n\) is given by
\begin{align}\notag
&T_n = \sum_{g=2}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g T_{b_l} + C_n \id_{\mathcal{F}} \\ \label{T_n recursive}
&+ d\Gamma\left( \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^{g+1}}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g Z_{b_l}  \right),
\end{align}
for some \(C_n\in \mathbb{C}\) which depends on the external field \(A\). The last summand will henceforth
be abbreviated by \(\Gamma_n\).
\end{Conj}

\textbf{Motivation:} We compute the commutator of the difference between \(T_n\) and
the first summand of \eqref{T_n recursive} with the creation and annihilation operator of an element of the
basis of \(\mathcal{H}\). This will turn out to be exactly equal
to the corresponding commutator
of the second summand of \eqref{T_n recursive}, since two operators on Fock space only
have the same commutator with general creation and annihilation operators if they
agree up to multiples of the identity this will conclude the motivation of this conjecture. 

 In order to simplify the notation as much as possible, we 
 will denote by \(a^\# z\) either \(a(z(\varphi_p))\) or
 \(a^*(z(\varphi_p))\) for any  one-particle operator \(z\) and any element
 \(\varphi_p\) of the orthonormal basis \((\varphi_p)_{p\in\mathbb{Z}\backslash\{0\}}\) of
 \(\mathcal{H}\). (We need not decide between creation and annihilation 
 operator, since the expressions all agree)
 
In order to organize the bookkeeping of all the summands which arise from iteratively
making use of the commutation rule \eqref{logarithmic lift condition} we organize them 
by the looking at a spanning set of the possible terms that arise 
our choice is

\begin{equation}\label{combinatorics span}
\left\{ \left. a^\# \prod_{k=1}^{m_1} Z_{\alpha_k} \prod_{k=1}^{m_2}T_{\beta_k} \right|
m_1\in\mathbb{N},m_2\in\mathbb{N}_0, \alpha\in \mathbb{N}^{m_1}, 
\beta \in \mathbb{N}^{m_2}, |\alpha|+|\beta|=n\right\}_.
\end{equation}

As a first step of computing the commutator in question we look at the summand
corresponding to a fixed value of the summation index \(g\) of 

\begin{equation}\label{combinatorics total sum of T}
-\sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g T_{b_l}.
\end{equation}

 We need to bring this object into the form of a sum
of terms which are multiples of elements of the set \eqref{combinatorics span}.
This we will commit ourselves to for the next few pages. First we apply
the product rule for the commutator:

\begin{align*}
&\left[ \sum_{\stackrel{\vec{l}\in\mathbb{N}^g}{|\vec{l}|=n}} \frac{(-1)^g}{g} \binom{n}{\vec{l}}
 \prod_{k=1}^g T_{l_k},a^\#\right]\\
 &= \sum_{\stackrel{\vec{l}\in\mathbb{N}^g}{|\vec{l}|=n}} \frac{(-1)^g}{g} \binom{n}{\vec{l}}
 \sum_{\tilde{k}=1}^g \prod_{j=1}^{\tilde{k}-1} T_{l_j} 
 \left[ T_{l_{\tilde{k}}},a^\#\right] \prod_{j=\tilde{k}+1}^g T_{l_j}\\
&=\sum_{\stackrel{\vec{l}\in\mathbb{N}^g}{|\vec{l}|=n}} \frac{(-1)^g}{g} \binom{n}{\vec{l}}
 \sum_{\tilde{k}=1}^g \prod_{j=1}^{\tilde{k}-1} T_{l_j} 
\sum_{\sigma_{\tilde{k}}=1}^{l_{\tilde{k}}} \binom{l_{\tilde{k}}}{\sigma_{\tilde{k}}} 
a^\# Z_f T_{l_{\tilde{k}}-\sigma_{\tilde{k}}} \prod_{j=\tilde{k}+1}^g T_{l_j},
\end{align*}
in the second step we used \eqref{logarithmic lift condition}. Now we commute
all the \(T_l\)s to the left of \(a^\#\) to its right:

\begin{equation}\label{combinatorics ordered product}
=\!\!\! \sum_{\stackrel{\vec{l}\in\mathbb{N}^g}{|l|=n}} \!\!\frac{(-1)^g}{g}\! \binom{n}{\vec{l}}
\!\! \sum_{\tilde{k}=1}^g \!\sum_{\stackrel{\forall 1\le j <\tilde{k}}{0\le \sigma_{j}\le l_j}}
\!\sum_{\sigma_{\tilde{k}}=1}^{l_{\tilde{k}}} \prod_{j=1}^{\tilde{k}}\! \binom{l_j}{\sigma_j}
a^\# \prod_{j=1}^{\tilde{k}} Z_{\sigma_j} \prod_{j=1}^{\tilde{k}} T_{l_j-\sigma_j}
\!\!\prod_{j=\tilde{k}+1}^g T_{l_j}.
\end{equation}
At this point we notice that the multinomial coefficient can be combined with all
the binomial coefficients to form a single multinomial coefficient of degree
\(g+\tilde{k}\). Incidentally this is also the amount of \(Z\) operators plus the amount
of \(T\) operators in each product. Moreover the indices of the multinomial index
agree with the indices of the \(Z\) and \(T\) operators in the product. Because of 
this, we see that if we fix an element of the spanning set \eqref{combinatorics span}
\(a^\# \prod_{k=1}^{m_1} Z_{\alpha_k} \prod_{k=1}^{m_2}T_{\beta_k}\), each 
summand of \eqref{combinatorics ordered product} which contributes to
this element, has the prefactor

\begin{equation}
\frac{(-1)^g}{g} \binom{n}{\alpha_1 \ \cdots \alpha_{m_1} \ \beta_1 \cdots \beta_{m_2}}
\end{equation}

no matter which summation index \(l\in\mathbb{N}^g\) it corresponds to. In order
to do the matching one may ignore the indices \(\sigma_j\) and \(l_j-\sigma_j\) 
which vanish, because the corresponding operators \(Z_0\) and \(T_0\) are equal to
the identity operator on \(\mathcal{H}\) respectively Fock space. 

Since we know that 

\begin{align*}
\left[ d\Gamma\left(\sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}}  \prod_{l=1}^g Z_{b_l}\right), a^\#\right]\\
= a^\# \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}}  \prod_{l=1}^g Z_{b_l}
\end{align*}
holds, all that is left to show is that 
\begin{align}\label{combinatorics total commutator}
&\left[-\sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g T_{b_l}, a^\#\right]\\\notag
&= a^\# \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^{g+1}}{g} 
\binom{n}{\vec{b}}  \prod_{l=1}^g Z_{b_l}
\end{align}
also holds. For which we need to count the summands which are multiples of each element of \eqref{combinatorics span}
 corresponding to each \(g\) in \eqref{combinatorics total sum of T}. So let us fix some element
 \(K(m_1,m_2)\) of \eqref{combinatorics span} corresponding to some \(m_1\in\mathbb{N},
 m_2\in\mathbb{N}_0, \alpha \in \mathbb{N}^{m_1}\) and \( \beta\in \mathbb{N}^{m_2}\).
Rephrasing this problem, we can ask which products
\begin{equation}
\prod_{l=1}^g T_{\gamma_l}
\end{equation}
 for suitable \(g\) and \((\gamma_l)_l\) produces, when commuted with a creation or annihilation operator, 
  multiples of \(K(m_1,m_2)\)? We will call this number of 
 total contributions weighted with the factor 
 \( - \frac{(-1)^g}{g}\) borrowed from \eqref{combinatorics total sum of T} \(\#K(m_1,m_2)\).  
 Looking at the commutation relations 
\eqref{logarithmic lift condition} we split the set of indices \(\{\gamma_1\dots \gamma_g\}\) into
three sets \(A,B\) and \(C\), where the commutation relation has to be used in such a way, that

\begin{align*}
&\forall k: \gamma_k \in A \iff \exists j\le m_1: \gamma_k = \alpha_j, \\
\wedge& \forall k: \gamma_k \in B \iff \exists j\le m_2: \gamma_k = \beta_j\\
\wedge & \forall k: \gamma_k \in C \iff \exists j\le m_1, l\le m_2: \gamma_k = \alpha_j + \beta_l
\end{align*}
 holds. Unfortunately not every splitting corresponds to a contribution and not every
 order of multiplication of a legal splitting corresponds to a contribution either.
 However \(\prod_{j} T_{\alpha_j} \prod_j T_{\beta_j}\) gives
 a contribution and it is in fact the longes product that does.
 We may apply the commutation relations backwards to obtain any
 shorter valid combination and hence all combinations. 
 Transforming the commutation rule for \(T_k\) read from right to left
 into a game results in the following rules.
 
Starting from the string 
\begin{equation}
A_1A_2\dots A_{m_1} B_1 B_2 \dots B_{m_2},
\end{equation}

representing the longes product, where here and in the following \(A\)'s
represent operators \(T_k\) which will turn into \(Z_k\) by the commutation rule,
\(B\)'s represent operators \(T_k\) which will stay \(T_k\) after commutation and
\(C\)'s represent operators \(T_k\) which will produce both a \(Z_l\) in the creation/annihilation
operator and a \(T_{k-l}\) behind that operator. The indices are merely there to keep track of
which operator moved where.

So the game consists in the answering how many strings can we produce by 
applying the following rules to the initial string?
\begin{enumerate}
\item You may replace any occurrence of \(A_k B_j\) by \(B_j A_k\) for any \(j\) and \(k\).
\item You may replace any occurrence of \(A_k B_j\) by \(C_{k,j}\) for any \(j\) and \(k\).
\end{enumerate}
Where we have to count the number of times we applied the second rule, or equivalently
the number \(\#C\) of \(C\)'s in the resulting string, because the summation index \(g\) in 
\eqref{combinatorics total sum of T} corresponds to \(m_1+m_2-\#C\). 

Fix \(\#C \in\{0,\dots ,\min(m_1,m_2)\}\). A valid string has \(m_1+m_2-\#C\) characters,
because the number of its \(C\)s is \(\#C\), its number of \(A\)s is \(m_1-\#C\) and 
its number of \(B\)s is \(m_2-\#C\). Ignoring the labelling of the \(A\)s, \(B\)s and \(C\)s 
there are \(\binom{m_1+m_2-\#C}{\#C \ (m_1 - \#C) \ (m_2-\#C)}\) such strings. Now if
we consider one such string without labelling, e.g.

\begin{equation}
C A A B A C C B B A C B B A B B B B,
\end{equation}

there is only one correct labelling to be restored, namely the one where each \(A\) and the first index of 
any \(C\)  receive increasing labels from left to right and analogously for \(B\) and the second 
 index of any \(C\), resulting for our example in
 
\begin{equation}
 C_{1,1} A_2 A_3 B_2 A_4 C_{5,3} C_{6,4} B_{5} B_6 A_7 C_{8,7} B_8 B_9 A_9 B_{10} B_{11} B_{12} B_{13}.
\end{equation}

So any unlabelled  string corresponds to exactly one labelled string which in turn corresponds to 
exactly one choice of operator product \(\prod T\). 
So returning to our Operators, we found the number \(\#K(m_1,m_2)\) it is

\begin{equation}\label{combinatorics binomial sum}
\#K(m_1,m_2) =-\hspace{-0.9cm}\sum_{g=\max(m_1,m_2)}^{m_1+m_2} \frac{(-1)^g}{g} \binom{g}{(m_1+m_2-g) \ (g-m_1) \ (g - m_2)},
\end{equation}
where the total minus sign comes from the total minus sign in front of \eqref{combinatorics total commutator}
with respect to \eqref{T_n recursive}. 

Now since we introduced the slightly non-standard definition of binomial coefficients used in \cite{graham1994concrete} we
can make use of the rules for summing binomial coefficients derived there.
As a first step to evaluate \eqref{combinatorics binomial sum} we split the trinomial coefficient into binomial
ones and make use of the absorption identity

\begin{equation}\tag{absorption}\label{absorption}
\forall a \in \mathbb{C}\ \forall b \in \mathbb{Z}: b \binom{a}{b} = a \binom{a-1}{b-1} 
\end{equation}

for \(m_2,m_1\neq 0\) as follows

\begin{align*}
&\#K(m_1,m_2) \\
&=-\sum_{g=\max(m_1,m_2)}^{m_1+m_2} \frac{(-1)^g}{g} \binom{g}{(m_1+m_2-g) \ (g-m_1) \ (g - m_2)}\\
&=-\sum_{g=\max(m_1,m_2)}^{m_1+m_2} \frac{(-1)^g}{g} \binom{g}{m_2}\binom{m_2}{g-m_1}\\
&\stackrel{\eqref{absorption}}{=}-\sum_{g=\max(m_1,m_2)}^{m_1+m_2} \frac{(-1)^g}{m_2} \binom{g-1}{m_2-1}\binom{m_2}{g-m_1}\\
&=\frac{-1}{m_2} \sum_{g=\max(m_1,m_2)}^{m_1+m_2} (-1)^g \binom{g-1}{m_2-1}\binom{m_2}{g-m_1}\\
&\overset{m_1>0}{=}\frac{-1}{m_2} \sum_{g\in\mathbb{Z}} (-1)^g \binom{m_2}{g-m_1}\binom{g-1}{m_2-1}\\
&\stackrel{*}{=} \frac{-1}{m_2} (-1)^{m_2-m_1} \binom{m_1-1}{-1} = 0,
\end{align*}
where for the second but last equality \(m_1>0\) is needed for the \(g=0\) summand not to contribute and
for the marked equality we used summation rule (5.24) of \cite{graham1994concrete}. 
So all the coefficients vanish that fulfil \(m_1,m_2\neq 0\). The sum for the remaining cases
is readily computed, since there is just one summand. Summarising we find

\begin{equation*}
\#K(m_1,m_2)= \delta_{m_2,0} \frac{(-1)^{1+m_1}}{m_1} + \delta_{m_1,0} \frac{(-1)^{1+m_2}}{m_2},
\end{equation*}

where the second summand can be ignored, since terms with \(m_1=0\) are irrelevant for our considerations.

 So the left hand side of 
\eqref{combinatorics total commutator} can be evaluated

\begin{align*}
\left[-\sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g T_{b_l}, a^\#\right]\\
= \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|b|=n}} \frac{(-1)^{g+1}}{g} \binom{n}{\vec{b}}  a^\# \prod_{l=1}^g Z_{b_l},
\end{align*}

which is exactly equal to the right hand side of \eqref{combinatorics total commutator}. This ends the motivation of the conjecture.



\subsection{Solution to Recursive Equation}

So we found a recursive equation for the \(T_n\)s, now we need to solve it. 
In order to do so we need the following lemma about combinatorial distributions

\begin{Lemma}\label{stirling lemma}
For any \(g\in\mathbb{N},k\in\mathbb{N}\)
\begin{equation}
\sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{|\vec{g}|=k}} \binom{k}{\vec{g}}=\sum_{l=0}^g (-1)^l (g-l)^k \binom{g}{l}
\end{equation}
holds. The reader interested in terminology may be eager to know, that the right hand side is equal to
 \(g!\) times the Stirling 
number of the second kind \(\left\{\begin{matrix}k\\g\end{matrix}\right\}\).
\end{Lemma}
\textbf{Proof:} We would like to apply the multinomial theorem but there are all the summands missing where at least
one of the entries of \(\vec{g}\) is zero, so we add an appropriate expression of zero. We also give the expression in
question a name, since we will later on arrive at a recursive expression.
\begin{multline}
F(g,k):=\sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{|\vec{g}|=k}} \binom{k}{\vec{g}}
= \sum_{\stackrel{\vec{g}\in\mathbb{N}_0^g}{|\vec{g}|=k}} \binom{k}{\vec{g}}
- \sum_{\stackrel{\stackrel{\vec{g}\in\mathbb{N}_0^g}{|\vec{g}|=k}}{\exists l: g_l=0}} \binom{k}{\vec{g}}\\
= g^k 
 - \sum_{\stackrel{\stackrel{\vec{g}\in\mathbb{N}_0^g}{|\vec{g}|=k}}{\exists l: g_l=0}} \binom{k}{\vec{g}}
=g^k 
- \sum_{n=1}^{g-1} \sum_{\stackrel{\vec{g}\in\mathbb{N}_0^g}{|\vec{g}|=k}}
 \binom{k}{\vec{g}} 1_{\exists! i_1\dots i_n : (\forall l\neq b:  i_l\neq i_b) \wedge \forall l :g_{i_l}=0}
\end{multline}
where in the last line the indicator function is to enforce there being exactly n different indices \(i_l\) for which \(g_{i_l}=0\)
holds. Now since it does not matter which entries of the vector vanish because the multinomial coefficient 
is symmetric and its value is identical to the corresponding multinomial coefficient where the vanishing entries
are omitted, we can further simplify the sum:

\begin{equation*}
F(g,k)= g^k -  \sum_{n=1}^{g-1} \binom{g}{n} \sum_{\stackrel{\vec{g}\in\mathbb{N}^{g-n}}{|\vec{g}|=k}}
 \binom{k}{\vec{g}}
\end{equation*}

The inner sum turns out to be \(F(g-n,k)\), so we found the recursive relation for \(F\):
\begin{equation}\label{combinatorics solution recursive}
F(g,k)= g^k -  \sum_{n=1}^{g-1} \binom{g}{n} F(g-n,k)= g^k -  \sum_{n=1}^{g-1} \binom{g}{n} F(n,k),
\end{equation}

where for the last equality we used the symmetry of binomial coefficients.
By iteratively applying this equation, we find the following formula, which we will now prove by induction

\begin{multline}\label{combinatorics induction}
\forall d\in\mathbb{N}_0: F(g,k)=\sum_{l=0}^d (-1)^l (g-l)^k \binom{g}{l}\\
+(-1)^{d+1} \sum_{n=1}^{g-d-1} \binom{n+d-1}{d} \binom{g}{n+d} F(g-d-n,k).
\end{multline}

We already showed the start of the induction, so what's left is the induction step. Before we do so the
following remark is in order: We are only interested in the case \(d=g\) and the formula seems meaningless
for \(d>g\); however, the additional summands in the left sum vanish, where as the right sum is empty
for these values of \(d\) since the  upper bound of the summation index is lower than its lower bound.

For the induction step, pick \(d\in\mathbb{N}_0\), use \eqref{combinatorics induction} and pull the first summand
 out of the second sum,
on this summand we apply the recursive relation \eqref{combinatorics solution recursive} resulting in

\begin{multline}
F(g,k)=\sum_{l=0}^d (-1)^l (g-l)^k \binom{g}{l}\\
 + (-1)^{d+1}\sum_{n=2}^{g-d-1} \binom{n+d-1}{d}\binom{g}{n+d} F(g-d-n,k)\\
  + (-1)^{d+1} \binom{d}{d} \binom{g}{d+1} F(g-d-1,k)\\
\overset{\eqref{combinatorics solution recursive}}{=}\sum_{l=0}^{d+1} (-1)^l (g-l)^k \binom{g}{l}\\
+(-1)^{d+1} \sum_{n=2}^{g-d-1} \binom{n+d-1}{d} \binom{g}{n+d} F(g-d-n,k)\\
-(-1)^{d+1} \binom{g}{d+1} \sum_{n=1}^{g-d-2} \binom{g-d-1}{n} F(g-d-1-n,k)\\
=\sum_{l=0}^{d+1} (-1)^l (g-l)^k \binom{g}{l}\\
+(-1)^{d+1} \sum_{n=1}^{g-d-2} \binom{n+d}{d} \binom{g}{n+d+1} F(g-d-1-n,k)\\
-(-1)^{d+1} \binom{g}{d+1} \sum_{n=1}^{g-d-2} \binom{g-d-1}{n} F(g-d-1-n,k).
\end{multline}
After the index shift we can combine the last two sums. 

\begin{multline}
F(g,k)= \sum_{l=0}^{d+1} (-1)^l (g-l)^k \binom{g}{l}\\
+ \sum_{n=1}^{g-d-2}\left[\binom{g}{d+1} \binom{g-d-1}{n} - \binom{n+d}{d} \binom{g}{n+d+1} \right] 
\\(-1)^{d+2} F(g-d-1-n,k).
\end{multline}


In order to combine the two binomials we reassemble \(\binom{g}{d+1}\binom{g-d-1}{n}\) 
into \(\binom{g}{n+d+1}\binom{n+d+1}{d+1}\), which can be seen to be possible by representing everything
in terms of factorials. This results in
\begin{multline}
F(g,k)= \sum_{l=0}^{d+1} (-1)^l (g-l)^k \binom{g}{l}\\
+(-1)^{d+2} \sum_{n=1}^{g-d-2}\left[\binom{n+d+1}{d+1} - \binom{n+d}{d}\right] \binom{g}{n+d+1} 
 F(g-d-1-n,k)\\
=\sum_{l=0}^{d+1} (-1)^l (g-l)^k \binom{g}{l}\\
+(-1)^{d+2}  \sum_{n=1}^{g-d-2} \binom{n+d}{d+1} \binom{g}{n+d+1}  F(g-d-1-n,k),
\end{multline}
where we used the addition formula for binomials:

\begin{equation}
\forall n\in \mathbb{C} \forall k \in \mathbb{Z}: \binom{n}{k} = \binom{n-1}{k} + \binom{n-1}{k-1}.
\end{equation}
This concludes the proof by induction. By setting \(d=g\) in equation \eqref{combinatorics induction} 
we arrive at the desired result. \qed

Using the previous lemma, we are able to show the next

\begin{Lemma}\label{combinatorics weak conjecture lemma 2}
For any \(k \in \mathbb{N}\backslash \{1\}\) the following equation holds
\begin{equation}
\sum_{g=1}^k \frac{(-1)^g}{g} \sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{|\vec{g}|=k}}\binom{k}{\vec{g}}=0.
\end{equation}
\end{Lemma}
\textbf{Proof:} Let \(k\in\mathbb{N}\backslash\{1\}\), as a first step we apply lemma \ref{stirling lemma}.
We change the order of summation, use \eqref{absorption}, extend the range of summation and shift 
summation index  to arrive at

\begin{multline}
\sum_{g=1}^k \frac{(-1)^g}{g} \sum_{l=0}^g (-1)^l (g-l)^k \binom{g}{l}
= \sum_{g=1}^k \frac{1}{g} \sum_{l=0}^g (-1)^{g-l} (g-l)^k \binom{g}{g-l}\\
= \sum_{g=1}^k \sum_{p=0}^g (-1)^{p} p^k \frac{1}{g} \binom{g}{p}
=\sum_{g=1}^k \sum_{p=0}^g (-1)^{p} p^k \frac{1}{p} \binom{g-1}{p-1}\\
=\sum_{g=1}^k \sum_{p\in\mathbb{Z}} (-1)^{p} p^{k-1}\binom{g-1}{p-1}
=\sum_{p\in\mathbb{Z}} (-1)^{p} p^{k-1} \sum_{g=1}^k \binom{g-1}{p-1}\\
=\sum_{p\in\mathbb{Z}} (-1)^{p} p^{k-1} \sum_{g=0}^{k-1} \binom{g}{p-1}.
\end{multline}

Now we use equation (5.10) of \cite{graham1994concrete}:

\begin{equation}\tag{upper summation}
\forall m,n\in\mathbb{N}_0: \sum_{k=0}^n \binom{k}{m} = \binom{n+1}{m+1},
\end{equation}
which can for example be proven by induction on \(n\).

We furthermore rewrite the power of the summation index \(p\) in terms of the derivative of an 
exponential and change order summation and differentiation. This results in

\begin{multline*}
\sum_{g=1}^k \frac{(-1)^g}{g} \sum_{l=0}^g (-1)^l (g-l)^k \binom{g}{l}
=\sum_{p\in\mathbb{Z}} (-1)^{p} p^{k-1}  \binom{k}{p}\\
=\sum_{p=0}^k (-1)^{p} \left. \frac{\partial^{k-1}}{\partial \alpha^{k-1}} e^{\alpha p}\right|_{\alpha=0}  \binom{k}{p}
=\left. \frac{\partial^{k-1}}{\partial \alpha^{k-1}}  \sum_{p=0}^k (-1)^{p} e^{\alpha p} \binom{k}{p}\right|_{\alpha=0} \\
=\left. \frac{\partial^{k-1}}{\partial \alpha^{k-1}}  \left( 1-e^{\alpha p}\right)^k \right|_{\alpha=0} 
=(-1)^k \left. \frac{\partial^{k-1}}{\partial \alpha^{k-1}} \left( \sum_{l=1}^\infty \frac{(\alpha p)^l}{l!} \right) ^k \right|_{\alpha=0} \\
=(-1)^k \left. \frac{\partial^{k-1}}{\partial \alpha^{k-1}} ((\alpha p)^k + \mathcal{O} ((\alpha p)^{k+1}) ) \right|_{\alpha=0} =0.
\end{multline*}
\qed




We are now in a position to state the solution to the recursive equation \eqref{T_n recursive}
and motivate that it is in fact a solution. 

\begin{Conj}
For \(n\in\mathbb{N}\) the solution of the recursive equation \eqref{T_n recursive} 
solely in terms of \(\Gamma_a\) and \(C_a\) is given by

\begin{equation}\label{recursive solution}
T_n = \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|= n}} \sum_{\vec{d}\in {\{0,1\}}^g} 
\frac{1}{g!} \binom{n}{\vec{b}} \prod_{l=1}^g F_{b_l,d_l},
\end{equation}
where \(F\) is given by
\begin{equation}\label{eq resursive weak solution}
F_{a,b} = \left\{ \begin{matrix}\mathrm\Gamma_a \quad \text{for } b=0 \\ C_a \quad \text{for } b=1  \end{matrix} \right._. 
\end{equation}
For the readers convenience we remind her, that \(\mathrm\Gamma_a\) and
the constants \(C_n\) are defined in conjecture \ref{thm: T_n recursive}. 
\end{Conj}

\textbf{Motivation:} The structure of this proof will be induction over \(n\). For \(n=1\) the whole expression
on the right hand side collapses to \(C_1 + \mathrm\Gamma_1\), which we already know to be equal to \(T_1\). For
arbitrary \(n\in\mathbb{N}\) we apply for the induction step 
the recursive equation \eqref{T_n recursive}
once and use the induction hypothesis for all \(k\le n\) and thereby arrive at the rather convoluted 
expression

\begin{multline}\label{recursive weak conjecture proof}
T_{n+1} \stackrel{\eqref{T_n recursive}}{=} 
\mathrm\Gamma_{n+1} + C_{n+1}+ \sum_{g=2}^{n+1} \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n+1}} 
\frac{(-1)^g}{g} \binom{n+1}{\vec{b}} \prod_{l=1}^g T_{b_l}\\
\stackrel{\text{induction hyp}}{=} \mathrm\Gamma_{n+1} + C_{n+1}+ \sum_{g=2}^{n+1} \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n+1}} 
\frac{(-1)^g}{g} \binom{n+1}{\vec{b}} \prod_{l=1}^g \\
\sum_{g_l=1}^{b_l} \sum_{\stackrel{\vec{c}_l \in\mathbb{N}^{g_l}}{|\vec{c}_l|=b_l}} \sum_{\vec{e}_l \in \{0,1\}^{g_l}}
\frac{1}{g_l!} \binom{b_l}{\vec{c}_l} \prod_{k=1}^{g_l} F_{c_{l,k},e_{l,k}}.
\end{multline}

If we were to count the contributions of this sum to a specific product \(\prod F_{c_j,e_j}\) for some choice of 
\((c_j)_j, (e_j)_j\) we would first recognize that all the multinomial factors in \eqref{recursive weak conjecture proof}
combine to a single one whose indices are given by the first indices of all the \(F\) factors involved.
Other than this factor each contribution adds \(\frac{(-1)^g}{g} \prod_{l=1}^g \frac{1}{g_l!}\) to the sum. So we 
need to keep track of how many contributions there are and which distributions of \(g_l\) they belong to. 

Fix some product \(\prod F :=\prod_{j=1}^{\tilde{g}} F_{\tilde{b}_j,\tilde{d}_j}\). In the sum 
\eqref{recursive weak conjecture proof} we pick some initial short product of length \(g\) and split each
factor into \(g_l\) pieces to arrive at one of length \(\tilde{g}\) if the product is to contribute to
\(\prod F\). So clearly \(\sum_{l=1}^g g_l = \tilde{g}\) holds for any contribution to \(\prod F\). 
The reverse is also true, for any
\(g\) and \(g_1, \dots, g_g\in\mathbb{N}\) such that \(\sum_{l=1}^g g_l=\tilde{g}\) holds
the corresponding expression in \eqref{recursive weak conjecture proof} contributes to 
\(\prod F\). Furthermore \(\prod F\) and \(g\), \(g_1,\dots g_g\) is enough to uniquely
determine the summand of \eqref{recursive weak conjecture proof} the contribution
belongs to. For an illustration of this splitting see

\begin{align*}
\underbrace{\underbrace{F^1_{3,1} F^2_{2,0} F^3_{7,1}}_{g_1=3} \underbrace{F^4_{5,0}}_{g_2=1} \underbrace{F^5_{4,1} F^6_{2,1}}_{\weightf_3=2} \underbrace{F^7_{1,1} F^8_{3,0} F^9_{4,1}}_{g_4=3} \underbrace{F^{10}_{4,1} F^{11}_{1,0}}_{g_5=2}}_{g=5}\\
 g_1+g_2+g_3+g_4+g_5=11=\tilde{g}.
\end{align*}

We recognize
that the sum we are about to perform is by no means unique for each order of \(n\) but only 
depends on the number of appearing factors and the number of splittings performed on
them. By the preceding argument we need 

\begin{equation}\label{combinatorics weak conjecture reformulated into equation}
\sum_{g=2}^{\tilde{g}} \frac{(-1)^g}{g} \sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{|\vec{g}|=\tilde{g}}} \prod_{l=1}^g \frac{1}{g_l!}
= \frac{1}{\tilde{g}!} 
\end{equation}


to hold for \(\tilde{g}>1\), in order to find agreement with the proposed solution \eqref{eq resursive weak solution}.
Now proving \eqref{combinatorics weak conjecture reformulated into equation} is done by 
realizing, that one can include the right hand side into the sum as the \(g=1\) summand, dividing
the equation by \(\tilde{g}!\) and using lemma \ref{combinatorics weak conjecture lemma 2}
with \(k=\tilde{g}\). The remaining case, \(\tilde{g}=1\), can directly be
read off of \eqref{recursive weak conjecture proof}. This ends the motivation of this conjecture.

\begin{Conj}\label{Corollary T_n by G's and C's}
For \(n\in\mathbb{N}\), \(T_n\) can be written as

\begin{equation}
\frac{1}{n!} T_n = \sum_{\stackrel{1\le c+g\le n}{c,g\in\mathbb{N}_0}} 
\sum_{\stackrel{\stackrel{\vec{g}\in\mathbb{N}^g}{\vec{c}\in\mathbb{N}^c}}{|\vec{c}| + |\vec{g}|=n}} 
\frac{1}{c! g!} \prod_{l=1}^c \frac{1}{c_l!} C_{c_l} \prod_{l=1}^g \frac{1}{g_l!} \mathrm\Gamma_{g_l}.
\end{equation}
Please note that for ease of notation we defined \(\mathbb{N}^0:= \{1\}\).
\end{Conj}
\textbf{Motivation:} By an argument completely analogous to the combinatorial argument in the motivation of conjecture
\eqref{thm: T_n recursive} we see that we can disentangle the \(F\)s in \eqref{recursive solution}
into \(\mathrm\Gamma\)s and \(C\)s if we multiply by a factor of \(\binom{c+g}{c}\) where \(c\) is the 
number of \(C\)s and \(g\) is the number of \(\mathrm\Gamma\)s giving

\begin{multline}
T_n = \sum_{\stackrel{1\le c+g\le n}{c,g\in\mathbb{N}_0}}
\sum_{\stackrel{\stackrel{\vec{g}\in\mathbb{N}^g}{\vec{c}\in\mathbb{N}^c}}{|\vec{c}| + |\vec{g}|=n}} 
\binom{c+g}{c} \frac{1}{(c+g)!} \binom{n}{\vec{g}\oplus \vec{c}}
\prod_{l=1}^c  C_{c_l} \prod_{l=1}^g \mathrm\Gamma_{g_l},
\end{multline}

which directly reduces to the equation we wanted to prove, by plugging in the multinomials in terms of
factorials. 

\begin{Conj}
As a formal power series, the second quantized scattering operator can be written in the form
\begin{equation}\label{Corollary double exp}
S= e^{\sum_{l\in\mathbb{N}} \frac{C_{l}}{l!}}
 e^{\sum_{l\in\mathbb{N}} \frac{\mathrm\Gamma_{l}}{l!}}.
\end{equation}
\end{Conj}
\textbf{Motivation:} We plug conjecture \ref{Corollary T_n by G's and C's} into the defining Series for the \(T_n\)s
giving

\begin{align}
&S= \sum_{n\in\mathbb{N}_0} \frac{1}{n!} T_n \\
&=\id_{\mathcal{F}}+ \sum_{n\in\mathbb{N}} \sum_{\stackrel{1\le c+g\le n}{c,g\in\mathbb{N}_0}} 
\sum_{\stackrel{\stackrel{\vec{g}\in\mathbb{N}^g}{\vec{c}\in\mathbb{N}^c}}{|\vec{c}| + |\vec{g}|=n}} 
\frac{1}{c! g!} \prod_{l=1}^c \frac{1}{c_l!} C_{c_l} \prod_{l=1}^g \frac{1}{g_l!} \mathrm\Gamma_{g_l}\\
&=\id_{\mathcal{F}}+  \sum_{\stackrel{1\le c+g }{c,g\in\mathbb{N}_0}} 
\sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{\vec{c}\in\mathbb{N}^c}} 
\frac{1}{c! g!} \prod_{l=1}^c \frac{1}{c_l!} C_{c_l} \prod_{l=1}^g \frac{1}{g_l!} \mathrm\Gamma_{g_l}\\
&=\sum_{c,g\in\mathbb{N}_0}
\sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{\vec{c}\in\mathbb{N}^c}} 
\frac{1}{c! g!} \prod_{l=1}^c \frac{1}{c_l!} C_{c_l} \prod_{l=1}^g \frac{1}{g_l!} \mathrm\Gamma_{g_l}\\
&=\sum_{c\in\mathbb{N}_0} \frac{1}{c!} \sum_{\vec{c}\in\mathbb{N}^c} \prod_{l=1}^c \frac{1}{c_l!} C_{c_l}
\sum_{g\in\mathbb{N}_0} \frac{1}{g!} \sum_{\vec{g}\in\mathbb{N}^g} \prod_{l=1}^g \frac{1}{g_l!} \mathrm\Gamma_{g_l}\\
&=\sum_{c\in\mathbb{N}_0} \frac{1}{c!} \prod_{l=1}^c \sum_{k\in\mathbb{N}} \frac{1}{k!} C_{k}
\sum_{g\in\mathbb{N}_0} \frac{1}{g!}  \prod_{l=1}^g \sum_{b\in\mathbb{N}} \frac{1}{b!} \mathrm\Gamma_{b}\\
&=\sum_{c\in\mathbb{N}_0} \frac{1}{c!} \left( \sum_{k\in\mathbb{N}} \frac{1}{k!} C_{k}\right)^c
\sum_{g\in\mathbb{N}_0} \frac{1}{g!}  \left( \sum_{b\in\mathbb{N}} \frac{1}{b!} \mathrm\Gamma_{b}\right)^g\\
&=e^{\sum_{l\in\mathbb{N}} \frac{1}{l!} C_{l}} e^{\sum_{l\in\mathbb{N}} \frac{1}{l!} \mathrm\Gamma_{l}}.
\end{align}


\begin{Conj}
For \(A\) such that 
\begin{equation}
\|\id-U^A\|<1.
\end{equation}
The second quantized scattering operator fulfils
\begin{equation}\label{conj:sleek_second_quantised_scattering_operator}
S= e^{\sum_{n\in\mathbb{N}} \frac{C_n}{n!}} e^{\mathrm{d}\Gamma(\ln (U))}
\end{equation}
where \(C_n\) must be imaginary for any \(n\in\mathbb{N}\) in order to satisfy unitarity.

\end{Conj}
\textbf{Motivation:} 
First the remark about \(C_n \in i \mathbb{R}\) for any \(n\) is a direct consequence of 
the second factor of \eqref{conj:sleek_second_quantised_scattering_operator} begin unitary.
This in turn follows directly from \(\mathrm{d}\Gamma^* (K)=-\mathrm{d}\Gamma(K)\) for any \(K\) in the domain of \(\mathrm{d}\Gamma\).
That \(\ln U\) is in the domain of \(\mathrm{d}\Gamma\) follows from \( (\ln U)^*=\ln U^*=\ln U^{-1}=-\ln U\)
and \(\|U-\id\|<1\).

 We are going to change the sum in the second exponential of 
\eqref{Corollary double exp}, so let's take a closer look at that: by exchanging summation
we can step by step simplify

\begin{multline}
\sum_{l\in\mathbb{N}} \frac{\mathrm\Gamma_{l}}{l!}= 
\sum_{n \in\mathbb{N}} \frac{1}{n!} 
\mathrm{d}\Gamma\left( \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^{g+1}}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g Z_{b_l}  \right)\\
=\mathrm{d}\Gamma\left( \sum_{n \in\mathbb{N}} \frac{1}{n!} 
 \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^{g+1}}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g Z_{b_l}  \right)\\
=\mathrm{d}\Gamma\left( \sum_{n \in\mathbb{N}}
 \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^{g+1}}{g} 
 \prod_{l=1}^g \frac{Z_{b_l}}{b_l!}  \right)\\
=\mathrm{d}\Gamma\left( 
 \sum_{g\in\mathbb{N}} \sum_{\vec{b}\in\mathbb{N}^g}\frac{(-1)^{g+1}}{g} 
\prod_{l=1}^g \frac{Z_{b_l}}{b_l!}  \right)\\
=\mathrm{d}\Gamma\left( 
 \sum_{g\in\mathbb{N}} \frac{(-1)^{g+1}}{g} 
\prod_{l=1}^g \left(\sum_{b_l\in\mathbb{N}} \frac{Z_{b_l}}{b_l!} \right) \right)\\
=\mathrm{d}\Gamma\left( 
 \sum_{g\in\mathbb{N}} \frac{(-1)^{g+1}}{g} 
 \left(\sum_{b\in\mathbb{N}} \frac{Z_{b}}{b!} \right)^g \right)\\
 =\mathrm{d}\Gamma\left( 
 \sum_{g\in\mathbb{N}} \frac{(-1)^{g+1}}{g} 
 \left(U-\id \right)^g \right)
 =\mathrm{d}\Gamma\left( -
 \sum_{g\in\mathbb{N}} \frac{1}{g} 
 \left(\id-U \right)^g \right)\\
  =\mathrm{d}\Gamma\left( 
 \ln \left(\id-\left(\id-U\right) \right) \right)
 =\mathrm{d}\Gamma\left( \ln \left(U\right)\right).
\end{multline}



The last conjecture is proven directly in section \ref{sec:proof simple formula}



\section[Proofs of Section \ref{sec: hadamard}][proofs for Hadamard comparison]{Proofs of Section \ref{sec: hadamard}}\label{sec: proof hadamard}

We first break  down the problem of the proof of theorem \ref{thm:hadamard=>Pol} to a problem on a bounded domain. Then we go on 
to show that the relevant functions are locally bounded so that an application of Lebesgue dominated convergence yields our result.
The same estimates we need for theorem \ref{thm:hadamard=>Pol} will be used again for the proof of theorem \ref{thm:Pol=>hadamard}.

\begin{Def} Let \(A\in \mathcal{V}\), \(\Sigma\) be a Cauchy surface 
  and \(\delta>0\), we introduce the sets
\begin{align}
J_1&:=\!\{(x,y)\!\in\!\mathbb{R}^{4+4}\mid (x-y)^2\ge -\delta^2/4 \wedge \overline{x~y} \cap \mathrm{supp}(A)\neq \emptyset\}\\
J_2&:=\!\{(x,y)\!\in\mathbb{R}^{4+4}\mid\!\! (x-y)^2\ge -\delta^2\!\! \wedge \overline{x~y} \!\cap\!\! \left(B_{\delta/2}(0)\!+\!\mathrm{supp}(A)\right)\!\neq\! \emptyset\}\\
J_3&:=\!\{(x,y)\!\in\! \Sigma \!\times\! \Sigma \mid\!\! (x-y)^2 \ge-\delta^2\!\!\wedge\! \overline{x ~ y} \!\cap\!\! \left(B_{\delta/2}(0)\!\!+\!\mathrm{supp}(A) \right)\!\neq\! \emptyset \},
\end{align}
where the sum of two sets is defined as 
\(S_1+S_2:=\{s_1+s_2\mid s_1\in S_1, s_2\in S_2\}\). 
Please recall that the line segment between \(x\) and \(y\) 
by is denoted by \(\overline{x~y}\). 
\end{Def}

\begin{Def}
For ease of comparison, we define 
for a four-potential \(A\in \mathcal{V}\),
\(\tilde{\lambda}:\mathbb{R}^{4+4}\rightarrow \mathbb{C}\):
\begin{equation}
\tilde{\lambda}(x,y)= (x-y)^\alpha\int_0^1 ds ~A_\alpha (x s + (1-s)y),
\end{equation}
and furthermore introduce the abbreviation \(G(x,y):=e^{-i \tilde{\lambda}(x,y)} \).
\end{Def}

\begin{Remark}
The function \(\tilde{\lambda}\not\in \mathcal{G}^A\), because it does not satisfy one of the technical conditions in definition
\ref{def:lambda}, there is not compact \(K\subset\mathbb{R}^4\) such that 
\(\mathrm{supp}(\tilde{\lambda})\subset K\times \mathbb{R}^4 \cup \mathbb{R}^4\times K\) holds. However, the other conditions are all fulfilled. 
We need to introduce it nonetheless, because it is present in the representation for the Hadamard states.
\end{Remark}


\begin{Lemma}\label{lem:pointwise}
For any \(A\in \mathcal{V}\) and any Hadamard state \(H\) 
of the form \eqref{eq:hadamard1} to \eqref{eq:hadamardexp3}
and any \(\lambda^A \in \mathcal{G}^A\), \(\delta>0\),  
there is a smooth family of
functions \(w_\varepsilon\in C^\infty(\mathbb{R}^4\times \mathbb{R}^4,\mathbb{C}^{4\times4})\) with \(\varepsilon \in [0,1]\) and a smooth function 
  \(w\in C^\infty(\mathbb{R}^4\times \mathbb{R}^4,\mathbb{C}^{4\times 4})\)  obeying
  
\begin{align}
&\int_{\mathbb{R}^4\times\mathbb{R}^4} \overline{f_1}(x) w_\varepsilon(x,y) f_2(y)dxdy =
\int_{\mathbb{R}^4\times\mathbb{R}^4} \overline{f_1}(x) (h_\varepsilon - p_\varepsilon^\lambda)(x,y) f_2(y)dxdy\\
&\int_{\mathbb{R}^4\times\mathbb{R}^4} \overline{f_1}(x) w(x,y)f_2(y)dxdy \notag\\
&\hspace{2cm}=\lim_{\epsilon\rightarrow 0}\int_{\mathbb{R}^4\times\mathbb{R}^4} \overline{f_1}(x)(h_\epsilon (x,y)-p^\lambda_\epsilon(x,y)) f_2(y)dxdy,
\end{align}

for all test functions \(f_1,f_2\) such that \(\mathrm{supp}(f_1)\times\mathrm{supp}(f_2)\subset J_2^c\)
  
Additionally \(\lim_{\varepsilon \rightarrow 0}w_\varepsilon=w\) pointwise and in addition 
is continuous as a function of type \(\mathbb{R}^{4+4} \times[0,1]\rightarrow \mathbb{C}^{4\times 4}\).
\end{Lemma}
\begin{proof}
Let \(A\in \mathcal{V}, \varepsilon, \delta>0\).
  Let \(H\) be a Hadamard state acting as 
\begin{equation}
H(f_1,f_2)=\lim_{\varepsilon\searrow 0} \int_{\mathbb{R}^4}d^4 x \overline{f_1}(x) \int_{\mathbb{R}^4} d^4y ~h_\varepsilon(x,y) f_2(y).
\end{equation}

be of the form of equation \eqref{eq:hadamardexp1} to \eqref{eq:hadamardexp3}. 
Pick a function \(\lambda\in \mathcal{G}^A\). 

We may choose \(w'\in C^\infty(\mathbb{R}^4\times\mathbb{R}^4,\mathbb{C}^{4\times 4})\)
such that the following conditions is fulfilled:

For all test functions \(f_1,f_2\in C_c^\infty(\mathbb{R}^4,\mathbb{C}^4)\) such that \( \mathrm{supp}(f_1)\times \mathrm{supp}(f_2) \subset J_1^c \)
we have

\begin{align}\label{eq:conditionfull}
\int_{\mathbb{R}^4\times\mathbb{R}^4} \overline{f_1}(x)& w'(x,y)f_2(y)dxdy \\
&=\lim_{\epsilon\rightarrow 0}\int_{\mathbb{R}^4\times\mathbb{R}^4} \overline{f_1}(x)(h_\epsilon (x,y)-p^\lambda_\epsilon(x,y)) f_2(y)dxdy.
\end{align}

To understand why, we consider two cases regarding the support of the testfunctions \(f_1,f_2\), 
\begin{enumerate}
\item \((x,y)\in\mathrm{supp}(f_1)\times\mathrm{supp}(f_2)\)
implies \(\overline{x~y}\cap \mathrm{supp}(A)=\emptyset\).
\item \((x,y)\in\mathrm{supp}(f_1)\times\mathrm{supp}(f_2)\)
implies \((x-y)^2<-\delta^2/4\).
\end{enumerate}

Regarding 1: In the representation of the Hadamard state \(H\), equation \eqref{Hadamard recursive equ.}, can be explicitly 
solved recursively (See \cite{bar2007wave}[lemma 2.2.2]. The factor \(V_0\) was already given, for \(k\ge 1\) the recursion is given by

\begin{equation}\label{eq:line integral}
V_k(x,y)=-k G(x,y) \int_0^1 ds s^{k-1} G(x+ s(y-x),x) P V_{k-1}(x,x+s(y-x)).
\end{equation}

Recall that \(P\) depends on the four potential in a local manner.
Here we observe  that, if the support of the external field \(A\) does not intersect the straight line connecting \(x\) and \(y\), the function
\(V(x,y)\) in the expression for \(h_\varepsilon(x,y)\) can be calculated to be

\begin{equation}
V(x,y)=\sum_{k=0}^\infty \frac{( (y-x)^2m^2/4)^k}{k! (k+1)!},
\end{equation}

which equals the logarithmic part of \(p^-_\varepsilon\), corresponding to \(Q_1(\xi)\) in \eqref{K1series}. 

This shows that in this case
\(p_\varepsilon^-(x,y)\) agrees with \(h_\varepsilon(x,y)\) up to smooth terms in case 1.
  
Regarding 2: we notice that the only points \((x,y)\) in 
the singular support of \(h_\varepsilon\) and 
\(p_\varepsilon^{\lambda}\) need to fulfil
\((y-x)^2=0\). This implies that for functions 
\(f_1,f_2\in C_c^\infty(\mathbb{R}^4,\mathbb{C}^4)\) 
of case 2 these operators act as 
integral operators with smooth kernel.


In fact, as \(w'\) is smooth, condition \eqref{eq:conditionfull} specifies the values of \(w'\)
uniquely for arguments \((x,y)\in\mathbb{R}^{4+4}\) in the complement of \(J_1\).
Analogously, we define a smooth function \(w_\varepsilon' \in C^\infty(\mathbb{R}^4\times\mathbb{R}^4,\mathbb{C}^{4\times 4})\) for
every \(\varepsilon>0\) fulfilling 

\begin{align}\label{eq:wepsilon_condition}
\int_{\mathbb{R}^4\times\mathbb{R}^4} \overline{f_1}(x) w'_\varepsilon(x,y) f_2(y)dxdy =
\int_{\mathbb{R}^4\times\mathbb{R}^4} \overline{f_1}(x) (h_\varepsilon - p_\varepsilon^\lambda)(x,y) f_2(y)dxdy
\end{align}

for test functions 
\(f_1,f_2\in C^\infty_c(\mathbb{R}^4,\mathbb{C}^4)\) such 
that \(\mathrm{supp}(f_1)\times \mathrm{supp}(f_2)\subset J_1^c\).
Next, we pick a function \(\chi\in C^\infty(\mathbb{R}^{4+4})\) such that 
\begin{align}
\left.\chi \right|_{J_2^c}=1, \quad \left. \chi \right|_{J_1}=0
\end{align}
hold. Now, we define

\begin{align}
w:=\chi w',\quad w_\varepsilon:= \chi w_\varepsilon',
\end{align}

where \(w',w_{\varepsilon}'\) are extended by the zero function inside \(J_1\).

The functions \(w, w_\varepsilon\) are now uniquely fixed 
in all of \(\mathbb{R}^{4+4}\) and fulfil 
\eqref{eq:conditionfull} and \eqref{eq:wepsilon_condition}, 
respectively
for test functions \(f_1,f_2\) such that 
\(\mathrm{supp}(f_1)\times \mathrm{supp}(f_2) 
\subset J_2^c\) holds. Observing the exact form of 
\(h_\varepsilon\), \eqref{eq:hadamardexp1} to 
\eqref{eq:hadamardexp3} and \(p_\varepsilon^{\lambda}\), 
\eqref{def:p lambda}, we notice that in fact 
\(w_{\varepsilon}(x,y) \xrightarrow{\varepsilon\rightarrow 0} 
w(x,y)\) for all \(x,y\in J_1^c\), because of the cutoff 
function \(\chi\) this also holds for \((x,y)\in J_1\). 
Moreover, we notice from the explicit form of 
\(h_\varepsilon\) and \(p_\varepsilon^{\lambda}\) that,
\(w_{\cdot_3}(\cdot_1,\cdot_2)\) is even continuous as a 
function of type \(\mathbb{R}^4\times\mathbb{R}^4\times
[0,1]\rightarrow \mathbb{C}^{4\times 4}\).
\end{proof}

\begin{Def}
Let \(\Sigma\) be a Cauchy surface and \(\delta>0\).
We define
\begin{align}
&\mathfrak{g}_1: \Sigma\times\Sigma\times ]0,1[\rightarrow \mathbb{C}^{4\times 4}\\
&(x,y,\varepsilon)\mapsto e^{-i\tilde{\lambda}(x,y)} \frac{m^2}{4\pi^2} (i\slashed{\partial}_x+m)\frac{1}{m^2(y-x-i\varepsilon e_0)^2} - \eqref{eq:hadamardexp1}(x,y)
\end{align}
and denoting \(\dom(g_2):=\Sigma\times\Sigma\times [0,1]\backslash \{(x,x,0)\mid x\in\Sigma\}\).
\begin{align}
&\mathfrak{g}_2:\dom(g_2)\ni (x,y,\varepsilon)\mapsto \frac{1}{(y-x-i\varepsilon e_0)^2} \\
&\times \left(\slashed{A}(x) + \slashed{A}(y)
-  2 \int_0^1 \mathrm{d}s \slashed{A}(s x + (1-s)y)  \right.\\
&\quad \left.+(y-x)^\alpha \int_0^1 \mathrm{d}s (1-2s) (\slashed{\partial}A_\alpha)(sx+(1-s)y)   \right).
\end{align}
\end{Def}

\begin{Lemma}\label{lem:bound,worstterm}
Let \(\Sigma\) be a Cauchy surface and \(\delta>0\). 
We have \(|\mathfrak{g}_1|=|\mathfrak{g}_2|\).
There is a constant \(M_1\in\mathbb{R}\), such that
\begin{equation}
 \forall (x,y,\varepsilon)\in J_3\times]0,1[ :|\mathfrak{g}_1(x,y,\varepsilon)|\le M_1.
\end{equation}
Furthermore, there is a function 
\(\mathfrak{g}_3 \in C(\Sigma\times\Sigma,\mathbb{R}^+)\) such that
\begin{equation}
\forall (x,y,\varepsilon)\in \dom(g_2): |\mathfrak{g}_2(x,y,\varepsilon)|\le \mathfrak{g}_3(x,y)
\end{equation}
holds.
\end{Lemma}
\begin{proof}
Pick a Cauchy surface \(\Sigma\), a four-potential 
\(A \in \mathcal{V}\) and \((x,y,\varepsilon)\in \dom(g_2)\).
A direct calculation yields
\begin{align}
&e^{-i\tilde{\lambda}(x,y)} \frac{m^2}{4\pi^2} (i\slashed{\partial}_x+m)\frac{1}{m^2(y-x-i\varepsilon e_0)^2} -\eqref{eq:hadamardexp1}(x,y)\\\nonumber
=&\frac{G(x,y)}{4\pi^2} \Bigg( (i \slashed{\partial}_x +m) \frac{1}{(y-x-i \varepsilon e_0)^2}\\
&\hspace{1.5cm} -\frac{1}{G(x,y)}(i \slashed{\nabla}/2 - i \slashed{\nabla}^*/2 +m) \frac{G(x,y)}{(y-x-i\varepsilon e_0)^2}\Bigg)\\\nonumber
=&\frac{iG(x,y)}{4\pi^2}  \Bigg( \slashed{\partial}_x \frac{1}{(y-x-i \varepsilon e_0)^2} \\
&\hspace{1cm}-\frac{1}{2G(x,y)}(\slashed{\partial}_x + i \slashed{A}(x) - \slashed{\partial}_y + i \slashed{A}(y) ) \frac{G(x,y)}{(y-x-i\varepsilon e_0)^2}\Bigg)\\\nonumber
=&\frac{iG(x,y)}{4\pi^2} \left(-i\frac{\slashed{A}(x) + \slashed{A}(y)}{2 (y-x-i\varepsilon e_0)^2} + \slashed{\partial}_x \frac{1}{(y-x-i \varepsilon e_0)^2}\right. \\
&-\frac{1}{2}(\slashed{\partial}_x\left.- \slashed{\partial}_y ) \frac{1}{(y-x-i\varepsilon e_0)^2}-\frac{1}{2G(x,y)} \frac{(\slashed{\partial}_x- \slashed{\partial}_y )G(x,y)}{(y-x-i\varepsilon e_0)^2}\right)\\\nonumber
=&\frac{iG(x,y)}{4\pi^2}  \Bigg(-i\frac{\slashed{A}(x) + \slashed{A}(y)}{2 (y-x-i\varepsilon e_0)^2} +\frac{1}{2}(\slashed{\partial}_x+ \slashed{\partial}_y ) \frac{1}{(y-x-i\varepsilon e_0)^2}\\
&\hspace{1.5cm}+\frac{1}{2G(x,y)} \frac{(-\slashed{\partial}_x+ \slashed{\partial}_y )G(x,y)}{(y-x-i\varepsilon e_0)^2}\Bigg)\\\nonumber
=&\frac{-iG(x,y)}{8\pi^2}  \frac{1}{(y-x-i\varepsilon e_0)^2} \left(i\slashed{A}(x) + i\slashed{A}(y)
+G(x,y)^{-1} \left( \slashed{\partial}_x- \slashed{\partial}_y\right) G(x,y) \right)\\\nonumber
=&\frac{G(x,y)}{8\pi^2} \frac{1}{(y-x-i\varepsilon e_0)^2} \left(\slashed{A}(x) + \slashed{A}(y)
-  2 \int_0^1 \mathrm{d}s \slashed{A}(s x + (1-s)y)  \right.\\
&\left.+(x-y)^\alpha \int_0^1 \mathrm{d}s (1-2s) (\slashed{\partial}A_\alpha)(sx+(1-s)y)   \right).
\end{align}

Now using Taylor's series for \(A\) around \((x+y)/2\) reveals 

\begin{align}\nonumber
\slashed{A}(x)& + \slashed{A}(y)- 2 \int_0^1 \mathrm{d}s \slashed{A}(s x + (1-s)y) =  \\\label{estimate1}
&\frac{(x-y)^\alpha}{6} (x-y)^\beta (\partial_\alpha \partial_\beta \slashed{A})((x+y)/2)+ \mathcal{O}(\|x-y\|^3)\\\label{estimate2}
(x-y)^\alpha &\int_0^1 \mathrm{d}s (1-2s) (\slashed{\partial}A_\alpha)(sx+(1-s)y)=
  \\\notag
& -\frac{(x-y)^\alpha}{12}(x-y)^\beta  (\slashed{\partial}\partial_\beta A_\alpha)((x+y)/2) + \mathcal{O}(\|x-y\|^3).
\end{align}

Because \(A\) is smooth and \(J_3\) is a compact region the terms \eqref{estimate1} and \eqref{estimate2} are 
bounded in this region. Because of their behaviour close to \(y=x\)
the function
is a bounded and point-wise an upper bound of the absolute value of 
\begin{align}
\left|e^{-i\tilde{\lambda}(x,y)} \frac{m^2}{4\pi^2} (i\slashed{\partial}_x+m)\frac{1}{m^2(y-x-i\varepsilon e_0)^2} -\eqref{eq:hadamardexp1}(x,y)\right|\\
\label{upper bound h first term}
\le\frac{\|\eqref{estimate1}\|(x,y)+\|\eqref{estimate2}\|(x,y)}{8\pi^2}\frac{1}{|(y-x)^2|}.
\end{align}

Also from the Taylor's expansion \eqref{estimate1} and \eqref{estimate2} directly follows that the right hand side of \eqref{upper bound h first term} is continuous.
\end{proof}


\begin{Lemma}\label{lem:bound,ivp2}
For any Cauchy surface \(\Sigma\), four-potential 
\(A\in \mathcal{V}\) and \(\lambda^A\in \mathcal{G}^A\),  
the function 
\begin{align}
&\Sigma\times \Sigma \times ]0,1[\rightarrow \mathbb{C}^{4\times 4}\\
&(x,y,\varepsilon)\mapsto \left(e^{-i\tilde{\lambda}(x,y)}-e^{-i\lambda^A(x,y)}\right) \frac{1}{4\pi^2}(i\slashed{\partial}_x+m)\frac{1}{(y-x-i\varepsilon e_0)^2}
\end{align}
is bounded by
\begin{align}\label{exp exp raw}
&\left|\left(e^{-i\tilde{\lambda}(x,y)}-e^{-i\lambda^A(x,y)}\right) \frac{1}{4\pi^2}(i\slashed{\partial}_x+m)\frac{1}{(y-x-i\varepsilon e_0)^2}\right|  \\
&\le \frac{\left| e^{-i\tilde{\lambda}(x,y)}-e^{-i\lambda^A(x,y)} \right|}{4\pi^2}\left(\eta(y-x)+\frac{\|y-x\|}{((y-x)^2)^2} + \frac{m}{|(y-x)^2|}\right)\label{exp exp term}\\
&:=M_2(x,y),
\end{align}
where \(\eta\) is given by
\begin{equation}
\eta(y-x):=\frac{1}{(-(y-x)^2 {\varepsilon^*}^{-0.5}+{\varepsilon^*}^{1.5})^2+\varepsilon^*(y^0-x^0)^2}
\end{equation}
and \(\varepsilon^*\) is given by
\begin{equation}
\varepsilon^* :=\frac{1}{\sqrt{6}} \sqrt{-\beta-2\alpha + \sqrt{(2\alpha + \beta)^2+12 \alpha^2}},
\end{equation}
with \(\alpha:=-(y-x)^2\) and \((y^0-x^0)^2\).
Furthermore \(M_2\in L^2_{\mathrm{loc}}(\Sigma\times\Sigma)\).
\end{Lemma}

\begin{proof}
Pick \(A\in \mathcal{V}\), Cauchy surface \(\Sigma\) and \(\lambda^A\in \mathcal{G}^A\).
By expanding \(\tilde{\lambda}(x,y)-\lambda^A(x,y)\) in a Taylor series around \(\frac{y+x}{2}\) we see directly that
\begin{equation}\label{exp exp diff}
e^{-i\tilde{\lambda}(x,y)}-e^{-i\lambda^A(x,y)}=\mathcal{O}(\|x-y\|^2).
\end{equation}

In order to show that \eqref{exp exp term} has a square integrable upper bound, we consider each term separately.  First, we look at the mass term. 
It obeys

\begin{align}
\left\|\frac{m}{(y-x-i\varepsilon e_0)^2}\right\|= \frac{m}{\sqrt{((y-x)^2-\varepsilon^2)^2+\varepsilon^2(y^0-x^0)^2}}<\frac{m}{|(y-x)^2|},
\end{align}
since \((y-x)^2<0\) for \(x,y\in \Sigma\), hence this 
term is bounded once multiplied with the difference of 
exponentials.
The term with the derivative will be split into two:

\begin{align}
\left\| i\slashed{\partial}_x \frac{1}{(y-x-i\varepsilon e_0)^2} \right\|\\
\le \frac{\| \slashed{y}-\slashed{x}-i\varepsilon \slashed{e_0}\|}{| (y-x-i\varepsilon e_0)^2|^2}
\le \frac{\varepsilon + \|x-y\|}{((y-x)^2-\varepsilon^2)^2+\varepsilon^2 (y^0-x^0)^2}\\\label{eq:uglyterm}
<\frac{1}{(-(y-x)^2 \varepsilon^{-0.5}+\varepsilon^{1.5})^2+\varepsilon(y^0-x^0)^2} +\frac{\|y-x\|}{((y-x)^2)^2},
\end{align}
we notice at this point, that the second term becomes locally square integrable in \(\Sigma\times\Sigma\) 
once multiplied with a function of type \(\mathcal{O}(\|x-y\|^2)\) close to \(x=y\). Indeed, the first term also has this property, in order to
deduce this more readily, we will maximise this term now.  Considering the limits \(\varepsilon \rightarrow 0\) and \(\varepsilon \rightarrow \infty\)
we see that this term has for arbitrary \((x,y\in\Sigma)\) a maximum in the interval \(]0,\infty[\). 
Abbreviating \(-(y-x)^2:=\alpha, (y^0-x^0)^2:=\beta\), this value of \(\varepsilon\) fulfills

\begin{align}
\partial_\varepsilon ( \varepsilon^{-0.5}\alpha + \varepsilon^{1.5})^2+\beta=0\\
\iff 3 \varepsilon^4 + \varepsilon^2(2 \alpha+\beta)-\alpha^2=0\\
\iff \varepsilon^2= \frac{-\beta-2\alpha + \sqrt{(2\alpha + \beta)^2+12 \alpha^2}}{6}\\
\iff \varepsilon=\varepsilon^* :=\frac{1}{\sqrt{6}} \sqrt{-\beta-2\alpha + \sqrt{(2\alpha + \beta)^2+12 \alpha^2}}.
\end{align}

So we can find an upper bound on the first summand of \eqref{eq:uglyterm} by replacing \(\varepsilon\) by what we just found. 
Now because all the terms in the resulting expression

\begin{equation}
\frac{1}{(-(y-x)^2 {\varepsilon^*}^{-0.5}+{\varepsilon^*}^{1.5})^2+\varepsilon^*(y^0-x^0)^2}=:\eta(y-x)
\end{equation}

are positive, we did not introduce any new singularities. Also the expression is homogenous of degree \(-3\):
\begin{align}
\eta(\delta(y-x))=\delta^{-3} \eta(y-x),
\end{align}
so we can conclude that also this term as well as the 
second term in \eqref{eq:uglyterm}, are of type 
\(\mathcal{O}(\|x-y\|^{-3})\) and therefore
locally square integrable once multiplied by the 
difference of exponentials in \eqref{exp exp diff}. So 
summarising
\eqref{exp exp raw} can be bounded by 

\begin{align}\nonumber
&\| \eqref{exp exp raw}(x,y)\|\le\\ \label{bound ivp2}
& \frac{\left| e^{-i\lambda^A(x,y)}-e^{-i\tilde{\lambda}(x,y)} \right|}{4\pi^2}\left(\eta(y-x)+\frac{\|y-x\|}{((y-x)^2)^2} + \frac{m}{|(y-x)^2|}\right),
\end{align}
which is locally square integrable in on \(\Sigma\times \Sigma\).
\end{proof}

\begin{Lemma}\label{lem:log term}
For any Cauchy surface \(\Sigma\), 
four-potential \(A\in \mathcal{V}\), the function 
\begin{align}
&\Sigma\times \Sigma \times ]0,1[\rightarrow \mathbb{C}^{4\times 4}\\\label{midterm}
&(x,y,\varepsilon)\mapsto (i\slashed{\partial}_x+m) \ln(-m^2(y-x-i\varepsilon e_0)^2)
\end{align}
has the locally in \(\Sigma\times\Sigma\) square integrable bound
\(M_3+M_4\). More explicitly,
\begin{align}
&\left|\slashed{\partial}_x\ln(-(y-x-i\varepsilon e_0)^2)\right|\le\\
& ~~~~~~~~~~~~\frac{2\|y-x\|}{|(y-x)^2|} + \frac{2}{\sqrt{4|(y-x)^2| + (y^0-x^0)^2}}:=M_3(x,y),
\end{align}
and
\begin{align}
& \| \ln(-m^2(y-x-i\varepsilon e_0)^2)\| \le  |\ln(-m^2(y-x)^2)| +\pi/2:=M_4(x,y).
\end{align}
\end{Lemma}


\begin{proof}
Pick \(A\in C_c^\infty(\mathbb{R}^4)\), a Cauchy surface \(\Sigma\) and \(f\in C(\Sigma\times\Sigma,\mathbb{C}^{4\times 4})\).
The terms containing \(\slashed{\partial}\ln(-(y-x-i\varepsilon e_0)^2)\) are bounded as follows

\begin{align}
\|i\partial_\alpha\ln(-m^2(y-x-i\varepsilon e_0)^2)\|=2\left\| \frac{y^\alpha-x^\alpha-i\varepsilon e_0^\alpha}{-(y-x-i\varepsilon e_0)^2}\right|\\
\le \frac{2\|y-x\|}{|(y-x)^2|} + \frac{2\varepsilon}{|(y-x-i\varepsilon e_0)^2|}\\
=\frac{2\|y-x\|}{|(y-x)^2|} + \frac{2}{\sqrt{(-(y-x)^2/\varepsilon + \varepsilon)^2 +(y^0-x^0)^2}}\\\label{bound d log}
\le \frac{2\|y-x\|}{|(y-x)^2|} + \frac{2}{\sqrt{4|(y-x)^2| + (y^0-x^0)^2}}, 
\end{align}
where inequality  in \eqref{bound d log} we maximised the expression with respect to \(\varepsilon \in ]0,\infty[\). 
The terms containing the logarithm without
any derivative are directly bounded by

\begin{align}\nonumber
|\ln(-m^2(y-x-i\varepsilon e_0)^2)|\le |\ln(-m^2(y-x)^2)| +\pi/2.
\end{align}
\end{proof}



\begin{Lemma}\label{lem:Hadamard=>Pol}
For every four-potential \(A\in \mathcal{V}\) and every Hadamard
state \(H\) of the form \eqref{eq:hadamard1} to \eqref{eq:hadamardexp3} the  
smooth function \(w\in C^\infty(\mathbb{R}^4\times 
\mathbb{R}^4,\mathbb{C}^{4\times 4})\) and family 
\((w_\varepsilon)_{\varepsilon \in ]0,1[ }
\subset C^\infty(\mathbb{R}^4\times \mathbb{R}^4,\mathbb{C}^{4\times4})\) 
provided by lemma \ref{lem:pointwise} also satisfy for any
Cauchy surface \(\Sigma\) and any \(\lambda^A\in\mathcal{G}^A\):

\begin{equation}
\left.h_\varepsilon^A-w_\varepsilon-p^{\lambda^A}_\varepsilon \right|_{\Sigma\times\Sigma} \in L^2(\Sigma\times\Sigma)
\end{equation}

and the \(L^2(\Sigma\times\Sigma)\) limit \(\lim_{\varepsilon\rightarrow 0} \left.h_\varepsilon^A-w_\varepsilon-p^{\lambda^A}_\varepsilon \right|_{\Sigma\times\Sigma}\) exists.
\end{Lemma}

  

\begin{proof}


Pick a Cauchy surface \(\Sigma\), a four-potential \(A \in C_c^\infty(\mathbb{R}^4)\), a Hadamard state of the form 
  \eqref{eq:hadamard1} to \eqref{eq:hadamardexp3}, \(\lambda^A\in\mathcal{G}^A\)
  and for \(\varepsilon \in]0,1[\) smooth functions \(w_\varepsilon \in C^\infty(\mathbb{R}^{4+4},\mathbb{C}^{4\times 4})\)
  according to lemma \ref{lem:pointwise}. 
Our aim is to show that 
\(\left.h_\varepsilon - w_\varepsilon -p_\varepsilon^{\lambda^A} \right|_{\Sigma\times\Sigma}\) converges in the 
sense of \(L^2(\Sigma\times\Sigma)\) in the limit \(\varepsilon\rightarrow 0\).
According to lemma \ref{lem:pointwise} we have that
  \(h_\varepsilon-w_\varepsilon-p^{\lambda^A}_{\varepsilon}|_{\Sigma\times \Sigma}\) vanishes 
  outside the set \(J_3\) which is bounded, independent of \(\varepsilon\) and of finite measure. 
  Taking the exact form of \(h_\varepsilon\) and \(p^{\lambda^A}_\varepsilon\) into account,
  one notices that the function \(h_\varepsilon-w_\varepsilon-p^{\lambda^A}_{\varepsilon}|_{\Sigma\times \Sigma} (x,y)\) converges point-wise to a function defined
  on \(\Sigma\times\Sigma \backslash \{(x,x)\mid x\in \Sigma\}\). In order to show that the convergence also holds in the sense of \(L^2(\Sigma\times\Sigma)\) we
  would like to use dominated convergence. Hence we should find a function \(M\in L^2(\Sigma\times\Sigma)\) such that 
  

\begin{equation}\label{eq: def bound}
\left|  (h_\varepsilon-w_\varepsilon-p^{\lambda^A}_{\varepsilon})(x,y)\right|\le |M|(x,y)
\end{equation}
  
  holds almost for almost all \(x,y\in\Sigma\) and all \(\varepsilon\) small enough. We may pick \(\left. M\right|_{J_3^c}=0\), of course. 
So we only have to pick \(M\) for arguments inside \(J_3\). Now because \(w_\varepsilon\) is continuous as a function from 
\(\mathbb{R}^{4+4}\times [0,1]\rightarrow \mathbb{C}^{4\times 4}\) and hence also when restricted to \(J_3\times[0,1]\). The 
set \(J_3\times[0,1]\) is compact which implies that there is a constant \(M_5\) such that

\begin{equation}
\forall (x,y,\varepsilon)\in J_3\times[0,1]: |w_\varepsilon(x,y)|\le M_5
\end{equation}
holds. So by the triangular inequality we only need to bound \(h_\varepsilon-p_\varepsilon^{\lambda^A}\)

We now dissect \(h_\varepsilon\) as well as \(p_\varepsilon^{\lambda^A}\) each into three pieces

\begin{align}\label{eq:h1}
h_\varepsilon(x,y)= \frac{-1}{2(2\pi)^2} (-i\slashed{\nabla} + i \slashed{\nabla}^*-2m) \frac{G(x,y)}{(y-x-i\varepsilon e_0)^2}\\\label{eq:h2}
+ \frac{-1}{2(2\pi)^2} (-i\slashed{\nabla} + i \slashed{\nabla}^*-2m)  V(x,y) \ln (-(y-x-i\varepsilon e_0)^2)\\\label{eq:h3}
+ B(x,y),
\end{align}


\begin{align}\label{eq:p1}
&p_\varepsilon^{\lambda^A}(x,y)=e^{-i\lambda^A(x,y)}\frac{m^2}{4\pi^2}(i\slashed{\partial}+m) \frac{1}{m^2(y-x-i\varepsilon e_0)^2}\\\label{eq:p2}
&-\frac{m^2}{4\pi^2}(i\slashed{\partial}+m) Q_1(-m^2(y-x-i\varepsilon e_0)^2) \ln (-m^2(y-x-i\varepsilon e_0)^2)\\\label{eq:p3}
&-\frac{m^2}{4\pi^2}(i\slashed{\partial}+m) Q_2(-m^2(y-x-i\varepsilon e_0)^2).
\end{align}

Let us first consider the most singular terms of  
\(h_\varepsilon-w_\varepsilon-
p^{\lambda^A}_{\varepsilon}|_{\Sigma\times \Sigma}\), 
namely \(\eqref{eq:h1}-\eqref{eq:p1}\). In order to 
better compare these terms, we will add \(0\) in the 
form of \(\eqref{eq:p1}-\eqref{eq:p1}\) 
where we
replace \(\lambda^A\) by \(\tilde{\lambda}\).
By lemma \ref{lem:bound,worstterm} the term 
\begin{equation}
\eqref{eq:h1}(x,y)- G(x,y)\frac{m^2}{4\pi^2}(i\slashed{\partial}+m) \frac{1}{m^2(y-x-i\varepsilon e_0)^2}
\end{equation}
is uniformly bounded in \(J_3\).

Next we find a square integrable upper bound on 
\begin{equation}
e^{-i\tilde{\lambda}(x,y)} \frac{m^2}{4\pi^2} (i\slashed{\partial}_x+m)\frac{1}{m^2(y-x-i\varepsilon e_0)^2}-\eqref{eq:p1}(x,y).
\end{equation}
We rewrite this term as

\begin{align}
e^{-i\tilde{\lambda}(x,y)} \frac{m^2}{4\pi^2} (i\slashed{\partial}_x+m)\frac{1}{m^2(y-x-i\varepsilon e_0)^2}-\eqref{eq:p1}(x,y)=\\\label{eq:ivp2estimate}
\left(e^{-i\tilde{\lambda}(x,y)}-e^{-i\lambda(x,y)}\right) \frac{1}{4\pi^2}(i\slashed{\partial}_x+m)\frac{1}{(y-x-i\varepsilon e_0)^2},
\end{align}

according to lemma \ref{lem:bound,ivp2} this has the 
upper bound 
\(M_2\in L^2_{\mathrm{loc}}(\Sigma\times\Sigma)\), which 
is independend of \(\varepsilon\). 
The term \(\eqref{eq:p2} -\eqref{eq:h2}\) are 
bounded by lemma \ref{lem:log term}.
Thus we obtain for \(M\) for \((x,y)\in J_3\):

\begin{align*}
&M(x,y):=M_5+M_1
+M_2(x,y)\\
&+\frac{1}{4\pi^2}\left(4 | V(x,y)| + m^2 \sup_{\varepsilon \in [0,1]}|Q_1(-m^2(y-x-i\varepsilon e_0)^2)|\right)M_3(x,y)\\
&+ \frac{1}{4\pi^2}\bigg(\!|(i\slashed{\nabla}\!-i\slashed{\nabla}^*\!-2m)V(x,y)|/2\\
&\hspace{1cm}+m^2\!\! \sup_{\varepsilon \in [0,1]}
  \!|(i\slashed{\partial}+m)Q_1(-m^2(y-x-i\varepsilon e_0))| \bigg)M_4(x,y)\\
&+|B(x,y)|+\frac{m^2}{4\pi^2}\sup_{\varepsilon\in[0,1]} |(i\slashed{\partial}_x+m)Q_2(-m^2(y-x-i\varepsilon e_0)^2)|
\end{align*}

The argument of \(h_\varepsilon-w_\varepsilon-p^\lambda_{\varepsilon}|_{\Sigma\times \Sigma}(x,y)\) 
converging to \(h_0-w-p^\lambda_{0}|_{\Sigma\times \Sigma}(x,y)\) in the sense of \(L^2(\Sigma\times\Sigma)\)
is completed by applying dominated convergence theorem. 

As a final point: the construction seems to depend on the function \(\lambda^A\) we chose, however for any different \({\lambda'}^A\in \mathcal{G}^A\) 
we have due to remark \ref{main results of ivp2}

\begin{equation}
P^{\lambda}-P^{\lambda'}\in I_2(\mathcal{H}_\Sigma ),
\end{equation}

therefore also the limit \(\lim_{\varepsilon\rightarrow 0} h_\varepsilon^A - w_\varepsilon - p_\varepsilon^{{\lambda'}^A}\) exists in the sense of \(L^2\).


\end{proof}


\begin{proof}[Proof of theorem \ref{thm:hadamard=>Pol}:]

We pick for a four-potential \(A\in \mathcal{V}\) a Hadamard state \(H\) of the form \eqref{eq:hadamard1} to \eqref{eq:hadamardexp3} 
and a \(\lambda^A\in\mathcal{G}^A\). Then we pick 
\(w_\varepsilon,w \in C_c^\infty(\mathbb{R}^{4+4},\mathbb{C}^{4\times 4})\) for all \(\varepsilon\in [0,1]\) according to lemma \ref{lem:pointwise}.
Because of lemma \ref{lem:Hadamard=>Pol}, we have that

\begin{equation}
h_\varepsilon^A-w_\varepsilon-p^{\lambda^A}_\varepsilon \in L^2(\Sigma\times\Sigma)
\end{equation}

holds. We can define the operator \(Z \in I_2(\mathcal{H}_\Sigma)\) for any Cauchy surface \(\Sigma\) as

\begin{equation}
\mathcal{H}_\Sigma\ni \psi\mapsto Z \psi := \lim_{\varepsilon \rightarrow 0} 
\int_{\Sigma} (h_\varepsilon^A-w_\varepsilon-p^{\lambda^A}_\varepsilon)(\cdot,y) i_\gamma(d^4y) \psi(y) 
\end{equation}

and

\begin{equation}
\tilde{P}_\Sigma:=Z + P^{\lambda^A}_\Sigma.
\end{equation}

Because of \eqref{equiv:pLambda} we have for any other \(\lambda' \in\mathcal{G}^A\) that \(\tilde{P}_\Sigma-P^{\lambda'}\in I_2(\mathcal{H}_\Sigma)\).


\end{proof}

\begin{proof}[Proof of theorem \ref{thm:Pol=>hadamard}]
Pick a four-potential \(A\in \mathcal{V}\),
 a \(\lambda^A\in\mathcal{G}^A\) and
a Hadamard state of the form 
\eqref{eq:hadamard1} to \eqref{eq:hadamardexp3}.
Next, we pick \(w_\varepsilon\) according to lemma 
\ref{lem:pointwise}; however,  
we will denote it by \(R_\varepsilon\).

Define for each \(\varepsilon \in ]0,1]\) the function 
\(w_\varepsilon\) as
\begin{align}
&w_\varepsilon (x,y):=\\
&-\frac{G(x,y)-e^{-i\lambda^A(x,y)}}{(2\pi)^2}(i\slashed{\partial}_x +m) \frac{1}{(y-x-i\varepsilon e_0)^2}\label{wurm A}\\
&+\frac{G(x,y)}{2(2\pi)^2 (y-x-i\varepsilon e_0)^2}\Bigg( \slashed{A}(x)+\slashed{A}(y)
-\!2\!\! \int_0^1 \!ds \slashed{A}(sx +(1\!-\!s)y) \\
&\left. + (x\!-\!y)^\alpha \!\int_0^1\! ds (1\!-\!2s)(\slashed{\partial}A_\alpha)(sx \!+\! (1\!-\!s)y) \right)\\
&+ \frac{1}{2(2\pi)^2} (-i\slashed{\nabla}+i\slashed{\nabla}^* -2m) V(x,y)\ln (-(y-x-i\varepsilon e_0)^2)\\
&-\frac{m^2 e^{-i \lambda^A(x,y)}}{4\pi^2} (i\slashed{\partial}_x+m)\bigg(Q_2(m\sqrt{-(y-x-i\varepsilon e_0)^2}\\
&+Q_1(m\sqrt{-(y-x-i\varepsilon e_0)^2}\ln(-m^2(y-x-i\varepsilon e_0)^2)\bigg)\label{wurm E}\\
& + R_\varepsilon(x,y).
\end{align}

We further define the distribution \(H^{\lambda^A}\) by its action on test functions 
\(f_1,f_2\in C_c^\infty(\mathbb{R}^4,\mathbb{C}^4)\)

\begin{equation}
\tilde{H}(f_1,f_2):=\lim_{\varepsilon \rightarrow 0} \int_{\mathbb{R}^4}\int_{\mathbb{R}^4} \overline{f}_1(x) (p_\varepsilon^{\lambda^A}(x,y)-w_\varepsilon(x,y)) f_2(y) d^4x d^4y.
\end{equation}

First, we verify that \(H^{\lambda^A}\) is indeed a Hadamard state. Pick \(\varepsilon>0\), we find

\begin{align*}
&p_\varepsilon^{\lambda^A}(x,y)-w_\varepsilon(x,y)\\
&=-e^{-i\lambda^A(x,y)}\frac{m^2}{4\pi^2} (i\slashed{\partial}_x+m)
\frac{K_1(m\sqrt{-(y-x-i\varepsilon e_0)^2})}{m\sqrt{-(y-x-i\varepsilon e_0)^2}} - w_\varepsilon(x,y)\\
&=-e^{-i\lambda^A(x,y)}\frac{m^2}{4\pi^2} (i\slashed{\partial}_x+m) \left( \frac{-1}{m^2(y-x-i\varepsilon e_0)^2} \right.\\
&+ Q_1(-m^2 (y-x-i\varepsilon e_0)^2) \ln (m\sqrt{-(y-x-i\varepsilon e_0)^2})\\
&+ Q_2(-m^2 (y-x-i\varepsilon e_0)^2)\bigg)\\
& -w_\varepsilon(x,y).
\end{align*}

Inserting \(w_\varepsilon(x,y)\) we find that the most divergent 
terms proportional to \(e^{-i\lambda^A}\), as well as the terms involving \(Q_1\) and \(Q_2\) cancel.
This results in 

\begin{align*}
&p_\varepsilon^{\lambda^A}(x,y)-w_\varepsilon(x,y)\\
&=\frac{G(x,y)}{(2\pi)^2}(i\slashed{\partial}_x+m)\frac{1}{(y-x-i\varepsilon e_0)^2}\\
&+\frac{G(x,y)}{2(2\pi)^2 (y-x-i\varepsilon e_0)^2}\left( \slashed{A}(x)+\slashed{A}(y) -2 \int_0^1 ds \slashed{A}(sx +(1-s)y) \right.\\
&\left.+ (x-y)^\alpha \int_0^1 ds (1-2s)(\slashed{\partial}A)(sx + (1-s)y) \right)\\
&- \frac{1}{2(2\pi)^2} (-i\slashed{\nabla}+i\slashed{\nabla}^* -2m) V(x,y)\ln (-(y-x-i\varepsilon e_0)^2)\\
&-R_\varepsilon(x,y).
\end{align*}

Now the terms involving 
\(G(x,y)=e^{-i (x-y)^\alpha\int_0^1 ds A_\alpha (x s + (1-s)y)}\) 
can be summarised

\begin{align*}
&\frac{G(x,y)}{(2\pi)^2}(i\slashed{\partial}_x+m)\frac{1}{(y-x-i\varepsilon e_0)^2}\\
&+\frac{G(x,y)}{2(2\pi)^2 (y-x-i\varepsilon e_0)^2}\left( \slashed{A}(x)+\slashed{A}(y) -2 \int_0^1 ds \slashed{A}(sx +(1-s)y) \right.\\
&\left.+ (x-y)^\alpha \int_0^1 ds (1-2s)(\slashed{\partial}A)(sx + (1-s)y) \right)\\
&=\frac{1}{2(2\pi)^2 }(i\slashed{\nabla}-i\slashed{\nabla}^*+2m) \frac{G(x,y)}{(y-x-i\varepsilon e_0)^2},
\end{align*}

so overall we find

\begin{align*}
&p_\varepsilon^{\lambda^A}(x,y)-w_\varepsilon(x,y)=\\
&\frac{-1}{2(2\pi)^2 }(-i\slashed{\nabla}+i\slashed{\nabla}^*-2m) \frac{G(x,y)}{(y-x-i\varepsilon e_0)^2}\\
&- \frac{1}{2(2\pi)^2} (-i\slashed{\nabla}+i\slashed{\nabla}^* -2m) V(x,y)\ln (-(y-x-i\varepsilon e_0)^2)\\
&-R_\varepsilon(x,y).
\end{align*}

Because the term in the last line is smooth, this means that indeed \(p_\varepsilon^{\lambda^A}(x,y)-w_\varepsilon(x,y)\) is the integration kernel of a Hadamard state.

Furthermore, for a given Cauchy surface \(\Sigma\) the function \(w_\varepsilon-R_\varepsilon\) has a limit in the sense of \(L^2_{\text{loc}}(\Sigma\times\Sigma)\),
because of
Lebesgue dominated convergence and
lemmata \ref{lem:bound,worstterm}, \ref{lem:bound,ivp2} and 
\ref{lem:log term}. That the term \(R_\varepsilon|_{\Sigma\times\Sigma}\) 
has a smooth pointwise limit follows from lemma \ref{lem:pointwise}.
Finally outside of the diagonal \(\{(x,x)\mid x\in \Sigma\}\)
 \(w_\varepsilon\) is smooth also in the limit
\(\varepsilon\rightarrow 0\). Since the set \(J_3\) has 
a positive distance form the diagonal we may pick a function 
\(\mathfrak{R}_\varepsilon\in C^\infty(\Sigma\times\Sigma\rightarrow \mathbb{C}^{4\times 4})\)
such that 
\(\mathfrak{R}_\varepsilon|_{J_3^c}=w_{\varepsilon}-R_{\varepsilon}\). 
Since \(J_3\) is of 
finite measure we then have 
\begin{equation}
  w_\varepsilon = \overbrace{w_\varepsilon-R_{\varepsilon}-\mathfrak{R}_\varepsilon}^{\exists L^2-\lim } + \overbrace{R_{\varepsilon}+ \mathfrak{R}_\varepsilon}^{\exists \text{pointwise-}\lim \in C^\infty}.
\end{equation}

\end{proof}


%\chapter{Bibliography concerning the state of the art, the research objectives, and the work program} 
%\vspace*{-0.68cm}

%\begingroup
%\renewcommand{\section}[2]{}
\nocite{*}

\backmatter
\appendix

\bibliographystyle{plain}
\bibliography{ref}


\newpage 

\begin{center}
  \textbf{{\large Eidestattliche Versicherung}}\\
  (siehe Promotionsordnung vom 29. September 2016)
\end{center}
Hiermit erkläre ich an Eides statt, dass die Dissertation von mir selbstständig
ohne unerlaubte Beihilfe angefertigt wurde.

Die Abschnitte \ref{sec: multitime overview} und \ref{sec: intro QED} 
fassen Ergebnisse anderer Autoren zusammen um 
einen in sich geschlossenen Einstieg 
in das Thema zu ermöglichen.


Die Abschnitte \ref{sec:KG lightcones} und \ref{sec:direct dirac}
enthalten Resultate welche mit Matthias Lienert in Zusammenarbeit 
entstanden und zur Veröffentlichung eingereicht sind. 
Diese Resultate sind aus gemeinschaftlicher 
Arbeit entstanden und können den Autoren nicht einzeln zugeordnet werden.


%Die Ergebnisse des Abschnitts \ref{chapter geometery} enstanden 
%aus Zusammenarbeit mit meinen beiden Betreuern Dirk Deckert 
%und Franz Merkl. 

%Der Abschnitt \ref{sec: hadamard} 
%entstand in Kooperation mit Dirk Deckert.

%Welchen Umfang mein Beitrag zu diesen Abschnitten hat 
%lässt sich nicht quantifizieren.

\end{document}

