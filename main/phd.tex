%\documentclass[oneside,reqno,12pt]{amsart}





\documentclass[b5paper,draft,openbib,12pt]{memoir} 
%\documentclass[b5paper,openbib,12pt]{memoir} 



\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{bbm}
\usepackage{graphicx}
\usepackage{slashed}
\usepackage{eurosym}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathabx}
\usepackage{enumitem}
\usepackage{longtable}
\usepackage[mathscr]{eucal}


%commutative diagram
\usepackage{amsmath,amscd}
%picture
\usepackage{wrapfig}

\usepackage[unicode=true, pdfusetitle, bookmarks=true,
  bookmarksnumbered=false, bookmarksopen=false, breaklinks=true, 
  pdfborder={0 0 0}, backref=false, colorlinks=true, linkcolor=blue,
  citecolor=blue, urlcolor=blue]{hyperref}
\hypersetup{final}
%needed to have hyperlinks in draft mode


% \numberwithin{equation}{section}
\allowdisplaybreaks[1]

\newtheorem{axiom}{Axiom}
\newtheorem{Def}{Definition}[section]
\newtheorem{Conj}[Def]{Conjecture}
\newtheorem{Thm}[Def]{Theorem}
\newtheorem{Prp}[Def]{Proposition}
\newtheorem{Lemma}[Def]{Lemma}
\newtheorem{Remark}[Def]{Remark}
\newtheorem{Corollary}[Def]{Corollary}
\newtheorem{Example}[Def]{Example}
\newtheorem{Assumption}[Def]{Assumption}


\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\dotCup}{\mathop{\dot{\bigcup}}}
\DeclareMathOperator{\dotcup}{\mathop{\dot{\cup}}}


\newcommand{\id}{{\mathbbm 1}}
\newcommand{\equaltext}[1]{\ensuremath{\stackrel{\text{#1}}{=}}}
\newcommand{\letext}[1]{\ensuremath{\stackrel{\text{#1}}{\le}}}
\newcommand{\Conv}{\mathop{\scalebox{1.7}{\raisebox{-0.2ex}{\(\ast\)}}}}
\newcommand{\CONV}{\mathop{\scalebox{3.0}{\raisebox{-0.2ex}{\(\ast\)}}}}

% Annotations
\usepackage[colorinlistoftodos,shadow,textsize=scriptsize,textwidth=2.75cm]{todonotes}
\newcommand{\noch}[1]{ \todo[color=blue!20]{Todo: #1} }
\newcommand{\black}{ \color{black} }


\renewcommand\chapterheadstart{
\vspace *{\beforechapskip}
\hrulefill
\vskip 0pt
}

\renewcommand\afterchaptertitle{%
\vskip 0pt
\hrulefill
\par \nobreak  \vskip  \afterchapskip  } 


\setsecnumdepth{all}


%all divisions are numbered in the text body

\parindent 0cm

\begin{document}



\frontmatter
%
%\noindent
%\begin{center}
%    \textsc{ \small{Description of the dissertation project of Markus Nöth,
%        Ludwig-Maximilians University of Munich} \\
%        \smallskip
%\large{ Electron-Positron Pair Creation in External Fields} \\
%\small{Rigorous Control of the Scattering-Matrix Expansion}}
%    \vskip.3cm
%    \small
% supervisor:    D.-A.\ Deckert (LMU)
% \vskip0.4cm
\title{Electron-Positron Pair Creation in External~Fields}
%\subtitle{\footnotesize{Rigorous Control of the Scattering-Matrix Expansion}}
\author{M. Nöth}
\maketitle

 \begin{abstract}
 In this project we investigate the phenomenon of creation of matter-antimatter
pairs of particles, more precisely electron-positron pairs, out of the vacuum
subject to strong external electromagnetic fields. 
Although this phenomenon was predicted already in 1929 and was
observed in many experiments, its rigorous
mathematical description still lies
at the frontier of human understanding of nature. 
Dirac introduced the heuristic description of the vacuum of quantum electrodynamics (QED) as a homogeneous sea of particles. Although the picture of pair creation as lifting a particle out of the Dirac sea, leaving a hole in the sea, is very
explanatory the mathematical formulation of the time evolution of the Dirac sea
faces many mathematical challenges. 
A straightforward interaction of sea particles and the radiation field is ill-defined and physically important
quantities such as the total charge current density are badly divergent due to the
infinitely many occupied states in the sea. 
Nevertheless, in the last century physicists and mathematicians
 have developed strong methods called
``perturbative renormalisation theory'' that allow at least to treat the
scattering regime perturbatively. 
Non-perturbative methods have to be developed in order to give an adequate theoretical description of upcoming next-generation experiments allowing a study of the time evolution.
Our endeavour focuses on the so-called \emph{external
field model of QED} in which one neglects the interaction between the sea
particles and only allows an interaction with a prescribed electromagnetic field.
It is the goal of this project to develop the necessary non-perturbative
methods in this model to give a rigorous construction of the scattering
and the time evolution operator. 
\\
\smallskip
\noindent \textbf{Keywords:} Second Quantised Dirac Equation, non-perturbative QED, external-field QED, Scattering Operator
 \end{abstract}


%\vskip.5cm
%\thispagestyle{empty}


\tableofcontents

\newpage



\mainmatter

\chapter{Introduction}

%\show\afterchaptertitle
\noch{Historische Einleitung durch Anfänge relativistischer Quantenphysik, Strahlungskatastrophe (unbounded below). No potentials resultat Lukas}



\chapter[Direct Interaction in Relativistic Quantum Mechanics][Direct Interaction]{Direct Interaction in Relativistic Quantum Mechanics}
As we have seen in the last chapter, having interaction mediated by potentials in a Dirac equation does not seem to be a viable option.
One alternative approach to this problem is to reformulate Diracs equation as an integral equation and to introduce interaction
afterwards. For the benefit of the unfamiliar reader, we will first follow the heuristic derivation of this type of equation
 in \cite{lienert2018direct}, then briefly review the mathematical results that had been established in the past and finally 
 discuss new results for which the author is at least partially to blame.

\section{Overview}
\subsection{Derivation}
\noch{Check whether copying from \cite{lienert2018direct} like this is fine.}
\newcommand{\free}{{\textup free}}
\newcommand{\ret}{{\textup ret}}
\newcommand{\adv}{{\textup adv}}
\newcommand{\sym}{{\textup sym}}
\newcommand{\vx}{{\mathbf{x}} }
\newcommand{\vy}{{\mathbf{y}} }

We now follow the heuristic derivation of \cite{lienert2018direct} 
for the two-particle equation for a multi-time wave function 
that expresses direct interaction along light-like configurations proposed in that article. 
This type of equation will then keep us occupied for the rest of this chapter. 
To this end, we start from a reformulation of the single-particle  Schr{\"o}dinger equation as an integral equation. 
Extending this equation to the two-particle case with Poincar\'{e} invariance in mind naturally leads to an 
integral equation for a multi-time wave function.

Consider the single-particle  Schr{\"o}dinger equation for the wave function $\varphi(t,\vx)$:
\begin{equation}
	i \partial_t \varphi(t,\vx) = \big( H^\free + V(t,\vx) \big) \varphi(t,\vx),
	\label{eq:singlepartschroed}
\end{equation}
where $H^\free$ denotes the free Hamiltonian, for example $H^\free = -\frac{1}{2m}\Delta$ or $H^\free = H^{\textup Dirac}$.\\
Let $G^\ret(t,\vx)$ be the retarded Green's function of the free  Schr{\"o}dinger equation, i.e.
\begin{equation}
	\big( i \partial_t - H^\free \big) G^\ret(t,\vx) = \delta(t) \delta^{(3)}(\vx)
	\label{eq:schroedgreensfn}
\end{equation}
with $G^\ret(t,\vx) = 0$ for $t< t_0$.
Then the initial value problem consisting of \eqref{eq:singlepartschroed} for $t\geq t_0$ with $\varphi(t_0,\vx) = \varphi_0(\vx)$ is equivalent to the integral equation (see \cite{feynman1949theory})
\begin{equation}
	\varphi(t,\vx) = \varphi^\free(t,\vx) + \int_{t_0}^\infty \! dt' \int d^3 \vx' \, G^\ret(t-t',\vx-\vx') V(t',\vx') \varphi(t',\vx'),
	\label{eq:singlepartint}
\end{equation}
where $\varphi^\free(t,\vx) = [e^{-i H^\free (t-t_0)} \varphi_0](\vx)$ is the respective solution of the free  Schr{\"o}dinger equation. The time integral in \eqref{eq:singlepartint} effectively only runs up to $t$ as $G^\ret(t-t',\vx-\vx') = 0$ for $t < t'$. One can easily check that a solution of \eqref{eq:singlepartint} satisfies \eqref{eq:singlepartschroed} by acting with $(i \partial_t - H^\free)$ on both sides of \eqref{eq:singlepartint} and using the Green's function property \eqref{eq:schroedgreensfn}. The initial conditions are satisfied as for $t=t_0$ the integral vanishes and $\varphi(t_0,\vx) = \varphi^\free(t_0,\vx) = \varphi_0(\vx)$. Conversely, we obtain \eqref{eq:singlepartint} from \eqref{eq:singlepartschroed} by inverting the operator $(i \partial_t - H^\free)$.
Note that the reformulation is exact (non-perturbative).

For two non-relativistic particles, one can proceed analogously.\footnote{In fact, this case is mathematically equivalent to the case of a single particle in 6 space dimensions.} The initial value problem $\varphi(t_0,\vx_1,\vx_2) = \varphi_0(\vx_1,\vx_2)$ of the  Schr{\"o}dinger equation
\begin{equation}
	i \partial_t \varphi(t,\vx_1,\vx_2) = \big(H_1^\free + H_2^\free + V(t,\vx_1,\vx_2)\big) \varphi(t,\vx_1,\vx_2)
	\label{eq:twopartschroed}
\end{equation}
for $t \geq t_0$ is equivalent to the integral equation
\begin{align}
	\varphi(t,\vx_1,\vx_2) = \varphi^\free&(t,\vx_1,\vx_2) + \int_{t_0}^\infty \! dt' \! \int d^3 \vx_1'\,  d^3 \vx_2'\, G_1^\ret(t-t',\vx_1-\vx_1') \nonumber\\
	\times&G_2^\ret(t-t',\vx_2-\vx_2') V(t',\vx_1',\vx_2') \varphi(t',\vx_1',\vx_2'),
	\label{eq:twopartschroedint}
\end{align}
where $\varphi^\free(t,\vx_1,\vx_2) = [e^{-i(H_1^\free + H_2^\free)(t-t_0)}\varphi_0](\vx_1,\vx_2)$ and $G_k^\ret(t,\vx_k)$ are the retarded Green's functions of the operators $(i\partial_t - H_k^\free)$. Note that the synchronized product $G_1^\ret(t,\vx_1) G_2^\ret(t,\vx_2)$ is the retarded Green's function of the operator $(i\partial_t - H_1^\free - H_2^\free)$.

While \eqref{eq:twopartschroedint} constitutes a viable equation for non-relativistic quantum physics, it is clearly not Lorentz invariant as it makes use of just a single time variable. Let us therefore pause and reconsider the step from the single-particle to the two-particle integral equation.\\
As we aim at a manifestly Poincar\'{e} invariant equation, it is helpful rewrite the single-particle integral equation \eqref{eq:singlepartint} in terms of spacetime variables:
\begin{equation}
	\psi(x) = \psi^\free(x) + \int d^4 x' \, G^\ret(x-x') V(x') \psi(x'),
	\label{eq:singlepartintspacetime}
\end{equation}
where we wrote $\psi$ instead of $\varphi$. In order to obtain a Poincar\'{e} invariant domain of integration, we take the initial time $t_0$ to $-\infty$. Note that the limits of the time integration as well as the choice of the Green's function mainly play a role for the initial value problem. A solution of the integral equation solves  Schr{\"o}dinger's equation regardless of these choices.

Now \eqref{eq:singlepartintspacetime} straightforwardly suggests a two-particle generalization in terms of a multi-time wave function:
\begin{align}\label{eq:twopartintgeneral}
  \psi(x_1,x_2) = &\psi^\free(x_1,x_2) \\\nonumber
  &+ \int d^4 x_1'\, d^4 x_2' \, G_1(x_1-x_1') G_2(x_2-x_2') K(x_1',x_2') \psi(x_1',x_2').
\end{align}
Here, the integration runs over $mathbb{RM} \times \mathbb{M}$ and $\psi^\free$ is (similarly to $\varphi^\free$ before) a given solution of the free multi-time equations. These are assumed to be covariant equations of the form
\begin{equation}
	D_k  \psi^\free(x_1,x_2) = 0,~~k=1,2,
	\label{eq:freemultitime}
\end{equation}
where $D_k$ is a first-order covariant differential operator, the main example being the Dirac operator $D_k = ( -i \gamma_k^\mu \partial_{k,\mu} + m_k)$.
Finally, $G_k(x_k)$ is a Green's function of the $k$-th free multi-time equation, i.e.
\begin{equation}
	D_k G_k(x_k) = \delta^{(4)}(x_k).
\end{equation}
In the following, we use the notation $G$ for a generic Green's functions of some covariant operator. If we want to be more specific which case we are considering, we indicate this by introducing new symbols or indices.
Apart from retarded Green's functions, which are expected to be relevant to the past initial value problem, we also allow for different choices such as advanced, time-symmetric and Feynman Green's functions here. Note that \eqref{eq:twopartintgeneral} is only manifestly time reversal invariant if the Green's functions are.

$K(x_1,x_2)$ is an, as yet, arbitrary function (or distribution) which we call the \textit{interaction kernel}. $K$ deserves this name as it occurs in the same place in \eqref{eq:twopartintgeneral} as the interaction potential in \eqref{eq:twopartschroedint}. As we aim at a Poincar\'{e} invariant equation, $K$ must be a Poincar\'{e} invariant function of $x_1,x_2$. Perhaps the most natural possibility is that $K$ depends on $x_1,x_2$ only through the Minkowski distance $s^2(x_1,x_2) = (x_1-x_2)^\mu (x_1-x_2)_\mu$. Stipulating that interaction happens exactly at light-like separation, we are led to
\begin{equation}
	K(x_1,x_2) = \kappa \; \delta(s^2(x_1,x_2)),
	\label{eq:twopartkernel}
\end{equation}
where $\kappa$ is a Poincar\'{e} invariant prefactor that may include coupling constants such as charges $e_1,e_2$ and $\gamma$-matrices. If $\gamma$-matrices are admitted, $\kappa$ can be non-constant, as then Poincar\'{e} invariant quantities besides $s^2(x_1,x_2)$ exist. For example, $\kappa$ could depend on $\gamma_i^\mu (x_1-x_2)_\mu$ for $i=1,2$. 

Thus, we arrive at the following class of integral equations:
\begin{align}\label{eq:twopartint}
  \psi&(x_1,x_2) = \psi^\free(x_1,x_2) \\\nonumber
  &+ \int d^4 x_1' \, d^4 x_2' \; G_1(x_1-x_1') G_2(x_2-x_2') \, \kappa \, \delta(s^2(x_1',x_2')) \psi(x_1',x_2').
\end{align}
The equation becomes fully specified by the choices of (a) the free multi-time equations \eqref{eq:freemultitime}, (b) the particular Green's functions of these equations, and (c) the prefactor $\kappa$.

\subsubsection{Examples.}
\begin{enumerate}
  \item \textit{Dirac particles.} In this case, the Green's functions are commonly denoted by $S^\ret$, $S^\sym$, $S_F$ etc. 
  In view of time-reversal invariance, the most natural choice is the symmetric Green's function  
  $S^\sym(x) = \frac{1}{2}( S^\ret(x)+S^\adv(x)$. Also the Feynman propagator $S_F$ is time-symmetric. A natural choice for $\kappa$ turns out to be:
	\begin{equation}
		\kappa = i\, \lambda \, \gamma_1^\mu \gamma_{2,\mu},
		\label{eq:naturalkappa}
  \end{equation}
  where $\lambda$ is a positive constant. Later, we shall see $\lambda = \frac{e_1e_2}{4\pi}$ where $e_1, e_2$ are 
  the charges of the particles. The factor $i$ is necessary to obtain the correct non-relativistic limit 
  (see Sec. \cite[3.6]{lienert2018direct}). Then \eqref{eq:twopartint} becomes (we here admit generic Green's functions):
	\begin{align}\label{eq:twopartintspin}
    &\psi(x_1,x_2) = \psi^\free(x_1,x_2)+i\lambda \! \int \! d^4 x_1' \, d^4 x_2' \, \\\nonumber
    & \times S_1(x_1-x_1') S_2(x_2-x_2') \gamma_1^\mu \gamma_{2,\mu} \delta(s^2(x_1',x_2')) \psi(x_1',x_2').
  \end{align}
  Section \ref{sec:direct dirac} will be about first results concerning Dirac particles.
	%
  \item \textit{KG particles.} Even though we have motivated \eqref{eq:twopartint} for cases where the 
  free multi-time equations are of first order, it is possible to consider \eqref{eq:twopartint} also for the case 
  that free multi-time equations are KG equations (which are of second order). In this case, 
  $\kappa \in \mathbb{R}$ and one uses the Green's functions of the KG equation instead of $G_1,G_2$ .
  All of the previously established results concern this case. In section \ref{sec:KG lightcones} we present a novel result, 
  incorporating the full singular interaction Kernel \(K=i\kappa\delta(s^2(x_1,x_2))\).
  \noch{check consistency of naming of the constant factors}
\end{enumerate}


\subsection{Previous Results on Directly Interacting Particles}
In this chapter we summarise existence results on equations of the type of 
\eqref{eq:twopartintgeneral}. Because this line of work is still fairely young,
it can still readily be summarised. The results are taken from \cite{lienertfirst} and 
\cite{lienertcurved}. The theorems are about slightly different versions of equations
of the type of \eqref{eq:twopartintgeneral} or of a related type and make use of
different function spaces. I tried to contain the necessary notation to within each
of the theorems. 

\begin{Thm}[Thm 3.1 of \cite{lienertfirst}]
Let \(T>0\), \(M,N\in\mathbb{N}\), consider 
the Banach space \(\mathcal{B}=L^\infty ([0,T]^N,L^2(\mathbb{R}^M))\).
Let \(\mathcal{L}:[0,T]^{2N}\rightarrow L^2(\mathbb{R}^{2M})\) such that 
\begin{equation*}
\sup_{t,t'\in[0,T]^{N}}\|\mathcal{L}(t,t')\|^2<\infty,
\end{equation*}
then for any \(f_0\in\mathcal{B}\) the equation
\begin{equation*}
f(t,x)=f_0(t,x)+ \int_0^t dt' \int dx' L(t,t',x,x') f(t',x')
\end{equation*}
has a unique solution \(f\in\mathcal{B}\).
\end{Thm}

\begin{Thm}[Thm 3.2 \((d=1)\) of \cite{lienertfirst}]
Let \(T>0, \lambda\in\mathbb{C}, m_1,m_2\ge 0\), every
\begin{equation*}
\psi^\free \in \mathcal{B}_1=L^\infty ([0,T]^2,L^2(\mathbb{R}^2)),
\end{equation*}
and every essentially bounded \(K:\mathbb{R}^4\rightarrow \mathbb{C}\), the integral equation 
\begin{align*}
\psi(t_1,z_1,t_2,z_2)=\psi^\free(t_1,z_1,t_2,z_2)+\frac{\lambda}{4}\int_0^{t_1}dt_1'\int_0^{t_2}dt_2'\int dz_1'dz_2'\\
 \times H(t_1-t_1'-|z_1-z_1'|) J_0(m_1\sqrt{(t_1-t_1')^2-|z_1-z_1'|^2})\\
 \times H(t_2-t_2'-|z_2-z_2'|) J_0(m_2\sqrt{(t_2-t_2')^2-|z_2-z_2'|^2})\\
  \times K(t_1',z_1',t_2',z_2')\psi(t_1',z_1',t_2',z_2')
\end{align*}
has a unique solution \(\psi \in \mathcal{B}_1\).
\end{Thm}

\begin{Thm}[Thm 3.3 \((d=2)\) of \cite{lienertfirst}]
Let \(T>0, \lambda\in\mathbb{C}, m_1,m_2\ge 0\), for every essentially bounded \(K:\mathbb{R}^6\rightarrow\mathbb{C}\)
and every \(\psi^\free \in \mathcal{B}_2=L^\infty([0,T]^2,L^2(\mathbb{R}^4))\) the equation
\begin{align*}
&\psi(t_1,\vx_1,t_2,\vx_2)=\psi^\free(t_1,\vx_1,t_2,\vx_2)+\frac{\lambda}{(2\pi)^2}\int_0^{t_1}dt_1'\int_0^{t_2}dt_2'\\
&\times\int d^2\vx_1'd^2\vx_2' H(t_1-t_1'-|\vx_1-\vx_1'|)\frac{\cos(m_1\sqrt{(t_1-t_1')^2-|\vx_1-\vx_1'|^2})}{\sqrt{(t_1-t_1')^2-|\vx_1-\vx_1'|^2}}\\
&\quad \times H(t_2-t_2'-|\vx_2-\vx_2'|)\frac{\cos(m_2\sqrt{(t_2-t_2')^2-|\vx_2-\vx_2'|^2})}{\sqrt{(t_2-t_2')^2-|\vx_2-\vx_2'|^2}} \\
&\quad \quad\quad \quad \times K(t_1',\vx_1',t_2',\vx_2')\psi(t_1',\vx_1',t_2',\vx_2')
\end{align*}
has a unique solution \(\psi \in \mathcal{B}_2\).
\end{Thm}

\begin{Thm}[Thm 3.4 \((d=3)\) of \cite{lienertfirst}]
Let \(T>0, \lambda\in\mathbb{C}\), for every bounded \(K:\mathbb{R}^8\rightarrow\mathbb{C}\) and every
\(\psi^\free \in\mathcal{B}_3=L^\infty([0,T]^2,L^2(\mathbb{R}^6))\)
the equation 

\begin{align*}
&\psi(t_1,\vx_1,t_2,\vx_2)=\psi^\free(t_1,\vx_1,t_2,\vx_2)+\frac{\lambda}{(4\pi)^2}\int d\vx_1' d\vx_2'\\
&\times \frac{H(t_1-|\vx_1-\vx_1'|)}{|\vx_1-\vx_1'|}\frac{H(t_2-|\vx_2-\vx_2'|)}{|\vx_2-\vx_2'|}K(t_1-|\vx_1-\vx_1'|,\vx_1',t_2-|\vx_2-\vx_2'|,\vx_2')\\
&\quad\quad\quad\quad \times\psi(t_1-|\vx_1-\vx_1'|,\vx_1',t_2-|\vx_2-\vx_2'|,\vx_2')
\end{align*}
has a unique solution \(\psi\in\mathcal{B}_3\).
\end{Thm}

\begin{Thm}[Thm 3.5 of \cite{lienertfirst}]
  Let \(T>0, \lambda\in\mathbb{C}\), for every bounded \(f:\mathbb{R}^8\rightarrow \mathbb{C}\) and every \(\psi^\free \in \mathcal{B}_3\) the equation
\begin{align*}
&\psi(t_1,\vx_1,t_2,\vx_2)=\psi^\free(t_1,\vx_1,t_2,\vx_2) + \frac{\lambda}{(4\pi)^2}\int d^3\vx_1'd^3\vx_2'\\
& \times \frac{H(t_1-|\vx_1-\vx_1'|)}{|\vx_1-\vx_1'|} \frac{H(t_2-|\vx_2-\vx_2'|)}{|\vx_2-\vx_2'|} \frac{f(t_1-|\vx_1-\vx_1'|,\vx_1',t_2-|\vx_2-\vx_2'|,\vx_2')}{|\vx_1'-\vx_1|}\\
&\quad \quad \quad \times \psi(t_1-|\vx_1-\vx_1'|,\vx_1',t_2-|\vx_2-\vx_2'|,\vx_2'),
\end{align*}
has a unique solution \(\psi\in\mathcal{B}_3\).
\end{Thm}





\section{Directly Interacting Dirac Particles}\label{sec:direct dirac}

\section{KG-Particles Interacting Directly Along Lightcones}\label{sec:KG lightcones}


\chapter[Quantum Field Theoretic Approach to Interactions][Interaction in QFT]{Quantum Field Theoretic Approach to Interactions} \label{sec:QFT}

\noch{quick introduction into Hadamard stuff and Dirk \& Franz stuff, erwähne Ruijsnaars stuff}

In order to be able to state our main conjecture \eqref{main_result} precisely
I will need to introduce the one-particle dynamics for electrons and their
scattering operator, see section \ref{sec:one-particle} below, and then move on
to the second quantised dynamics and its corresponding scattering operator  in
section \ref{sec:second quant}. Second quantization is the canonical
method of turning a one-particle theory into one of an arbitrary and
possibly changing number of particles. The informal
series expansion of the one-particle scattering operator \(U\) is derived 
from Dirac's equation of motion for the electron. In section
 \ref{sec:well-def} the convergence of this
expansion is shown. The informal expansion of the second quantized
scattering operator $S$ is then derived from $U$ by second quantisation in
section \ref{sec:second quant}. At this point I have gathered enough tools to present the main conjecture \ref{main_result} in section \ref{sec:main result}. 
After the main conjecture is known, I present several of my own results in sections \ref{sec: odd orders}, \ref{sec: first order} and \ref{sec: second order} about the first order, the second order and all other odd orders. 
These results give an intuition on how to control the convergence of the informal expansion of the scattering operator \(S\).



\section{Defining One-Particle Scattering-Matrix}\label{sec:one-particle}


%The goal of this and the next section is to introduce some results, which are
%known to the community and form the basis of my work. 
In order to introduce the one-particle dynamics I introduce Diracs equation \eqref{dirac} and reformulate it in integral form in equation \eqref{dirac_integral}. By iterating this equation we will naturally be led to the informal series expansion of the scattering operator equation \eqref{DefU}, whose convergence is discussed in the next section. 
%\Dirk{ordne es anders: wir wollen $S$, dazu Zeitentwicklung $U$, dazu Dirac
%Gleichung, Integralversion, formale Iteration, Konvergenz}
%\Markus{So? Oder wolltest du, dass ich auch die Mathematik umordne?} Gut so.

Throughout this thesis I will consider four-potentials $A, F$ or \(G\) to be smooth functions
in \(C_{c}^\infty(\mathbb{R}^4)\otimes \mathbb{C}^4\), where the index \(c\)
denotes that the elements have compact support. The Dirac
equation for a wave function \(\phi \in L^2(\mathbb{R}^3)\otimes \mathbb{C}^4\)
is
\begin{equation}\label{dirac}
0= (i\slashed{\partial}-e\slashed{A}-m \id) \phi,
\end{equation}
where \(m\) is the mass of the electron, \(\id: \mathbb{C}^4\rightarrow \mathbb{C}^4\) is the identity  and crossed out letters mean that their four-index is contracted with Dirac matrices
\begin{equation}
\slashed{A}:= A_\alpha \gamma^\alpha,
\end{equation}
where Einstein's summation convention is used. These matrices fulfil the anti-commutation relation
\begin{equation}
\forall \alpha, \beta \in \{0,1,2,3\}:\{\gamma^\alpha, \gamma^\beta\}:= \gamma^\alpha \gamma^\beta+ \gamma^\beta \gamma^\alpha= g^{\alpha \beta},
\end{equation}
where \(g\) is the Minkowski metric. I work with the \(+---\) metric signature and the Dirac representation of this algebra. Squared four dimensional objects always refer to the Minkowski square, meaning for all \(a\in \mathbb{C}^4\), \(a^2:= a^{\alpha} a_{\alpha}\). 

In order to define Lorentz invariant measures for four dimensional integrals I employ the same notation as in \cite{ivp1}. The standard volume form over \(\mathbb{R}^4\) is denoted by \(\mathrm{d}^4 x= \mathrm{d}x^0 \mathrm{d}x^1\mathrm{d}x^2 \mathrm{d}x^3\), the product of forms is understood as the wedge product. The symbol \(\mathrm{d}^3x\)  means the 3-form \(\mathrm{d}^3x= \mathrm{d}x^1\mathrm{d}x^2\mathrm{d}x^3\) on \(\mathbb{R}^4\). Contraction of a form \(\omega\) with a vector \(v\) is denoted by \(\mathfrak{i}_v(\omega)\). The notation \(\mathfrak{i}_v (\omega)\) is also used for the spinor matrix valued vector \(\gamma=(\gamma^0,\gamma^1,\gamma^2,\gamma^3)=\gamma^\alpha e_\alpha\):
\begin{equation}
\mathfrak{i}_\gamma (\mathrm{d}^4x) := \gamma^\alpha \mathfrak{i}_{e_\alpha}(\mathrm{d}^4 x),
\end{equation} 

with \((e_\alpha)_{\alpha}\) being the canonical basis of \(\mathbb{C}^4\). Let \(\mathcal{C}_A\) be the space of solutions to \eqref{dirac} which have compact support on any spacelike hyperplane \(\Sigma\). Let \(\phi, \psi\) be in \(\mathcal{C_A}\), the scalar product \(\langle \cdot, \cdot\rangle\) of elements of \(\mathcal{C}_A\) is defined as

\begin{equation}
\langle \phi, \psi \rangle := \int_{\Sigma} \overline{\phi (x)} \mathfrak{i}_{\gamma} (\mathrm{d}^4x) \psi (x)=: \int_{\Sigma} \phi^\dagger (x) \gamma^0 \mathfrak{i}_{\gamma} (\mathrm{d}^4x) \psi (x) .
\end{equation}
Furthermore define \(\mathcal{H}\) to be \(\mathcal{H}:=\overline{\mathcal{C}_A}^{\langle \cdot, \cdot \rangle}\). The mas-shell \(\mathcal{M}\subset \mathbb{R}^4\) is given by
\begin{equation}
\mathcal{M}=\{p\in \mathbb{R}^4\mid p^2=m^2\}.
\end{equation}
The subset \(\mathcal{M}^+\) of \(\mathcal{M}\) is defined to be \(\mathcal{M}^+:=\{p\in\mathcal{M}\mid p^0>0\}\). The image  of \(\mathcal{H}\) by the projector \(1_{\mathcal{M^+}}\), given in momentum space representation, is denoted by \(\mathcal{H}^+\) and its orthogonal complement by \(\mathcal{H}^-\). 
I introduce a family of Cauchy hypersurfaces \((\Sigma_t)_{t\in\mathbb{R}}\) governed by a family of normal vector fields \((\left.v_t n\right|_{\Sigma_t})\), where \(n: \mathbb{R}^4 \times \mathbb{R} \rightarrow \mathbb{R}^4\) and \(v: \mathbb{R}^4 \times \mathbb{R} \rightarrow \mathbb{R}\) are smooth functions. For \(x\in\Sigma_t\) the vector \(n_t(x)\) denotes the future directed unit-normal vector to \(\Sigma_t\) at \(x\) and \(v_t(x)\) the corresponding normal velocity of the flow of the Cauchy surfaces. 

Now we have the tools to recast the Dirac equation into an integral version
which will allow me to define the scattering operator. 
Let \(\psi \in \mathcal{C}_A\), for any \(t\in\mathbb{R}\) I denote by \(\phi_t\) the solution to the free Dirac equation, that is equation \eqref{dirac} with \(A=0\), with \(\left.\psi\right|_{\Sigma_t}\) as initial condition on \(\Sigma_t\). Let \(t_0\in\mathbb{R}\) have some fixed value, equation \eqref{dirac} can be reformulated, c.f. theorem 2.23 of \cite{ivp1}, as
\begin{multline}\label{dirac_integral}
\phi_t(y)=\phi_{t_0}(y)
-i \int_{t_0}^t \text{d}s \int_{\Sigma_s}\int_{\mathcal{M}}\frac{\slashed{p}+m}{2m^2}e^{ip(x-y)}\mathfrak{i}_p(\text{d}^4p) \frac{\mathfrak{i}_{\gamma}(\text{d}^4x)}{(2\pi)^{3}}\\
v_s(x)\slashed{n}_s(x) \slashed{A}(x)\phi_s(x),
\end{multline}
which holds for any \(t\in\mathbb{R}\). Employing the following rewriting of integrals

\begin{equation}
\int_{\mathcal{M}}\frac{\slashed{p}+m}{2 m^2} f(p) \mathfrak{i}_p(\text{d}^4p)=\frac{1}{2\pi i}   \left( \int_{\mathbb{R}^4-i \epsilon e_0}-\int_{\mathbb{R}^4+i \epsilon e_0} \right) (\slashed{p}-m)^{-1} f(p)  \text{d}^4p,
\end{equation}
which is due to the theorem of residues, equation \eqref{dirac_integral} assumes the form

\begin{multline}
\phi_t(y)=\phi_{t_0}(y)
- \int_{[t_0,t]\times\mathbb{R}^3}  \left( \int_{\mathbb{R}^4-i \epsilon e_0}-\int_{\mathbb{R}^4+i \epsilon e_0} \right)\\
 (\slashed{p}-m)^{-1} e^{ip(x-y)}  \text{d}^4p  \frac{\text{d}^4x}{(2\pi)^{4}}\slashed{A}(x)\phi_s(x). 
\end{multline} 
In the last expression I picked all hypersurfaces \(\Sigma_s\) to be equal time
hyperplanes such that \(v_s=1\) and \(\slashed{n}_s=\gamma^0 e_0\). We identify
the advanced and retarded Greens functions of the Dirac equation:
\begin{equation}
\Delta^\pm (x):= \frac{-1}{(2\pi)^4} \int_{\mathbb{R}^4\pm i \varepsilon e_0} \frac{\slashed{p}+ m}{p^2-m^2} e^{-ipx} d^4 p,
\end{equation}
yielding
\begin{multline}\label{dirac integral split}
\phi_t(y)=\phi_{t_0}(y)
+ \int_{[t_0,t]\times\mathbb{R}^3}  (\Delta^--\Delta^+)(y-x)  \text{d}^4x \slashed{A}(x)\phi_s(x). 
\end{multline} 

 Iteratingequation \eqref{dirac integral split} and picking \(t\) in the future of
\(\supp A\) and \(t_0\) in the past of it, denoting them by \(\pm \infty\) since 
their exact value is no longer important, the following series expansion is 
obtained informally

\begin{equation}\label{DefU}
\phi_\infty(y)=U^A \phi_{-\infty} :=\sum_{k=0}^\infty Z_k(A) \phi_{-\infty},
\end{equation} 
with \(Z_0=\id \), the identity on \(\mathbb{C}^4\), and where for arbitrary \(\phi\in \mathcal{H}\), \(Z_k \) is defined as
\begin{align*}
&Z_k(A)\phi(y):= \int_{\mathbb{R}^4}  (\Delta^--\Delta^+)(y-x_1)  \text{d}^4x_1 \slashed{A}(x_1) \\
&\prod_{l=2}^k \left[\int_{[-\infty,x^0_{l-1}]\times\mathbb{R}^3}  (\Delta^--\Delta^+)(x_{l-1}-x_l)   \slashed{A}(x_l)\text{d}^4x_l\right]
 \phi(x_k).
\end{align*}
Now since the integration variables are time ordered and \(\supp \Delta^\pm \subseteq \text{Cau}^\pm\) 
in every one but the first factor the contribution of \(\Delta^-\) vanishes. Therefore we can simply \noch{führe Cau als kausale Menge ein}
drop it. Furthermore we may continue the integration domain to all of \(\mathbb{R}^4\), since
there \(\Delta^+\) gives no contribution, giving
\begin{multline}\label{Z_kDelta}
Z_k(A)\phi(y)= (-1)^{k-1}\int_{\mathbb{R}^4}\text{d}^4x_1  (\Delta^--\Delta^+)(y-x_1)   \slashed{A}(x_1) \\
\prod_{l=2}^k \left[\int_{\mathbb{R}^4}\text{d}^4x_l \Delta^+(x_{l-1}-x_l)   \slashed{A}(x_l)\right]
 \phi(x_k).
\end{multline}


 This is convenient, because we may now use the spacetime
integration with the exponential factor of the definition of \(\Delta^-\) as a Fourier transform
acting on the four-potentials and the wave function. 
Undoing the substitutions again for the first factor and executing the just mentioned Fourier
transforms using the convolution theorem inductively results in

\begin{multline}\label{explicit_Zk}
Z_k(A)\phi(y) =- i  \int_{\mathcal{M}}\frac{\mathfrak{i}_p(\text{d}^4p_1)}{(2\pi)^{3}} \frac{\slashed{p}_1+m}{2m} e^{-ip_1y}  \\
  \prod_{l=2}^{k} \left[ \int_{\mathbb{R}^4+i \epsilon e_0}\frac{\text{d}^4p_l}{(2\pi)^{4}} \slashed{A}(p_{l-1}-p_l)  (\slashed{p}_l-m)^{-1}  
 \right]\\
 \int_{\mathcal{M}}  \mathfrak{i}_p(\text{d}^4p_{k+1})\slashed{A}(p_{k}-p_{k+1})\hat{\phi}(p_{k+1}).
\end{multline}

Due to the representation \eqref{Z_kDelta} one may also represent \(Z_k\) in terms of The operators
\begin{align}
\Delta^0:= \Delta^+-\Delta^-\\
L_A^{\pm,0}:= \Delta^{\pm,0} \ast \slashed{A}
\end{align}
in this manner
\begin{equation}
Z_k(A)\phi(y)= (-1)^{k} L^0_A \left({L_A^+}^{k-1}( \phi)\right) (y),
\end{equation}
where the upper right index for an operator means iterative application of said operator.

\noch{delete derivation; simply state series representation and convergence result citing something}

\section{Construction of the Second Quantised Scattering-Matrix}\label{sec:second quant}
 In the following I outline how the construction of the
second quantised scattering operator is to be carried out, we will naturally be
led to an informal power series representation for the scattering operator \(S\). 

First I fix some more notation in agreement with \cite{ivp2}. Using a general Hilbertspace \(\mathcal{H}\) as a one-particle Hilbertspace. 
A closed subspace \(\mathcal{H}^+\) of \(\mathcal{H}\) is called polarisation if both \(\mathcal{H}^+\) and \(\mathcal{H}^-:=\left(\mathcal{H}^+\right)^\perp\)
are infinite dimensional, where by \(\perp\) I denote the orthogonal complement. With a polarisation \(\mathcal{H}^+\) comes also the orthogonal
projection operator \(P^+\) onto the subspace \(\mathcal{H}^+\) and its complement \(P^-=1-P^+\). For one particle operators \(C\) we 
introduce the notation \(C_{\#\ddag}:= P^\# C P^\ddag\), where \(\#,\ddag\in\{+,-\}\).
%\Dirk{am besten schon oben einführen}
One constructs the Fock space associated with \(\mathcal{H}\) and a polarisation \(\mathcal{H}^+\) of \(\mathcal{H}\) in the following way.
We define \(\overline{\mathcal{H}^-}\) identical with \(\mathcal{H}^-\) as a set, but scalar multiplication as 
\(\mathbb{C}\times \overline{\mathcal{H}} \ni (a, \psi)\mapsto \overline{a} \psi\) where the bar denotes complex conjugation of complex numbers.
A wedge \(\wedge\) in the exponent denotes that only elements which are antisymmetric with respect to permutations
are allowed. This antisymmetric product as well as the tensor product are to be understood in the Hilbert space sense. 
The Factor \(\left(\mathcal{H}^{\pm}\right)^0\) is understood as
\(\mathbb{C}\). We now define Fock space as

\begin{equation}
\mathcal{F}:=\bigoplus_{m,p=0}^\infty \left(\mathcal{H}^+ \right)^{\wedge m} \otimes \left(\overline{\mathcal{H}^- }\right)^{\wedge p}.
\end{equation}

I will denote the sectors of Fock space of fixed particle
numbers by \(\mathcal{F}_{m,p}\). The element of
\(\mathcal{F}_{0,0}\) of norm \(1\) will be denoted by \(\Omega\).
The simplest and yet interesting example of this construction is
the Fock space constructed on a hyperplane prior to the support of an external field,
in this case \(\mathcal{H}=L^2(\mathbb{R}^3,\mathbb{C}^4)\) and \(\mathcal{H}^+\)
consists of the wavefunctions that can be constructed from the generalised eigenfunctions
of positive energy with respect to the free Dirac Hamiltonian.

The
annihilation operator \(a\) acts on an arbitrary sector of Fock space
\(\mathcal{F}_{m,p}\), for any \(m,p\in\mathbb{N}_0\) with either of the operator types


\begin{align}
a: &\overline{\mathcal{H}}\otimes \mathcal{F}_{m,p} \rightarrow \mathcal{F}_{m-1,p}\oplus \mathcal{F}_{m,p+1}\\
a: &\overline{\mathcal{H}}\times \mathcal{F}_{m,p} \rightarrow \mathcal{F}_{m-1,p}\oplus \mathcal{F}_{m,p+1}
\end{align}
regardless of the exact type of the annihilation operator I will denote it by \(a\). Also here the tensor product is 
understood in the algebraic sense.
I start out by defining \(a\) on elements of 
\(\{\bigwedge_{l=1}^m \varphi_l \otimes \bigwedge_{c=1}^p \phi_c  \mid \forall c:  \varphi_c \in \mathcal{H}^+, \phi_c \in \mathcal{H}^-   \}\)
which spans a dense subset of \(\mathcal{F}_{m,p}\), then one continues this operator uniquely by 
linearity and finally by the bounded linear extension theorem to all of \(\mathcal{F}_{m,p}\) and then 
again by linearity to all of \(\overline{\mathcal{H}}\otimes \mathcal{F}_{m,p}\).
\begin{align}
&a\left(\phi \otimes \bigwedge_{l=1}^m \varphi_l \otimes \bigwedge_{c=1}^p \phi_c\right)=a\left(\phi,\bigwedge_{l=1}^m \varphi_l \otimes \bigwedge_{c=1}^p \phi_c\right)\\
&= \sum_{k=1}^m (-1)^{1+k} \langle P^+ \phi, \varphi_k\rangle \bigwedge_{\overset{l=1}{l\neq k}}^m \varphi_l \otimes \bigwedge_{c=1}^p \phi_c + \bigwedge_{l=1}^m \varphi_l \otimes P^- \phi \wedge \bigwedge_{c=1}^p \phi_c
\end{align}


where \(\langle, \rangle\) denotes that the scalar product of \(\mathcal{H}\). The first summand on the right hand side is taken to vanish for \(m=0\). 
For \(\varphi\in \mathcal{H}\) I will also use the abbreviation \(a(\varphi):=a(\varphi,\cdot)\).

Now we turn to the construction of the \(S\)-matrix, the second quantised analogue of \(U^A\). This construction is carried out axiomatically. The first axiom makes sure that the following diagram, and the analogue for the adjoint of the annihilation operator commute.
\begin{equation}
\begin{CD}								%heuristics with infinite wedge space?
\mathcal{F}     @>S^A>>  \mathcal{F}\\
@AAaA        @AAaA\\
\overline{\mathcal{H}}\otimes \mathcal{F}     @>U^A\otimes S^A>>  \overline{\mathcal{H}}\otimes \mathcal{F} 
\end{CD}
\end{equation}
\begin{axiom}
The \(S\) operator fulfils the ``lift condition''.
\begin{align}\label{lift_condition1}
\forall \phi\in \mathcal{H}:& \hspace{0.5cm} S^A \circ a(\phi)=a\left( U^A \phi \right)  \circ S^A,\tag{lift condition}\\
\label{lift_condition2}
\forall \phi\in \mathcal{H}:& \hspace{0.5cm} S^A \circ a^*(\phi)=a^*\left( U^A \phi \right)  \circ S^A,\tag{adjoint lift condition}
\end{align}
where \(a^*\) is the adjoint of the annihilation operator, the creation operator. 
\end{axiom}

There is a convergent power series of the one-particle scattering operator \(U^A\):
\begin{equation}\label{U_expansion}
U^A = \sum_{k=0}^\infty \frac{1}{k!} Z_k(A),
\end{equation}
where \(Z_k(A)\) are bounded operators on \(\mathcal{H}\), which are homogeneous of degree \(k\) in \(A\).
We try an analogous formal power series ansatz for the second quantised scattering operator \(S^A\)

\begin{equation}\label{S_expansion}
S^A=\sum_{k=0}^\infty \frac{1}{k!} T_k(A).
\end{equation}
Here \(T_k\) are assumed to be homogeneous of degree \(k\) in \(A\); however, they will only turn out to be bounded on
fixed particle number subspaces \(\mathcal{F}_{m,p}\) of Fock space. It is the goal of the following  sections to
show that this ansatz indeed works. That is, we can identify operators \(T_k\) such that \eqref{S_expansion}
holds up to a global phase and furthermore the question of convergence can be settled if one assumes that 
the phase is analytic in the external field \(A\). %In constructing a guess for the scattering operator \(S^A\) we will assume \eqref{S_expansion} to converge absolutely when applied to an element of Fock space with finitely many particles.
In order to fully characterise \(S^A\) it is enough to characterise all of the \(T_k\) operators. 
Using the \eqref{lift_condition1} one can derive commutation relations for the operators 
\(T_k\) by plugging in \eqref{U_expansion} and \eqref{S_expansion} into \eqref{lift_condition1} and \eqref{lift_condition2}
and collecting all terms with the same degree of homogeneity. They are given by

\begin{equation}\label{logarithmic lift condition}
\left[T_m(A) , a^\# (\phi)\right]= \sum_{j=1}^{m} \begin{pmatrix} m \\ j \end{pmatrix} a^\# \left(Z_j (A) \phi \right) T_{m-j}(A), 
\end{equation}
where \(a^\#\) is either \(a\) or \(a^*\). Together \(T_k\) and \(\langle T_k\rangle\) characterise the operator \(T_k\) on the whole algebraic
direct sum, it can then be further extended to all of Fock space.

Before we go on to construct a concrete form of the scattering operator, we will first define a certain kind of unitary operator on Fock space.

\section{Differential second quantisation}

Let \(B:\mathcal{H}\rightarrow\mathcal{H}\) be a bounded
operator on \(\mathcal{H}\), such that \(i B\) is self adjoint and \(B_{+-}\) is a Hilbert-Schmidt operator. 
We would like to construct a version \(\mathrm{d}\Gamma(B)\) of \(B\) that acts on Fock space and also is skew adjoint.
The strategy of this section is to construct an operator in two steps that is essentially self adjoint of the Fock space of 
finitely many particles, a dense subset of Fock space. It is denoted by

\begin{Def}
\begin{equation}
\mathcal{F}':=\bigobot_{m,p=0}^\infty \mathcal{F}_{m,p},
\end{equation}
where \(\bigobot\) refers to the algebraic direct sum.
\end{Def}
Because \(B_{-+}:\mathcal{H}^+\rightarrow \mathcal{H}^-\) is compact, there is an ONB \((\varphi_n)_{n\in\mathbb{N}}\) 
of \(\mathcal{H}^+\) and likewise an ONB \((\varphi_{-n})_{n\in\mathbb{N}}\) of \(\mathcal{H}^-\) such that it takes the canonical form 
of compact operators

\begin{equation}
B_{-+} = \sum_{n\in\mathbb{N}} \lambda_n |\varphi_{-n}\rangle \langle \varphi_{n}|, \quad \lambda_n \ge 0.
\end{equation}
Here the numbers \(\lambda_n\) fulfil \(\sum_{k=1}^\infty \lambda_k^2 = \|B_{-+}\|_{\text{HS}}<\infty\). As a consequence we have

\begin{equation}
B_{+-} = -\sum_{n\in\mathbb{N}} \lambda_n |\varphi_{n}\rangle \langle \varphi_{-n}|.
\end{equation}

With respect to this basis we define the set of finite linear combinations of product states of finitely many particles

\begin{Def}
We define
\begin{equation}
\mathcal{F}^0\!\!:=\! \mathrm{span}\!\! \left\{\prod_{k=1}^m \!a^*\!(\varphi_{L_k}\!)\!\prod_{c=1}^p\!\! a(\varphi_{-C_c})\Omega\mid m,p\!\in\!\!\mathbb{N}, (L_k)_k,\!(C_c)_c\!\subset\!\mathbb{N} \!\right\}\!,
\end{equation}
we will refer to a subset of this set for fixed values of \(m\) and \(p\) by \(\mathcal{F}^0_{m,p}\).
\end{Def}

In order to do so, the following splitting turns out to be advantageous. 

\begin{Def}
We define the following operators of type \(\mathcal{F}^0\rightarrow \mathcal{F}\)

\begin{align}\label{predefdGamma}
\mathrm{d}\Gamma(B_{++})&:= \sum_{n\in\mathbb{N}}  a^*(B_{++} \varphi_n) a(\varphi_n) \\
\mathrm{d}\Gamma(B_{--})&:= -\sum_{n\in\mathbb{N}}   a(\varphi_{-n})a^*(B_{--} \varphi_{-n}) \\
\mathrm{d}\Gamma(B_{-+})&:= \sum_{n\in\mathbb{N}}  a^*(B_{-+}\varphi_{n}) a(\varphi_n)
\end{align}
where the sum converges in the strong operator topology and \((\varphi_n)_n , (\varphi_{-n})_n\) are arbitrary ONBs of \(\mathcal{H}^+\) and \(\mathcal{H}^-\).
\end{Def}



\begin{Lemma}
The operators \(\mathrm{d}\Gamma(B_{++}),\mathrm{d}\Gamma(B_{--})\) and \(\mathrm{d}\Gamma(B_{-+})\) 
restricted to \(|_{\mathcal{F}^0_{m,p}}\) they have the following type
\begin{align}
\mathrm{d}\Gamma(B_{++})|_{\mathcal{F}^0_{m,p}}&: \quad \mathcal{F}^0_{m,p} \rightarrow \mathcal{F}_{m,p}\\
\mathrm{d}\Gamma(B_{--})|_{\mathcal{F}^0_{m,p}}&: \quad \mathcal{F}^0_{m,p} \rightarrow \mathcal{F}_{m,p}\\
\mathrm{d}\Gamma(B_{-+})|_{\mathcal{F}^0_{m,p}}&: \quad \mathcal{F}^0_{m,p} \rightarrow \mathcal{F}_{m-1,p-1}
\end{align}
 and fulfil
the following bounds for all \(m,p\)
\begin{align}
\|\mathrm{d}\Gamma(B_{++})|_{\mathcal{F}^0_{m,p}}\|&\le (m+1)\|B_{++}\|\\
\|\mathrm{d}\Gamma(B_{--})|_{\mathcal{F}^0_{m,p}}\|&\le (p+1)\|B_{--}\|\\
\|\mathrm{d}\Gamma(B_{-+})|_{\mathcal{F}^0_{m,p}}\|&\le \|B_{-+}\|_{\text{HS}}.
\end{align}
\end{Lemma}
\begin{proof}
Pick \(\alpha\in\mathcal{F}^0_{m,p}\) for \(m,p\in\mathbb{N}_0\), \(\alpha\) can be expressed in terms of a general ONB 
\((\tilde{\varphi}_k)_{k\in\mathbb{N}}\) of \(\mathcal{H}^+\) and \((\tilde{\varphi}_{-k})_{k\in\mathbb{N}}\) of \(\mathcal{H}^-\)
\begin{equation}
\alpha=\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\!\!\!\!\!\!\alpha_{L,C} \prod_{l=1}^m a^*(\tilde{\varphi}_{L_l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C_c}) \Omega.
\end{equation}
In this expansion only finitely many coefficients \(\alpha_{\cdot, \cdot}\) are nonzero. Our operators all map the vacuum onto the zero vector, so commuting them 
through the products of of creation and annihilation operators in the expansion of \(\alpha\) we can make the action of them more explicit:
\begin{align}\nonumber
\mathrm{d}\Gamma(B_{++}) \alpha =\hspace{-0.5cm} \sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\!\!\!\!\!\!\alpha_{L,C} \sum_{b=1}^m 
\prod_{l=1}^{b-1} a^*(\tilde{\varphi}_{L_l})  \sum_{n\in\mathbb{N}} a^*(B_{++}\varphi_n) \langle \varphi_n, \tilde{\varphi}_{L_b}\rangle \\
\prod_{l=b+1}^m a^*(\tilde{\varphi}_{l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C_c}) \Omega\\
=\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\!\!\!\!\!\!\alpha_{L,C} \sum_{b=1}^m 
\prod_{l=1}^{b-1} a^*(\tilde{\varphi}_{L_l})  ~~ a^*(B_{++} \tilde{\varphi}_{L_b})  \!\!\!
\prod_{l=b+1}^m a^*(\tilde{\varphi}_{l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C_c}) \Omega.
\end{align}
We notice, that \(\mathrm{d}\Gamma(B_{++})\alpha \in \mathcal{F}_{m,p}\) holds. What is left to show for the first operator is therefore
its norm. For estimating this we see that \(B_{++}\) in the last line can be replaced by 
\begin{equation}
B^L_{L_b}:=\left(1-\sum_{\overset{l=1}{l\neq b}}^m |\tilde{\varphi}_{L_l}\rangle \langle \tilde{\varphi}_{L_l}|\right) B_{++},
\end{equation}
due to the antisymmetry of fermions. Expanding 
\begin{align}\nonumber
&\|\mathrm{d}\Gamma(B_{++})\alpha\|^2 = \langle \mathrm{d}\Gamma(B_{++})\alpha, \mathrm{d}\Gamma(B_{++})\alpha \rangle \\\nonumber
&= \hspace{-1cm}\sum_{\overset{L,C, L',C'\subset \mathbb{N}}{|L'|=|L|=m,|C'|=|C|=p}}\hspace{-1cm}\overline{\alpha_{L,C}}\alpha_{L',C'} \sum_{b,b'=1}^m 
\left\langle \prod_{l=1}^{b-1} a^*(\tilde{\varphi}_{L_l})  ~~ a^*(B^{L}_{L_b} \tilde{\varphi}_{L_b})\right.  \\\nonumber
&\prod_{l=b+1}^m a^*(\tilde{\varphi}_{L_l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C_c}) \Omega, 
\prod_{l=1}^{b'-1} a^*(\tilde{\varphi}_{L'_l})  ~~ a^*(B_{L'_{b'}}^{L'} \tilde{\varphi}_{L'_b})  \\
&\left.\prod_{l=b'+1}^m a^*(\tilde{\varphi}_{L'_l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C'_c}) \Omega\right\rangle
\end{align}
we see that in fact \(C\) and \(C'\) need to agree, because we can just commute the corresponding annihilation operators from one end of the 
scalar product to the other. Furthermore only a single wavefunction on each side of the scalar product is modified, this implies that in order for the
scalar product not to vanish \(|L\cap L'|\ge m-2\) has to hold. If \(L\neq L'\) the double sum over \(n,n'\) has only the contribution where 
\(b=L_l \not\in L'\) and \(b'=L'_{l'}\not\in L\) are selected. Otherwise the full sum contributes, yielding
\begin{align}\nonumber
&\|\mathrm{d}\Gamma(B_{++})\alpha\|^2 = \\\nonumber
&= \hspace{-0.4cm}\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|C|=p}{|L|=m-1}}}\hspace{-0.2cm}\sum_{n\neq n'\in\mathbb{N}\backslash L }
\hspace{-0.4cm}\overline{\alpha_{L\cup\{n\},C}}\alpha_{L\cup\{n'\},C}
 \langle B^{L\cup\{n\}}_n \tilde{\varphi}_{n}, B^{L\cup\{n'\}}_{n'}\tilde{\varphi}_{n'}\rangle (-1)^{g(L,n)+g(L,n')}\\\label{B++estimate}
&+\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\hspace{-0.4cm} |\alpha_{L,C}|^2
 \sum_{b,b'=1}^m 
\left\langle \prod_{l=1}^{b-1} a^*(\tilde{\varphi}_{L_l})  ~~ a^*(B^{L}_{L_b} \tilde{\varphi}_{L_b})\right.  \\\nonumber
&\prod_{l=b+1}^m a^*(\tilde{\varphi}_{L_l}) \Omega, 
\prod_{l=1}^{b'-1} a^*(\tilde{\varphi}_{L_l})  ~~ a^*(B_{L_{b'}}^{L} \tilde{\varphi}_{L_b})  \left.\prod_{l=b'+1}^m a^*(\tilde{\varphi}_{L_l}) ) \Omega\right\rangle,
\end{align}
where \(g(L,n):=|\{l\in L \mid l<n\}|\) keeps track of the number of anti commutations. In the first sum we add and subtract the terms 
where \(n=n'\). The enlarged sum can then be reformulated

\begin{align}\nonumber
&\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|L|=m-1}{|C|=p}}}\hspace{-0.1cm}\sum_{n,n'\in\mathbb{N}\backslash L} \hspace{-0.3cm}\overline{\alpha_{L\cup\{n\},C}}\alpha_{L\cup\{n'\},C} 
 \langle B^{L\cup\{n\}}_n \tilde{\varphi}_{n}, B^{L\cup\{n'\}}_{n'}\tilde{\varphi}_{n'}\rangle (-1)^{g(L,n)+g(L,n')}\\\nonumber
 &=\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m-1,|C|=p}}\left\|\sum_{n\in\mathbb{N}\backslash L}\alpha_{L\cup\{n\},C}  B^{L\cup\{n\}}_n \tilde{\varphi}_{n} (-1)^{g(L,n)} \right\|^2\\\label{B++ first term}
  &=\sum_{\overset{L,C\subset \mathbb{N}}{\overset{|L|=m-1}{|C|=p}}}\left\|\left(1-\sum_{l\in L}|\tilde{\varphi}_l\rangle\langle \tilde{\varphi}_l | \right)B_{++}\hspace{-0.2cm}\sum_{n\in\mathbb{N}\backslash L}\hspace{-0.2cm}\alpha_{L\cup\{n\},C}  \tilde{\varphi}_{n} (-1)^{g(L,n)} \right\|^2
\end{align}
Now the operator product inside the norm has operator norm \(\|B_{++}\|\) and so we can estimate the whole object by
\begin{equation}\label{B++estimatefinal1}
\eqref{B++ first term}\le \|\alpha\|^2 \|B_{++}\|^2.
\end{equation}
Now for the first term in \eqref{B++estimate} we need to estimate the term we added to complete the norm square, this is done as follows
\begin{align}\nonumber
&\sum_{\overset{L,C\subset\mathbb{N}}{|L|=m-1,|C|=p}} \hspace{-0.4cm}\sum_{n\in\mathbb{N}\backslash L} |\alpha_{L\cup\{n\},C}|^2 \|B_n^{L\cup\{n\}} \tilde{\varphi}_{n}\|^2\\\label{B++estimatefinal2}
&\le \hspace{-0.6cm}\sum_{\overset{L,C\subset\mathbb{N}}{|L|=m,|C|=p}}\hspace{-0.5cm} \|B_{++}\|^2|\alpha_{L,C}|^2 =\|\alpha\|^2 \|B_{++}\|^2.
\end{align}
What remains is the second sum in \eqref{B++estimate}, for this term there are two cases.  If \(b=b'\) then the scalar product is 
equal to \(\langle B_{L_b}^L \tilde{\varphi}_b, B_{L_{b}}^L \tilde{\varphi}_{b}\rangle\). If \(b\neq b'\) the scalar product is, up to a sign,
equal to \(\langle B_{L_b}^L \tilde{\varphi}_b,\tilde{\varphi}_{b}\rangle \langle \tilde{\varphi}_{b'}, B_{L_{b'}}^L \tilde{\varphi}_{b'}\rangle\).
However both of these terms can be estimated by \(\|B_{++}\|^2\). So all \(m^2\) summands of this sum contribute \(\|B_{++}\|^2\). Overall 
this estimate yields
\begin{align}\nonumber
&\|\mathrm{d}\Gamma(B_{++})\alpha\|^2 \le \eqref{B++estimatefinal1}+\eqref{B++estimatefinal2} + \|\alpha\|^2 m^2 \|B_{++}\|^2 \\\nonumber
&= \|\alpha\|^2 (2+m^2) \|B_{++}\|^2.
\end{align}
For convenience of notation the estimate can be weakened to 
\begin{equation}
\|\mathrm{d}\Gamma(B_{++})\alpha\| \le (m+1) \|B_{++}\|,
\end{equation}
because for all \(m\neq0\) 
this estimate is and upper bound on what we found, but for \(m=0\) the operator \(\mathrm{d}\Gamma(B_{++})\) is actually the zero operator.
A completely analogous argument works for \(\mathrm{d}\Gamma(B_{--})\). 

So lets move on to \(\mathrm{d}\Gamma(B_{-+})\). Applying it to the same \(\alpha\in \mathcal{F}^0_{m,p}\) again we permute all the operators
to the right, where they annihilate the vacuum. The remaining terms are

\begin{align}\nonumber
\sum_{n\in\mathbb{N}} a^*(B_{-+}\varphi_n)a(\varphi_{n})\hspace{-0.5cm}\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}  \hspace{-0.5cm}\alpha_{L,C} 
\prod_{l=1}^m a^*(\tilde{\varphi}_{L_l}) \prod_{c=1}^p a(\tilde{\varphi}_{-C_c}) \Omega  \\\nonumber
=\sum_{\overset{L,C\subset \mathbb{N}}{|L|=m,|C|=p}}\hspace{-0.5cm} \alpha_{L,C} \sum_{b=1}^m \sum_{d=1}^p (-1)^{m-1+b+d} \langle B_{+-} \tilde{\varphi}_{-C_d},\tilde{\varphi}_{L_b}\rangle \\
\prod_{\overset{l=1}{l\neq b}}^m a^*(\tilde{\varphi}_{L_l})
\prod_{\overset{c=1}{c\neq d}}^p a(\tilde{\varphi}_{-C_c})\Omega.
\end{align}
By counting the remaining creation and annihilation operators we immediately see that \(\mathrm{d}\Gamma(B_{-+})\alpha\in \mathcal{F}_{m-1,p-1}\). 
For estimating the norm of this vector, we switch basis from \((\tilde{\varphi}_{\pm n})_n\) to \((\varphi_{\pm n}')_n\), the basis where 
\(B_{-+}\) takes its canonical form. Then the scalar product involving \(B_{-+}\) reduces to \(\lambda_{L_b}\delta_{L_b,C_d}\). We estimate

\begin{align}\nonumber
&\|\mathrm{d}\Gamma(B_{-+})\alpha\|^2= \hspace{-0.5cm}\sum_{\overset{L,L',C,C'\subset\mathbb{N}}{\overset{|L|=|L'|=m}{|C|=|C'|=p}}} ~\sum_{a,a'=1}^m \sum_{b,b'=1}^p
\overline{\alpha}_{L,C} \alpha_{L',C'}(-1)^{b+d+b'+d'}\lambda_{L_b} \lambda_{L_{b'}'} \\
&\delta_{L_b,C_d} \delta_{L_{b'}',C_{d'}'} \left\langle \prod_{\overset{l=1}{l\neq b}}^m a^*(\varphi_{L_l}')\prod_{\overset{c=1}{c\neq d}}^p 
a(\varphi_{-C_c}')\Omega, \prod_{\overset{l=1}{l\neq b'}}^m a^*(\varphi_{L_l'}')
\prod_{\overset{c=1}{c\neq d'}}^p a(\varphi_{-C_c'}')\Omega\right\rangle.
\end{align}

The scalar product in the second line tells us that \(L\backslash \{L_b\}=L'\backslash \{L_{b'}'\}\) and \(C\backslash \{C_{d}\}=C'\backslash \{C_{d'}'\}\) have
to hold in order for the term not to vanish. So this means that \(L\) and \(L'\) as well as \(C\) and \(C'\) can respectively differ at most by one element
which then has to be in the intersection \(L\cap C\). Because this sum is really just a finite sum, we can reorder it in the following way

\begin{align}\nonumber
\|\mathrm{d}\Gamma(B_{-+})\alpha\|^2
&=\hspace{-0.4cm}\sum_{\overset{L,C\subset\mathbb{N}}{\overset{|L|=m-1}{|C|=p-1}}} \sum_{b,b'\in \mathbb{N}\backslash (L\cup C)}\hspace{-0.3cm} \lambda_{b} \lambda_{b'} 
\overline{\alpha}_{L\cup\{b\},C\cup \{b\}} \alpha_{L\cup\{b'\},C\cup\{b'\}}\\
&(-1)^{g(L,b)+g(C,b)+g(L,b')+g(C,b')},
\end{align}
where \(g(L,b)=|\{l\in L \mid l<b\}|\) as before. This expression can be rewritten in terms of a scalar product in \(\ell^2(\mathbb{N})\)

\begin{align}\nonumber
\|\mathrm{d}\Gamma(B_{-+})\alpha\|^2
&=\hspace{-0.4cm}\sum_{\overset{L,C\subset\mathbb{N}}{\overset{|L|=m-1}{|C|=p-1}}} \left|\left\langle 1_{(L\cup C)^c} \alpha_{L\cup \{\cdot \}, C\cup \{\cdot\}} (-1)^{g(L,\cdot)+g(C,\cdot)},\lambda_\cdot \right\rangle_{\ell^2}  \right|^2 \\
&\le \hspace{-0.4cm}\sum_{\overset{L,C\subset\mathbb{N}}{\overset{|L|=m-1}{|C|=p-1}}} \sum_{b\in \mathbb{N}} 1_{(L\cup C)^c}(b) |\alpha_{L\cup\{b\},C\cup\{b\}}|^2 \sum_{d\in\mathbb{N}}\lambda_d^2\\
&\le \|\alpha\|^2 \|B_{-+}\|^2_{\text{HS}}.
\end{align}

\end{proof}

\begin{Corollary}
The operators \(\mathrm{d}\Gamma(B_{--})\) and \(\mathrm{d}\Gamma(B_{++})\) can be extended by continuity on \(\mathcal{F}^0_{m,p}\) to unbounded operators on all of \(\mathcal{F}'\).
The operator \(\mathrm{d}\Gamma(B_{-+})\) can be continuously extended to all of \(\mathcal{F}\).
\end{Corollary}

\begin{Lemma}
The operator \(\left(\mathrm{d}\Gamma(B_{-+})\right)^*\)  acts on elements of \(\mathcal{F}^0\) as

\begin{equation}
- \sum_{n\in\mathbb{N}} a^*(B_{+-}\varphi_{-n}) a(\varphi_{-n})=:-\mathrm{d}\Gamma(B_{+-}).
\end{equation}
So also \(\mathrm{d}\Gamma(B_{+-}):\mathcal{F}^0\rightarrow \mathcal{F}\) can be extended continuously to all of \(\mathcal{F}\).
Moreover \(\mathrm{d}\Gamma(B_{-+})+\mathrm{d}\Gamma(B_{+-})\) is skew-adjoint.
\end{Lemma}
\begin{proof}
Pick \(\beta,\alpha \in \mathcal{F}^0\). We expand those states with respect to the basis \((\varphi_k')_{k\in\mathbb{Z}\backslash \{0\}}\). Consider

\begin{align}\nonumber
&\langle \beta, \mathrm{d}\Gamma(B_{-+}) \alpha \rangle=\left\langle \beta, \sum_{n\in\mathbb{N}} a^*(B_{-+}\varphi_n)a(\varphi_{n}) \alpha \right\rangle\\\nonumber
&=\sum_{n\in\mathbb{N}} \langle \beta , a^*(B_{-+}\varphi_n)a(\varphi_{n}) \alpha\rangle
=\sum_{n\in\mathbb{N}}  \langle a^*(\varphi_{n})  a(B_{-+}\varphi_n)\beta , \alpha\rangle\\\nonumber
&=\left\langle \sum_{n\in\mathbb{N}}a^*(\varphi_{n})  a(B_{-+}\varphi_n) \beta, \alpha \right\rangle
=\left\langle \sum_{n\in\mathbb{N}} \lambda_n a^*(\varphi_{n})  a(\varphi_{-n}) \beta, \alpha \right\rangle\\
&=\left\langle \sum_{n\in\mathbb{N}}  a^*(- B_{+-}\varphi_{-n})  a(\varphi_{-n}) \beta, \alpha \right\rangle
=-\langle \mathrm{d}\Gamma(B_{+-})  \beta, \alpha \rangle,
\end{align}
 So we see that \(\mathrm{d}\Gamma(B_{+-})\)
and \(\mathrm{d}\Gamma(B_{-+})^*\) agree on \(\mathcal{F}^0\) which is dense. So they are the same bounded and continuous operator on all of
Fock space. 
\end{proof}

\begin{Lemma}
The operator \(\mathrm{d}\Gamma(B):\mathcal{F}'\rightarrow \mathcal{F}\),
\begin{equation}
\mathrm{d}\Gamma(B):=\mathrm{d}\Gamma(B_{++})+\mathrm{d}\Gamma(B_{+-})+\mathrm{d}\Gamma(B_{-+})+\mathrm{d}\Gamma(B_{--})
\end{equation}
is skew symmetric.
\end{Lemma}
\begin{proof}
Since the sum of skew symmetric operators is skew symmetric, it suffices to show skew symmetry of \(\mathrm{d}\Gamma(B_{++})\) and \(\mathrm{d}\Gamma(B_{--})\).
Moreover since both of these operators are extended versions of operators of the same name of type \(\mathcal{F}^0\rightarrow \mathcal{F}\) it suffices to show skew symmetry
on this domain. We will only do the calculation for \(\mathrm{d}\Gamma(B_{++})\), the other calculation is analogous. 
First we notice that
\begin{equation}
\mathrm{d}\Gamma(B_{++})=\sum_{n\in\mathbb{N}} a^*(B_{++}\varphi_{n})a(\varphi_n)
=\sum_{n\in\mathbb{N}} \sum_{m\in\mathbb{N}}  \langle \varphi_m, B_{++}\varphi_n\rangle a^*(\varphi_m) a(\varphi_n)
\end{equation}
holds.  Pick \(\alpha,\beta \in \mathcal{F}^0\). Consider
\begin{align}\nonumber
\left\langle \beta, \mathrm{d}\Gamma(B_{++}) \alpha \right\rangle
= \sum_{L,L',C,C'\subset \mathbb{N}} \overline{\beta}_{L',C'}\alpha_{L,C} 
\left\langle \prod_{l=1}^{|L'|}a^*(\varphi_{L_l'})\prod_{c=1}^{|C'|} a(\varphi_{-C_c'})\Omega,\right. \\ \nonumber
\left. \sum_{n\in\mathbb{N}} a^*(B_{++}\varphi_{n})a(\varphi_n) \prod_{l=1}^{|L|}a^*(\varphi_{L_l})\prod_{c=1}^{|C|} a(\varphi_{-C_c})\Omega\right\rangle\\\nonumber
= \sum_{L,L',C,C'\subset \mathbb{N}} \overline{\beta}_{L',C'}\alpha_{L,C} \sum_{n\in\mathbb{N}}
\left\langle \prod_{l=1}^{|L'|}a^*(\varphi_{L_l'})\prod_{c=1}^{|C'|} a(\varphi_{-C_c'})\Omega,\right. \\ \nonumber
\left. a^*(B_{++}\varphi_{n})a(\varphi_n) \prod_{l=1}^{|L|}a^*(\varphi_{L_l})\prod_{c=1}^{|C|} a(\varphi_{-C_c})\Omega\right\rangle\\\nonumber
= \sum_{L,L',C,C'\subset \mathbb{N}} \overline{\beta}_{L',C'}\alpha_{L,C} \sum_{n\in\mathbb{N}}
\left\langle a^*(\varphi_n) a(B_{++}\varphi_{n})\prod_{l=1}^{|L'|}a^*(\varphi_{L_l'})\prod_{c=1}^{|C'|} a(\varphi_{-C_c'})\Omega,\right. \\ \nonumber
\left.  \prod_{l=1}^{|L|}a^*(\varphi_{L_l})\prod_{c=1}^{|C|} a(\varphi_{-C_c})\Omega\right\rangle\\\nonumber
= \sum_{L,L',C,C'\subset \mathbb{N}} \overline{\beta}_{L',C'}\alpha_{L,C} 
\left\langle \sum_{n\in\mathbb{N}} \sum_{m\in\mathbb{N}} \langle B_{++}\varphi_n,\varphi_m\rangle a^*(\varphi_n) a(\varphi_{m})\right. \\ \nonumber
\left. \prod_{l=1}^{|L'|}a^*(\varphi_{L_l'})\prod_{c=1}^{|C'|} a(\varphi_{-C_c'})\Omega, \prod_{l=1}^{|L|}a^*(\varphi_{L_l})\prod_{c=1}^{|C|} a(\varphi_{-C_c})\Omega\right\rangle.
\end{align}
Now because \(B_{++}^*=-B_{++}\) we see that 
\begin{equation}
\left\langle \beta, \mathrm{d}\Gamma(B_{++})\alpha\right\rangle =- \left\langle \mathrm{d}\Gamma(B_{++})\beta, \alpha\right\rangle 
\end{equation}
holds.
\end{proof}



Now we would like to define \(e^{\mathrm{d}\Gamma(B)}\), in order to do so, we will show that \(\mathrm{d}\Gamma(B)\) is essentially skew-adjoint. 
One way of doing so is by Nelson's analytic vector theorem. 

\begin{Thm}[Nelson's analytic vector theorem]
Let \(C\) be a symmetric operator on a Hilbert space \(\mathscr{H}\). If \(D(C)\) contains a total set 
\(S\subset \bigcap_{n=1}^\infty D(C^n)\) of analytic vectors, then \(C\) is essentially self adjoint. 
A vector \(\phi\in \bigcap_{n=1}^\infty D(C^n)\) is called analytic if there is \(t>0\) such that
\(\sum_{k=0}^\infty \frac{\|C^n \phi\|}{n!} t^n<\infty\) holds. A set \(S\) is said to be total if \(\overline{\text{span}(S)}=\mathscr{H}\)
\end{Thm}
For a proof see e.g. \cite{SimonReed2}.

\begin{Lemma}\label{Gamma exponential bound}
For any \( \alpha \in \mathcal{F}', t>0\) the operator \(\mathrm{d}\Gamma(B):\mathcal{F}'\rightarrow \mathcal{F}\) satisfies
\begin{equation}
\sum_{k=0}^\infty \frac{\|\mathrm{d}\Gamma(B)^k \alpha\|}{k!} t^k <\infty.
\end{equation}
\end{Lemma}
\begin{proof}
 By definition of \(\mathcal{F}'\) there are \(m,p\in\mathbb{N}\) such that \(\alpha \in \bigobot_{l=0}^m\bigobot_{c=0}^p \mathcal{F}_{l,p}\). Fix \(t>0\). 
We dissect \(\alpha\) into its parts of fixed particle numbers:
\begin{equation}
\sum_{k=0}^\infty \frac{\|\mathrm{d}\Gamma(B)^k \alpha\|}{k!} t^k \le \sum_{l=0}^m\sum_{c=0}^p \sum_{k=0}^\infty \frac{\|\mathrm{d}\Gamma(B)^k \alpha_{l,c}\|}{k!} t^k .
\end{equation}
 Using the following abbreviations
\begin{align}
&\Gamma_{-1}:=\mathrm{d}\Gamma(B)_{-+}\\
&\Gamma_0:=\mathrm{d}\Gamma(B)_{++}+\mathrm{d}\Gamma(B)_{--}\\
&\Gamma_{+1}:=\mathrm{d}\Gamma(B)_{+-}\\
&\beta:=\max\{\|B_{++}\|+\|B_{--}\|,\|B_{-+},\|_{\mathrm{HS}}\}
\end{align}
we estimate
\begin{align}\nonumber
\|\mathrm{d}\Gamma(B)^k \alpha_{l,c}\|\le \sum_{x\in \{-1,0,+1\}^k} \left\| \prod_{b=1}^k \Gamma_{x_b}\alpha_{l,c}\right\|\\\label{essentialSelfadjointnessOperatorProduct}
\le  \sum_{x\in \{-1,0,+1\}^k} \prod_{b=1}^k \left\| \Gamma_{x_b}|_{\mathcal{F}_{l+\sum_{d=1}^{b-1} x_d,c+\sum_{d=1}^{b-1} x_d}}\right\| \|\alpha_{l,c}\|\\
\le 3^k \|\alpha\| \max_{x\in \{-1,0,+1\}^k} \prod_{b=1}^k\left\| \Gamma_{x_b}|_{\mathcal{F}_{l+\sum_{d=1}^{b-1} x_d,c+\sum_{d=1}^{b-1} x_d}}\right\|  .
\end{align}
At this point the factors only depend on the number of particles the Fock space vector attains as we act on it with the operators \(\Gamma_{\cdot}\). 
As these bounds increase with the particle number we can restrict the set \(\{-1,0,+1\}\) in the last line to \(\{0,+1\}\).
We notice that the bound in \eqref{essentialSelfadjointnessOperatorProduct} will only increase if  we exchange each pair 
\(x_{i}=1, x_{h}=0\) by the pair \(x_{\max\{i,h\}}=1, x_{\min\{i,h\}}=0\) so that the norm of the operator that acts like
a particle number operator is taken after the particle number is increased. The maximum therefore has the form \((c+l+2+2d)^{k-d}\), which we bound by
\(2^k (c/2+d/2+1+d)^{k-d}\).
For maximising this object we treat \(d\) as a continuous variable take the derivative and set it to zero. From the form of the function to be maximised
it is clear that it is equal to \(1\) for \(d=k\) and at \(d=-c/2-l/2\), but for \(k\) large it will be bigger in between. We abbreviate \(y=c/2+l/2+1\).
\begin{align}
0= (y+d)^{k-d} (-\ln(y+d) + \frac{k-d}{y+d})\\
\iff \frac{k-d}{y+d}= \ln (y+d)\\
\iff \frac{k+y}{y+d}  -1 = -1 + \ln (e (y+d))\\
\iff e(k+y)=e(y+d)\ln(e(y+d))\\
\iff e(k+y)=\ln(e(y+d)) e^{\ln(e(y+d))}\\
\iff W_0(e(k+y))=\ln(e(y+d))\\
\iff e^{W_0(e(k+y))-1}-y=d,
\end{align}

where we made use of the Lambert W function, which is the inverse function of \(x\mapsto x e^x\) and has multiple branches; however as \(e(y+d)>0\) 
\(W_0\) is the only real branch which is applicable here, it corresponds to the inverse of \(x\mapsto x e^x\) for \(x>-1\). 
From the form of the maximising value we see, that it is always bigger than \(-y\). Plugging this back onto our
function we find its maximum

\begin{align}\nonumber
&\max_{d\in ]-y,\infty[} (y+d)^{k-d}=e^{(W_0(e(k+y))-1) (k+y)- (W_0(e(k+y))-1)e^{W_0(e(k+y))-1}}\\\nonumber
&=e^{-(k+y) + (k+y)W_0(e(k+y)) + e^{W_0(e(k+y))-1} -((k+y)e)/e}\\\nonumber
&=e^{-2(k+y) + (k+y)W_0((k+y)e)+ \frac{e(k+y)}{eW_0((k+y)e)}}\\
&=e^{(k+y)(-2+W_0((k+y)e) + W_0((k+y)e)^{-1})},
\end{align}
where we repeatedly used \(W_0(x)e^{W_0(x)}=x\). Putting things together we find

\begin{align}
\|\Gamma(B)^k\alpha_{l,c}\|\le (6\beta )^k \|\alpha\| e^{(k+y)(-2+W_0((k+y)e) + W_0((k+y)e)^{-1})}.
\end{align}
Dividing this by \(k!\) and using the lower bound given by Sterling's formula we would like to prove that 

\begin{align}\label{essentialSelfadjointnessSimplifiedSum}
\sum_{k=1}^\infty (6\beta t )^k   e^{k(1-\ln(k))-\frac{1}{2}\ln(k) +(k+y)(-2+W_0((k+y)e) + W_0((k+y)e)^{-1})}<\infty
\end{align}
holds, where we neglected constant factors and the summand \(k=0\) which do not matter for the task at hand. Next we are going
to use an inequality about the growth of \(W_0\) proven in \cite{hoorfar2008inequalities}. For any \(x\ge e\) 
\begin{equation}
W_0(x)\le \ln(x)-\ln( \ln (x)) + \frac{e}{e-1}\frac{\ln (\ln (x))}{\ln (x)}
\end{equation}
holds true. Plugging this into our sum the exponent is bounded from above by

\begin{align}\nonumber
&k(1-\ln(k))-\frac{1}{2}\ln(k) +(k+y)\Big[-1+\ln(k+y) - \ln(1+ \ln (k+y))\\ \nonumber
&\left.+\frac{e}{e-1} \frac{\ln(1+\ln(k+y))}{1+\ln(k+y)} + W_0((k+y)e)^{-1}\right]\\\nonumber
&=-y + k \ln\left(1+\frac{y}{k}\right) + y \ln (k+y) -\frac{1}{2}\ln(k) +\\\nonumber
&(k+y)\left[ \ln (1+\ln(k+y))\frac{1-(e-1)\ln(k+y)}{(e-1)(1+\ln(k+y))} + W_0((k+y)e)^{-1}\right]\\\label{essentialSelfadjointnessExponent}
&\le y \ln (k+y) -\frac{1}{2}\ln(k) + (k+y)W_0((k+y)e)^{-1} +\\\nonumber
&(k+y) \ln (1+\ln(k+y))\frac{1-(e-1)\ln(k+y)}{(e-1)(1+\ln(k+y))} .
\end{align}
Now it is important to notice that the only remaining term that grows faster than linearly in magnitude is the last summand.
This term; however, is negative for large \(k\), as the fraction converges to \(-(e-1)\) for large \(k\), while the double logarithm
in front grows without bounds. So there is a \(k^*\) big enough such that  for all \(k>k^*\) \eqref{essentialSelfadjointnessExponent} 
is smaller than \(- k (\ln(6\beta t) + 1)\), proving that \eqref{essentialSelfadjointnessSimplifiedSum} in fact holds.

\end{proof}



\begin{Thm}\label{Gamma essential selfadjointness}
The operator \(\mathrm{d}\Gamma(B):\mathcal{F}'\rightarrow \mathcal{F}\) is essentially skew adjoint and hence by Stones theorem
 generates a strongly continuous unitary group \(\left( e^{t ~\widehat{\mathrm{d}\Gamma(B)}}\right)_t\), where \(\widehat{\mathrm{d}\Gamma(B)}\) is the closure of 
 \(\mathrm{d}\Gamma(B)\).
\end{Thm}
\begin{proof}
In order to apply Nelson's analytic vector theorem we pick \(C=\mathcal{F}'\). Pick \(\alpha \in\mathcal{F}'\). We need to show that there is \(t>0\) such that
\begin{equation}
\sum_{k=0}^\infty \frac{\|\mathrm{d}\Gamma(B)^k \alpha\|}{k!} t^k <\infty
\end{equation}
holds. This is guaranteed by the last lemma.
\end{proof}

Lastly in this chapter, we will investigate the commutation properties of \(\mathrm{d}\Gamma(B)\) with general creation and annihilation operators.
These properties are the reason we are interested in this operator, they will prove to be very useful in the next chapter.

\begin{Thm}\label{Commutation Gamma}
For \(\psi \in \mathcal{H}\) we have
\begin{equation}
[\mathrm{d}\Gamma(B),a^\# (\psi)]=a^\#(B\psi),
\end{equation}
where \(a^\#\) can be either \(a\) or \(a^*\).
\end{Thm}
\begin{proof}
Because \(\mathrm{d}\Gamma(B)\) is defined as the extension of an operator on \(\mathcal{F}^0\) it suffices to show the desired identity on this space. In order to do so
we first restrict \(\psi\in \text{span}\{\varphi_{n}| n \in \mathbb{Z}\backslash\{0\}\}\). We will first cover the case \(a(\psi)\).  
As a first step we decompose \(\mathrm{d}\Gamma(B)\) into its four parts

\begin{align}
\left[ \mathrm{d}\Gamma(B),a(\psi) \right] = \left[ \mathrm{d}\Gamma(B_{++})
+\mathrm{d}\Gamma(B_{-+})+\mathrm{d}\Gamma(B_{-+})+\mathrm{d}\Gamma(B_{--}),a(\psi) \right],
\end{align}
each of those parts is evaluated directly. We begin with the \(B_{++}\) part, this can be expressed as

\begin{align}
\left[ \mathrm{d}\Gamma(B_{++}),a(\psi) \right] \\
= \sum_{n\in\mathbb{N}} a^*(B_{++}\varphi_n)a(\varphi_n) a(\psi) - \sum_{n\in\mathbb{N}} a(\psi) a^*(B_{++}\varphi_n)a(\varphi_n) \\
=\sum_{n\in\mathbb{N}} \left[ -\langle \psi, B_{++} \varphi_n\rangle a(\varphi_n) +a(\psi) a^*(B_{++}\varphi_n)a(\varphi_n) \right]  \\
- \sum_{n\in\mathbb{N}} a(\psi) a^*(B_{++}\varphi_n)a(\varphi_n).
\end{align}

Let \(\alpha \in \mathcal{F}^0\). Now applying the expression in the last two lines to \(\alpha\) online finitely many elements of the sum in fact contribute.
So we may split the firs sum into two and observe the cancellation between the last two terms. Continuing we find

\begin{align}
\left[ \mathrm{d}\Gamma(B_{++}),a(\psi) \right] \alpha
=-\sum_{n\in\mathbb{N}}  \langle \psi, B_{++} \varphi_n\rangle a(\varphi_n)\alpha\\
=-a\left(\sum_{n\in\mathbb{N}} \langle B_{++}\varphi_n, \psi\rangle  \varphi_n  \right)\alpha
=a\left(\sum_{n\in\mathbb{N}} \langle \varphi_n, B_{++}\psi\rangle  \varphi_n  \right)\alpha\\
=a(B_{++}\psi)\alpha,
\end{align}

where we used \(B^*=-B^*\). Now for a general \(\psi\in\mathcal{H}\) we pick a sequence 
\((\psi_k)_{k\in\mathbb{N}}\subset \text{span}\{\varphi_{n}| n \in \mathbb{Z}\backslash\{0\}\}\)
such that \(\lim_{k\rightarrow \infty} \psi_k = \psi\). Now because of the calculation we have the equality

\begin{equation}
\left[ \mathrm{d}\Gamma(B_{++}),a(\psi_k) \right] \alpha =a(B_{++}\psi_k)\alpha
\end{equation}

for each \(k\in\mathbb{N}\) and hence if a limit exists it also holds in the limit. Now on the right hand side, because
\(a\) is a bounded operator on all of \(\mathcal{F}\) clearly the limit exists and is equal to \(a(B_{++}\psi)\alpha\).
On the left hand side we know \(\mathrm{d}\Gamma(B)\) to be bounded and hence continuous on every \(\mathcal{F}_{m,p}\)
for every \(m,p\in\mathbb{N}\).  Furhtermore since \(\alpha\in\mathcal{F}^0\) there is are \(m',p'\in\mathbb{N}\) such that 
\(\alpha \in \bigobot_{m=0}^{m'}\bigobot_{p=0}^{p'} \mathcal{F}_{m,p}\) holds and hence we can exchange the limit also 
with \(\mathrm{d}\Gamma(B)\) and find

\begin{equation}
\left[ \mathrm{d}\Gamma(B_{++}),a(\psi) \right] \alpha =a(B_{++}\psi)\alpha
\end{equation}

for general \(\psi\in\mathcal{H}\). The final extension of this equation to all \(\alpha \in \mathcal{F}'\) happens via the continuous linear
extension theorem on \(\mathcal{F}_{m,p}\) for each \(m,p\in\mathbb{N}\). The proof in all seven other cases are completely analogous.
Putting thins together again we obtain

\begin{align}
\left[ \mathrm{d}\Gamma(B_{++}),a(\psi) \right] +\left[ \mathrm{d}\Gamma(B_{-+}),a(\psi) \right] \\
+\left[ \mathrm{d}\Gamma(B_{+-}),a(\psi) \right] +\left[ \mathrm{d}\Gamma(B_{--}),a(\psi) \right]  =\\
a(B_{++}\psi)+a(B_{+-}\psi)+a(B_{-+}\psi)+a(B_{--}\psi)\iff \\
\left[ \mathrm{d}\Gamma(B),a(\psi) \right] =a(B\psi)
\end{align}
on all of \(\mathcal{F}'\).

\end{proof}

 

\section{A Simple Formula for the \(S\)-Matrix}\label{sec:proof simple formula}

In this chapter we verify the formula for the \(S\)-matrix directly.
For a heuristic derivation in the appendix in section\ref{sec:heuristic construction}


\begin{Thm}\label{sleek_second_quantised_scattering_operator}
For \(A\) such that 
\begin{equation}
\|\id-U^A\|<1.
\end{equation}\label{eq:sleek_scattering}
The second quantized scattering operator fulfils
\begin{equation}\label{eq:sleek_second_quantised_scattering_operator}
S^A= e^{i \varphi^A} e^{\mathrm{d}\Gamma(\ln (U^A))}
\end{equation}
for some phase \(\varphi^A\in\mathbb{R}\), that may depend on the external field \(A\).

\end{Thm}
\begin{proof}
In order to establish this theorem we need to verify that the expression given in \eqref{eq:sleek_scattering} for the scattering operator
 is a well defined object
and fulfils \eqref{lift_condition1} and \eqref{lift_condition2}. Because these conditions uniquely fix the Operator \(S^A\)  up to a phase this suffices as a proof.

Well definedness is established, by theorem \ref{Gamma essential selfadjointness}, because for unitary \(U^A\)
with \(\|1-U^A\|<1\) the power series of the logarithm converges and fulfils
\begin{align}
\|\ln(U^A)\|=\|\ln (1-(1-U^A))\|= \left\| -\sum_{k=1}^\infty \frac{(1-U^A)^k}{k} \right\|\\
 \le   \sum_{k=1}^\infty \frac{\|1-U^A\|^k}{k}=-\ln(1-\|1-U^A\|)
\end{align}
implying that the power series of the logarithm around the identity is a well defined map from the one particle operators of norm less than
one to the bounded one particle operators. Moreover this operator fulfils \([\ln (U^A)]^*=\ln (U^A)^*= \ln (U^A)^{-1}=-\ln (U^A)\), so 
\(\mathrm{d}\Gamma(\ln U^A)\) is a well defined unbounded operator that is essentially self adjoint on the finite particle sector of Fockspace \(\mathcal{F}'\).


Let \(\varphi\in \mathcal{H}\), for any \(k\in \mathbb{N}_0\) we see applying the commutation relation of \(\mathrm{d}\Gamma\):
\begin{multline*}
\mathrm{d}\Gamma(\ln U) \sum_{l=0}^k \binom{k}{l} a^\# \left(\left(\ln U\right)^l \varphi \right) \left(\mathrm{d}\Gamma(\ln U)\right)^{k-l} = \\
\sum_{l=0}^k \binom{k}{l} a^\# \left(\left(\ln U\right)^{l+1} \varphi \right) \left(\mathrm{d}\Gamma(\ln U)\right)^{k-l}\\
+\sum_{l=0}^k \binom{k}{l} a^\# \left(\left(\ln U\right)^l \varphi \right) \left(\mathrm{d}\Gamma(\ln U)\right)^{k-l+1}\\
= \sum_{b=0}^{k+1} \left( \binom{k}{b-1} + \binom{k}{b}\right) a^\#\left( (\ln U)^b \varphi\right) \left( \mathrm{d}\Gamma(\ln U)\right)^{k+1-b}\\
=\sum_{b=0}^{k+1}  \binom{k+1}{b}  a^\#\left( (\ln U)^b \varphi\right) \left( \mathrm{d}\Gamma(\ln U)\right)^{k+1-b},
\end{multline*}
so we see that for \(k\in\mathbb{N}_0\)
\begin{equation}
\left(\mathrm{d}\Gamma(\ln U)\right)^k a^\# (\varphi) = \sum_{b=0}^{k}  \binom{k}{b}  a^\#\left( (\ln U)^b \varphi\right) \left( \mathrm{d}\Gamma(\ln U)\right)^{k-b}
\end{equation}
holds. Let \(\alpha \in \mathcal{F}'\). Using what we just obtained, we conclude
\begin{multline*}
e^{\mathrm{d}\Gamma(\ln U)}a^\#(\varphi) = \sum_{k=0}^\infty \frac{1}{k!} \left(\mathrm{d}\Gamma(\ln U)\right)^k a^\# (\varphi)\alpha\\
=\sum_{k=0}^\infty \frac{1}{k!}  \sum_{b=0}^{k}  \binom{k}{b}  a^\#\left( (\ln U)^b \varphi \right) \left( \mathrm{d}\Gamma(\ln U)\right)^{k-b}\alpha\\
\overset{*}{=}\sum_{c=0}^\infty \sum_{l=0}^\infty \frac{1}{c! l!} a^\#\left( (\ln U)^c \varphi \right) \left( \mathrm{d}\Gamma(\ln U)\right)^{l}\alpha\\
=a^\#\left( e^{\ln U} \varphi \right) e^{\mathrm{d}\Gamma( \ln U)}\alpha
=a^\#\left( U \varphi \right) e^{\mathrm{d}\Gamma( \ln U)}\alpha.
\end{multline*}
For the marked equality changing oder of summation is justified, because by the bounds
 \(\|a^\#((\ln U)^c \varphi)\|\le \|\ln U\|^c\) and  lemma \ref{Gamma exponential bound} the sum obtained by changing the order
 of summands converges absolutely.
Clearly multiplying the second quantised operator by an additional phase as in 
\eqref{sleek_second_quantised_scattering_operator} does not influence this calculation.
\end{proof}

\noch{decide whether to use or delete this part.}
As a preparation for calculating the vacuum polarisation current we proof the following 
\begin{Lemma}\label{G_kommutator}
Let \(P_k,P_l\in Q\) then the following holds
\begin{equation}
\left[G(P_k),G(P_l)\right]= 
\tr\left(P_{\stackrel{k}{-+}}P_{\stackrel{l}{+-}}\right)
-\tr\left(P_{\stackrel{l}{-+}}P_{\stackrel{k}{+-}}\right) 
+G\left(\left[P_k,P_l\right]\right)
.\end{equation}
\end{Lemma}
For a proof of this lemma let \(P_k,P_l \in Q\), we compute
\begin{align*}
&\left[G(P_k),G(P_l)\right]\stackrel{\eqref{G commutator}}{=}\\
&=\sum_{n,b\in\mathbb{N}} \left[ a^*\left(P_k\varphi_n\right) a(\varphi_n), a^*\left(P_l\varphi_b\right)a(\varphi_n)\right]\\
&-\sum_{-b,n\in\mathbb{N}}\left[a^*\left(P_k\varphi_n\right)a(\varphi_n), a(\varphi_b) a^*\left(P_l\varphi_b\right)\right]\\
&-\sum_{-n,b\in\mathbb{N}}\left[a(\varphi_n)a^*\left(P_k\varphi_n\right),a^*\left(P_l\varphi_b\right)a(\varphi_b)\right]\\
&+\sum_{n,b\in\mathbb{N}}\left[ a(\varphi_n)a^*\left(P_k\varphi_n\right), a(\varphi_b)a^*\left(P_l\varphi_b\right)\right]\\
&=\sum_{n,b\in\mathbb{N}} \left(a^*\left(P_k\varphi_n\right)\left<\varphi_n,P_l\varphi_b\right>a(\varphi_b)-a^*\left(P_l\varphi_b\right) \left<\varphi_b,P_k\varphi_n\right>a(\varphi_n) \right)\\
&-\sum_{-b,n\in\mathbb{N}}\left( - \left<\varphi_b,P_k \varphi_n\right>a(\varphi_n)a^*\left(P_l\varphi_b\right) + a(\varphi_b) a^*\left(P_k\varphi_n\right)\left<\varphi_n,P_l\varphi_b\right>\right)\\
&-\sum_{-n,b\in\mathbb{N}} \left( - \left< \varphi_n,P_l\varphi_b\right> a^*\left(P_k\varphi_n\right) a(\varphi_b) + a^*\left(P_l\varphi_b\right)a(\varphi_n)\left<\varphi_b,P_k\varphi_n\right>\right)\\
&+\sum_{n,b\in -\mathbb{N}} \left(a(\varphi_n) \left< \varphi_b,P_k\varphi_n\right>a^*\left(P_l\varphi_b\right)-a(\varphi_b)\left<\varphi_n,P_l\varphi_b\right> a^*\left(P_k\varphi_n\right)\right)\\
&=\sum_{b\in\mathbb{N}} a^*\left(P_k P_{\stackrel{l}{++}}\varphi_b\right)a(\varphi_b) - \sum_{n\in\mathbb{N}}a^*\left(P_l P_{\stackrel{k}{++}}\varphi_n\right)a(\varphi_n)\\
&+\sum_{n\in\mathbb{N}}a(\varphi_n)a^*\left(P_l P_{\stackrel{k}{-+}}\varphi_n\right) - \sum_{-b\in\mathbb{N}} a(\varphi_b)a^*\left(P_k P_{\stackrel{l}{+-}}\varphi_b\right)\\
&+\sum_{b\in\mathbb{N}}a^*\left(P_k P_{\stackrel{l}{-+}}\varphi_b\right)a(\varphi_b)-\sum_{-n\in\mathbb{N}}a^*\left(P_l P_{\stackrel{k}{+-}}\varphi_n\right) a(\varphi_n)\\
&+\sum_{-n\in\mathbb{N}}a(\varphi_n)a^*\left(P_l P_{\stackrel{k}{--}}\varphi_n\right) - \sum_{-b \in \mathbb{N}} a(\varphi_b)a^*\left(P_k P_{\stackrel{l}{--}}\varphi_b\right)\\
=&\sum_{n\in\mathbb{N}} a^*\left(P_k P_l \varphi_n \right) a(\varphi_n) - \sum_{n\in\mathbb{N}} a^*\left(P_l P_{\stackrel{k}{++}} \varphi_n \right) a(\varphi_n)\\
&+\tr \left( P_{\stackrel{l}{+-}} P_{\stackrel{k}{-+}}\right) - \sum_{n\in\mathbb{N}} a^*\left( P_l P_{\stackrel{k}{-+}} \varphi_n\right)a(\varphi_n)\\
&-\tr \left( P_{\stackrel{l}{-+}} P_{\stackrel{k}{+-}}\right) + \sum_{-b\in\mathbb{N}} a(\varphi_b) a^*\left(P_l P_{\stackrel{k}{+-}} \varphi_b\right)\\
&+\sum_{-b\in\mathbb{N}} a(\varphi_b) a^*\left( P_l P_{\stackrel{k}{--}}\varphi_b\right) - \sum_{-b\in\mathbb{N}} a(\varphi_b) a^*\left( P_k P_l \varphi_b\right)\\
&=\tr \left( P_{\stackrel{l}{+-}} P_{\stackrel{k}{-+}}\right)
-\tr \left( P_{\stackrel{l}{-+}} P_{\stackrel{k}{+-}}\right)\\
&+\sum_{n\in\mathbb{N}} a^*\left(\left[P_k ,P_l\right] \varphi_n \right) a(\varphi_n)
+\sum_{-b\in\mathbb{N}} a(\varphi_b)a^*\left(\left[P_l ,P_k\right] \varphi_b \right) \\
&=\tr \left( P_{\stackrel{l}{+-}} P_{\stackrel{k}{-+}}\right)
-\tr \left( P_{\stackrel{l}{-+}} P_{\stackrel{k}{+-}}\right)
+G\left(\left[P_k,P_l\right]\right)
\end{align*}
\qed

\begin{Def}
For \(k\in\mathbb{N}_0\), \(X,Y\in \mathcal{B}(\mathcal{H})\) the nested commutator \([X,Y]_k\) is defined inductively as
\begin{align*}
[X,Y]_0&:= Y\\
[X,Y]_{k+1}&:=[X,[X,Y]_{k}] \quad \forall k\in\mathbb{N}_0.
\end{align*}
\end{Def}

\begin{Lemma}\label{nested_kommuted_G}
For \(m\in\mathbb{N}\) and \(B,C \in Q\) the following holds
\begin{multline}
\left[ G(B),G(C)\right]_m=  \tr\left(P_-BP_+[B,C]_{m-1}\right) - \tr\left(P_+BP_-[B,C]_{m-1}\right)\\
+G\left([B,C]_m\right) .
\end{multline}
\end{Lemma}
\textbf{Proof:} Proof by Induction is the first thing that comes to mind, looking at the claim. Indeed, \(m=1\) is the consequence
of the lemma \ref{G_kommutator}. For \(m\) general we have

\begin{multline}
\left[ G(B),G(C)\right]_{m+1}
=\left[ G(B),\left[ G(B),G(C)\right]_{m}\right]\\
\stackrel{\text{ind.hyp.}}{=}\left[ G(B), \tr\left(P_-BP_+[B,C]_{m-1}\right) - \tr\left(P_+BP_-[B,C]_{m-1}\right)
+G\left([B,C]_m\right) \right]\\
=\left[ G(B),G\left([B,C]_m\right) \right]\\
\stackrel{\text{lemma } \ref{G_kommutator}}{=} 
\tr\left(P_- B P_+ [B,C]_m\right)
-\tr\left(P_+BP_- [B,C]_m \right) 
+G\left(\left[B,[B,C]_m\right]\right)\\
=
\tr\left(P_- B P_+ [B,C]_m\right)
-\tr\left(P_+BP_- [B,C]_m \right) 
+G\left([B,C]_{m+1}\right)
\end{multline}
\qed 

\begin{Lemma}\label{lemma:derivativeJ}
For external potentials \(A, X\) small enough the derivatives of the scattering operator can be computed to fulfil
\begin{align}\label{eq:derivativeS1}
\partial_\varepsilon |_{\varepsilon=0} e^{G \ln U^{A+\varepsilon X}} &= e^{G \ln U^A} j_A^0(X) + e^{G \ln U^A} G( (U^A)^{-1} \partial_{\varepsilon} U^{A+\varepsilon X})\\
\partial_\varepsilon |_{\varepsilon=0} e^{-G \ln U^{A+\varepsilon X}} &=- e^{-G \ln U^A} j_A^0(X) + G( \partial_{\varepsilon} \left(U^{A+\varepsilon X}\right)^{-1} U^A ) e^{-G \ln U^A},
\end{align}
with 
\begin{multline}\label{def:vacuumExpectationCurrent}
j^0_A(X):= \sum_{l\in\mathbb{N}_0} \frac{(-1)^{l+1}}{(l+2)!} \left(\tr P_- \ln U^A P_+ \left[ \ln U^A, \partial_\varepsilon \ln U^{A+\varepsilon X}\right]_{l}\right.\\
\left. - \tr P_+ \ln U^A P_- \left[ \ln U^A, \partial_\varepsilon \ln U^{A+\varepsilon X}\right]_{l} \right).
\end{multline}
\end{Lemma}
\textbf{Proof:} We start out by employing Duhamel's and Hadamard's formulas. \todo{ref!! + restrictions, something better than 
 \href{https://s3.amazonaws.com/academia.edu.documents/46627661/CBH.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1517999839&Signature=m\%2FGNTMS\%2FNAH7ioWII76ZlULcCRY\%3D&response-content-disposition=inline\%3B\%20filename\%3DCrib_Notes_on_Campbell-Baker-Hausdorff_e.pdf}{this}}
These are

\begin{equation}\label{Duhamel}
\partial_{\alpha}\left. e^{Y+\alpha X}\right|_{\alpha=0} = \int_0^1 d t e^{(1-t) Y} X e^{t Y}\tag{Duhamel's formula}
\end{equation}

and
\begin{equation}\tag{Hadamard's formula}\label{Hadamard}
e^{X}Ye^{-X}=\sum_{k=0}^\infty \frac{1}{k!} [X,Y]_k.
\end{equation}

So one gets

\begin{align}\label{proof:duhamelApplied}
\partial_\varepsilon |_{\varepsilon=0} e^{G \ln U^{A+\varepsilon X}} &= \int_0^1 d z e^{(1-z) G \ln U^A} \partial_\varepsilon |_{\varepsilon=0} G \ln U^{A+\varepsilon X} e^{z G \ln U^A}\\\notag
&=e^{G \ln U^A} \int_0^1 d z \sum_{l\in\mathbb{N}_0} \frac{1}{l!} \left[ - z G \ln U^A, \partial_\varepsilon |_{\varepsilon=0} G \ln U^{A+\varepsilon X} \right]_l\\\notag
&=e^{G \ln U^A} \int_0^1 d z \sum_{l\in\mathbb{N}_0} \frac{(-z)^l}{l!} \partial_\varepsilon |_{\varepsilon=0} \left[  G \ln U^A,  G \ln U^{A+\varepsilon X} \right]_l.
\end{align}
At this point we see that for \(l=0\) the summand vanishes. For all other values of \(l\) we use lemma \ref{nested_kommuted_G}, yielding
\begin{multline}
\partial_\varepsilon |_{\varepsilon=0} e^{G \ln U^{A+\varepsilon X}}= 
e^{G \ln U^A} \int_0^1 d z \sum_{l\in\mathbb{N}} \frac{(-z)^l}{l!} \partial_\varepsilon |_{\varepsilon=0} \left( G\left(\left[ \ln U^A, \ln U^{A+\varepsilon X}\right]\right) \right.\\
+\tr P_- \ln U^A P_+ \left[ \ln U^A, \partial_\varepsilon |_{\varepsilon=0} \ln U^{A+\varepsilon X}\right]_{l-1}\\
\left. - \tr P_+ \ln U^A P_- \left[ \ln U^A, \partial_\varepsilon |_{\varepsilon=0} \ln U^{A+\varepsilon X}\right]_{l-1}\right).
\end{multline}

The last two terms together result in the first term of \eqref{eq:derivativeS1} after performing the integration and shifting the summation
index. For the first term we will use linearity and continuity of \(G\)\todo{contiuity of G!!}   ~and use the same identities backwards to give

\begin{multline}
e^{G \ln U^A} \int_0^1 d z \sum_{l\in\mathbb{N}} \frac{(-z)^l}{l!} \partial_\varepsilon |_{\varepsilon=0} G\left(\left[ \ln U^A, \ln U^{A+\varepsilon X}\right]\right) \\
=e^{G \ln U^A}  G\left( \int_0^1 d z \sum_{l\in\mathbb{N}} \frac{1}{l!}  \left[ -z \ln U^A,\partial_\varepsilon|_{\varepsilon=0} \ln U^{A+\varepsilon X}\right]\right) \\
=e^{G \ln U^A}  G\left(e^{- \ln U^A} \int_0^1 d z e^{ \ln U^A} e^{-z \ln U^A}\partial_\varepsilon|_{\varepsilon=0} \ln U^{A+\varepsilon X} e^{z \ln U^A}\right) \\
=e^{G \ln U^A}  G\left(e^{ \ln \left(U^A\right)^{-1}} \partial_\varepsilon|_{\varepsilon=0} e^{ \ln U^{A+\varepsilon X}} \right) \\
=e^{G \ln U^A}  G\left(\left(U^A\right)^{-1} \partial_\varepsilon|_{\varepsilon=0}U^{A+\varepsilon X} \right).
\end{multline}
Putting things together results in the first equality we wanted to prove. For the second one the computation is completely analogous, except for after applying Duhamel's formula as in \eqref{proof:duhamelApplied} we substitute \(u=1-z\). The minus sign in front of the first term then arises by the chain rule, where as the second term does not share the sign change with the first, since we have to revert the use of the chain rule in the second half of the calculation when we apply  \eqref{Duhamel} backwards. \qed

\begin{Def}
We use Bogoliubov's formula to define the vacuum expectation value of the current \todo{ref!!}
\begin{equation}
j_A(F) = i \partial_{\varepsilon}\left. \langle \Omega, {S^{A} }^* S^{A+\varepsilon F}\Omega \rangle \right|_{\varepsilon=0}.
\end{equation}
\end{Def}



\begin{Thm}\label{thm:CurrentExact}
The vacuum expectation value of the current of the scattering operator takes the form
\begin{align*}
j_A(F)&=- \partial_{\varepsilon} \left. \varphi(A+\varepsilon F) \right|_{\varepsilon=0}\\
-2\int_0^1 &d z (1-z)  \Im \tr\left(P_+ \ln U^A P_- e^{ -z \ln U^A} \partial_{\varepsilon} \left. \ln U^{A+\varepsilon F}\right|_{\varepsilon=0} e^{ z \ln U^A}\right)\\
&=- \partial_{\varepsilon} \left.\varphi(A+\varepsilon F) \right|_{\varepsilon=0}\\
  - 2\Im \sum_{k=0}^\infty&\frac{(-1)^k}{(k+2)!}  \tr \left( P_+ \ln U^A P_-\left[\ln U^A,\left.\partial_{\varepsilon}\ln U^{A+\varepsilon F} \right|_{\varepsilon=0}\right]_{k}\right) 
\end{align*}
\end{Thm}
\textbf{Proof:} By theorem \ref{sleek_second_quantised_scattering_operator} and abbreviating
\(\varphi(A)= \sum_{n\in\mathbb{N}} \frac{C_n(A)}{n!} \)we see that the current can be written in the form

\begin{multline}\label{sleek_current_calc1}
j_A(F) = i \partial_{\varepsilon}\left. \langle \Omega, {S^{A} }^* S^{A+\varepsilon F}\Omega \rangle \right|_{\varepsilon=0}\\
=i \partial_{\varepsilon}\left. \langle \Omega, e^{-i\varphi(A)} e^{-G(\ln (U^A))} 
e^{i\varphi(A+\varepsilon F)}  e^{G(\ln (U^{A+\varepsilon F}))} \Omega\rangle \right|_{\varepsilon=0}\\
=- \partial_{\varepsilon} \left. \varphi(A+\varepsilon F) \right|_{\varepsilon=0}
+i\langle \Omega,\partial_{\varepsilon}\left.  e^{-G(\ln (U^A))} 
e^{G(\ln (U^{A+\varepsilon F}))} \Omega\rangle \right|_{\varepsilon=0},
\end{multline}
so the first summand works out just as claimed. For the second summand we employ lemma \ref{lemma:derivativeJ} and note that the vacuum expectation value of \(G\) vanishes no matter its argument.

\begin{multline}\label{sleek_current_calc3}
i\langle \Omega,\partial_{\varepsilon}\left.  e^{-G(\ln (U^A))} 
e^{G(\ln (U^{A+\varepsilon F}))} \Omega\rangle \right|_{\varepsilon=0}\\
=-i  \partial_{\varepsilon} \left.\sum_{k=0}^\infty \frac{(-1)^k}{(k+2)!} 
 \tr\left(P_- \ln U^A P_+[\ln U^A ,\ln U^{A+\varepsilon F} ]_{k}\right) \right|_{\varepsilon=0}\\
 +i  \partial_{\varepsilon} \left.\sum_{k=0}^\infty \frac{(-1)^k}{(k+2)!}  \tr\left(P_+ \ln U^A P_-[\ln U^A,\ln U^{A+\varepsilon F} ]_{k}\right) \right|_{\varepsilon=0}\\ 
\end{multline}

In order to apply Hadamard's formula once again in the opposite direction, we introduce two auxiliary integrals.
The second term then becomes

\begin{multline}\label{sleek_current_calc4}
 i  \partial_{\varepsilon} \left.\sum_{k=0}^\infty \frac{(-1)^k}{(k+2)!}  \tr\left(P_+ \ln U^A P_-[\ln U^A,\ln U^{A+\varepsilon F} ]_{k}\right) \right|_{\varepsilon=0}\\
= i  \partial_{\varepsilon} \left.\sum_{k=0}^\infty \frac{(-1)^k}{k!} \int_0^1 d t \int_0^1 s^k t^{k+1}
\tr\left(P_+ \ln U^A P_-[\ln U^A,\ln U^{A+\varepsilon F} ]_{k}\right) \right|_{\varepsilon=0}\\
= i  \partial_{\varepsilon} \left.\sum_{k=0}^\infty \frac{1}{k!} \int_0^1 d t \int_0^1 ds\ t
\tr\left(P_+ \ln U^A P_-[ -t s \ln U^A,\ln U^{A+\varepsilon F} ]_{k}\right) \right|_{\varepsilon=0}\\
= i  \partial_{\varepsilon} \left.\sum_{k=0}^\infty \frac{1}{k!} \int_0^1 d z \int_z^1 ds\ 
\tr\left(P_+ \ln U^A P_-[ -z \ln U^A,\ln U^{A+\varepsilon F} ]_{k}\right) \right|_{\varepsilon=0}\\
= i  \partial_{\varepsilon} \left.\sum_{k=0}^\infty \frac{1}{k!} \int_0^1 d z (1-z)
\tr\left(P_+ \ln U^A P_-[ -z \ln U^A,\ln U^{A+\varepsilon F} ]_{k}\right) \right|_{\varepsilon=0}\\
= i  \partial_{\varepsilon} \left. \int_0^1 d z (1-z) 
\tr\left(P_+ \ln U^A P_- \sum_{k=0}^\infty \frac{1}{k!} [ -z \ln U^A,\ln U^{A+\varepsilon F} ]_{k}\right) \right|_{\varepsilon=0}\\
\stackrel{\eqref{Hadamard}}{=} i  \partial_{\varepsilon} \left. \int_0^1 d z (1-z) 
\tr\left(P_+ \ln U^A P_- e^{ -z \ln U^A}\ln U^{A+\varepsilon F} e^{ z \ln U^A}\right) \right|_{\varepsilon=0}\\
=i  \int_0^1 d z (1-z) 
\tr\left(P_+ \ln U^A P_- e^{ -z \ln U^A} \partial_{\varepsilon} \left. \ln U^{A+\varepsilon F}\right|_{\varepsilon=0} e^{ z \ln U^A}\right) .
\end{multline}

The calculation for the first term of \eqref{sleek_current_calc3} is identical.
At this point we notice that \eqref{sleek_current_calc4} and the term where the 
projectors are exchanged are complex conjugates of one another. So summarising we find
\begin{multline*}
j_A(F)=- \partial_{\varepsilon} \left. \varphi (A+\varepsilon F) \right|_{\varepsilon=0}\\
-2\int_0^1 d z (1-z)  \Im \tr\left(P_+ \ln U^A P_- e^{ -z \ln U^A} \partial_{\varepsilon} \left. \ln U^{A+\varepsilon F}\right|_{\varepsilon=0} e^{ z \ln U^A}\right).
\end{multline*}
\qed

\begin{Thm}
Independent of the phase that is used to correct the scattering operator the following formula holds true for any 
 four potentials \(A,F,H\), with \(A\) small enough so that the relevant series converge.
\begin{multline}
\partial_\varepsilon |_{\varepsilon=0} ( j_{A+\varepsilon H} (F)-j_{A+\varepsilon F}(H)) = \\
2 \Im \tr \left(P_+ \left(U^A\right)^{-1} \partial_{\varepsilon}|_{\varepsilon=0} U^{A+\varepsilon F} P_-\left(U^A\right)^{-1} \partial_{\delta}|_{\delta=0} U^{A+\delta H}\right)
\end{multline}
\end{Thm}
\textbf{Proof:} We compute \(\partial_\varepsilon |_{\varepsilon=0} j_{A+\varepsilon F}(H) \). 

\begin{align*}
&-i\partial_\varepsilon |_{\varepsilon=0} j_{A+\varepsilon H}(F)=\\
&\partial_\varepsilon |_{\varepsilon=0} \partial_\delta |_{\delta=0} \langle \Omega, e^{i\varphi(A+\varepsilon H + \delta F)-i\varphi(A+\varepsilon H)} e^{-G \ln U^{A+\varepsilon H}} e^{G \ln U^{A+\varepsilon H + \delta F}}\Omega \rangle\\
\end{align*}

We first act with the derivative with respect to \(H\), fixing \(F\).

\begin{align*}
&-i\partial_\varepsilon |_{\varepsilon=0} j_{A+\varepsilon H}(F)=\\
&\partial_\delta |_{\delta=0}   i(\partial_\varepsilon |_{\varepsilon=0}\varphi(A+\varepsilon H + \delta F)-\partial_\varepsilon |_{\varepsilon=0}\varphi(A+\varepsilon H ))e^{i\varphi(A + \delta F)-i\varphi(A)} \\
&\langle \Omega, e^{-G \ln U^{A}} e^{G \ln U^{A + \delta F}}\Omega \rangle\\
&+\partial_\delta |_{\delta=0} e^{i\varphi(A + \delta F)-i\varphi(A)} \langle \Omega
\partial_\varepsilon |_{\varepsilon=0} e^{-G \ln U^{A+\varepsilon H}} e^{G \ln U^{A + \delta F}}\Omega \rangle\\
&+\partial_\delta |_{\delta=0} e^{i\varphi(A + \delta F)-i\varphi(A)} 
 \langle \Omega e^{-G \ln U^{A}} \partial_\varepsilon |_{\varepsilon=0}e^{G \ln U^{A+\varepsilon H + \delta F}}\Omega \rangle
\end{align*}

In computing further one can notice a few cancellations. For the first summand the first factor vanishes if \(\delta\) is set to zero, so the only 
the first summand in the product rule will not vanish. For the second and third summand we will use lemma \ref{lemma:derivativeJ},
giving

\begin{align*}
&-i\partial_\varepsilon |_{\varepsilon=0} j_{A+\varepsilon H}(F)=\\
&\partial_\delta |_{\delta=0}   i\partial_\varepsilon |_{\varepsilon=0}\varphi(A+\varepsilon H + \delta F)\\
&-\partial_\delta |_{\delta=0} e^{i\varphi(A + \delta F)-i\varphi(A)}  j^0_{A}(H) 
\langle \Omega, e^{-G \ln U^{A}} e^{G \ln U^{A + \delta F}}\Omega \rangle \\
&+\partial_\delta |_{\delta=0} e^{i\varphi(A + \delta F)-i\varphi(A)} \langle \Omega,
 G \left(\partial_\varepsilon |_{\varepsilon=0} \left(U^{A+\varepsilon H}\right)^{-1} U^A\right) e^{-G \ln U^{A}} e^{G \ln U^{A + \delta F}}  \Omega \rangle\\
&+\partial_\delta |_{\delta=0} e^{i\varphi(A + \delta F)-i\varphi(A)} j^0_{A+\delta F}(H)
\langle \Omega, e^{-G \ln U^{A}} e^{G \ln U^{A+ \delta F}}\Omega \rangle\\
&+\partial_\delta |_{\delta=0} e^{i\varphi(A + \delta F)-i\varphi(A)} 
\langle \Omega, e^{-G \ln U^{A}} e^{G \ln U^{A+ \delta F}}G\left( \left(U^{A+\delta F}\right)^{-1}\partial_\varepsilon |_{\varepsilon=0} U^{A+\varepsilon H + \delta F} \right) \Omega \rangle.
\end{align*}

Now there are a few further simplifications to appreciate: since \(\langle \Omega, G \Omega \rangle=0\), in the third and last summand only the derivatives with respect to \(\delta\) which produce by lemma \ref{lemma:derivativeJ} another factor of \(G\)  will contribute to the sum.
 For the other summands except for the first we can spot the appearance of \(j^0\). Respecting all this results in

\begin{align*}
&-i\partial_\varepsilon |_{\varepsilon=0} j_{A+\varepsilon H}(F)=
i\partial_\delta |_{\delta=0}   \partial_\varepsilon |_{\varepsilon=0}\varphi(A+\varepsilon H + \delta F)\\
&-i\partial_\delta |_{\delta=0}\varphi(A + \delta F)j^0_{A}(H) -  j^0_{A}(H) j^0_A(F)\\
&+\langle \Omega,
 G \left(\partial_\varepsilon |_{\varepsilon=0} \left(U^{A+\varepsilon H}\right)^{-1} U^A\right) G\left( \left(U^{A}\right)^{-1}\partial_\delta |_{\delta=0} U^{A +\delta F} \right)  \Omega \rangle\\
&+i\partial_\delta |_{\delta=0} \varphi(A + \delta F) j^0_{A}(H)
+\partial_\delta |_{\delta=0}  j^0_{A+\delta F}(H)
+ j^0_{A}(H)j^0_A(F)\\
&+\langle \Omega, G\left( \left(U^{A}\right)^{-1}\partial_\delta |_{\delta=0} U^{A + \delta F} \right) G\left( \left(U^{A}\right)^{-1}\partial_\varepsilon |_{\varepsilon=0} U^{A+\varepsilon H} \right) \Omega \rangle.
\end{align*}

A few more terms cancel in the second and fourth line, also since \(\partial_\varepsilon |_{\varepsilon=0} \left(U^{A+\varepsilon H}\right)^{-1} U^{A+\varepsilon H}=0\) we can combine the two products of \(G\) into a commutator:

\begin{align*}
&-i\partial_\varepsilon |_{\varepsilon=0} j_{A+\varepsilon H}(F)=
i\partial_\delta |_{\delta=0}   \partial_\varepsilon |_{\varepsilon=0}\varphi(A+\varepsilon H + \delta F)\\
&+\partial_\delta |_{\delta=0}  j^0_{A+\delta F}(H)\\
&+\langle \Omega, \left[G\left( \left(U^{A}\right)^{-1}\partial_\delta |_{\delta=0} U^{A + \delta F} \right), G\left( \left(U^{A}\right)^{-1}\partial_\varepsilon |_{\varepsilon=0} U^{A+\varepsilon H} \right)\right] \Omega \rangle.
\end{align*}

So we can once again apply lemma \ref{G_kommutator}, which results in exactly right hand side of the equation
we claimed to produce in the statement of this theorem. So all that is left is to recognise that one can combine
the first two summands into \(-i \partial_{\varepsilon} j_{A+\varepsilon H} (F)\), which is a direct consequence
of theorem \ref{thm:CurrentExact}.\qed

\section{Quantitative Estimates}
\noch{probably this part cannot be made rigorous. Decide whether to keep it as heuristics}
Since we do not only want to give an expression for the time evolution operator, but also give bounds on the numerical errors
which are due to truncate the occurring series we need to look at these series a little closer. The series involve powers of the 
second quantisation operator \(G\), so we start by examining these in greater depth. In order to do so we define an object 
closely related to \(G\).

\begin{Def}
\begin{multline}\label{def:L}
L: \{M\subset B(\mathcal{H})\mid |M|<\infty\} \times \{M\subset B(\mathcal{H})\mid |M|<\infty\} \rightarrow B(\mathcal{F})\\
L(\{A_1,\dots, A_c\},\{ B_1,\dots ,B_m\}):= \prod_{l=1}^m a(\varphi_{-k_l}) \\
\prod_{l=1}^c a^*(A_l \varphi_{n_l}) \prod_{l=1}^m a^*(B_l \varphi_{-k_l}) \prod_{l=1}^c a(\varphi_{n_l}),
\end{multline}
where for notational reasons we chose to list the occurring one-particle operators in a specific order; however, 
the order does not matter, since commutation of the relevant creation and annihilation operators always results an 
overall factor of one.
\end{Def}

Since this operator \(L\) occurs when computing powers of \(G\) we compute is product with some \(G\) with 
the following 

\begin{Lemma}\label{lem:Ntimes1} For any \(a,b,\in\mathbb{N}_0\) and apropriate one particle operators \(A_k, B_l, C\) for \(1\le k\le a\), \(1\le l\le b\) we have the following equality
\begin{align}
&L\Big(\bigcup_{l=1}^a \{A_l\}; \bigcup_{l=1}^b \{B_l\}\Big)G(C) =\\\label{Ntimes1:simplyAdd1}
 &(-1)^{a+b} L\Big(\bigcup_{l=1}^a \{A_l\}\cup \{C\}; \bigcup_{l=1}^b \{B_l\}\Big) \\\label{Ntimes1:simplyAdd2}
 &+(-1)^{a+b+1} L\Big(\bigcup_{l=1}^a \{A_l\}; \bigcup_{l=1}^b \{B_l\}\cup \{C\} \Big) \\\label{Ntimes1:n+1atEnd1}
&+ \sum_{f=1}^a  L\Big(\bigcup_{\stackrel{l=1}{l\neq f}}^a \{A_l\}\cup \{A_fP_+C \}; \bigcup_{l=1}^b \{B_l\}\Big) \\\label{Ntimes1:n+1atBeginning1}
&+\sum_{f=1}^a
 L\Big(\bigcup_{\stackrel{l=1}{f\neq l}}^a \{A_l\}\cup \{- CP_- A_f\}; \bigcup_{l=1}^b \{B_l\}\Big)\\\label{Ntimes1:n+1atEnd2}
& -\sum_{f=1}^a L\Big(\bigcup_{\stackrel{l=1}{f\neq l}}^a \{A_l\}; \bigcup_{l=1}^b \{B_l\}\cup \{A_f P_+ C\}\Big)\\\label{Ntimes1:n+1atBeginning2}
&+ \sum_{f=1}^b L\Big(\bigcup_{l=1}^a \{A_l\}; \bigcup_{\stackrel{l=1}{l\neq f}}^b \{B_l\}\cup \{-CP_- B_f\}\Big)\\\label{Ntimes1:TrTerm}
&+ (-1)^{a+b+1} \sum_{f=1}^a \tr \Big(P_+ C P_- A_f\Big) L\Big(\bigcup_{\stackrel{l=1}{l \neq f}}^a \{A_l\}; \bigcup_{l=1}^b \{B_l\}\Big)\\\label{Ntimes1:middle1}
&+ (-1)^{a+b+1} \sum_{\stackrel{f_1,f_2=1}{f_1\neq f_2}}^a L\Big(\bigcup_{\stackrel{l=1}{l\neq f_1,f_2}}^a \{A_l\}\cup \{-A_{f_2} P_+ C P_- A_{f_1}\}; \bigcup_{l=1}^b \{B_l\}\Big)\\\label{Ntimes1:middle2}
&+(-1)^{a+b+1} \sum_{f=1}^b \sum_{g=1}^a L\Big(\bigcup_{\stackrel{l=1}{l\neq g}}^a \{A_l\}; \bigcup_{\stackrel{l=1}{l\neq f}}^b \{B_l\}\cup \{-A_g P_+ C P_- B_f\}\Big).
\end{align}
\end{Lemma}
{\bfseries Proof:}  The proof of this equality is a rather long calculation, where \eqref{def:L} is used repeatedly. We break up the calculation into 
several parts. Let us start with

\begin{multline}
L\left(\bigcup_{l=1}^a \{A_l\}; \bigcup_{l=1}^b \{B_l\}\right) L(C;)=\\
\prod_{l=1}^b a(\varphi_{-k_l}) \prod_{l=1}^a a^*(A_l \varphi_{n_l}) \prod_{l=1}^b a^*(B_l \varphi_{-k_l}) \prod_{l=1}^a a(\varphi_{n_l}) a^*(C \varphi_m) a(\varphi_m).
\end{multline}

We (anti)commute the creation operator involving \(C\) to its place at the end of the second product, after that the term
will be normally ordered and can be rephrased in terms of \(L\)s. During the commutation the creation operator
in question can be picked up by any of the annihilation operators in the rightmost product. For each term where that happens
we can perform the sum over the basis of \(\mathcal{H}^-\) related to the annihilation operator whose anticommutator triggered.
After this sum the corresponding term is also normally ordered and can be rephrased in terms of an \(L\) after some 
reshuffling which may only produce signs. So performing these steps we get

\begin{multline}
L\left(\bigcup_{l=1}^a \{A_l\}; \bigcup_{l=1}^b \{B_l\}\right) L(C;)=\\
\sum_{f=a}^1 (-1)^{a-f} \prod_{l=1}^b a(\varphi_{-k_l}) \prod_{l=1}^{f-1} a^*(A_l \varphi_{n_l}) a^*(A_fP_+C\varphi_m)\\
 \prod_{l=f+1}^a a^*(A_l \varphi_{n_l}) \prod_{l=1}^b a^*(B_l \varphi_{-k_l}) \prod_{\stackrel{l=1}{l\neq f}}^a a(\varphi_{n_l}) a(\varphi_m)\\
+ L\left(\bigcup_{l=1}^a \{A_l\} \cup \{C\}; \bigcup_{l=1}^b \{B_l\}\right)\\
=\sum_{f=1}^a  L\left(\bigcup_{\stackrel{l=1}{l \neq f}}^a \{A_l\} \cup \{A_f P_+ C\}; \bigcup_{l=1}^b \{B_l\}\right)\\
+ L\left(\bigcup_{l=1}^a \{A_l\} \cup \{C\}; \bigcup_{l=1}^b \{B_l\}\right).
\end{multline}

Now the remaining case is more laborious, that is why we will split off and treat some of the appearing terms separately. 
We start off analogous to before 

\begin{multline}
L\left(\bigcup_{l=1}^a \{A_l\}; \bigcup_{l=1}^b \{B_l\}\right) L(;C)=\\
\prod_{l=1}^b a(\varphi_{-k_l}) \prod_{l=1}^a a^*(A_l \varphi_{n_l}) \prod_{l=1}^b a^*(B_l \varphi_{-k_l}) \prod_{l=1}^a a(\varphi_{n_l})a(\varphi_{-m}) a^*(C \varphi_{-m}).
\end{multline}

This time we need to (anti)commute the rightmost annihilation operator all the way to the end of the first product and the creation operator to the end of the second but last product. So there will be several qualitatively different terms. From the first step alone we get
\begin{align}\notag
L\left(\bigcup_{l=1}^a \{A_l\}; \bigcup_{l=1}^b \{B_l\}\right) L(;C)&=\\\notag
(-1)^{a}\sum_{f=b}^1 (-1)^{b-f} \prod_{l=1}^b a(\varphi_{-k_l}) &\prod_{l=1}^a a^*(A_l \varphi_{n_l}) \prod_{\stackrel{l=1}{l\neq f}}^b a^*(B_l \varphi_{-k_l})\\ \label{Ntimes1 term 1}
& \prod_{l=1}^a a(\varphi_{n_l}) a^*(C P_- B_f \varphi_{-k_f})\\\notag
+(-1)^{a+b}\sum_{f=a}^1 (-1)^{b-f} \prod_{l=1}^b a(\varphi_{-k_l}) &\prod_{\stackrel{l=1}{l\neq f}}^a a^*(A_l \varphi_{n_l})\\\label{Ntimes1 term 2}
& \prod_{l=1}^b a^*(B_l \varphi_{-k_l}) \prod_{l=1}^a a(\varphi_{n_l}) a^*(CP_- \varphi_{n_f})\\\notag
+(-1)^b\prod_{l=1}^b a(\varphi_{-k_l}) a(\varphi_{-m}) &\prod_{l=1}^a a^*(A_l \varphi_{n_l}) \\ \label{Ntimes1 term 3}
&\prod_{l=1}^b a^*(B_l \varphi_{-k_l}) \prod_{l=1}^a a(\varphi_{n_l})a^*(C \varphi_{-m}).
\end{align}

We will discuss terms \eqref{Ntimes1 term 1}, \eqref{Ntimes1 term 2} and \eqref{Ntimes1 term 3} separately. 
In Term \eqref{Ntimes1 term 1} we need to commute the last creation operator into its place in the third product,
it can be picked up by one of the annihilation operators of the last product, but after performing the sum over
the corresponding basis the resulting term can be rephrased in terms of an \(L\) operator by commuting
only creation operators of the second and third product. Performing these steps yields the identity

\begin{multline}
\eqref{Ntimes1 term 1}=\sum_{f=1}^b L\left( \bigcup_{l=1}^a \{A_l\}; \bigcup_{\stackrel{l=1}{l\neq f}}^b \{B_l\}\cup  \{CP_- B_f \}\right)\\
+(-1)^{a+b+1}\sum_{f=1}^b \sum_{g=1}^a L\left( \bigcup_{\stackrel{l=1}{l\neq g}}^a \{A_l\}; \bigcup_{\stackrel{l=1}{l\neq f}}^b \{B_l\} \{A_gP_+CP_- B_f \}\right).
\end{multline}

For \eqref{Ntimes1 term 2} the last creation operator needs to be commuted to the end of the second product. It can be picked up by 
one of the annihilation operators of the last product, but here we have to distinguish between two cases. If the index of this
annihilation operator equals \(f\) the resulting commutator will be \(\tr P_+ C P_- A_f \) otherwise one can again perform the sum
over the corresponding index and express the whole Product in terms of an \(L\) operator. All this results in 

\begin{multline}
\eqref{Ntimes1 term 2}=\sum_{f=1}^a L\left( \bigcup_{\stackrel{l=1}{l\neq f}}^a \{A_l\}\cup \{C P_- A_f\}; \bigcup_{l=1}^b \{B_l\}\right)\\
+(-1)^{a+b}\sum_{f=1}^a  L\left( \bigcup_{\stackrel{l=1}{l\neq f}}^a \{A_l\}; \bigcup_{l=1}^b \{B_l\} \right) \tr (P_+ C P_- A_f )\\
+(-1)^{a+b+1}\sum_{\stackrel{f_1,f_2=1}{f_1\neq f_2}}^a L\left( \bigcup_{\stackrel{l=1}{l\neq f_1,f_2}}^a \{A_l\} \cup \{A_{f_2} P_+CP_- A_{f_1} \}; \bigcup_{l=1}^b \{B_l\} \right).
\end{multline}

For \eqref{Ntimes1 term 3} the procedure is basically the same as for \eqref{Ntimes1 term 1}, it results in

\begin{multline}
\eqref{Ntimes1 term 3}= (-1)^{a+b} L\left( \bigcup_{l=1}^a \{A_l\}; \bigcup_{l=1}^b \{B_l\}\right)\\
+ \sum_{f=1}^a L\left( \bigcup_{\stackrel{l=1}{l \neq f}}^a \{A_l\}\cup \{C P_- A_f\}; \bigcup_{l=1}^b \{B_l\}\cup \{A_f P_+ C\}\right).
\end{multline}

Putting the results of the calculation together results in the claimed equation, after pulling in some factors of \(-1\) into \(L\). \qed

We carry on with defining the important quantities for powers of \(G\). First we introduce for each \(k \in \mathbb{N}\) a linear
bounded operator on \(\mathcal{H}\), \(X_k\) which fulfils \(\tr P_+ X_k P_- X_k<\infty\wedge \tr P_- X_k P_+ X_k<\infty\). 

\begin{Def}
Let 
\begin{equation*}
Y:=\{X_k\mid k\in\mathbb{N}\}.
\end{equation*}
Let for \(n\in\mathbb{N}\)
\begin{equation*}
\langle n\rangle := \{X_l\mid l\in\mathbb{N}, l\le n\}.
\end{equation*}
\end{Def}

\begin{Def}
Let for  \(b\subset Y\), such that \(|b|<\infty\)
\begin{align}\notag
f_b:\{l\in\mathbb{N}\mid l\le |b|\}\rightarrow b\\
\forall k<|b| : f_b(k)=X_l\wedge f_b(k+1)=X_m\rightarrow l<m
\end{align}
\end{Def}

\begin{Def}
For any set \(b\), we denote by \(S(b)\) the symmetric group (group of permutations) over \(b\).
\end{Def}

\begin{Def}
Let for  \(b\subset Y\), such that \(|b|<\infty\) and \(\sigma_b \in S(b)\)
\begin{align*}
\text{VZ}^b_{\sigma_b}: \{k\in\mathbb{N}\mid k<|b|\} \rightarrow \{-1,1\}\\
\text{VZ}^b_{\sigma_b}(k):=\text{sgn}\big[f_b^{-1}(\sigma_b(f_b(k+1))) - f_b^{-1}(\sigma_b(f_b(k)))  \big]
\end{align*}
\end{Def}

In what is to follow the order of one particle operators will be changed in all possible ways, to keep track of this by
use of a compact notation we introduce
\begin{Def}
\begin{align*}
W: \{(b,\sigma_b) \mid b\subseteq Y \wedge |b|<\infty \wedge \sigma_b \in S(b) \} \rightarrow B(\mathcal{H})\\
W(b,\sigma_b):= \left( \prod_{k=1}^{|b|-1} \sigma_{b}(f_b(k)) P_{\text{VZ}_{\sigma_b}^b(k)} \text{VZ}_{\sigma_b}^b(k) \right) \sigma_b (f_b(|b|))
\end{align*}
\end{Def}

\begin{Def} Let \(l\) be any finite subset of \(Y\). Denote by \(X^l_{\text{max}}\) the operator \(X_k\in l \)
such that for any \(X_c\in l \) the relation \(k\ge c\) is fulfilled. Furthermore define
\begin{align*}
&\text{PT}: \{T\subset \mathcal{P}(Y)\mid |T|<\infty, \forall b\in T: |b|<\infty\}\rightarrow \mathbb{C}\\
&\text{for: } T=\emptyset: \text{PT}(T)=1, \text{ otherwise: }\\
&\text{PT}(T)=\sum_{\stackrel{\forall l \in T:}{\sigma_l \in S(l \backslash \{X_{\text{max}}^l\})}} \prod_{l\in T} 
\tr [P_+ X^l_{\text{max}} P_- W(l, \sigma_l)]
\end{align*}
\end{Def}

There is one more function left to define
\begin{Def}
\begin{align*}
\text{Op}:  \{R\in \mathcal{P}(Y)\mid |R|<\infty\} \times \{D\subset \mathcal{P}(Y)\mid |T|<\infty\}\rightarrow \mathcal{B}(\mathcal{F})\\
\text{Op}(R,D)=\sum_{\stackrel{\forall l \in D:}{\sigma_l \in S(l)}} \sum_{a \subseteq R \cup \bigcup_{l\in D} \{W(l,\sigma_l)\}} L(a,a^c)(-1)^{|a|+  \frac{(|R| + |D|)(|R|+|D|+1)}{2}}
\end{align*}
\end{Def}

Now we are able to state the main theorem which will help us do quantitative estimates.

\begin{Thm}
Let \(n\in\mathbb{N}\), \(X_1,\dots, X_n \in Y\) then the following equation holds

\begin{equation}\label{eq:ProductG}
\prod_{k=1}^n G(X_k)= 
\sum_{\stackrel{\langle n \rangle = \dot{\Cup}_{l\in T} l \dot{\cup} \dot{\Cup}_{l\in D} l \dot{\cup} R}{ \forall l \in T \cup D: |l|\ge 2}} \text{PT}(T) \text{Op}(R,D),
\end{equation}
where the abbreviation \(\langle n\rangle:= \{X_k\mid k\le n\}\) was used.
\end{Thm}
{\bfseries Proof:} The proof will be by induction on \(n\). Since the formula in the claim reduces to 1 for \(n=0\) we will
not spend any more time on the start of the induction. The general strategy of the proof is to break up the right 
hand side of \eqref{eq:ProductG} for \(n+1\) into small pieces and show for each piece that it corresponds to one of
the contributions of lemma \ref{lem:Ntimes1}, while also each term in this lemma is represented by one of the terms
obtained by breaking up \eqref{eq:ProductG}.

As a first step we break the right hand side of \eqref{eq:ProductG} into three pieces separated by in which set \(X_{n+1}\) 
ends up in :
\begin{align}\notag
\sum_{\stackrel{\langle n +1 \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{ \forall l \in T \cup D: |l|\ge 2}} \text{PT}(T) \text{Op}(R,D)=\\\label{ProductGI}
\sum_{\stackrel{\langle n +1 \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{\stackrel{\exists l \in T: X_{n+1}\in l}{ \forall l \in T \cup D: |l|\ge 2}}} \text{PT}(T) \text{Op}(R,D)\\\label{ProductGII}
+\sum_{\stackrel{\langle n +1 \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{\stackrel{\exists l\in D: X_{n+1}\in l}{ \forall l \in T \cup D: |l|\ge 2}}} \text{PT}(T) \text{Op}(R,D)\\\label{ProductGIII}
+\sum_{\stackrel{\langle n +1 \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{\stackrel{X_{n+1}\in R}{ \forall l \in T \cup D: |l|\ge 2}}} \text{PT}(T) \text{Op}(R,D),
\end{align}

We will discuss each term separately. For term \eqref{ProductGI} the term containing \(X_{n+1}\) is in one of the elements \(l'\) of \(T\), 
but each such element has to have more than one element. So if we were to sum over the partitions of \(\langle n\rangle \) instead,
the rest of \(l'\backslash \{X_{n+1}\}\) is either an element of \(D\) or, if it contains only one element, of \(R\). Picking \(D\) instead of \(T\)
is at this stage an arbitrary choice, but this choice leads to the terms of lemma \ref{lem:Ntimes1}. Alls this means that one
correct rewriting of term \eqref{ProductGI} is

\begin{multline}\label{eq:ProductGI2}
\eqref{ProductGI}= \sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D} l \dotcup R}{\forall l \in D \cup T: |l|>2} } \sum_{b \in D \cup \{ \{r\} \mid r\in R \}}  \\
\text{PT}(T\cup \{\{X_{n+1} \cup f\}) \text{Op}(R \backslash b, D\backslash \{b\}).
\end{multline}

Next we pull one factor and the corresponding sum out of PT and write out Op. Then we see that the sums over permutations 
can be merged into one. There we take the convention that for any set \(f\) such that \(|f|=1\) holds, we define \(\sigma_f\) to be
the identity on that set.

This results in

\begin{align}\notag
\eqref{eq:ProductGI2}= \sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D} l \dotcup R}{\forall l \in D \cup T: |l|>2} }\sum_{b \in D \cup \{ \{r\} \mid r\in R \}}  \sum_{\sigma_b \in S(b)}\\\notag
 \tr[P_+ X_{n+1} P_- W(b,\sigma_b)] \text{PT}(T) \sum_{\stackrel{\forall l \in D\backslash \{b\}}{\sigma_l \in S(l)}} \\\notag
 \sum_{a\subseteq R\backslash b \cup \bigcup_{l\in D\backslash \{b\}}\{W(l,\sigma_l)\}}  L(a,a^c) (-1)^{|a|+ \frac{(|R|+|D|-1)(|R|+|D|)}{2}}\\\notag
 =\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D} l \dotcup R}{\forall l \in D \cup T: |l|>2} }\sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}}  \sum_{b \in D \cup \{ \{r\} \mid r\in R \}} \text{PT}(T)\\\notag
 \sum_{a\subseteq R\backslash b \cup \bigcup_{l\in D\backslash \{b\}}\{W(l,\sigma_l)\}}  L(a,a^c) (-1)^{|a|+ \frac{(|R|+|D|-1)(|R|+|D|)}{2}}\\\notag
\tr[P_+ X_{n+1} P_- W(b,\sigma_b)]   \\\notag
=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D} l \dotcup R}{\forall l \in D \cup T: |l|>2} }\sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}}   \text{PT}(T)  \sum_{a\subseteq R \cup \bigcup_{l\in D}\{W(l,\sigma_l)\}}\\\notag
\sum_{b \in D \cup \{ \{r\} \mid r\in R \}} \id_{W(b,\sigma_b)\in a}  L(a\backslash\{b\},a^c) (-1)^{|a|+1}\\\notag
(-1)^\frac{(|R|+|D|-1)(|R|+|D|)}{2} \tr[P_+ X_{n+1} P_- W(b,\sigma_b)]\\\notag
=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D} l \dotcup R}{\forall l \in D \cup T: |l|>2} }\text{PT}(T) \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}}  \sum_{a\subseteq R \cup \bigcup_{l\in D}\{W(l,\sigma_l)\}} \\\notag
 \sum_{b \in a  }   L(a\backslash\{b\},a^c) (-1)^{|a|+\frac{(|R|+|D|+1)(|R|+|D|)}{2}}\\\notag
 (-1)^{1+|R|+|D|} \tr[P_+ X_{n+1} P_- W(b,\sigma_b)]\\\notag
 =\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D} l \dotcup R}{\forall l \in D \cup T: |l|>2} }\text{PT}(T) \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}}  \sum_{a\subseteq R \cup \bigcup_{l\in D}\{W(l,\sigma_l)\}} \\
   (-1)^{|a|+\frac{(|R|+|D|+1)(|R|+|D|)}{2}}  \eqref{Ntimes1:TrTerm}_{L(a,a^c) G(X_{n+1})},
\end{align}

where the notation in the last line is to be taken as ``apply Lemma \ref{lem:Ntimes1} apply it to \(L(a,a^c) G(X_{n+1})\) and
pick only term \eqref{Ntimes1:TrTerm}''. We will use this abbreviating notation also for the next terms.

The next term is \eqref{ProductGII}. Here we need a few more notational conventions. For any  set 
\(b\subseteq \langle n \rangle\) and corresponding
permutation \(\sigma_b\in S(b)\), we denote by the same symbol \(\sigma_b\) the continuation of \(\sigma_b\) to \(b\cup \{X_{n+1}\}\),
where for this continuation \(X_{n+1}\) is a fixed point. Furthermore we define for any set 
\(b\subseteq \langle n \rangle\), \(\sigma_c^b\) by

\begin{align}\notag
&\sigma_c^b \in  S(b\cup\{X_{n+1}\}), \\\notag
\forall k\le |b|: &\sigma_c^b(f_{b\cup \{X_{n+1}\}}(k))=f_{b\cup \{X_{n+1}\}}(k+1)\\
 &\sigma^b_c (X_{n+1})=f_b(1).
\end{align}

Finally we define for sets \(b_1,b_2 \subseteq \langle n \rangle, b_1\cap b_2=\emptyset\) and corresponding
permutations \(\sigma_{b_1}\in S(b_1), \sigma_{b_2} \in S(b_2)\) the permutation 
\(\sigma_{b_1,b_2}^{n+1}\) by

\begin{align}\notag
M_{b_1,b_2}^{n+1} :=b_1\cup b_2 \cup \{X_{n+1}\}\\\notag
\sigma_{b_1,b_2}^{n+1}\in S(M_{b_1,b_2}^{n+1} )\\\notag
\forall 1\le k \le |b_1|: \sigma_{b_1,b_2}^{n+1}(f_{M_{b_1,b_2}^{n+1}}(k))=\sigma_{b_1}(f_{b_1}(k))\\\notag
\sigma_{b_1,b_2}^{n+1}(f_{M_{b_1,b_2}^{n+1}}(|b_1|+1))=X_{n+1}\\\notag
\forall |b_1|+2\le k \le |b_1|+|b_2|+1:\\
 \sigma_{b_1,b_2}^{n+1}(f_{M_{b_1,b_2}^{n+1}}(k))
= \sigma_{b_2} ( f_{b_2}(k-|b_1|-1))
\end{align}

The beginning of the treatment of term \eqref{ProductGII} is analogous to \eqref{ProductGI}, we rewrite the
partition of \(\langle n+1\rangle \) into one of \(\langle n \rangle \) with an additional sum over where the
other operators packed to together with \(X_{n+1}\) come from. This splits into three parts, either \(X_{n+1}\)
is put at the beginning of the compound operator, or its put at the end of the compound object, or 
to the left as well as to the right are operators with smaller index. Since the overall sign is decided by 
how often the operator index rises or falls, this separation into cases is helpful. The last case we then
rewrite as picking two sets of operators, one of which will be in front of \(X_{n+1}\) and the other one
behind this operator. 

The calculation is as follows

\begin{align}\notag
&\eqref{ProductGII}= \sum_{\stackrel{\langle n +1 \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{\stackrel{\exists l\in D: X_{n+1}\in l}{ \forall l \in T \cup D: |l|\ge 2}}} \text{PT}(T) \text{Op}(R,D)\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} \text{PT}(T) \sum_{b\in D \cup \{\{r\}\mid r \in R\}} \text{Op} (R\backslash b , D\cup \{ b \cup \{X_{n+1}\}\backslash \{b\}\})\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} \text{PT}(T) \sum_{b\in D \cup \{\{r\}\mid r \in R\}} \sum_{\stackrel{\forall l \in D \cup \{b \cup \{X_{n+1}\}\}}{\sigma_l \in S(l)}}\\\notag
 &\sum_{a \subseteq R\backslash b \cup \bigcup_{l \in D \cup \{b \cup \{X_{n+1}\} \}\backslash \{b\}}\{W(l,\sigma_l)\}} L(a,a^c) (-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}}\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} \text{PT}(T) \sum_{b\in D \cup \{\{r\}\mid r \in R\}} \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}}\Big[\\\label{ProductGII.1}
 &\sum_{a \subseteq R\backslash b \cup \bigcup_{l \in D\backslash \{b\}}\{W(l,\sigma_l)\} \cup \{W(b\cup \{X_{n+1}\},\sigma_b)\}} L(a,a^c) (-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}}\\\label{ProductGII.2}
&+\sum_{a \subseteq R\backslash b \cup \bigcup_{l \in D\backslash \{b\}}\{W(l,\sigma_l)\}\cup \{W(b\cup \{X_{n+1}\},\sigma^b_c \circ\sigma_b)\}} L(a,a^c) (-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}}\Big]\\\notag
&+\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in \overline{D}}l \dotcup \overline{R}}{\forall l \in \overline{D}\cup T: |l|\ge 2}} \text{PT}(T) \sum_{\stackrel{b_1,b_2\in \overline{D} \cup \{\{r\}\mid r \in \overline{R}\}}{b_1 \neq b_2}} \sum_{\stackrel{\forall l \in \overline{D} }{\sigma_l \in S(l)}}\\\label{ProductGII.3}
&\sum_{a \subseteq \tilde{R}\cup \bigcup_{l \in \tilde{D}}\{W(l,\sigma_l)\} \cup \{W(b_1\cup \{X_{n+1}\}\cup b_2,\sigma^{n+1}_{b_1,b_2})\}} L(a,a^c) (-1)^{|a|+ \frac{(|\overline{R}|+|\overline{D}|-1)(|\overline{R}|+|\overline{D}|)}{2}}
\end{align}

where \(\tilde{R}=\overline{R} \backslash (b_1\cup b_2)\) and
\(\tilde{D}:=\overline{D} \cup \{b_1 \cup \{X_{n+1}\} \cup b_2 \}\backslash \{b_1,b_2\}\). For the term 
\eqref{ProductGII.3} we had to reshuffle the outermost
sum a bit. For each term in the original sum where \(X_{n+1}\) is neither the first nor the last factor in its product (we will call the set of factors in front of \(X_{n+1}\)  \( \alpha\) and the factors behind it \(\beta\)) there is a different splitting of \(\langle n \rangle \) into \(\overline{R}\) and \(\overline{D}\) such that \(\alpha\) and \(\beta\) are separate elements of \(\overline{D}\cup \{\{r\}\mid r \in \overline R\}\).
So we replace the original sum over \(D\) and \(R\) into one of \(\overline{D}\) and \(\overline{R}\). Since this is a one to one
correspondence and the sum is finite this is always possible. The exponent of the sign also changes for this reason, since
\(|R|+|D|=|\overline{R}|+|\overline{D}|-1\) holds. Continuing with \eqref{ProductGII.1} the next steps are similar to the last steps
in treating \eqref{ProductGI}. They are

\begin{align}\notag
&\eqref{ProductGII.1}=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} \text{PT}(T) \sum_{b\in D \cup \{\{r\}\mid r \in R\}} \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}}\\\notag
 &\sum_{a \subseteq R\backslash b \cup \bigcup_{l \in D\backslash \{b\}}\{W(l,\sigma_l)\} \cup \{W(b\cup \{X_{n+1}\},\sigma_b)\}} L(a,a^c) (-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}}\\\notag
 &=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} \text{PT}(T) \sum_{b\in D \cup \{\{r\}\mid r \in R\}} \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}} \\\notag
 &\sum_{a \subseteq R \cup \bigcup_{l \in D}\{W(l,\sigma_l)\}} (-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}}\id_{W(b,\sigma_b)\in a} \\\notag
& \big[L(a\backslash \{W(b,\sigma_b)\} \cup \{W(b\cup \{X_{n+1}\},\sigma_b)\},a^c) \\\notag
& -L(a\backslash \{W(b,\sigma_b)\},a^c \cup \{W(b\cup \{X_{n+1}\},\sigma_b)\}) \big]\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} \text{PT}(T)  \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}} \\\notag
 &\sum_{a \subseteq R \cup \bigcup_{l \in D}\{W(l,\sigma_l)\}} (-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}}
 \sum_{W(b,\sigma_b) \in a }  \\\notag
& \big[L(a\backslash \{W(b,\sigma_b)\} \cup \{W(b\cup \{X_{n+1}\},\sigma_b)\},a^c) \\\notag
& -L(a\backslash \{W(b,\sigma_b)\},a^c \cup \{W(b\cup \{X_{n+1}\},\sigma_b)\}) \big]\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} \text{PT}(T)  \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}} \sum_{a \subseteq R \cup \bigcup_{l \in D}\{W(l,\sigma_l)\}} \\
 & (-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}}
 (\eqref{Ntimes1:n+1atEnd1}+\eqref{Ntimes1:n+1atEnd2})_{L(a,a^c)G(X_{n+1})}.
\end{align}

Almost the same procedure applies to \eqref{ProductGII.2}. It yields %\label{Ntimes1:n+1atBeginnign1}

\begin{align}\notag
&\eqref{ProductGII.2}=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} \text{PT}(T) \sum_{b\in D \cup \{\{r\}\mid r \in R\}} \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}}\\\notag
 &\sum_{a \subseteq R\backslash b \cup \bigcup_{l \in D\backslash \{b\}}\{W(l,\sigma_l)\} \cup \{W(b\cup \{X_{n+1}\},\sigma^b_c\circ \sigma_b)\}} L(a,a^c) (-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}}\\\notag
 &=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} \text{PT}(T) \sum_{b\in D \cup \{\{r\}\mid r \in R\}} \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}} \\\notag
 &\sum_{a \subseteq R \cup \bigcup_{l \in D}\{W(l,\sigma_l)\}} (-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}} \\\notag
& \big[ \id_{W(b,\sigma^b_c\circ\sigma_b)\in a} L(a\backslash \{W(b,\sigma_b)\} \cup \{W(b\cup \{X_{n+1}\},\sigma^b_c \circ\sigma_b)\},a^c) \\\notag
& +\id_{W(b,\sigma^b_c\circ \sigma_b)\in a^c} L(a\backslash \{W(b,\sigma_b)\},a^c \cup \{W(b\cup \{X_{n+1}\},\sigma^b_c \circ \sigma_b)\}) \big]\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} \text{PT}(T)  \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}} \\\notag
 &\sum_{a \subseteq R \cup \bigcup_{l \in D}\{W(l,\sigma_l)\}} (-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}}
  \\\notag
& \big[ \sum_{W(b,\sigma_b) \in a }L(a\backslash \{W(b,\sigma_b)\} \cup \{W(b\cup \{X_{n+1}\},\sigma^b_c \circ\sigma_b)\},a^c) \\\notag
&+  \sum_{W(b,\sigma_b) \in a^c } L(a,a^c \backslash \{W(b,\sigma_b)\} \cup \{W(b\cup \{X_{n+1}\},\sigma^b_c \circ \sigma_b)\}) \big]\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} \text{PT}(T)  \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}} \sum_{a \subseteq R \cup \bigcup_{l \in D}\{W(l,\sigma_l)\}} \\
 & (-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}}
 (\eqref{Ntimes1:n+1atBeginning1}+\eqref{Ntimes1:n+1atBeginning2})_{L(a,a^c)G(X_{n+1})}.
\end{align}


Also for \eqref{ProductGII.3} the procedure is almost the same. We bring the sums into a form such that one can read off the
terms generated by the induction. We begin be renaming the sets which we had to change by resumming back to the names 
of the original sets. 


\begin{align}\notag
&\eqref{ProductGII.3}=
\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in \overline{D}}l \dotcup \overline{R}}{\forall l \in \overline{D}\cup T: |l|\ge 2}} 
\text{PT}(T) 
\sum_{\stackrel{b_1,b_2\in \overline{D} \cup \{\{r\}\mid r \in \overline{R}\}}{b_1 \neq b_2}} 
\sum_{\stackrel{\forall l \in \overline{D} }{\sigma_l \in S(l)}}\\\notag
&\sum_{a \subseteq \tilde{R}\cup \bigcup_{l \in \tilde{D}}\{W(l,\sigma_l)\} \cup \{W(b_1\cup \{X_{n+1}\}\cup b_2,\sigma^{n+1}_{b_1,b_2})\}} L(a,a^c) (-1)^{|a|+ \frac{(|\overline{R}|+|\overline{D}|-1)(|\overline{R}|+|\overline{D}|)}{2}}\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} 
\text{PT}(T) 
\sum_{\stackrel{b_1,b_2\in D \cup \{\{r\}\mid r \in R\}}{b_1 \neq b_2}} 
\sum_{\stackrel{\forall l \in D }{\sigma_l \in S(l)}}\\\notag
&\sum_{a \subseteq R\cup \bigcup_{l \in D}\{W(l,\sigma_l)\} \cup \{W(b_1\cup \{X_{n+1}\}\cup b_2,\sigma^{n+1}_{b_1,b_2})\}} L(a,a^c) (-1)^{|a|+ \frac{(| R|+|D|-1)(|R|+|D|)}{2}}\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} 
\text{PT}(T) 
\sum_{\stackrel{b_1,b_2\in D \cup \{\{r\}\mid r \in R\}}{b_1 \neq b_2}} 
\sum_{\stackrel{\forall l \in D }{\sigma_l \in S(l)}} \sum_{a \subseteq R\cup \bigcup_{l \in D}\{W(l,\sigma_l)\}} \\\notag
&(-1)^{|R|+|D|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}} \id_{W(b_1,\sigma_1)\in a}\\\notag
&\left[+(-1)^{|a|+1}\id_{W(b_2,\sigma_2)\in a} L\Big(a\backslash\{W(b_1,\sigma_1),W(b_2,\sigma_2)\}\cup\right.\\\notag
&\cup \{W(b_1\cup \{X_{n+1}\}\cup b_2,\sigma^{n+1}_{b_1,b_2})\} ,a^c\Big) \\\notag
&+(-1)^{|a|+1}\id_{W(b_2,\sigma_2)\in a^c}L\Big(a\backslash\{W(b_1,\sigma_1)\} ,a^c \backslash\{W(b_2,\sigma_2)\}\cup\\\notag
&\left. \cup \{W(b_1\cup \{X_{n+1}\}\cup f_2,\sigma^{n+1}_{b_1,b_2})\}\Big) \right]\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} 
\text{PT}(T) 
\sum_{\stackrel{\forall l \in D }{\sigma_l \in S(l)}} \sum_{a \subseteq R\cup \bigcup_{l \in D}\{W(l,\sigma_l)\}} \\\notag
&(-1)^{|R|+|D|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}} \\\notag
&\Big[(-1)^{|a|+1}\sum_{\stackrel{b_1,b_2 \in a}{b_1 \neq b_2}}  L\Big(a\backslash\{W(b_1,\sigma_1),W(b_2,\sigma_2)\}\cup\\\notag
&\cup \{W(b_1\cup \{X_{n+1}\}\cup b_2,\sigma^{n+1}_{b_1,b_2})\} ,a^c\Big) \\\notag
&+(-1)^{|a|+1}\sum_{b_1\in a,b_2\in a^c}  L\Big(a\backslash\{W(b_1,\sigma_1)\} ,a^c \backslash\{W(b_2,\sigma_2)\}\cup\\\notag
&\left. \cup \{W(b_1\cup \{X_{n+1}\}\cup f_2,\sigma^{n+1}_{b_1,b_2})\}\Big) \right]\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D}l \dotcup R}{\forall l \in D\cup T: |l|\ge 2}} 
\text{PT}(T) 
\sum_{\stackrel{\forall l \in D }{\sigma_l \in S(l)}} \sum_{a \subseteq R\cup \bigcup_{l \in D}\{W(l,\sigma_l)\}} \\\notag
&(-1)^{|a|+ \frac{(|R|+|D|)(|R|+|D|+1)}{2}} (\eqref{Ntimes1:middle1}+\eqref{Ntimes1:middle2})_{L(a,a^c)G(X_{n+1})}
\end{align}

Lastly we will discuss term \eqref{ProductGIII}; luckily, this term is less involved than the other two. The general procedure;
however, stays the same. First we reformulate the partition of \(\langle n+1\rangle\) into one of \(\langle n \rangle \), where
the terms acquire modifications. Secondly we massage these terms until the involved sums look exactly like the one 
in our induction hypothesis \eqref{eq:ProductG} and realise that the terms are produced by lemma \ref{lem:Ntimes1}.
For term \eqref{ProductGIII}  this results in

\begin{align}\notag
&\eqref{ProductGIII}
=\sum_{\stackrel{\langle n +1 \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{\stackrel{X_{n+1}\in R}{ \forall l \in T \cup D: |l|\ge 2}}} \text{PT}(T) \text{Op}(R,D)\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{ \forall l \in T \cup D: |l|\ge 2}} \text{PT}(T)
\text{Op}(R\cup \{X_{n+1}\},D)\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{ \forall l \in T \cup D: |l|\ge 2}} \text{PT}(T)
\sum_{\stackrel{\forall l \in D:}{\sigma_l \in S(l)}} \quad \sum_{a\subseteq R \cup \{X_{n+1}\} \cup \bigcup_{l\in D} \{W(l,\sigma_l)\}}\\\notag
&L(a,a^c)(-1)^{|a| + \frac{(|R|+1+|D|)(|R|+|D|+2)}{2}}\\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{ \forall l \in T \cup D: |l|\ge 2}} \text{PT}(T)
\sum_{\stackrel{\forall l \in D:}{\sigma_l \in S(l)}} \quad \sum_{a\subseteq R \cup \bigcup_{l\in D} \{W(l,\sigma_l)\}}
(-1)^{|a| + \frac{(|R|+1+|D|)(|R|+|D|)}{2}}\\\notag
&\big(-L(a\cup\{X_{n+1}\},a^c)+L(a,a^c\cup \{X_{n+1}\}) \big)(-1)^{|R|+|D|+1} \\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{ \forall l \in T \cup D: |l|\ge 2}} \text{PT}(T)
\sum_{\stackrel{\forall l \in D:}{\sigma_l \in S(l)}} \quad \sum_{a\subseteq R \cup \bigcup_{l\in D} \{W(l,\sigma_l)\}}
(-1)^{|a| + \frac{(|R|+1+|D|)(|R|+|D|)}{2}}\\\notag
&\big(L(a\cup\{X_{n+1}\},a^c)(-1)^{|R|+|D|}+L(a,a^c\cup \{X_{n+1}\})(-1)^{|R|+|D|+1} \big) \\\notag
&=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{ \forall l \in T \cup D: |l|\ge 2}} \text{PT}(T)
\sum_{\stackrel{\forall l \in D:}{\sigma_l \in S(l)}} \quad \sum_{a\subseteq R \cup \bigcup_{l\in D} \{W(l,\sigma_l)\}}
(-1)^{|a| + \frac{(|R|+1+|D|)(|R|+|D|)}{2}}\\\notag
&\big(\eqref{Ntimes1:simplyAdd1}+\eqref{Ntimes1:simplyAdd2} \big)_{L(a,a^c)G(X_{n+1})}.
\end{align}

Summarising we showed 
\begin{align*}
&\sum_{\stackrel{\langle n +1 \rangle = \dotCup_{l\in T} l \dotcup \dotCup_{l\in D} l \dotcup R}{ \forall l \in T \cup D: |l|\ge 2}} \text{PT}(T) \text{Op}(R,D)\\
 &=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D} l \dotcup R}{\forall l \in D \cup T: |l|>2} }\text{PT}(T) \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}}  \sum_{a\subseteq R \cup \bigcup_{l\in D}\{W(l,\sigma_l)\}} \\
  & (-1)^{|a|+\frac{(|R|+|D|+1)(|R|+|D|)}{2}}  \\
  &\big( \eqref{Ntimes1:TrTerm}+\eqref{Ntimes1:n+1atEnd1}+\eqref{Ntimes1:n+1atEnd2} 
  +\eqref{Ntimes1:n+1atBeginning1}+\eqref{Ntimes1:n+1atBeginning2}\\
 &+\eqref{Ntimes1:middle1}+\eqref{Ntimes1:middle2}
  +\eqref{Ntimes1:simplyAdd1}+\eqref{Ntimes1:simplyAdd2}\big)_{L(a,a^c) G(X_{n+1})}\\
 &=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D} l \dotcup R}{\forall l \in D \cup T: |l|>2} }\text{PT}(T) \sum_{\stackrel{\forall l \in D}{\sigma_l \in S(l)}}  \sum_{a\subseteq R \cup \bigcup_{l\in D}\{W(l,\sigma_l)\}} \\
  & (-1)^{|a|+\frac{(|R|+|D|+1)(|R|+|D|)}{2}} L(a,a^c)G(X_{n+1})\\
  &=\sum_{\stackrel{\langle n \rangle = \dotCup_{l\in T}l \dotcup \dotCup_{l\in D} l \dotcup R}{\forall l \in D \cup T: |l|>2} }\text{PT}(T) \text{Op}(R,D)G(X_{n+1})\\
  &=\prod_{l=1}^n G(X_{l}) \quad G(X_{n+1}),
\end{align*}

which ends our proof by induction.\qed




\appendix

\backmatter

\chapter{Appendix}

\section{Heuristic Construction of \(S\)-Matrix expression}\label{sec:heuristic construction}

In the following I derive a recursive equation for the coefficients of the expansion 
of the second quantized scattering operator. The starting point of this derivation is 
the commutator of \(T_m\), equation \eqref{logarithmic lift condition}.

\subsection{Guessing Equations}

Why at this point one might suspect that such a representation exists is, because
looking at equation \eqref{logarithmic lift condition} for a while, one
comes to the conclusion that if one replaces \(T_m\) by 
\begin{equation}
T_m - \frac{1}{2} \sum_{k=1}^{m-1} \begin{pmatrix} m \\ k\end{pmatrix} T_k T_{m-k},
\end{equation}
no \(T_k\) with \(k>m-2\) will occur on the right hand side of the resulting equation.
So if one subtracts the right polynomial in \(T_k\) for suitable \(k\) one might achieve
a commutator which contains only the creation respectively annihilation operator 
concatenated with some one particle operator. From our treatment of \(T_1\)
\noch{place proper reference to definition of G operator} we know which
operators have such commutation relations. 

So having this in Mind we start with the ansatz

\begin{equation}\label{Def Gamma_m}
\Gamma_m := \sum_{g=2}^m \sum_{\stackrel{b\in\mathbb{N}^g}{|b|=m}} c_{b} \prod_{k=1}^g T_{b_k}.
\end{equation}

Now in order to show that \(T_m\) and \(\Gamma_m\) agree up to operators which have a commutation 
relation of the form \eqref{G commutator}, we calculate \(\left[ T_m-\Gamma_m, a^\#(\varphi_n) \right]\)
for arbitrary \(n\in\mathbb{Z}\) and try to choose the coefficients \(c_b\) of \eqref{Def Gamma_m}
such that all contributions vanish which do not have the form \(a^\# \left( \prod_k Z_{\alpha_k}\right)\)
for any suitable \((\alpha_k)_k\subset \mathbb{N} \). If one does so, one is led to a system of equations
of which I wrote down a few to give an overview of its structure. The objects \(\alpha_k, \beta_l\) 
in the system of equations can be any natural Number for any \(k,l\in\mathbb{N}\).

\begin{align*}
&0 =c_{\alpha_1,\beta_1} + c_{\beta_1,\alpha_1}+ \binom{ \alpha_1 + \beta_1}{ \alpha_1} \\
&0 = c_{\alpha_1,\alpha_2,\beta_1} + c_{\beta_1,\alpha_1,\alpha_2} + c_{\alpha_2,\alpha_1,\beta_1} + 
\binom{\alpha_2 + \beta_1}{ \alpha_2} c_{\alpha_1,\alpha_2+\beta_1} \\
&\hspace{2cm}  +\binom{\alpha_1+\beta_1}{\alpha_1} c_{\alpha_1+\beta_1,\alpha_2}\\
&0= c_{\alpha_1,\alpha_2,\alpha_3,\beta_1} + c_{\alpha_1,\alpha_2,\beta_1,\alpha_3} 
+ c_{\alpha_1,\beta_1,\alpha_2,\alpha_3} + c_{\beta_1,\alpha_1,\alpha_2,\alpha_3}\\
&+\binom{\alpha_1+\beta_1}{\beta_1} 
c_{\alpha_1+\beta_1,\alpha_2,\alpha_3} 
+ \binom{\alpha_2+\beta_1}{\beta_1} c_{\alpha_1,\alpha_2+\beta_1,\alpha_3}\\
&\hspace{2cm} + \binom{\alpha_3+\beta_1}{\beta_1} c_{\alpha_1,\alpha_2,\alpha_3+\beta_1}\\
&0= c_{\alpha_1,\alpha_2,\beta_1,\beta_2} +c_{\alpha_1,\beta_1,\alpha_2,\beta_2} +
c_{\beta_1,\alpha_1,\alpha_2,\beta_2} +c_{\alpha_1,\beta_1,\beta_2,\alpha_2} \\
&+c_{\beta_1,\alpha_1,\beta_2,\alpha_2} +c_{\beta_1,\beta_2,\alpha_1,\alpha_2} 
+\binom{\alpha_1+\beta_1}{\alpha_1} (c_{\alpha_1+\beta_1,\alpha_2,\beta_2} \\
&+ c_{\alpha_1+\beta_1,\beta_2,\alpha_2})  
+\binom{\alpha_1+\beta_2}c_{\beta_1,\alpha_1+\beta_2,\alpha_1} \\
&+\binom{\alpha_2+\beta_1}{\alpha_2} c_{\alpha_1,\alpha_2+\beta_1,\beta_2}
+ \binom{\alpha_2+\beta_2}{\alpha_2} (c_{\alpha_1,\beta_1,\alpha_2+\beta_2}\\
&+ c_{\beta_1,\alpha_1,\alpha_2+\beta_2})
+ \binom{\alpha_1+\beta_1}{\alpha_1} \binom{\alpha_2+\beta_2}{\alpha_2}
 c_{\alpha_1+\beta_1,\alpha_2+\beta_2}\\
&0=c_{\alpha_1,\beta_1,\beta_2,\beta_3,\beta_4} 
+ c_{\beta_1,\alpha_1,\beta_2,\beta_3,\beta_4} 
+ c_{\beta_1,\beta_2,\alpha_1,\beta_3,\beta_4} \\
&\hspace{1cm}+ c_{\beta_1,\beta_2,\beta_3,\alpha_1,\beta_4} 
+ c_{\beta_1,\beta_2,\beta_3,\beta_4,\alpha_1} \\
&+\binom{\alpha_1+\beta_1}{\alpha_1} c_{\alpha_1+\beta_1,\beta_2,\beta_3,\beta_4}
+ \binom{\alpha_1+\beta_2}{\alpha_1} c_{\beta_1,\alpha_1+\beta_2,\beta_3,\beta_4}\\
&+ \binom{\alpha_1+\beta_3}{\alpha_1} c_{\beta_1,\beta_2,\alpha_1+\beta_3,\beta_4}
+ \binom{\alpha_1+\beta_4}{\alpha_1} c_{\beta_1,\beta_2,\beta_3,\alpha_1+\beta_4}\\
&0= c_{\alpha_1,\alpha_2,\beta_1,\beta_2,\beta_3} 
+c_{\alpha_1,\beta_1,\alpha_2,\beta_2,\beta_3} 
+c_{\beta_1,\alpha_1,\alpha_2,\beta_2,\beta_3} \\
&+c_{\alpha_1,\beta_1,\beta_2,\alpha_2,\beta_3} 
+c_{\beta_1,\alpha_1,\beta_2,\alpha_2,\beta_3} 
+c_{\beta_1,\beta_2,\alpha_1,\alpha_2,\beta_3} \\
&+c_{\alpha_1,\beta_1,\beta_2,\beta_3,\alpha_2} 
+c_{\beta_1,\alpha_1,\beta_2,\beta_3,\alpha_2} 
+c_{\beta_1,\beta_2,\alpha_1,\beta_3,\alpha_2} \\
&+c_{\beta_1,\beta_2,\beta_3,\alpha_1,\alpha_2} 
+\binom{\alpha_1+\beta_1}{\beta_1} (c_{\alpha_1+\beta_1,\alpha_2,\beta_2,\beta_3}\\
&+c_{\alpha_1+\beta_1,\beta_2,\alpha_2,\beta_3}
+c_{\alpha_1+\beta_1,\beta_2,\beta_3,\alpha_2})\\
&+\binom{\alpha_2+\beta_1}{\beta_1} c_{\alpha_1,\alpha_2+\beta_1,\beta_2,\beta_3}\\
&+\binom{\alpha_2+\beta_2}{\beta_2} (c_{\beta_1,\alpha_1,\alpha_2+\beta_2,\beta_3}
+c_{\alpha_1,\beta_1,\alpha_2+\beta_2,\beta_3})\\
&+\binom{\alpha_1+\beta_2}{\beta_2} (c_{\beta_1,\alpha_1+\beta_2,\alpha_2,\beta_3}
+c_{\beta_1,\alpha_1+\beta_2,\beta_3,\alpha_2})\\
&+\binom{\alpha_2+\beta_3}{\beta_3}( c_{\alpha_1,\beta_1,\beta_2,\alpha_2+\beta_3}
+c_{\beta_1,\alpha_1,\beta_2,\alpha_2+\beta_3}\\
&+c_{\beta_1,\beta_2,\alpha_1,\alpha_2+\beta_3})
+\binom{\alpha_1+\beta_3}{\beta_3} c_{\beta_1,\beta_2,\alpha_1+\beta_3,\alpha_2}\\
&+\binom{\alpha_1+\beta_1}{\alpha_1} \binom{\alpha_2+\beta_2}{\alpha_2} 
c_{\alpha_1+\beta_1,\alpha_2+\beta_2,\beta_3}\\
&+\binom{\alpha_1+\beta_2}{\alpha_1} \binom{\alpha_2+\beta_3}{\alpha_2} 
c_{\beta_1,\alpha_1+\beta_2,\alpha_2+\beta_3}\\
&+\binom{\alpha_1+\beta_1}{\alpha_1} \binom{\alpha_2+\beta_3}{\alpha_2} 
c_{\alpha_1+\beta_1,\beta_2,\alpha_2+\beta_3}\\
& \hspace{3cm} \vdots
\end{align*}

Solving the first few equations and plugging the solution into the consecutive
 equations one can see that at least the first equations are solved by 
\begin{equation}
c_{\alpha_1,\dots, \alpha_k} = \frac{(-1)^k}{k} \begin{pmatrix}\sum_{l=1}^k \alpha_l\\ \alpha_1\ \alpha_2 \ \cdots \alpha_k\end{pmatrix},
\end{equation}
where the last factor is the multinomial coefficient of the indices \(\alpha_1,\dots, \alpha_k\in\mathbb{N}\).

\subsection{Recursive equation for Coefficients of the second quantised scattering operator}

For the rest of this chapter, we are going to derive a concrete form of the second quantised scattering matrix. In order to turn the ``conjectures'' 
into ``theorems'' not only would one have to turn the rough sketches of the combinatorics into proofs, one also would have to show linearity (over real numbers) and
continuity of \(\mathrm{d}\Gamma(B)\) in \(B\).
However, since the final result can be verified to be well defined and to fulfil the lift conditions, this will not be necessary.
We will nonetheless come across various combinatorial assertions that we are going to prove rigorously. 
These will be clearly marked: ``lemma'' and ``proof''.

We are going to use the following definition of binomial coefficients:
\begin{Def}
For \(a\in\mathbb{C}, b\in\mathbb{Z}\) we define

\begin{equation}
\binom{a}{b} := \left\{\begin{matrix}
\prod_{l=0}^{b-1} \frac{a-l}{l+1} \quad \text{for } b\ge 0\\
0 \hspace{1.7cm} \text{otherwise.}
\end{matrix}\right.
\end{equation}
\end{Def}

Defining the binomial coefficient for negative lower index to be zero has the merit, that one can extend the
range of validity of many rules and sums involving binomial coefficients, also one does not have 
to worry about the range of summation in many cases.



The coefficients which we have already guessed more generally to be

\begin{Conj}\label{thm: T_n recursive}
For any \(n\in\mathbb{N}\) the n-th expansion coefficient of the second quantised scattering operator \(T_n\) is given by
\begin{align}\notag
&T_n = \sum_{g=2}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g T_{b_l} + C_n \id_{\mathcal{F}} \\ \label{T_n recursive}
&+ d\Gamma\left( \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^{g+1}}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g Z_{b_l}  \right),
\end{align}
for some \(C_n\in \mathbb{C}\) which depends on the external field \(A\). The last summand will henceforth
be abbreviated by \(\Gamma_n\).
\end{Conj}

\textbf{Motivation:} The way we will prove this is to compute the commutator of the difference between \(T_n\) and
the first summand of \eqref{T_n recursive} with the creation and annihilation operator of an element of the
basis of \(\mathcal{H}\). This will turn out to be exactly equal
to the corresponding commutator
of the second summand of \eqref{T_n recursive}, since two operators on Fock space only
have the same commutator with general creation and annihilation operators if they
agree up to multiples of the identity this will conclude the motivation of this conjecture. 

 In order to simplify the notation as much as possible, 
I will denote by \(a^\# z\) either \(a(z(\varphi_p))\) or
 \(a^*(z(\varphi_p))\) for any one particle operator \(z\) and any element
 \(\varphi_p\) of the orthonormal basis \((\varphi_p)_{p\in\mathbb{Z}\backslash\{0\}}\) of
 \(\mathcal{H}\). (We need not decide between creation and annihilation 
 operator, since the expressions all agree)
 
In order to organize the bookkeeping of all the summands which arise from iteratively
making use of the commutation rule \eqref{logarithmic lift condition} we organize them 
by the looking at a spanning set of the possible terms that arise my choice is

\begin{equation}\label{combinatorics span}
\left\{ \left. a^\# \prod_{k=1}^{m_1} Z_{\alpha_k} \prod_{k=1}^{m_2}T_{\beta_k} \right|
m_1\in\mathbb{N},m_2\in\mathbb{N}_0, \alpha\in \mathbb{N}^{m_1}, 
\beta \in \mathbb{N}^{m_2}, |\alpha|+|\beta|=n\right\}_.
\end{equation}

As a first step of computing the commutator in question we look at the summand
corresponding to a fixed value of the summation index \(g\) of 

\begin{equation}\label{combinatorics total sum of T}
-\sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g T_{b_l}.
\end{equation}

 We need to bring this object into the form of a sum
of terms which are multiples of elements of the set \eqref{combinatorics span}.
This we will commit ourselves to for the next few pages. First we apply
the product rule for the commutator:

\begin{align*}
&\left[ \sum_{\stackrel{\vec{l}\in\mathbb{N}^g}{|\vec{l}|=n}} \frac{(-1)^g}{g} \binom{n}{\vec{l}}
 \prod_{k=1}^g T_{l_k},a^\#\right]\\
 &= \sum_{\stackrel{\vec{l}\in\mathbb{N}^g}{|\vec{l}|=n}} \frac{(-1)^g}{g} \binom{n}{\vec{l}}
 \sum_{\tilde{k}=1}^g \prod_{j=1}^{\tilde{k}-1} T_{l_j} 
 \left[ T_{l_{\tilde{k}}},a^\#\right] \prod_{j=\tilde{k}+1}^g T_{l_j}\\
&=\sum_{\stackrel{\vec{l}\in\mathbb{N}^g}{|\vec{l}|=n}} \frac{(-1)^g}{g} \binom{n}{\vec{l}}
 \sum_{\tilde{k}=1}^g \prod_{j=1}^{\tilde{k}-1} T_{l_j} 
\sum_{\sigma_{\tilde{k}}=1}^{l_{\tilde{k}}} \binom{l_{\tilde{k}}}{\sigma_{\tilde{k}}} 
a^\# Z_f T_{l_{\tilde{k}}-\sigma_{\tilde{k}}} \prod_{j=\tilde{k}+1}^g T_{l_j},
\end{align*}
in the second step we used \eqref{logarithmic lift condition}. Now we commute
all the \(T_l\)s to the left of \(a^\#\) to its right:

\begin{equation}\label{combinatorics ordered product}
=\!\!\! \sum_{\stackrel{\vec{l}\in\mathbb{N}^g}{|l|=n}} \!\!\frac{(-1)^g}{g}\! \binom{n}{\vec{l}}
\!\! \sum_{\tilde{k}=1}^g \!\sum_{\stackrel{\forall 1\le j <\tilde{k}}{0\le \sigma_{j}\le l_j}}
\!\sum_{\sigma_{\tilde{k}}=1}^{l_{\tilde{k}}} \prod_{j=1}^{\tilde{k}}\! \binom{l_j}{\sigma_j}
a^\# \prod_{j=1}^{\tilde{k}} Z_{\sigma_j} \prod_{j=1}^{\tilde{k}} T_{l_j-\sigma_j}
\!\!\prod_{j=\tilde{k}+1}^g T_{l_j}.
\end{equation}
At this point we notice that the multinomial coefficient can be combined with all
the binomial coefficients to form a single multinomial coefficient of degree
\(g+\tilde{k}\). Incidentally this is also the amount of \(Z\) operators plus the amount
of \(T\) operators in each product. Moreover the indices of the Multinomial index
agree with the indices of the \(Z\) and \(T\) operators in the product. Because of 
this, we see that if we fix an element of the spanning set \eqref{combinatorics span}
\(a^\# \prod_{k=1}^{m_1} Z_{\alpha_k} \prod_{k=1}^{m_2}T_{\beta_k}\), each 
summand of \eqref{combinatorics ordered product} which contributes to
this element, has the prefactor

\begin{equation}
\frac{(-1)^g}{g} \binom{n}{\alpha_1 \ \cdots \alpha_{m_1} \ \beta_1 \cdots \beta_{m_2}}
\end{equation}

no matter which summation index \(l\in\mathbb{N}^g\) it corresponds to. In order
to do the matching one may ignore the indices \(\sigma_j\) and \(l_j-\sigma_j\) 
which vanish, because the corresponding operators \(Z_0\) and \(T_0\) are equal to
the identity operator on \(\mathcal{H}\) respectively Fock space. 

Since we know that 

\begin{align*}
\left[ d\Gamma\left(\sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}}  \prod_{l=1}^g Z_{b_l}\right), a^\#\right]\\
= a^\# \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}}  \prod_{l=1}^g Z_{b_l}
\end{align*}
holds, all that is left to show is that 
\begin{align}\label{combinatorics total commutator}
&\left[-\sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g T_{b_l}, a^\#\right]\\\notag
&= a^\# \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^{g+1}}{g} 
\binom{n}{\vec{b}}  \prod_{l=1}^g Z_{b_l}
\end{align}
also holds. For which we need to count the summands which are multiples of each element of \eqref{combinatorics span}
 corresponding to each \(g\) in \eqref{combinatorics total sum of T}. So let us fix some element
 \(K(m_1,m_2)\) of \eqref{combinatorics span} corresponding to some \(m_1\in\mathbb{N},
 m_2\in\mathbb{N}_0, \alpha \in \mathbb{N}^{m_1}\) and \( \beta\in \mathbb{N}^{m_2}\).
Rephrasing this problem, we can ask which products
\begin{equation}
\prod_{l=1}^g T_{\gamma_l}
\end{equation}
 for suitable \(g\) and \((\gamma_l)_l\) produce, when commuted with a creation or annihilation operator, 
  multiples of \(K(m_1,m_2)\)? We will call this number of 
 total contributions weighted with the factor 
 \( - \frac{(-1)^g}{g}\) borrowed from \eqref{combinatorics total sum of T} \(\#K(m_1,m_2)\).  
 Looking at the commutation relations 
\eqref{logarithmic lift condition} we split the set of indices \(\{\gamma_1\dots \gamma_g\}\) into
three sets \(A,B\) and \(C\), where the commutation relation has to be used in such a way, that

\begin{align*}
&\forall k: \gamma_k \in A \iff \exists j\le m_1: \gamma_k = \alpha_j, \\
\wedge& \forall k: \gamma_k \in B \iff \exists j\le m_2: \gamma_k = \beta_j\\
\wedge & \forall k: \gamma_k \in C \iff \exists j\le m_1, l\le m_2: \gamma_k = \alpha_j + \beta_l
\end{align*}
 holds. Unfortunately not every splitting corresponds to a contribution and not every
 order of multiplication of a legal splitting corresponds to a contribution either.
 However \(\prod_{j} T_{\alpha_j} \prod_j T_{\beta_j}\) gives
 a contribution and it is in fact the longes product that does.
 We may apply the commutation relations backwards to obtain any
 shorter valid combination and hence all combinations. 
 Transforming the commutation rule for \(T_k\) read from right to left
 into a game results in the following rules.
 
Starting from the string 
\begin{equation}
A_1A_2\dots A_{m_1} B_1 B_2 \dots B_{m_2},
\end{equation}

representing the longes product, where here and in the following \(A\)'s
represent operators \(T_k\) which will turn into \(Z_k\) by the commutation rule,
\(B\)'s represent operators \(T_k\) which will stay \(T_k\) after commutation and
\(C\)'s represent operators \(T_k\) which will produce both a \(Z_l\) in the creation/annihilation
operator and a \(T_{k-l}\) behind that operator. The indices are merely there to keep track of
which operator moved where.

So the game consists in the answering how many strings can we produce by 
applying the following rules to the initial string?
\begin{enumerate}
\item You may replace any occurrence of \(A_k B_j\) by \(B_j A_k\) for any \(j\) and \(k\).
\item You may replace any occurrence of \(A_k B_j\) by \(C_{k,j}\) for any \(j\) and \(k\).
\end{enumerate}
Where we have to count the number of times we applied the second rule, or equivalently
the number \(\#C\) of \(C\)'s in the resulting string, because the summation index \(g\) in 
\eqref{combinatorics total sum of T} corresponds to \(m_1+m_2-\#C\). 

Fix \(\#C \in\{0,\dots ,\min(m_1,m_2)\}\). A valid string has \(m_1+m_2-\#C\) characters,
because the number of its \(C\)s is \(\#C\), its number of \(A\)s is \(m_1-\#C\) and 
its number of \(B\)s is \(m_2-\#C\). Ignoring the labelling of the \(A\)s, \(B\)s and \(C\)s 
there are \(\binom{m_1+m_2-\#C}{\#C \ (m_1 - \#C) \ (m_2-\#C)}\) such strings. Now if
we consider one such string without labelling, e.g.

\begin{equation}
C A A B A C C B B A C B B A B B B B,
\end{equation}

there is only one correct labelling to be restored, namely the one where each \(A\) and the first index of 
any \(C\)  receive increasing labels from left to right and analogously for \(B\) and the second 
 index of any \(C\), resulting for our example in
 
\begin{equation}
 C_{1,1} A_2 A_3 B_2 A_4 C_{5,3} C_{6,4} B_{5} B_6 A_7 C_{8,7} B_8 B_9 A_9 B_{10} B_{11} B_{12} B_{13}.
\end{equation}

So any unlabelled  string corresponds to exactly one labelled string which in turn corresponds to 
exactly one choice of operator product \(\prod T\). 
So returning to our Operators, we found the number \(\#K(m_1,m_2)\) it is

\begin{equation}\label{combinatorics binomial sum}
\#K(m_1,m_2) =-\sum_{g=\max(m_1,m_2)}^{m_1+m_2} \frac{(-1)^g}{g} \binom{g}{(m_1+m_2-g) \ (g-m_1) \ (g - m_2)},
\end{equation}
where the total minus sign comes from the total minus sign in front of \eqref{combinatorics total commutator}
with respect to \eqref{T_n recursive}. 

Now since we introduced the slightly non-standard definition of binomial coefficients used in \cite{graham1994concrete} we
can make use of the rules for summing binomial coefficients derived there.
As a first step to evaluate \eqref{combinatorics binomial sum} we split the trinomial coefficient into binomial
ones and make use of the absorption identity

\begin{equation}\tag{absorption}\label{absorption}
\forall a \in \mathbb{C}\ \forall b \in \mathbb{Z}: b \binom{a}{b} = a \binom{a-1}{b-1} 
\end{equation}

for \(m_2,m_1\neq 0\) as follows

\begin{align*}
&\#K(m_1,m_2) \\
&=-\sum_{g=\max(m_1,m_2)}^{m_1+m_2} \frac{(-1)^g}{g} \binom{g}{(m_1+m_2-g) \ (g-m_1) \ (g - m_2)}\\
&=-\sum_{g=\max(m_1,m_2)}^{m_1+m_2} \frac{(-1)^g}{g} \binom{g}{m_2}\binom{m_2}{g-m_1}\\
&\stackrel{\eqref{absorption}}{=}-\sum_{g=\max(m_1,m_2)}^{m_1+m_2} \frac{(-1)^g}{m_2} \binom{g-1}{m_2-1}\binom{m_2}{g-m_1}\\
&=\frac{-1}{m_2} \sum_{g=\max(m_1,m_2)}^{m_1+m_2} (-1)^g \binom{g-1}{m_2-1}\binom{m_2}{g-m_1}\\
&\overset{m_1>0}{=}\frac{-1}{m_2} \sum_{g\in\mathbb{Z}} (-1)^g \binom{m_2}{g-m_1}\binom{g-1}{m_2-1}\\
&\stackrel{*}{=} \frac{-1}{m_2} (-1)^{m_2-m_1} \binom{m_1-1}{-1} = 0,
\end{align*}
where for the second but last equality \(m_1>0\) is needed for the \(g=0\) summand not to contribute and
for the marked equality we used summation rule (5.24) of \cite{graham1994concrete}. 
So all the coefficients vanish that fulfil \(m_1,m_2\neq 0\). The sum for the remaining cases
is readily computed, since there is just one summand. Summarising we find

\begin{equation*}
\#K(m_1,m_2)= \delta_{m_2,0} \frac{(-1)^{1+m_1}}{m_1} + \delta_{m_1,0} \frac{(-1)^{1+m_2}}{m_2},
\end{equation*}

where the second summand can be ignored, since terms with \(m_1=0\) are irrelevant for our considerations.

 So the left hand side of 
\eqref{combinatorics total commutator} can be evaluated

\begin{align*}
\left[-\sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^g}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g T_{b_l}, a^\#\right]\\
= \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|b|=n}} \frac{(-1)^{g+1}}{g} \binom{n}{\vec{b}}  a^\# \prod_{l=1}^g Z_{b_l},
\end{align*}

which is exactly equal to the right hand side of \eqref{combinatorics total commutator}. This ends the motivation of the conjecture.



\subsection{Solution to Recursive Equation}

So we found a recursive equation for the \(T_n\)s, now we need to solve it. 
In order to do so we need the following lemma about combinatorial distributions

\begin{Lemma}\label{stirling lemma}
For any \(g\in\mathbb{N},k\in\mathbb{N}\)
\begin{equation}
\sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{|\vec{g}|=k}} \binom{k}{\vec{g}}=\sum_{l=0}^g (-1)^l (g-l)^k \binom{g}{l}
\end{equation}
holds. The reader interested in terminology may be eager to know, that the right hand side is equal to
 \(g!\) times the Stirling 
number of the second kind \(\left\{\begin{matrix}k\\g\end{matrix}\right\}\).
\end{Lemma}
\textbf{Proof:} We would like to apply the multinomial theorem but there are all the summands missing where at least
one of the entries of \(\vec{g}\) is zero, so we add an appropriate expression of zero. We also give the expression in
question a name, since we will later on arrive at a recursive expression.
\begin{multline}
F(g,k):=\sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{|\vec{g}|=k}} \binom{k}{\vec{g}}
= \sum_{\stackrel{\vec{g}\in\mathbb{N}_0^g}{|\vec{g}|=k}} \binom{k}{\vec{g}}
- \sum_{\stackrel{\stackrel{\vec{g}\in\mathbb{N}_0^g}{|\vec{g}|=k}}{\exists l: g_l=0}} \binom{k}{\vec{g}}\\
= g^k 
 - \sum_{\stackrel{\stackrel{\vec{g}\in\mathbb{N}_0^g}{|\vec{g}|=k}}{\exists l: g_l=0}} \binom{k}{\vec{g}}
=g^k 
- \sum_{n=1}^{g-1} \sum_{\stackrel{\vec{g}\in\mathbb{N}_0^g}{|\vec{g}|=k}}
 \binom{k}{\vec{g}} 1_{\exists! i_1\dots i_n : \forall i_l\neq i_k \wedge \forall l :g_{i_l}=0}
\end{multline}
where in the last line the indicator function is to enforce there being exactly n different indices \(i_l\) for which \(g_{i_l}=0\)
holds. Now since it does not matter which entries of the vector vanish because the multinomial coefficient 
is symmetric and its value is identical to the corresponding multinomial coefficient where the vanishing entries
are omitted, we can further simplify the sum:

\begin{equation*}
F(g,k)= g^k -  \sum_{n=1}^{g-1} \binom{g}{n} \sum_{\stackrel{\vec{g}\in\mathbb{N}^n}{|\vec{g}|=k}}
 \binom{k}{\vec{g}}
\end{equation*}

The inner sum turns out to be \(F(g-n,k)\), so we found the recursive relation for \(F\):
\begin{equation}\label{combinatorics solution recursive}
F(g,k)= g^k -  \sum_{n=1}^{g-1} \binom{g}{n} F(n,k)= g^k -  \sum_{n=1}^{g-1} \binom{g}{n} F(g-n,k),
\end{equation}

where for the last equality we used the symmetry of binomial coefficients.
By iteratively applying this equation, we find the following formula, which we will now prove by induction

\begin{multline}\label{combinatorics induction}
\forall d\in\mathbb{N}_0: F(g,k)=\sum_{l=0}^d (-1)^l (g-l)^k \binom{g}{l}\\
+(-1)^{d+1} \sum_{n=1}^{g-d-1} \binom{n+d-1}{d} \binom{g}{n+d} F(g-d-n,k).
\end{multline}

We already showed the start of the induction, so what's left is the induction step. Before we do so the
following remark is in order: We are only interested in the case \(d=g\) and the formula seems meaningless
for \(d>g\); however, the additional summands in the left sum vanish, where as the right sum is empty
for these values of \(d\) since the  upper bound of the summation index is lower than its lower bound.

For the induction step, pick \(d\in\mathbb{N}_0\), use \eqref{combinatorics induction} and pull the first summand
 out of the second sum,
on this summand we apply the recursive relation \eqref{combinatorics solution recursive} resulting in

\begin{multline}
F(g,k)=\sum_{l=0}^d (-1)^l (g-l)^k \binom{g}{l}\\
 + (-1)^{d+1}\sum_{n=2}^{g-d-1} \binom{n+d-1}{d}\binom{g}{n+d} F(g-d-n,k)\\
  + (-1)^{d+1} \binom{d}{d} \binom{g}{d+1} F(g-d-1,k)\\
\overset{\eqref{combinatorics solution recursive}}{=}\sum_{l=0}^{d+1} (-1)^l (g-l)^k \binom{g}{l}\\
+(-1)^{d+1} \sum_{n=2}^{g-d-1} \binom{n+d-1}{d} \binom{g}{n+d} F(g-d-n,k)\\
-(-1)^{d+1} \binom{g}{d+1} \sum_{n=1}^{g-d-2} \binom{g-d-1}{n} F(g-d-1-n,k)\\
=\sum_{l=0}^{d+1} (-1)^l (g-l)^k \binom{g}{l}\\
+(-1)^{d+1} \sum_{n=1}^{g-d-2} \binom{n+d}{d} \binom{g}{n+d+1} F(g-d-1-n,k)\\
-(-1)^{d+1} \binom{g}{d+1} \sum_{n=1}^{g-d-2} \binom{g-d-1}{n} F(g-d-1-n,k).
\end{multline}
After the index shift we can combine the last two sums. 

\begin{multline}
F(g,k)= \sum_{l=0}^{d+1} (-1)^l (g-l)^k \binom{g}{l}\\
+ \sum_{n=1}^{g-d-2}\left[\binom{g}{d+1} \binom{g-d-1}{n} - \binom{n+d}{d} \binom{g}{n+d+1} \right] 
\\(-1)^{d+2} F(g-d-1-n,k).
\end{multline}


In order to combine the two binomials we reassemble \(\binom{g}{d+1}\binom{g-d-1}{n}\) 
into \(\binom{g}{n+d+1}\binom{n+d+1}{d+1}\), which can be seen to be possible by representing everything
in terms of factorials. This results in
\begin{multline}
F(g,k)= \sum_{l=0}^{d+1} (-1)^l (g-l)^k \binom{g}{l}\\
+(-1)^{d+2} \sum_{n=1}^{g-d-2}\left[\binom{n+d+1}{d+1} - \binom{n+d}{d}\right] \binom{g}{n+d+1} 
 F(g-d-1-n,k)\\
=\sum_{l=0}^{d+1} (-1)^l (g-l)^k \binom{g}{l}\\
+(-1)^{d+2}  \sum_{n=1}^{g-d-2} \binom{n+d}{d+1} \binom{g}{n+d+1}  F(g-d-1-n,k),
\end{multline}
where we used the addition formula for binomials:

\begin{equation}
\forall n\in \mathbb{C} \forall k \in \mathbb{Z}: \binom{n}{k} = \binom{n-1}{k} + \binom{n-1}{k-1}.
\end{equation}
This concludes the proof by induction. By setting \(d=g\) in equation \eqref{combinatorics induction} 
we arrive at the desired result. \qed

Using the previous lemma, we are able to show the next

\begin{Lemma}\label{combinatorics weak conjecture lemma 2}
For any \(k \in \mathbb{N}\backslash \{1\}\) the following equation holds
\begin{equation}
\sum_{g=1}^k \frac{(-1)^g}{g} \sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{|\vec{g}|=k}}\binom{k}{\vec{g}}=0.
\end{equation}
\end{Lemma}
\textbf{Proof:} Let \(k\in\mathbb{N}\backslash\{1\}\), as a first step we apply lemma \ref{stirling lemma}.
We change the order of summation, use \eqref{absorption}, extend the range of summation and shift 
summation index  to arrive at

\begin{multline}
\sum_{g=1}^k \frac{(-1)^g}{g} \sum_{l=0}^g (-1)^l (g-l)^k \binom{g}{l}
= \sum_{g=1}^k \frac{1}{g} \sum_{l=0}^g (-1)^{g-l} (g-l)^k \binom{g}{g-l}\\
= \sum_{g=1}^k \sum_{p=0}^g (-1)^{p} p^k \frac{1}{g} \binom{g}{p}
=\sum_{g=1}^k \sum_{p=0}^g (-1)^{p} p^k \frac{1}{p} \binom{g-1}{p-1}\\
=\sum_{g=1}^k \sum_{p\in\mathbb{Z}} (-1)^{p} p^{k-1}\binom{g-1}{p-1}
=\sum_{p\in\mathbb{Z}} (-1)^{p} p^{k-1} \sum_{g=1}^k \binom{g-1}{p-1}\\
=\sum_{p\in\mathbb{Z}} (-1)^{p} p^{k-1} \sum_{g=0}^{k-1} \binom{g}{p-1}.
\end{multline}

Now we use equation (5.10) of \cite{graham1994concrete}:

\begin{equation}\tag{upper summation}
\forall m,n\in\mathbb{N}_0: \sum_{k=0}^n \binom{k}{m} = \binom{n+1}{m+1},
\end{equation}
which can for example be proven by induction on \(n\).

We furthermore rewrite the power of the summation index \(p\) in terms of the derivative of an 
exponential and change order summation and differentiation. This results in

\begin{multline*}
\sum_{g=1}^k \frac{(-1)^g}{g} \sum_{l=0}^g (-1)^l (g-l)^k \binom{g}{l}
=\sum_{p\in\mathbb{Z}} (-1)^{p} p^{k-1}  \binom{k}{p}\\
=\sum_{p=0}^k (-1)^{p} \left. \frac{\partial^{k-1}}{\partial \alpha^{k-1}} e^{\alpha p}\right|_{\alpha=0}  \binom{k}{p}
=\left. \frac{\partial^{k-1}}{\partial \alpha^{k-1}}  \sum_{p=0}^k (-1)^{p} e^{\alpha p} \binom{k}{p}\right|_{\alpha=0} \\
=\left. \frac{\partial^{k-1}}{\partial \alpha^{k-1}}  \left( 1-e^{\alpha p}\right)^k \right|_{\alpha=0} 
=(-1)^k \left. \frac{\partial^{k-1}}{\partial \alpha^{k-1}} \left( \sum_{l=1}^\infty \frac{(\alpha p)^l}{l!} \right) ^k \right|_{\alpha=0} \\
=(-1)^k \left. \frac{\partial^{k-1}}{\partial \alpha^{k-1}} ((\alpha p)^k + \mathcal{O} ((\alpha p)^{k+1}) ) \right|_{\alpha=0} =0.
\end{multline*}
\qed




We are now in a position to state the solution to the recursive equation \eqref{T_n recursive}
and motivate that it is in fact a solution. 

\begin{Conj}
For \(n\in\mathbb{N}\) the solution of the recursive equation \eqref{T_n recursive} 
solely in terms of \(G_a\) and \(C_a\) is given by

\begin{equation}\label{recursive solution}
T_n = \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|= n}} \sum_{\vec{d}\in {\{0,1\}}^g} 
\frac{1}{g!} \binom{n}{\vec{b}} \prod_{l=1}^g F_{b_l,d_l},
\end{equation}
where \(F\) is given by
\begin{equation}\label{eq resursive weak solution}
F_{a,b} = \left\{ \begin{matrix}\mathrm\Gamma_a \quad \text{for } b=0 \\ C_a \quad \text{for } b=1  \end{matrix} \right._. 
\end{equation}
For the readers convenience we remind her, that \(\mathrm\Gamma_a\) and
the constants \(C_n\) are defined in theorem \ref{thm: T_n recursive}. 
\end{Conj}

\textbf{Motivation:} The structure of this proof will be induction over \(n\). For \(n=1\) the whole expression
on the right hand side collapses to \(C_1 + \mathrm\Gamma_1\), which we already know to be equal to \(T_1\). For
arbitrary \(n+1\in\mathbb{N}\backslash\{1\}\) we apply the recursive equation \eqref{T_n recursive}
once and use the induction hypothesis for all \(k\le n\) and thereby arrive at the rather convoluted 
expression

\begin{multline}\label{recursive weak conjecture proof}
T_{n+1} \stackrel{\eqref{T_n recursive}}{=} 
\mathrm\Gamma_{n+1} + C_{n+1}+ \sum_{g=2}^{n+1} \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n+1}} 
\frac{(-1)^g}{g} \binom{n+1}{\vec{b}} \prod_{l=1}^g T_{b_l}\\
\stackrel{\text{induction hyp}}{=} \mathrm\Gamma_{n+1} + C_{n+1}+ \sum_{g=2}^{n+1} \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n+1}} 
\frac{(-1)^g}{g} \binom{n+1}{\vec{b}} \prod_{l=1}^g \\
\sum_{g_l=1}^{b_l} \sum_{\stackrel{\vec{c}_l \in\mathbb{N}^{g_l}}{|\vec{c}_l|=b_l}} \sum_{\vec{e}_l \in \{0,1\}^{g_l}}
\frac{1}{g_l!} \binom{b_l}{\vec{c}_l} \prod_{k=1}^{g_l} F_{c_{l,k},e_{l,k}}.
\end{multline}

If we were to count the contributions of this sum to a specific product \(\prod F_{c_j,e_j}\) for some choice of 
\((c_j)_j, (e_j)_j\) we would first recognize that all the multinomial factors in \eqref{recursive weak conjecture proof}
combine to a single one whose indices are given by the first indices of all the \(F\) factors involved.
Other than this factor each contribution adds \(\frac{(-1)^g}{g} \prod_{l=1}^g \frac{1}{g_l!}\) to the sum. So we 
need to keep track of how many contributions there are and which distributions of \(g_l\) they belong to. 

Fix some product \(\prod F :=\prod_{j=1}^{\tilde{g}} F_{\tilde{b}_j,\tilde{d}_j}\). In the sum 
\eqref{recursive weak conjecture proof} we pick some initial short product of length \(g\) and split each
factor into \(g_l\) pieces to arrive at one of length \(\tilde{g}\) if the product is to contribute to
\(\prod F\). So clearly \(\sum_{l=1}^g g_l = \tilde{g}\) holds for any contribution to \(\prod F\). 
The reverse is also true, for any
\(g\) and \(g_1, \dots, g_g\in\mathbb{N}\) such that \(\sum_{l=1}^g g_l=\tilde{g}\) holds
the corresponding expression in \eqref{recursive weak conjecture proof} contributes to 
\(\prod F\). Furthermore \(\prod F\) and \(g\), \(g_1,\dots g_g\) is enough to uniquely
determine the summand of \eqref{recursive weak conjecture proof} the contribution
belongs to. For an illustration of this splitting see

\begin{align*}
\underbrace{\underbrace{F^1_{3,1} F^2_{2,0} F^3_{7,1}}_{g_1=3} \underbrace{F^4_{5,0}}_{g_2=1} \underbrace{F^5_{4,1} F^6_{2,1}}_{g_3=2} \underbrace{F^7_{1,1} F^8_{3,0} F^9_{4,1}}_{g_4=3} \underbrace{F^{10}_{4,1} F^{11}_{1,0}}_{g_5=2}}_{g=5}\\
 g_1+g_2+g_3+g_4+g_5=11=\tilde{g},
\end{align*}

where I labelled the factors in the upper right index for the readers convenience. We recognize
that the sum we are about to perform is by no means unique for each order of \(n\) but only 
depends on the number of appearing factors and the number of splittings performed on
them. By the preceding argument we need 

\begin{equation}\label{combinatorics weak conjecture reformulated into equation}
\sum_{g=2}^{\tilde{g}} \frac{(-1)^g}{g} \sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{|\vec{g}|=\tilde{g}}} \prod_{l=1}^g \frac{1}{g_l!}
= \frac{1}{\tilde{g}!} 
\end{equation}


to hold for \(\tilde{g}>1\), in order to find agreement with the proposed solution \eqref{eq resursive weak solution}.
Now proving \eqref{combinatorics weak conjecture reformulated into equation} is done by 
realizing, that one can include the right hand side into the sum as the \(g=1\) summand, dividing
the equation by \(\tilde{g}!\) and using lemma \ref{combinatorics weak conjecture lemma 2}
with \(k=\tilde{g}\). The remaining case, \(\tilde{g}=1\), can directly be
read off of \eqref{recursive weak conjecture proof}. This ends the motivation of this conjecture.

\begin{Conj}\label{Corollary T_n by G's and C's}
For \(n\in\mathbb{N}\), \(T_n\) can be written as

\begin{equation}
\frac{1}{n!} T_n = \sum_{\stackrel{1\le c+g\le n}{c,g\in\mathbb{N}_0}} 
\sum_{\stackrel{\stackrel{\vec{g}\in\mathbb{N}^g}{\vec{c}\in\mathbb{N}^c}}{|\vec{c}| + |\vec{g}|=n}} 
\frac{1}{c! g!} \prod_{l=1}^c \frac{1}{c_l!} C_{c_l} \prod_{l=1}^g \frac{1}{g_l!} \mathrm\Gamma_{g_l}.
\end{equation}
Please note that for ease of notation we defined \(\mathbb{N}^0:= \{1\}\).
\end{Conj}
\textbf{Motivation:} By an argument completely analogous to the combinatorial argument in the motivation of conjecture
\eqref{thm: T_n recursive} we see that we can disentangle the \(F\)s in \eqref{recursive solution}
into \(\mathrm\Gamma\)s and \(C\)s if we multiply by a factor of \(\binom{c+g}{c}\) where \(c\) is the 
number of \(C\)s and \(g\) is the number of \(\mathrm\Gamma\)s giving

\begin{multline}
T_n = \sum_{\stackrel{1\le c+g\le n}{c,g\in\mathbb{N}_0}}
\sum_{\stackrel{\stackrel{\vec{g}\in\mathbb{N}^g}{\vec{c}\in\mathbb{N}^c}}{|\vec{c}| + |\vec{g}|=n}} 
\binom{c+g}{c} \frac{1}{(c+g)!} \binom{n}{\vec{g}\oplus \vec{c}}
\prod_{l=1}^c  C_{c_l} \prod_{l=1}^g \mathrm\Gamma_{g_l},
\end{multline}

which directly reduces to the equation we wanted to prove, by plugging in the multinomials in terms of
factorials. 

\begin{Conj}
As a formal power series, the second quantized scattering operator can be written in the form
\begin{equation}\label{Corollary double exp}
S= e^{\sum_{l\in\mathbb{N}} \frac{C_{l}}{l!}}
 e^{\sum_{l\in\mathbb{N}} \frac{\mathrm\Gamma_{l}}{l!}}.
\end{equation}
\end{Conj}
\textbf{Proof:} We plug conjecture \ref{Corollary T_n by G's and C's} into the defining Series for the \(T_n\)s
giving

\begin{align}
&S= \sum_{n\in\mathbb{N}_0} \frac{1}{n!} T_n \\
&=\id_{\mathcal{F}}+ \sum_{n\in\mathbb{N}} \sum_{\stackrel{1\le c+g\le n}{c,g\in\mathbb{N}_0}} 
\sum_{\stackrel{\stackrel{\vec{g}\in\mathbb{N}^g}{\vec{c}\in\mathbb{N}^c}}{|\vec{c}| + |\vec{g}|=n}} 
\frac{1}{c! g!} \prod_{l=1}^c \frac{1}{c_l!} C_{c_l} \prod_{l=1}^g \frac{1}{g_l!} \mathrm\Gamma_{g_l}\\
&=\id_{\mathcal{F}}+  \sum_{\stackrel{1\le c+g }{c,g\in\mathbb{N}_0}} 
\sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{\vec{c}\in\mathbb{N}^c}} 
\frac{1}{c! g!} \prod_{l=1}^c \frac{1}{c_l!} C_{c_l} \prod_{l=1}^g \frac{1}{g_l!} \mathrm\Gamma_{g_l}\\
&=\sum_{c,g\in\mathbb{N}_0}
\sum_{\stackrel{\vec{g}\in\mathbb{N}^g}{\vec{c}\in\mathbb{N}^c}} 
\frac{1}{c! g!} \prod_{l=1}^c \frac{1}{c_l!} C_{c_l} \prod_{l=1}^g \frac{1}{g_l!} \mathrm\Gamma_{g_l}\\
&=\sum_{c\in\mathbb{N}_0} \frac{1}{c!} \sum_{\vec{c}\in\mathbb{N}^c} \prod_{l=1}^c \frac{1}{c_l!} C_{c_l}
\sum_{g\in\mathbb{N}_0} \frac{1}{g!} \sum_{\vec{g}\in\mathbb{N}^g} \prod_{l=1}^g \frac{1}{g_l!} \mathrm\Gamma_{g_l}\\
&=\sum_{c\in\mathbb{N}_0} \frac{1}{c!} \prod_{l=1}^c \sum_{k\in\mathbb{N}} \frac{1}{k!} C_{k}
\sum_{g\in\mathbb{N}_0} \frac{1}{g!}  \prod_{l=1}^g \sum_{b\in\mathbb{N}} \frac{1}{b!} \mathrm\Gamma_{b}\\
&=\sum_{c\in\mathbb{N}_0} \frac{1}{c!} \left( \sum_{k\in\mathbb{N}} \frac{1}{k!} C_{k}\right)^c
\sum_{g\in\mathbb{N}_0} \frac{1}{g!}  \left( \sum_{b\in\mathbb{N}} \frac{1}{b!} \mathrm\Gamma_{b}\right)^g\\
&=e^{\sum_{l\in\mathbb{N}} \frac{1}{l!} C_{l}} e^{\sum_{l\in\mathbb{N}} \frac{1}{l!} \mathrm\Gamma_{l}}.
\end{align}


\begin{Conj}
For \(A\) such that 
\begin{equation}
\|\id-U^A\|<1.
\end{equation}
The second quantized scattering operator fulfils
\begin{equation}\label{conj:sleek_second_quantised_scattering_operator}
S= e^{\sum_{n\in\mathbb{N}} \frac{C_n}{n!}} e^{\mathrm{d}\Gamma(\ln (U))}
\end{equation}
where \(C_n\) must be imaginary for any \(n\in\mathbb{N}\) in order to satisfy unitarity.

\end{Conj}
\textbf{Motivation:} 
First the remark about \(C_n \in i \mathbb{R}\) for any \(n\) is a direct consequence of 
the second factor of \eqref{conj:sleek_second_quantised_scattering_operator} begin unitary.
This in turn follows directly from \(\mathrm{d}\Gamma^* (K)=-\mathrm{d}\Gamma(K)\) for any \(K\) in the domain of \(\mathrm{d}\Gamma\).
That \(\ln U\) is in the domain of \(\mathrm{d}\Gamma\) follows from \( (\ln U)^*=\ln U^*=\ln U^{-1}=-\ln U\)
and \(\|U-\id\|<1\).

 We are going to change the sum in the second exponential of 
\eqref{Corollary double exp}, so let's take a closer look at that: by exchanging summation
we can step by step simplify

\begin{multline}
\sum_{l\in\mathbb{N}} \frac{\mathrm\Gamma_{l}}{l!}= 
\sum_{n \in\mathbb{N}} \frac{1}{n!} 
\mathrm{d}\Gamma\left( \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^{g+1}}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g Z_{b_l}  \right)\\
=\mathrm{d}\Gamma\left( \sum_{n \in\mathbb{N}} \frac{1}{n!} 
 \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^{g+1}}{g} 
\binom{n}{\vec{b}} \prod_{l=1}^g Z_{b_l}  \right)\\
=\mathrm{d}\Gamma\left( \sum_{n \in\mathbb{N}}
 \sum_{g=1}^n \sum_{\stackrel{\vec{b}\in\mathbb{N}^g}{|\vec{b}|=n}}\frac{(-1)^{g+1}}{g} 
 \prod_{l=1}^g \frac{Z_{b_l}}{b_l!}  \right)\\
=\mathrm{d}\Gamma\left( 
 \sum_{g\in\mathbb{N}} \sum_{\vec{b}\in\mathbb{N}^g}\frac{(-1)^{g+1}}{g} 
\prod_{l=1}^g \frac{Z_{b_l}}{b_l!}  \right)\\
=\mathrm{d}\Gamma\left( 
 \sum_{g\in\mathbb{N}} \frac{(-1)^{g+1}}{g} 
\prod_{l=1}^g \left(\sum_{b_l\in\mathbb{N}} \frac{Z_{b_l}}{b_l!} \right) \right)\\
=\mathrm{d}\Gamma\left( 
 \sum_{g\in\mathbb{N}} \frac{(-1)^{g+1}}{g} 
 \left(\sum_{b\in\mathbb{N}} \frac{Z_{b}}{b!} \right)^g \right)\\
 =\mathrm{d}\Gamma\left( 
 \sum_{g\in\mathbb{N}} \frac{(-1)^{g+1}}{g} 
 \left(U-\id \right)^g \right)
 =\mathrm{d}\Gamma\left( -
 \sum_{g\in\mathbb{N}} \frac{1}{g} 
 \left(\id-U \right)^g \right)\\
  =\mathrm{d}\Gamma\left( 
 \ln \left(\id-\left(\id-U\right) \right) \right)
 =\mathrm{d}\Gamma\left( \ln \left(U\right)\right).
\end{multline}



The last conjecture is proven directly in section \ref{sec:proof simple formula}



%\chapter{Bibliography concerning the state of the art, the research objectives, and the work program} 
%\vspace*{-0.68cm}

%\begingroup
%\renewcommand{\section}[2]{}
\bibliographystyle{amsplain}
\bibliography{ref}

%\bibliography{../../aarbeit/felix}
%\include{bib}
%\endgroup

\chapter{Cooperating Researchers} 
Prof. Dr. Franz Merkl (LMU)\\
Junior Research Group Leader Dr. Dirk Deckert (LMU)



\end{document}

